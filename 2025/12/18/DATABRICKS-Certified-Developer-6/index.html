<!DOCTYPE html><html lang="[&quot;en&quot;,&quot;ko&quot;,&quot;default&quot;]" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>DATABRICKS-Certified-Developer-6 | Danny's Blog</title><meta name="author" content="Danny Ki"><meta name="copyright" content="Danny Ki"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="DataFrame Schema 정의 방법 이해하기DataFrame은 각 컬럼의 이름(Name) 과 데이터 타입(Data Type) 을 정의하는Schema를 가지고 있습니다. DataFrame의 Schema를 확인하려면 printSchema 메서드를 사용합니다. 1customerDF.printSchema()  이 명령을 실행하면 DataFrame의 Schem">
<meta property="og:type" content="article">
<meta property="og:title" content="DATABRICKS-Certified-Developer-6">
<meta property="og:url" content="https://kish191919.github.io/2025/12/18/DATABRICKS-Certified-Developer-6/index.html">
<meta property="og:site_name" content="Danny&#39;s Blog">
<meta property="og:description" content="DataFrame Schema 정의 방법 이해하기DataFrame은 각 컬럼의 이름(Name) 과 데이터 타입(Data Type) 을 정의하는Schema를 가지고 있습니다. DataFrame의 Schema를 확인하려면 printSchema 메서드를 사용합니다. 1customerDF.printSchema()  이 명령을 실행하면 DataFrame의 Schem">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://kish191919.github.io/img/my_pic.jpeg">
<meta property="article:published_time" content="2025-12-18T15:48:12.000Z">
<meta property="article:modified_time" content="2025-12-18T16:10:23.876Z">
<meta property="article:author" content="Danny Ki">
<meta property="article:tag" content="DATABRICKS">
<meta property="article:tag" content="DATABRICKS_CERTIFIED_DEVELOPER">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://kish191919.github.io/img/my_pic.jpeg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "DATABRICKS-Certified-Developer-6",
  "url": "https://kish191919.github.io/2025/12/18/DATABRICKS-Certified-Developer-6/",
  "image": "https://kish191919.github.io/img/my_pic.jpeg",
  "datePublished": "2025-12-18T15:48:12.000Z",
  "dateModified": "2025-12-18T16:10:23.876Z",
  "author": [
    {
      "@type": "Person",
      "name": "Danny Ki",
      "url": "https://kish191919.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://kish191919.github.io/2025/12/18/DATABRICKS-Certified-Developer-6/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="UfZT9jGVnwcVj8z_sCj9LyqnWho6ubHg1Q7o_bvXfKs"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=GTM-N66KNRNW"></script><script>window.dataLayer = window.dataLayer || []
function gtag(){dataLayer.push(arguments)}
gtag('js', new Date())
gtag('config', 'GTM-N66KNRNW')
btf.addGlobalFn('pjaxComplete', () => {
  gtag('config', 'GTM-N66KNRNW', {'page_path': window.location.pathname})
}, 'google_analytics')
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'DATABRICKS-Certified-Developer-6',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/custom.css"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "WebSite",
  "url": "https://kish191919.github.io/",
  "name": "Danny's Blog",
  "inLanguage": "en"
}</script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="Danny's Blog" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/my_pic.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">117</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">37</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">13</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="/tech/"><i class="fa-fw fas fa-laptop-code"></i><span> Tech</span></a></div><div class="menus_item"><a class="site-page" href="/showcase/"><i class="fa-fw fas fa-star"></i><span> Showcase</span></a></div><div class="menus_item"><a class="site-page" href="/resume/"><i class="fa-fw fas fa-id-card"></i><span> Resume</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Danny's Blog</span></a><a class="nav-page-title" href="/"><span class="site-name">DATABRICKS-Certified-Developer-6</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="/tech/"><i class="fa-fw fas fa-laptop-code"></i><span> Tech</span></a></div><div class="menus_item"><a class="site-page" href="/showcase/"><i class="fa-fw fas fa-star"></i><span> Showcase</span></a></div><div class="menus_item"><a class="site-page" href="/resume/"><i class="fa-fw fas fa-id-card"></i><span> Resume</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">DATABRICKS-Certified-Developer-6</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-12-18T15:48:12.000Z" title="Created 2025-12-18 10:48:12">2025-12-18</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-12-18T16:10:23.876Z" title="Updated 2025-12-18 11:10:23">2025-12-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/CERTIFICATION/">CERTIFICATION</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/CERTIFICATION/DATABRICKS-CERTIFIED-DEVELOPER/">DATABRICKS_CERTIFIED_DEVELOPER</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="DataFrame-Schema-정의-방법-이해하기"><a href="#DataFrame-Schema-정의-방법-이해하기" class="headerlink" title="DataFrame Schema 정의 방법 이해하기"></a>DataFrame Schema 정의 방법 이해하기</h1><p>DataFrame은 각 컬럼의 <strong>이름(Name)</strong> 과 <strong>데이터 타입(Data Type)</strong> 을 정의하는<br><strong>Schema</strong>를 가지고 있습니다.</p>
<p>DataFrame의 Schema를 확인하려면 printSchema 메서드를 사용합니다.</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">customerDF.printSchema()</span><br></pre></td></tr></table></figure>

<p>이 명령을 실행하면 DataFrame의 Schema가<br>사람이 읽기 쉬운 형태로 출력됩니다.</p>
<hr>
<h2 id="1-왜-Schema를-직접-정의해야-할까"><a href="#1-왜-Schema를-직접-정의해야-할까" class="headerlink" title="1. 왜 Schema를 직접 정의해야 할까?"></a>1. 왜 Schema를 직접 정의해야 할까?</h2><p>예를 들어, 데이터 파일을 보면 address_id 컬럼의 값은 크지 않습니다.<br>하지만 Spark는 자동으로 이를 <strong>Long 타입</strong>으로 인식할 수 있습니다.</p>
<p>이 경우:</p>
<ul>
<li>Long 타입은 불필요하게 큰 타입이고</li>
<li>Integer 타입으로 충분한 상황입니다</li>
</ul>
<p>따라서 <strong>Schema를 직접 정의하여 데이터 타입을 정확히 지정</strong>하는 것이 좋습니다.</p>
<hr>
<h2 id="2-Schema를-정의하는-첫-번째-방법-DDL-문자열-방식"><a href="#2-Schema를-정의하는-첫-번째-방법-DDL-문자열-방식" class="headerlink" title="2. Schema를 정의하는 첫 번째 방법: DDL 문자열 방식"></a>2. Schema를 정의하는 첫 번째 방법: DDL 문자열 방식</h2><p>DataFrame Schema를 정의하는 첫 번째 방법은<br><strong>DDL(Data Definition Language) 형식의 문자열</strong>을 사용하는 것입니다.</p>
<p>DDL 문자열은:</p>
<ul>
<li>컬럼 이름</li>
<li>컬럼 데이터 타입</li>
</ul>
<p>을 문자열 형태로 나열한 것입니다.</p>
<hr>
<h3 id="DDL-Schema-정의-절차"><a href="#DDL-Schema-정의-절차" class="headerlink" title="DDL Schema 정의 절차"></a>DDL Schema 정의 절차</h3><ol>
<li><p>Schema 정보를 담을 변수를 생성합니다<br>변수 이름 예시: customerDFSchemaDDL</p>
</li>
<li><p>문자열 안에 각 컬럼의 이름과 데이터 타입을 순서대로 작성합니다</p>
</li>
</ol>
<p>예를 들어:</p>
<ul>
<li>address_id → Integer</li>
<li>birth_country → String</li>
<li>birth_date → Date</li>
</ul>
<hr>
<h3 id="데이터-타입-지정-시-주의-사항"><a href="#데이터-타입-지정-시-주의-사항" class="headerlink" title="데이터 타입 지정 시 주의 사항"></a>데이터 타입 지정 시 주의 사항</h3><p>예를 들어 birth_date 컬럼은:</p>
<ul>
<li>원본 JSON 파일에서는 문자열(String) 형태로 저장되어 있지만</li>
<li>실제 의미는 날짜(Date)입니다</li>
</ul>
<p>따라서 <strong>Schema를 수동으로 정의할 때는</strong><br>실제 의미에 맞는 데이터 타입(Date)을 지정해야 합니다.</p>
<hr>
<h3 id="DDL-Schema-적용"><a href="#DDL-Schema-적용" class="headerlink" title="DDL Schema 적용"></a>DDL Schema 적용</h3><p>DDL 문자열을 정의한 후에는<br>DataFrame을 생성할 때 schema 옵션으로 적용합니다.</p>
<p>이렇게 하면 Spark는:</p>
<ul>
<li>자동 추론이 아니라</li>
<li><strong>우리가 지정한 Schema를 그대로 사용</strong>합니다</li>
</ul>
<hr>
<h3 id="Schema-변경-결과-확인"><a href="#Schema-변경-결과-확인" class="headerlink" title="Schema 변경 결과 확인"></a>Schema 변경 결과 확인</h3><p>다시 customerDF.printSchema()를 실행하면:</p>
<ul>
<li>이전에는 address_id가 Long 타입</li>
<li>이제는 Integer 타입</li>
<li>birth_date는 String → Date</li>
</ul>
<p>로 변경된 것을 확인할 수 있습니다.</p>
<hr>
<h2 id="3-Schema를-정의하는-두-번째-방법-StructType-사용"><a href="#3-Schema를-정의하는-두-번째-방법-StructType-사용" class="headerlink" title="3. Schema를 정의하는 두 번째 방법: StructType 사용"></a>3. Schema를 정의하는 두 번째 방법: StructType 사용</h2><p>두 번째 방법은<br><strong>StructType과 StructField를 직접 사용하는 방식</strong>입니다.</p>
<hr>
<h3 id="기존-DataFrame의-Schema-확인"><a href="#기존-DataFrame의-Schema-확인" class="headerlink" title="기존 DataFrame의 Schema 확인"></a>기존 DataFrame의 Schema 확인</h3><p>DataFrame에는 schema라는 속성이 있습니다.</p>
<p>customerDF.schema</p>
<p>이 값을 출력해 보면:</p>
<ul>
<li>문자열이 아니라</li>
<li>Apache Spark의 StructType 객체 형태로 Schema가 반환됩니다</li>
</ul>
<p>StructType은:</p>
<ul>
<li>여러 개의 StructField로 구성되고</li>
<li>각 StructField는 다음 정보를 포함합니다<ul>
<li>컬럼 이름</li>
<li>데이터 타입</li>
<li>nullable 여부</li>
</ul>
</li>
</ul>
<p>nullable 플래그는:</p>
<ul>
<li>Spark 내부 최적화를 위한 힌트일 뿐이며</li>
<li>false라고 해서 null 값이 실제로 없는 것은 아닙니다</li>
</ul>
<hr>
<h3 id="StructType-Schema-직접-정의하기"><a href="#StructType-Schema-직접-정의하기" class="headerlink" title="StructType Schema 직접 정의하기"></a>StructType Schema 직접 정의하기</h3><p>StructType은:</p>
<ul>
<li>StructField들의 컬렉션이며</li>
<li>복합 타입(Struct 안에 Struct, Array 등)도 표현할 수 있습니다</li>
</ul>
<p>demographics 컬럼은:</p>
<ul>
<li>StructType 안에</li>
<li>Array 타입 필드를 포함하는</li>
<li>복합 컬럼의 예시입니다</li>
</ul>
<hr>
<h3 id="필요한-패키지-Import"><a href="#필요한-패키지-Import" class="headerlink" title="필요한 패키지 Import"></a>필요한 패키지 Import</h3><p>StructType을 사용하려면 다음 패키지를 import 해야 합니다.</p>
<p>import org.apache.spark.sql.types._</p>
<hr>
<h3 id="StructType-Schema-적용"><a href="#StructType-Schema-적용" class="headerlink" title="StructType Schema 적용"></a>StructType Schema 적용</h3><p>StructType Schema 역시<br>DataFrameReader의 schema 메서드에 그대로 전달할 수 있습니다.</p>
<p>DDL 문자열과 StructType은<br><strong>동일한 결과</strong>를 만들어 냅니다.</p>
<hr>
<h2 id="4-Schema를-정의하는-세-번째-방법-Infer-Schema"><a href="#4-Schema를-정의하는-세-번째-방법-Infer-Schema" class="headerlink" title="4. Schema를 정의하는 세 번째 방법: Infer Schema"></a>4. Schema를 정의하는 세 번째 방법: Infer Schema</h2><p>세 번째 방법은<br><strong>Apache Spark에게 Schema 추론을 맡기는 방식</strong>입니다.</p>
<p>이를 위해 DataFrameReader에 옵션을 추가합니다.</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">option(<span class="string">&quot;inferSchema&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>Spark는:</p>
<ul>
<li>일부 데이터를 먼저 읽고</li>
<li>데이터 타입을 추론한 뒤</li>
<li>전체 데이터를 다시 읽습니다</li>
</ul>
<hr>
<h3 id="Infer-Schema의-단점"><a href="#Infer-Schema의-단점" class="headerlink" title="Infer Schema의 단점"></a>Infer Schema의 단점</h3><p>Infer Schema 방식은:</p>
<ul>
<li>데이터를 두 번 읽기 때문에 성능 비용이 발생하고</li>
<li>Integer와 Long을 정확히 구분하지 못할 수 있습니다</li>
</ul>
<p>따라서 <strong>운영 환경에서는 Schema를 직접 정의하는 것이 권장</strong>됩니다.</p>
<hr>
<h2 id="5-Apache-Spark-문서-활용-방법-시험-대비-핵심"><a href="#5-Apache-Spark-문서-활용-방법-시험-대비-핵심" class="headerlink" title="5. Apache Spark 문서 활용 방법 (시험 대비 핵심)"></a>5. Apache Spark 문서 활용 방법 (시험 대비 핵심)</h2><p>시험 준비 시 매우 중요한 역량은<br><strong>Apache Spark 공식 문서를 빠르게 찾고 읽는 능력</strong>입니다.</p>
<hr>
<h3 id="DataFrameReader-문서-확인"><a href="#DataFrameReader-문서-확인" class="headerlink" title="DataFrameReader 문서 확인"></a>DataFrameReader 문서 확인</h3><p>Apache Spark 공식 문서에서:</p>
<ul>
<li>최신 버전 선택</li>
<li>Scala API 문서 선택</li>
<li>DataFrameReader 검색</li>
</ul>
<p>이를 통해 다음을 확인할 수 있습니다.</p>
<ul>
<li>format 메서드의 정확한 시그니처</li>
<li>json 메서드 사용법</li>
<li>option, load 등 모든 사용 가능한 API</li>
</ul>
<hr>
<h3 id="문서-활용의-중요성"><a href="#문서-활용의-중요성" class="headerlink" title="문서 활용의 중요성"></a>문서 활용의 중요성</h3><p>시험 문제 예시:</p>
<ul>
<li>format 메서드는 몇 개의 인자를 받는가?</li>
<li>inferSchema 옵션은 어떻게 사용하는가?</li>
</ul>
<p>이런 문제는:</p>
<ul>
<li>문서를 읽을 수 있다면</li>
<li>바로 답을 찾을 수 있습니다</li>
</ul>
<hr>
<h2 id="6-정리"><a href="#6-정리" class="headerlink" title="6. 정리"></a>6. 정리</h2><p>이번 강의에서 배운 내용:</p>
<ul>
<li>DataFrame Schema 확인 방법</li>
<li>Schema 정의 3가지 방법<ul>
<li>DDL 문자열</li>
<li>StructType</li>
<li>Infer Schema</li>
</ul>
</li>
<li>운영 환경에서는 Schema 수동 정의 권장</li>
<li>Apache Spark 문서 활용 방법</li>
</ul>
<p>다음 강의에서는:</p>
<ul>
<li>DataFrameReader의 다양한 옵션</li>
<li>JSON 외 다른 데이터 소스 읽기</li>
</ul>
<p>를 살펴보겠습니다.</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://kish191919.github.io">Danny Ki</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://kish191919.github.io/2025/12/18/DATABRICKS-Certified-Developer-6/">https://kish191919.github.io/2025/12/18/DATABRICKS-Certified-Developer-6/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/DATABRICKS/">DATABRICKS</a><a class="post-meta__tags" href="/tags/DATABRICKS-CERTIFIED-DEVELOPER/">DATABRICKS_CERTIFIED_DEVELOPER</a></div><div class="post-share"><div class="social-share" data-image="/img/my_pic.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related full-width" href="/2025/12/18/DATABRICKS-Certified-Developer-5/" title="DATABRICKS-Certified-Developer-5"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">DATABRICKS-Certified-Developer-5</div></div><div class="info-2"><div class="info-item-1">Spark DataFrame 기초 실습 시작하기1. 실습 시작 전 확인 사항 (매우 중요)본격적으로 실습을 시작하기 전에, 두 가지를 반드시 확인해야 합니다. ✅ 1) 데이터셋이 정상적으로 설치되었는지 확인Databricks 환경의 왼쪽 메뉴에서 다음 순서로 이동합니다.  Data 클릭 Add Data DBFS (Databricks File System) FileStore Tables 이전 강의에서 생성한 데이터 폴더  이 경로에서:  이전 강의에서 업로드한 모든 데이터 파일이 보인다면👉 데이터셋은 정상적으로 설치된 것입니다.   ✅ 2) 클러스터가 실행 중인지 확인Apache Spark는 클러스터 없이는 아무 작업도 할 수 없습니다. Community Edition에서는:  동시에 하나의 클러스터만 실행 가능합니다.  클러스터가 없다면:  Create Cluster 클릭 클러스터 이름 입력 Create Cluster 클릭  자세한 클러스터 생성 방법은👉 이전 강의 영상을 ...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/12/18/DATABRICKS-Certified-Developer-1/" title="DATABRICKS-Certified-Developer-1"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-18</div><div class="info-item-2">DATABRICKS-Certified-Developer-1</div></div><div class="info-2"><div class="info-item-1">Apache Spark Cluster Architecture – Easy Explanation1. Computing on a Single Computer먼저, 하나의 컴퓨터에서 컴퓨팅이 어떻게 이루어지는지 살펴보겠습니다. 하나의 컴퓨터에는 다음과 같은 컴퓨팅 자원이 있습니다.  CPU: 연산을 수행 Memory (RAM): 실행 중인 데이터 저장 GPU: 대규모 병렬 연산 (필요한 경우)  이 모든 자원은 운영체제(OS) 가 관리합니다. Operating System의 역할운영체제는 여러 애플리케이션이 동시에 실행될 때:  CPU와 메모리를 어떻게 나눠 쓸지 결정하고 각 애플리케이션의 자원 사용을 스케줄링합니다  덕분에 여러 프로그램이 동시에 실행되어도 시스템이 안정적으로 동작합니다.  2. Why Single Computer Is Not Enough for Big Data빅데이터를 처리하려면 다음과 같은 문제가 발생합니다.  데이터 크기가 너무 큼 연산량이 많음 처리 시간이 ...</div></div></div></a><a class="pagination-related" href="/2025/12/18/DATABRICKS-Certified-Developer-2/" title="DATABRICKS-Certified-Developer-2"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-18</div><div class="info-item-2">DATABRICKS-Certified-Developer-2</div></div><div class="info-2"><div class="info-item-1">Azure Databricks에서 Apache Spark 클러스터 생성하기1. 이 강의에서 배울 내용이 영상에서는 Apache Spark를 실행하기 위한 Databricks 클러스터를 생성하는 방법을 살펴보겠습니다.구체적으로는 다음 내용을 다룹니다.  Azure Databricks 워크스페이스 생성 Databricks 환경 실행 Spark 클러스터 생성 클러스터 주요 설정 옵션 이해 클러스터 상태 및 Spark UI 확인  Spark는 클러스터 없이 실행될 수 없기 때문에,이 단계는 이후 모든 실습의 기초가 되는 매우 중요한 과정입니다.  2. Azure Databricks 워크스페이스 생성먼저 Azure Portal에서 시작합니다. 이미 Azure 계정이 있다면:  Azure Portal에 로그인 상단 검색창에서 Databricks 검색 Azure Databricks 선택  만약 바로 보이지 않으면 검색창에Databricks 라고 입력하면 쉽게 찾을 수 있습니다. Azure ...</div></div></div></a><a class="pagination-related" href="/2025/12/18/DATABRICKS-Certified-Developer-3/" title="DATABRICKS-Certified-Developer-3"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-18</div><div class="info-item-2">DATABRICKS-Certified-Developer-3</div></div><div class="info-2"><div class="info-item-1">Databricks Community Edition 계정 생성 및 클러스터 만들기1. 이 강의에서 필요한 준비 사항이 강의에 포함된 모든 예제를 따라 하기 위해서는Databricks Community Edition 계정이 필요합니다. Databricks Community Edition은:  무료로 제공되는 Databricks 계정이며 Apache Spark를 학습하기에 충분한 환경을 제공합니다  실무에서 사용하는 대규모 클러스터는 아니지만,Spark의 핵심 개념과 동작 방식을 이해하기에는 충분합니다.  2. Databricks Community Edition 회원 가입먼저 웹 브라우저를 열고 다음 사이트로 이동합니다. 👉 https://databricks.com 메인 페이지에서:  Try Databricks 버튼을 클릭합니다  그러면 회원 가입(Sign Up) 페이지가 나타납니다.  회원 가입 정보 입력다음과 같은 기본 정보를 입력합니다.  Company Name (회사명) ...</div></div></div></a><a class="pagination-related" href="/2025/12/18/DATABRICKS-Certified-Developer-4/" title="DATABRICKS-Certified-Developer-4"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-18</div><div class="info-item-2">DATABRICKS-Certified-Developer-4</div></div><div class="info-2"><div class="info-item-1">실습 데이터셋 및 Databricks 노트북 설치하기1. 이 강의에서 할 일이 강의에서는 앞으로의 모든 실습을 위해 필요한:  📁 데이터셋(Data files) 📓 Databricks 노트북(Notebooks)  을 Databricks 환경에 설치합니다. 이 과정이 제대로 되지 않으면👉 이후 강의에서 제공하는 소스 코드가 정상적으로 실행되지 않기 때문에반드시 차근차근 따라와 주세요.  2. 강의 자료 다운로드 (Zip 파일)먼저 이 강의의 Resources(자료) 섹션으로 이동합니다. 여기에서 두 개의 zip 파일을 다운로드합니다.  📓 Notebooks zip 파일 강의에서 사용할 Databricks 노트북들   📁 Dataset zip 파일 실습에 사용할 데이터 파일들 (JSON, CSV 등)    두 파일 모두 로컬 PC에 다운로드 후 압축을 해제해 주세요.  3. Databricks에 데이터셋 업로드하기이제 Databricks 환경으로 돌아가서먼저 데이터 파일을...</div></div></div></a><a class="pagination-related" href="/2025/12/18/DATABRICKS-Certified-Developer-5/" title="DATABRICKS-Certified-Developer-5"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-18</div><div class="info-item-2">DATABRICKS-Certified-Developer-5</div></div><div class="info-2"><div class="info-item-1">Spark DataFrame 기초 실습 시작하기1. 실습 시작 전 확인 사항 (매우 중요)본격적으로 실습을 시작하기 전에, 두 가지를 반드시 확인해야 합니다. ✅ 1) 데이터셋이 정상적으로 설치되었는지 확인Databricks 환경의 왼쪽 메뉴에서 다음 순서로 이동합니다.  Data 클릭 Add Data DBFS (Databricks File System) FileStore Tables 이전 강의에서 생성한 데이터 폴더  이 경로에서:  이전 강의에서 업로드한 모든 데이터 파일이 보인다면👉 데이터셋은 정상적으로 설치된 것입니다.   ✅ 2) 클러스터가 실행 중인지 확인Apache Spark는 클러스터 없이는 아무 작업도 할 수 없습니다. Community Edition에서는:  동시에 하나의 클러스터만 실행 가능합니다.  클러스터가 없다면:  Create Cluster 클릭 클러스터 이름 입력 Create Cluster 클릭  자세한 클러스터 생성 방법은👉 이전 강의 영상을 ...</div></div></div></a><a class="pagination-related" href="/2025/12/12/DATABRICKS-Fundamentals-1/" title="DATABRICKS-Fundamentals-1"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-12</div><div class="info-item-2">DATABRICKS-Fundamentals-1</div></div><div class="info-2"><div class="info-item-1">1. Apache Spark란?Apache Spark는👉 분산 클러스터 환경에서 대규모 데이터를 빠르게 처리하기 위한 데이터 처리 엔진(Engine) 입니다. Spark는 다음 작업을 하나의 통합된 프레임워크에서 처리할 수 있습니다.  배치 데이터 처리 (Batch Processing) 스트리밍 데이터 처리 (Stream Processing) 머신러닝 (Machine Learning) 그래프 처리 (Graph Processing) SQL 기반 데이터 분석  📌 시험 포인트  Spark는 데이터베이스가 아니다 Spark는 스토리지 시스템이 아니다 Spark는 데이터 처리 엔진(Processing Engine) 이다   2. Spark가 제공하는 주요 API (Unified Framework)Spark는 하나의 엔진 위에서 여러 API를 제공합니다. (1) Spark SQL &amp; DataFrame API SQL 기반 데이터 처리 ANSI SQL 호환 가장 많이 사용됨 ⭐⭐...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/my_pic.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Danny Ki</div><div class="author-info-description">A data engineer's journey in coding, analytics, and building real-world systems.</div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">117</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">37</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">13</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/kish191919"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/kish191919" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#DataFrame-Schema-%EC%A0%95%EC%9D%98-%EB%B0%A9%EB%B2%95-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0"><span class="toc-number">1.</span> <span class="toc-text">DataFrame Schema 정의 방법 이해하기</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%EC%99%9C-Schema%EB%A5%BC-%EC%A7%81%EC%A0%91-%EC%A0%95%EC%9D%98%ED%95%B4%EC%95%BC-%ED%95%A0%EA%B9%8C"><span class="toc-number">1.1.</span> <span class="toc-text">1. 왜 Schema를 직접 정의해야 할까?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Schema%EB%A5%BC-%EC%A0%95%EC%9D%98%ED%95%98%EB%8A%94-%EC%B2%AB-%EB%B2%88%EC%A7%B8-%EB%B0%A9%EB%B2%95-DDL-%EB%AC%B8%EC%9E%90%EC%97%B4-%EB%B0%A9%EC%8B%9D"><span class="toc-number">1.2.</span> <span class="toc-text">2. Schema를 정의하는 첫 번째 방법: DDL 문자열 방식</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#DDL-Schema-%EC%A0%95%EC%9D%98-%EC%A0%88%EC%B0%A8"><span class="toc-number">1.2.1.</span> <span class="toc-text">DDL Schema 정의 절차</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%83%80%EC%9E%85-%EC%A7%80%EC%A0%95-%EC%8B%9C-%EC%A3%BC%EC%9D%98-%EC%82%AC%ED%95%AD"><span class="toc-number">1.2.2.</span> <span class="toc-text">데이터 타입 지정 시 주의 사항</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DDL-Schema-%EC%A0%81%EC%9A%A9"><span class="toc-number">1.2.3.</span> <span class="toc-text">DDL Schema 적용</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Schema-%EB%B3%80%EA%B2%BD-%EA%B2%B0%EA%B3%BC-%ED%99%95%EC%9D%B8"><span class="toc-number">1.2.4.</span> <span class="toc-text">Schema 변경 결과 확인</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Schema%EB%A5%BC-%EC%A0%95%EC%9D%98%ED%95%98%EB%8A%94-%EB%91%90-%EB%B2%88%EC%A7%B8-%EB%B0%A9%EB%B2%95-StructType-%EC%82%AC%EC%9A%A9"><span class="toc-number">1.3.</span> <span class="toc-text">3. Schema를 정의하는 두 번째 방법: StructType 사용</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%EA%B8%B0%EC%A1%B4-DataFrame%EC%9D%98-Schema-%ED%99%95%EC%9D%B8"><span class="toc-number">1.3.1.</span> <span class="toc-text">기존 DataFrame의 Schema 확인</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#StructType-Schema-%EC%A7%81%EC%A0%91-%EC%A0%95%EC%9D%98%ED%95%98%EA%B8%B0"><span class="toc-number">1.3.2.</span> <span class="toc-text">StructType Schema 직접 정의하기</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%ED%95%84%EC%9A%94%ED%95%9C-%ED%8C%A8%ED%82%A4%EC%A7%80-Import"><span class="toc-number">1.3.3.</span> <span class="toc-text">필요한 패키지 Import</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#StructType-Schema-%EC%A0%81%EC%9A%A9"><span class="toc-number">1.3.4.</span> <span class="toc-text">StructType Schema 적용</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Schema%EB%A5%BC-%EC%A0%95%EC%9D%98%ED%95%98%EB%8A%94-%EC%84%B8-%EB%B2%88%EC%A7%B8-%EB%B0%A9%EB%B2%95-Infer-Schema"><span class="toc-number">1.4.</span> <span class="toc-text">4. Schema를 정의하는 세 번째 방법: Infer Schema</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Infer-Schema%EC%9D%98-%EB%8B%A8%EC%A0%90"><span class="toc-number">1.4.1.</span> <span class="toc-text">Infer Schema의 단점</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Apache-Spark-%EB%AC%B8%EC%84%9C-%ED%99%9C%EC%9A%A9-%EB%B0%A9%EB%B2%95-%EC%8B%9C%ED%97%98-%EB%8C%80%EB%B9%84-%ED%95%B5%EC%8B%AC"><span class="toc-number">1.5.</span> <span class="toc-text">5. Apache Spark 문서 활용 방법 (시험 대비 핵심)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#DataFrameReader-%EB%AC%B8%EC%84%9C-%ED%99%95%EC%9D%B8"><span class="toc-number">1.5.1.</span> <span class="toc-text">DataFrameReader 문서 확인</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EB%AC%B8%EC%84%9C-%ED%99%9C%EC%9A%A9%EC%9D%98-%EC%A4%91%EC%9A%94%EC%84%B1"><span class="toc-number">1.5.2.</span> <span class="toc-text">문서 활용의 중요성</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%EC%A0%95%EB%A6%AC"><span class="toc-number">1.6.</span> <span class="toc-text">6. 정리</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/18/DATABRICKS-Certified-Developer-6/" title="DATABRICKS-Certified-Developer-6">DATABRICKS-Certified-Developer-6</a><time datetime="2025-12-18T15:48:12.000Z" title="Created 2025-12-18 10:48:12">2025-12-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/18/DATABRICKS-Certified-Developer-5/" title="DATABRICKS-Certified-Developer-5">DATABRICKS-Certified-Developer-5</a><time datetime="2025-12-18T15:38:46.000Z" title="Created 2025-12-18 10:38:46">2025-12-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/18/DATABRICKS-Certified-Developer-4/" title="DATABRICKS-Certified-Developer-4">DATABRICKS-Certified-Developer-4</a><time datetime="2025-12-18T15:32:28.000Z" title="Created 2025-12-18 10:32:28">2025-12-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/18/DATABRICKS-Certified-Developer-3/" title="DATABRICKS-Certified-Developer-3">DATABRICKS-Certified-Developer-3</a><time datetime="2025-12-18T15:27:05.000Z" title="Created 2025-12-18 10:27:05">2025-12-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/18/DATABRICKS-Certified-Developer-2/" title="DATABRICKS-Certified-Developer-2">DATABRICKS-Certified-Developer-2</a><time datetime="2025-12-18T15:13:19.000Z" title="Created 2025-12-18 10:13:19">2025-12-18</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 By Danny Ki</span><span class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.3</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>