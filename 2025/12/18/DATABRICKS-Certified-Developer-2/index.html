<!DOCTYPE html><html lang="[&quot;en&quot;,&quot;ko&quot;,&quot;default&quot;]" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>DATABRICKS-Certified-Developer-2 | Danny's Blog</title><meta name="author" content="Danny Ki"><meta name="copyright" content="Danny Ki"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Azure Databricks에서 Apache Spark 클러스터 생성하기1. 이 강의에서 배울 내용이 영상에서는 Apache Spark를 실행하기 위한 Databricks 클러스터를 생성하는 방법을 살펴보겠습니다.구체적으로는 다음 내용을 다룹니다.  Azure Databricks 워크스페이스 생성 Databricks 환경 실행 Spark 클러스터 생성 클">
<meta property="og:type" content="article">
<meta property="og:title" content="DATABRICKS-Certified-Developer-2">
<meta property="og:url" content="https://kish191919.github.io/2025/12/18/DATABRICKS-Certified-Developer-2/index.html">
<meta property="og:site_name" content="Danny&#39;s Blog">
<meta property="og:description" content="Azure Databricks에서 Apache Spark 클러스터 생성하기1. 이 강의에서 배울 내용이 영상에서는 Apache Spark를 실행하기 위한 Databricks 클러스터를 생성하는 방법을 살펴보겠습니다.구체적으로는 다음 내용을 다룹니다.  Azure Databricks 워크스페이스 생성 Databricks 환경 실행 Spark 클러스터 생성 클">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://kish191919.github.io/img/my_pic.jpeg">
<meta property="article:published_time" content="2025-12-18T15:13:19.000Z">
<meta property="article:modified_time" content="2025-12-18T15:22:08.584Z">
<meta property="article:author" content="Danny Ki">
<meta property="article:tag" content="DATABRICKS">
<meta property="article:tag" content="DATABRICKS_CERTIFIED_DEVELOPER">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://kish191919.github.io/img/my_pic.jpeg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "DATABRICKS-Certified-Developer-2",
  "url": "https://kish191919.github.io/2025/12/18/DATABRICKS-Certified-Developer-2/",
  "image": "https://kish191919.github.io/img/my_pic.jpeg",
  "datePublished": "2025-12-18T15:13:19.000Z",
  "dateModified": "2025-12-18T15:22:08.584Z",
  "author": [
    {
      "@type": "Person",
      "name": "Danny Ki",
      "url": "https://kish191919.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://kish191919.github.io/2025/12/18/DATABRICKS-Certified-Developer-2/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="UfZT9jGVnwcVj8z_sCj9LyqnWho6ubHg1Q7o_bvXfKs"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=GTM-N66KNRNW"></script><script>window.dataLayer = window.dataLayer || []
function gtag(){dataLayer.push(arguments)}
gtag('js', new Date())
gtag('config', 'GTM-N66KNRNW')
btf.addGlobalFn('pjaxComplete', () => {
  gtag('config', 'GTM-N66KNRNW', {'page_path': window.location.pathname})
}, 'google_analytics')
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'DATABRICKS-Certified-Developer-2',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/custom.css"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "WebSite",
  "url": "https://kish191919.github.io/",
  "name": "Danny's Blog",
  "inLanguage": "en"
}</script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="Danny's Blog" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/my_pic.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">117</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">37</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">13</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="/tech/"><i class="fa-fw fas fa-laptop-code"></i><span> Tech</span></a></div><div class="menus_item"><a class="site-page" href="/showcase/"><i class="fa-fw fas fa-star"></i><span> Showcase</span></a></div><div class="menus_item"><a class="site-page" href="/resume/"><i class="fa-fw fas fa-id-card"></i><span> Resume</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Danny's Blog</span></a><a class="nav-page-title" href="/"><span class="site-name">DATABRICKS-Certified-Developer-2</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="/tech/"><i class="fa-fw fas fa-laptop-code"></i><span> Tech</span></a></div><div class="menus_item"><a class="site-page" href="/showcase/"><i class="fa-fw fas fa-star"></i><span> Showcase</span></a></div><div class="menus_item"><a class="site-page" href="/resume/"><i class="fa-fw fas fa-id-card"></i><span> Resume</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">DATABRICKS-Certified-Developer-2</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-12-18T15:13:19.000Z" title="Created 2025-12-18 10:13:19">2025-12-18</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-12-18T15:22:08.584Z" title="Updated 2025-12-18 10:22:08">2025-12-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/CERTIFICATION/">CERTIFICATION</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/CERTIFICATION/DATABRICKS-CERTIFIED-DEVELOPER/">DATABRICKS_CERTIFIED_DEVELOPER</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="Azure-Databricks에서-Apache-Spark-클러스터-생성하기"><a href="#Azure-Databricks에서-Apache-Spark-클러스터-생성하기" class="headerlink" title="Azure Databricks에서 Apache Spark 클러스터 생성하기"></a>Azure Databricks에서 Apache Spark 클러스터 생성하기</h1><h2 id="1-이-강의에서-배울-내용"><a href="#1-이-강의에서-배울-내용" class="headerlink" title="1. 이 강의에서 배울 내용"></a>1. 이 강의에서 배울 내용</h2><p>이 영상에서는 <strong>Apache Spark를 실행하기 위한 Databricks 클러스터를 생성하는 방법</strong>을 살펴보겠습니다.<br>구체적으로는 다음 내용을 다룹니다.</p>
<ul>
<li>Azure Databricks 워크스페이스 생성</li>
<li>Databricks 환경 실행</li>
<li>Spark 클러스터 생성</li>
<li>클러스터 주요 설정 옵션 이해</li>
<li>클러스터 상태 및 Spark UI 확인</li>
</ul>
<p>Spark는 <strong>클러스터 없이 실행될 수 없기 때문에</strong>,<br>이 단계는 이후 모든 실습의 기초가 되는 매우 중요한 과정입니다.</p>
<hr>
<h2 id="2-Azure-Databricks-워크스페이스-생성"><a href="#2-Azure-Databricks-워크스페이스-생성" class="headerlink" title="2. Azure Databricks 워크스페이스 생성"></a>2. Azure Databricks 워크스페이스 생성</h2><p>먼저 <strong>Azure Portal</strong>에서 시작합니다.</p>
<p>이미 Azure 계정이 있다면:</p>
<ul>
<li>Azure Portal에 로그인</li>
<li>상단 검색창에서 <strong>Databricks</strong> 검색</li>
<li><strong>Azure Databricks</strong> 선택</li>
</ul>
<p>만약 바로 보이지 않으면 검색창에<br><code>Databricks</code> 라고 입력하면 쉽게 찾을 수 있습니다.</p>
<p>Azure Databricks를 선택한 후 <strong>Add(추가)</strong> 또는 <strong>Create(생성)</strong> 를 클릭합니다.</p>
<hr>
<h3 id="필수-설정-항목"><a href="#필수-설정-항목" class="headerlink" title="필수 설정 항목"></a>필수 설정 항목</h3><p>이제 몇 가지 필수 정보를 입력해야 합니다.</p>
<h4 id="1-Resource-Group"><a href="#1-Resource-Group" class="headerlink" title="1) Resource Group"></a>1) Resource Group</h4><ul>
<li>새로운 Resource Group 생성</li>
<li>예시 이름:<ul>
<li><code>spark-certification-resources</code></li>
</ul>
</li>
</ul>
<p>Resource Group은 관련된 Azure 리소스들을<br><strong>하나의 묶음으로 관리하기 위한 컨테이너</strong>라고 생각하시면 됩니다.</p>
<hr>
<h4 id="2-Workspace-Name"><a href="#2-Workspace-Name" class="headerlink" title="2) Workspace Name"></a>2) Workspace Name</h4><ul>
<li>Databricks 워크스페이스 이름 지정</li>
<li>예시:<ul>
<li><code>spark-certification-training</code></li>
</ul>
</li>
</ul>
<p>이 이름은 Databricks 환경의 식별자 역할을 합니다.</p>
<hr>
<h4 id="3-Location"><a href="#3-Location" class="headerlink" title="3) Location"></a>3) Location</h4><ul>
<li>Databricks를 생성할 리전 선택</li>
<li>예시:<ul>
<li><code>US EAST</code></li>
</ul>
</li>
</ul>
<p>일반적으로는 <strong>본인과 가까운 지역</strong>을 선택하는 것이 좋습니다.</p>
<hr>
<h3 id="선택-Tags-설정"><a href="#선택-Tags-설정" class="headerlink" title="(선택) Tags 설정"></a>(선택) Tags 설정</h3><p>Tags는 필수는 아니지만 <strong>실무에서는 매우 유용</strong>합니다.</p>
<p>예시:</p>
<ul>
<li>Key: <code>purpose</code></li>
<li>Value: <code>spark-certification</code></li>
</ul>
<p>Tags를 사용하면:</p>
<ul>
<li>리소스 목적 구분</li>
<li>비용 추적</li>
<li>리소스 관리</li>
</ul>
<p>에 도움이 됩니다.</p>
<hr>
<h3 id="Review-Create"><a href="#Review-Create" class="headerlink" title="Review &amp; Create"></a>Review &amp; Create</h3><ul>
<li><strong>Review + Create</strong> 클릭</li>
<li>설정을 확인한 뒤 <strong>Create</strong> 클릭</li>
</ul>
<p>Databricks 워크스페이스 생성에는<br>보통 몇 분 정도가 소요됩니다.</p>
<p>이 시점에서는 영상을 잠시 멈추고,<br>배포가 완료될 때까지 기다립니다.</p>
<hr>
<h2 id="3-Databricks-워크스페이스-실행"><a href="#3-Databricks-워크스페이스-실행" class="headerlink" title="3. Databricks 워크스페이스 실행"></a>3. Databricks 워크스페이스 실행</h2><p>배포가 완료되면:</p>
<ul>
<li><strong>Go to resource</strong> 클릭</li>
<li>또는 Azure 홈 화면에서 해당 리소스로 이동</li>
</ul>
<p>리소스 화면에서 <strong>Launch Workspace</strong> 를 클릭합니다.</p>
<p>이제 브라우저에서 <strong>Azure Databricks 환경</strong>이 열립니다.</p>
<hr>
<h2 id="4-Databricks-클러스터-생성"><a href="#4-Databricks-클러스터-생성" class="headerlink" title="4. Databricks 클러스터 생성"></a>4. Databricks 클러스터 생성</h2><p>Databricks 환경에 접속한 후:</p>
<ul>
<li>왼쪽 메뉴에서 <strong>Clusters</strong> 클릭</li>
<li><strong>Create Cluster</strong> 클릭</li>
</ul>
<p>이제 Spark가 실행될 <strong>클러스터 설정 단계</strong>로 들어갑니다.</p>
<hr>
<h3 id="클러스터-이름"><a href="#클러스터-이름" class="headerlink" title="클러스터 이름"></a>클러스터 이름</h3><p>클러스터를 구분할 수 있도록 이름을 지정합니다.</p>
<p>예시:</p>
<ul>
<li><code>spark-training-cluster</code></li>
</ul>
<hr>
<h3 id="Cluster-Mode"><a href="#Cluster-Mode" class="headerlink" title="Cluster Mode"></a>Cluster Mode</h3><p>두 가지 모드가 있습니다.</p>
<ul>
<li><strong>Standard</strong></li>
<li><strong>High Concurrency</strong></li>
</ul>
<p>이 강의에서는:</p>
<ul>
<li>✅ <strong>Standard 모드</strong>를 사용합니다.</li>
</ul>
<p>High Concurrency 모드는<br>여러 사용자가 동시에 하나의 클러스터를 사용할 때 주로 사용됩니다.</p>
<hr>
<h2 id="5-Databricks-Runtime-Version"><a href="#5-Databricks-Runtime-Version" class="headerlink" title="5. Databricks Runtime Version"></a>5. Databricks Runtime Version</h2><p>다음은 <strong>Databricks Runtime Version</strong> 선택입니다.</p>
<p>Databricks Runtime은 다음을 포함한 <strong>통합 실행 환경</strong>입니다.</p>
<ul>
<li>Apache Spark</li>
<li>Scala</li>
<li>Python</li>
<li>다양한 최적화 라이브러리</li>
</ul>
<p>이 강의에서는:</p>
<ul>
<li><strong>Spark 3.x Runtime</strong>을 사용합니다.</li>
</ul>
<p>처음에는 기본값을 사용해도 전혀 문제 없습니다.</p>
<hr>
<h2 id="6-Driver와-Worker-설정-중요"><a href="#6-Driver와-Worker-설정-중요" class="headerlink" title="6. Driver와 Worker 설정 (중요)"></a>6. Driver와 Worker 설정 (중요)</h2><p>이제 클러스터의 <strong>하드웨어 사양</strong>을 설정합니다.</p>
<h3 id="Worker-Type"><a href="#Worker-Type" class="headerlink" title="Worker Type"></a>Worker Type</h3><p>Worker 노드는 <strong>Spark Executor가 실행되는 머신</strong>입니다.</p>
<p>예시:</p>
<ul>
<li>Memory: 14GB</li>
<li>CPU: 4 cores</li>
</ul>
<p>드롭다운을 열면:</p>
<ul>
<li>다양한 VM 타입</li>
<li>메모리&#x2F;CPU 조합</li>
<li>비용 차이</li>
</ul>
<p>를 확인할 수 있습니다.</p>
<p>지금은 기본 설정을 그대로 사용하겠습니다.</p>
<hr>
<h3 id="Driver-Type"><a href="#Driver-Type" class="headerlink" title="Driver Type"></a>Driver Type</h3><p>Driver 노드는 <strong>Spark Driver 프로세스</strong>가 실행되는 머신입니다.</p>
<ul>
<li>Worker와 동일한 사양을 사용할 수도 있고</li>
<li>Driver에 더 많은 메모리를 줄 수도 있습니다</li>
</ul>
<p>예를 들어:</p>
<ul>
<li>Driver를 Worker보다 <strong>메모리 2배</strong>로 설정</li>
</ul>
<p>Driver는 전체 작업을 조율하기 때문에<br>대규모 작업에서는 더 많은 리소스를 주는 것이 일반적입니다.</p>
<hr>
<h2 id="7-Worker-개수와-Auto-Scaling"><a href="#7-Worker-개수와-Auto-Scaling" class="headerlink" title="7. Worker 개수와 Auto Scaling"></a>7. Worker 개수와 Auto Scaling</h2><p>여기서 다음을 설정할 수 있습니다.</p>
<ul>
<li>최소 Worker 수</li>
<li>최대 Worker 수</li>
</ul>
<p>예시:</p>
<ul>
<li>최소: 2</li>
<li>최대: 8</li>
</ul>
<p>이 의미는:</p>
<ul>
<li>항상 최소 2개의 Worker는 유지</li>
<li>작업량이 증가하면 자동으로 Worker 추가</li>
</ul>
<p>이 기능을 <strong>Auto Scaling</strong>이라고 합니다.</p>
<hr>
<h3 id="Auto-Scaling의-장점"><a href="#Auto-Scaling의-장점" class="headerlink" title="Auto Scaling의 장점"></a>Auto Scaling의 장점</h3><ul>
<li>Worker 수 증가 → 병렬 처리 증가</li>
<li>병렬 처리 증가 → 처리 속도 향상</li>
</ul>
<p>예시:</p>
<ul>
<li>4 Workers × 14GB &#x3D; <strong>56GB 메모리</strong></li>
<li>8 Workers × 14GB &#x3D; <strong>112GB 메모리</strong></li>
</ul>
<p>CPU 코어도 동일한 방식으로 증가합니다.</p>
<hr>
<h2 id="8-클러스터-생성"><a href="#8-클러스터-생성" class="headerlink" title="8. 클러스터 생성"></a>8. 클러스터 생성</h2><p>모든 설정이 완료되면:</p>
<ul>
<li><strong>Create Cluster</strong> 클릭</li>
</ul>
<p>클러스터 생성에는 몇 분 정도가 소요됩니다.</p>
<p>이 단계에서도 잠시 영상을 멈추고 기다립니다.</p>
<hr>
<h2 id="9-클러스터-상태-확인-Spark-UI"><a href="#9-클러스터-상태-확인-Spark-UI" class="headerlink" title="9. 클러스터 상태 확인 (Spark UI)"></a>9. 클러스터 상태 확인 (Spark UI)</h2><p>클러스터 생성이 완료되면:</p>
<ul>
<li>클러스터 이름 클릭</li>
<li><strong>Spark UI</strong> 확인</li>
</ul>
<p>여기서 다음 정보를 볼 수 있습니다.</p>
<ul>
<li>Worker 개수</li>
<li>각 Worker의 메모리 및 CPU</li>
<li>실행 중인 애플리케이션</li>
<li>각 노드의 IP 주소</li>
</ul>
<p>중요한 포인트 하나:</p>
<ul>
<li><strong>실제 멀티 노드 클러스터</strong>에서는<br>각 Worker가 <strong>서로 다른 IP 주소</strong>를 가집니다.</li>
<li><strong>Databricks Community Edition</strong>에서는<br>모든 것이 한 머신에서 실행되기 때문에 IP가 동일합니다.</li>
</ul>
<p>이를 통해:</p>
<ul>
<li>실제 분산 환경</li>
<li>단일 노드 환경</li>
</ul>
<p>의 차이를 명확히 확인할 수 있습니다.</p>
<hr>
<h2 id="10-다음-강의-예고"><a href="#10-다음-강의-예고" class="headerlink" title="10. 다음 강의 예고"></a>10. 다음 강의 예고</h2><p>이제 Azure Databricks에서<br><strong>실제 Spark 클러스터를 생성하는 방법</strong>을 배웠습니다.</p>
<p>다음 강의에서는:</p>
<ul>
<li><strong>Databricks Community Edition</strong>에서 클러스터 생성</li>
<li>Single-node 환경에서 Spark가 어떻게 동작하는지를 살펴보겠습니다.</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://kish191919.github.io">Danny Ki</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://kish191919.github.io/2025/12/18/DATABRICKS-Certified-Developer-2/">https://kish191919.github.io/2025/12/18/DATABRICKS-Certified-Developer-2/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/DATABRICKS/">DATABRICKS</a><a class="post-meta__tags" href="/tags/DATABRICKS-CERTIFIED-DEVELOPER/">DATABRICKS_CERTIFIED_DEVELOPER</a></div><div class="post-share"><div class="social-share" data-image="/img/my_pic.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/12/18/DATABRICKS-Certified-Developer-3/" title="DATABRICKS-Certified-Developer-3"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">DATABRICKS-Certified-Developer-3</div></div><div class="info-2"><div class="info-item-1">Databricks Community Edition 계정 생성 및 클러스터 만들기1. 이 강의에서 필요한 준비 사항이 강의에 포함된 모든 예제를 따라 하기 위해서는Databricks Community Edition 계정이 필요합니다. Databricks Community Edition은:  무료로 제공되는 Databricks 계정이며 Apache Spark를 학습하기에 충분한 환경을 제공합니다  실무에서 사용하는 대규모 클러스터는 아니지만,Spark의 핵심 개념과 동작 방식을 이해하기에는 충분합니다.  2. Databricks Community Edition 회원 가입먼저 웹 브라우저를 열고 다음 사이트로 이동합니다. 👉 https://databricks.com 메인 페이지에서:  Try Databricks 버튼을 클릭합니다  그러면 회원 가입(Sign Up) 페이지가 나타납니다.  회원 가입 정보 입력다음과 같은 기본 정보를 입력합니다.  Company Name (회사명) ...</div></div></div></a><a class="pagination-related" href="/2025/12/18/DATABRICKS-Certified-Developer-1/" title="DATABRICKS-Certified-Developer-1"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">DATABRICKS-Certified-Developer-1</div></div><div class="info-2"><div class="info-item-1">Apache Spark Cluster Architecture – Easy Explanation1. Computing on a Single Computer먼저, 하나의 컴퓨터에서 컴퓨팅이 어떻게 이루어지는지 살펴보겠습니다. 하나의 컴퓨터에는 다음과 같은 컴퓨팅 자원이 있습니다.  CPU: 연산을 수행 Memory (RAM): 실행 중인 데이터 저장 GPU: 대규모 병렬 연산 (필요한 경우)  이 모든 자원은 운영체제(OS) 가 관리합니다. Operating System의 역할운영체제는 여러 애플리케이션이 동시에 실행될 때:  CPU와 메모리를 어떻게 나눠 쓸지 결정하고 각 애플리케이션의 자원 사용을 스케줄링합니다  덕분에 여러 프로그램이 동시에 실행되어도 시스템이 안정적으로 동작합니다.  2. Why Single Computer Is Not Enough for Big Data빅데이터를 처리하려면 다음과 같은 문제가 발생합니다.  데이터 크기가 너무 큼 연산량이 많음 처리 시간이 ...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/12/18/DATABRICKS-Certified-Developer-1/" title="DATABRICKS-Certified-Developer-1"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-18</div><div class="info-item-2">DATABRICKS-Certified-Developer-1</div></div><div class="info-2"><div class="info-item-1">Apache Spark Cluster Architecture – Easy Explanation1. Computing on a Single Computer먼저, 하나의 컴퓨터에서 컴퓨팅이 어떻게 이루어지는지 살펴보겠습니다. 하나의 컴퓨터에는 다음과 같은 컴퓨팅 자원이 있습니다.  CPU: 연산을 수행 Memory (RAM): 실행 중인 데이터 저장 GPU: 대규모 병렬 연산 (필요한 경우)  이 모든 자원은 운영체제(OS) 가 관리합니다. Operating System의 역할운영체제는 여러 애플리케이션이 동시에 실행될 때:  CPU와 메모리를 어떻게 나눠 쓸지 결정하고 각 애플리케이션의 자원 사용을 스케줄링합니다  덕분에 여러 프로그램이 동시에 실행되어도 시스템이 안정적으로 동작합니다.  2. Why Single Computer Is Not Enough for Big Data빅데이터를 처리하려면 다음과 같은 문제가 발생합니다.  데이터 크기가 너무 큼 연산량이 많음 처리 시간이 ...</div></div></div></a><a class="pagination-related" href="/2025/12/18/DATABRICKS-Certified-Developer-3/" title="DATABRICKS-Certified-Developer-3"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-18</div><div class="info-item-2">DATABRICKS-Certified-Developer-3</div></div><div class="info-2"><div class="info-item-1">Databricks Community Edition 계정 생성 및 클러스터 만들기1. 이 강의에서 필요한 준비 사항이 강의에 포함된 모든 예제를 따라 하기 위해서는Databricks Community Edition 계정이 필요합니다. Databricks Community Edition은:  무료로 제공되는 Databricks 계정이며 Apache Spark를 학습하기에 충분한 환경을 제공합니다  실무에서 사용하는 대규모 클러스터는 아니지만,Spark의 핵심 개념과 동작 방식을 이해하기에는 충분합니다.  2. Databricks Community Edition 회원 가입먼저 웹 브라우저를 열고 다음 사이트로 이동합니다. 👉 https://databricks.com 메인 페이지에서:  Try Databricks 버튼을 클릭합니다  그러면 회원 가입(Sign Up) 페이지가 나타납니다.  회원 가입 정보 입력다음과 같은 기본 정보를 입력합니다.  Company Name (회사명) ...</div></div></div></a><a class="pagination-related" href="/2025/12/18/DATABRICKS-Certified-Developer-4/" title="DATABRICKS-Certified-Developer-4"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-18</div><div class="info-item-2">DATABRICKS-Certified-Developer-4</div></div><div class="info-2"><div class="info-item-1">실습 데이터셋 및 Databricks 노트북 설치하기1. 이 강의에서 할 일이 강의에서는 앞으로의 모든 실습을 위해 필요한:  📁 데이터셋(Data files) 📓 Databricks 노트북(Notebooks)  을 Databricks 환경에 설치합니다. 이 과정이 제대로 되지 않으면👉 이후 강의에서 제공하는 소스 코드가 정상적으로 실행되지 않기 때문에반드시 차근차근 따라와 주세요.  2. 강의 자료 다운로드 (Zip 파일)먼저 이 강의의 Resources(자료) 섹션으로 이동합니다. 여기에서 두 개의 zip 파일을 다운로드합니다.  📓 Notebooks zip 파일 강의에서 사용할 Databricks 노트북들   📁 Dataset zip 파일 실습에 사용할 데이터 파일들 (JSON, CSV 등)    두 파일 모두 로컬 PC에 다운로드 후 압축을 해제해 주세요.  3. Databricks에 데이터셋 업로드하기이제 Databricks 환경으로 돌아가서먼저 데이터 파일을...</div></div></div></a><a class="pagination-related" href="/2025/12/18/DATABRICKS-Certified-Developer-5/" title="DATABRICKS-Certified-Developer-5"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-18</div><div class="info-item-2">DATABRICKS-Certified-Developer-5</div></div><div class="info-2"><div class="info-item-1">Spark DataFrame 기초 실습 시작하기1. 실습 시작 전 확인 사항 (매우 중요)본격적으로 실습을 시작하기 전에, 두 가지를 반드시 확인해야 합니다. ✅ 1) 데이터셋이 정상적으로 설치되었는지 확인Databricks 환경의 왼쪽 메뉴에서 다음 순서로 이동합니다.  Data 클릭 Add Data DBFS (Databricks File System) FileStore Tables 이전 강의에서 생성한 데이터 폴더  이 경로에서:  이전 강의에서 업로드한 모든 데이터 파일이 보인다면👉 데이터셋은 정상적으로 설치된 것입니다.   ✅ 2) 클러스터가 실행 중인지 확인Apache Spark는 클러스터 없이는 아무 작업도 할 수 없습니다. Community Edition에서는:  동시에 하나의 클러스터만 실행 가능합니다.  클러스터가 없다면:  Create Cluster 클릭 클러스터 이름 입력 Create Cluster 클릭  자세한 클러스터 생성 방법은👉 이전 강의 영상을 ...</div></div></div></a><a class="pagination-related" href="/2025/12/18/DATABRICKS-Certified-Developer-6/" title="DATABRICKS-Certified-Developer-6"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-18</div><div class="info-item-2">DATABRICKS-Certified-Developer-6</div></div><div class="info-2"><div class="info-item-1">DataFrame Schema 정의 방법 이해하기DataFrame은 각 컬럼의 이름(Name) 과 데이터 타입(Data Type) 을 정의하는Schema를 가지고 있습니다. DataFrame의 Schema를 확인하려면 printSchema 메서드를 사용합니다. 1customerDF.printSchema()  이 명령을 실행하면 DataFrame의 Schema가사람이 읽기 쉬운 형태로 출력됩니다.  1. 왜 Schema를 직접 정의해야 할까?예를 들어, 데이터 파일을 보면 address_id 컬럼의 값은 크지 않습니다.하지만 Spark는 자동으로 이를 Long 타입으로 인식할 수 있습니다. 이 경우:  Long 타입은 불필요하게 큰 타입이고 Integer 타입으로 충분한 상황입니다  따라서 Schema를 직접 정의하여 데이터 타입을 정확히 지정하는 것이 좋습니다.  2. Schema를 정의하는 첫 번째 방법: DDL 문자열 방식DataFrame Schema를 정의하는 첫 번째 방...</div></div></div></a><a class="pagination-related" href="/2025/12/12/DATABRICKS-Fundamentals-1/" title="DATABRICKS-Fundamentals-1"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-12</div><div class="info-item-2">DATABRICKS-Fundamentals-1</div></div><div class="info-2"><div class="info-item-1">1. Apache Spark란?Apache Spark는👉 분산 클러스터 환경에서 대규모 데이터를 빠르게 처리하기 위한 데이터 처리 엔진(Engine) 입니다. Spark는 다음 작업을 하나의 통합된 프레임워크에서 처리할 수 있습니다.  배치 데이터 처리 (Batch Processing) 스트리밍 데이터 처리 (Stream Processing) 머신러닝 (Machine Learning) 그래프 처리 (Graph Processing) SQL 기반 데이터 분석  📌 시험 포인트  Spark는 데이터베이스가 아니다 Spark는 스토리지 시스템이 아니다 Spark는 데이터 처리 엔진(Processing Engine) 이다   2. Spark가 제공하는 주요 API (Unified Framework)Spark는 하나의 엔진 위에서 여러 API를 제공합니다. (1) Spark SQL &amp; DataFrame API SQL 기반 데이터 처리 ANSI SQL 호환 가장 많이 사용됨 ⭐⭐...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/my_pic.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Danny Ki</div><div class="author-info-description">A data engineer's journey in coding, analytics, and building real-world systems.</div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">117</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">37</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">13</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/kish191919"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/kish191919" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Azure-Databricks%EC%97%90%EC%84%9C-Apache-Spark-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0-%EC%83%9D%EC%84%B1%ED%95%98%EA%B8%B0"><span class="toc-number">1.</span> <span class="toc-text">Azure Databricks에서 Apache Spark 클러스터 생성하기</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%EC%9D%B4-%EA%B0%95%EC%9D%98%EC%97%90%EC%84%9C-%EB%B0%B0%EC%9A%B8-%EB%82%B4%EC%9A%A9"><span class="toc-number">1.1.</span> <span class="toc-text">1. 이 강의에서 배울 내용</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Azure-Databricks-%EC%9B%8C%ED%81%AC%EC%8A%A4%ED%8E%98%EC%9D%B4%EC%8A%A4-%EC%83%9D%EC%84%B1"><span class="toc-number">1.2.</span> <span class="toc-text">2. Azure Databricks 워크스페이스 생성</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%ED%95%84%EC%88%98-%EC%84%A4%EC%A0%95-%ED%95%AD%EB%AA%A9"><span class="toc-number">1.2.1.</span> <span class="toc-text">필수 설정 항목</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-Resource-Group"><span class="toc-number">1.2.1.1.</span> <span class="toc-text">1) Resource Group</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-Workspace-Name"><span class="toc-number">1.2.1.2.</span> <span class="toc-text">2) Workspace Name</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-Location"><span class="toc-number">1.2.1.3.</span> <span class="toc-text">3) Location</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EC%84%A0%ED%83%9D-Tags-%EC%84%A4%EC%A0%95"><span class="toc-number">1.2.2.</span> <span class="toc-text">(선택) Tags 설정</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Review-Create"><span class="toc-number">1.2.3.</span> <span class="toc-text">Review &amp; Create</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Databricks-%EC%9B%8C%ED%81%AC%EC%8A%A4%ED%8E%98%EC%9D%B4%EC%8A%A4-%EC%8B%A4%ED%96%89"><span class="toc-number">1.3.</span> <span class="toc-text">3. Databricks 워크스페이스 실행</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Databricks-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0-%EC%83%9D%EC%84%B1"><span class="toc-number">1.4.</span> <span class="toc-text">4. Databricks 클러스터 생성</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0-%EC%9D%B4%EB%A6%84"><span class="toc-number">1.4.1.</span> <span class="toc-text">클러스터 이름</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Cluster-Mode"><span class="toc-number">1.4.2.</span> <span class="toc-text">Cluster Mode</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Databricks-Runtime-Version"><span class="toc-number">1.5.</span> <span class="toc-text">5. Databricks Runtime Version</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-Driver%EC%99%80-Worker-%EC%84%A4%EC%A0%95-%EC%A4%91%EC%9A%94"><span class="toc-number">1.6.</span> <span class="toc-text">6. Driver와 Worker 설정 (중요)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Worker-Type"><span class="toc-number">1.6.1.</span> <span class="toc-text">Worker Type</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Driver-Type"><span class="toc-number">1.6.2.</span> <span class="toc-text">Driver Type</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-Worker-%EA%B0%9C%EC%88%98%EC%99%80-Auto-Scaling"><span class="toc-number">1.7.</span> <span class="toc-text">7. Worker 개수와 Auto Scaling</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Auto-Scaling%EC%9D%98-%EC%9E%A5%EC%A0%90"><span class="toc-number">1.7.1.</span> <span class="toc-text">Auto Scaling의 장점</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0-%EC%83%9D%EC%84%B1"><span class="toc-number">1.8.</span> <span class="toc-text">8. 클러스터 생성</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0-%EC%83%81%ED%83%9C-%ED%99%95%EC%9D%B8-Spark-UI"><span class="toc-number">1.9.</span> <span class="toc-text">9. 클러스터 상태 확인 (Spark UI)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-%EB%8B%A4%EC%9D%8C-%EA%B0%95%EC%9D%98-%EC%98%88%EA%B3%A0"><span class="toc-number">1.10.</span> <span class="toc-text">10. 다음 강의 예고</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/18/DATABRICKS-Certified-Developer-6/" title="DATABRICKS-Certified-Developer-6">DATABRICKS-Certified-Developer-6</a><time datetime="2025-12-18T15:48:12.000Z" title="Created 2025-12-18 10:48:12">2025-12-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/18/DATABRICKS-Certified-Developer-5/" title="DATABRICKS-Certified-Developer-5">DATABRICKS-Certified-Developer-5</a><time datetime="2025-12-18T15:38:46.000Z" title="Created 2025-12-18 10:38:46">2025-12-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/18/DATABRICKS-Certified-Developer-4/" title="DATABRICKS-Certified-Developer-4">DATABRICKS-Certified-Developer-4</a><time datetime="2025-12-18T15:32:28.000Z" title="Created 2025-12-18 10:32:28">2025-12-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/18/DATABRICKS-Certified-Developer-3/" title="DATABRICKS-Certified-Developer-3">DATABRICKS-Certified-Developer-3</a><time datetime="2025-12-18T15:27:05.000Z" title="Created 2025-12-18 10:27:05">2025-12-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/18/DATABRICKS-Certified-Developer-2/" title="DATABRICKS-Certified-Developer-2">DATABRICKS-Certified-Developer-2</a><time datetime="2025-12-18T15:13:19.000Z" title="Created 2025-12-18 10:13:19">2025-12-18</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 By Danny Ki</span><span class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.3</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>