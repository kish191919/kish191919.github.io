<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Danny&#39;s Blog</title>
  
  <subtitle>Data, AI, and Tech Insight</subtitle>
  <link href="https://kish191919.github.io/atom.xml" rel="self"/>
  
  <link href="https://kish191919.github.io/"/>
  <updated>2025-09-15T20:57:53.356Z</updated>
  <id>https://kish191919.github.io/</id>
  
  <author>
    <name>Danny Ki</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Databricks CV Anomaly Detection</title>
    <link href="https://kish191919.github.io/2025/09/15/Databricks-CV-Anomaly-Detection/"/>
    <id>https://kish191919.github.io/2025/09/15/Databricks-CV-Anomaly-Detection/</id>
    <published>2025-09-15T20:40:23.000Z</published>
    <updated>2025-09-15T20:57:53.356Z</updated>
    
    <content type="html"><![CDATA[<h2 id="👁️-Databricks-Computer-Vision-Anomaly-Detection-Model-Deployment"><a href="#👁️-Databricks-Computer-Vision-Anomaly-Detection-Model-Deployment" class="headerlink" title="👁️ Databricks + Computer Vision Anomaly Detection &amp; Model Deployment"></a>👁️ Databricks + Computer Vision Anomaly Detection &amp; Model Deployment</h2><p><em>A complete guide to anomaly detection with Databricks and Apache Spark</em>  </p><blockquote><p>“From data ingestion to real-time serving — build and deploy scalable computer vision anomaly detection models.”</p></blockquote><p>📎 <strong>Full Project</strong>:<br><a href="https://github.com/kish191919/Databricks_CV_Anomaly_Detection">👉 View Jupyter Notebooks on GitHub</a></p><p align="center">  <img src="/images/CA_Anomaly_Detection.png" width="80%"></p><hr><h3 id="📌-One-Line-Summary"><a href="#📌-One-Line-Summary" class="headerlink" title="📌 One-Line Summary"></a>📌 One-Line Summary</h3><p>This project provides a full pipeline for <strong>computer vision–based anomaly detection</strong>, covering <strong>data ingestion, preprocessing, model training, deployment, and REST API serving</strong> — all within <strong>Databricks</strong> and powered by <strong>Apache Spark</strong>.</p><hr><h2 id="1️⃣-How-It-Was-Built"><a href="#1️⃣-How-It-Was-Built" class="headerlink" title="1️⃣ How It Was Built"></a>1️⃣ How It Was Built</h2><h3 id="1-Utilities-00-utils-ipynb"><a href="#1-Utilities-00-utils-ipynb" class="headerlink" title="1. Utilities (00_utils.ipynb)"></a><strong>1. Utilities (00_utils.ipynb)</strong></h3><ul><li>Common helper functions for preprocessing and visualization  </li><li>Reusable utilities to streamline workflows</li></ul><hr><h3 id="2-Data-Ingestion-ETL-01-Ingestion-ETL-ipynb"><a href="#2-Data-Ingestion-ETL-01-Ingestion-ETL-ipynb" class="headerlink" title="2. Data Ingestion &amp; ETL (01_Ingestion_ETL.ipynb)"></a><strong>2. Data Ingestion &amp; ETL (01_Ingestion_ETL.ipynb)</strong></h3><ul><li>Ingested large-scale image datasets into Databricks  </li><li>Implemented Spark-based ETL for scalability  </li><li>Optimized storage and partitioning for performance and cost efficiency </li><li>Image Processing Visualization</li></ul><p align="center">  <img src="/images/image_processing_visualization.png" width="80%"></p><hr><h3 id="3-Deep-Learning-Training-02-HF-Deep-Learning-ipynb"><a href="#3-Deep-Learning-Training-02-HF-Deep-Learning-ipynb" class="headerlink" title="3. Deep Learning Training (02_HF_Deep_Learning.ipynb)"></a><strong>3. Deep Learning Training (02_HF_Deep_Learning.ipynb)</strong></h3><ul><li>Applied image preprocessing and augmentation  </li><li>Trained models using <strong>PyTorch + Hugging Face</strong>  </li><li>Evaluated performance with metrics like <strong>Accuracy</strong>, <strong>Loss</strong>, and <strong>PR-AUC</strong></li></ul><hr><h3 id="4-Model-Deployment-03-Model-Deployment-ipynb"><a href="#4-Model-Deployment-03-Model-Deployment-ipynb" class="headerlink" title="4. Model Deployment (03_Model_Deployment.ipynb)"></a><strong>4. Model Deployment (03_Model_Deployment.ipynb)</strong></h3><ul><li>Registered trained models in <strong>MLflow</strong>  </li><li>Managed versions for reproducibility  </li><li>Optimized inference pipelines for deployment</li></ul><hr><h3 id="5-Model-Serving-04-Model-Serving-ipynb"><a href="#5-Model-Serving-04-Model-Serving-ipynb" class="headerlink" title="5. Model Serving (04_Model_Serving.ipynb)"></a><strong>5. Model Serving (04_Model_Serving.ipynb)</strong></h3><ul><li>Deployed models with <strong>Databricks Model Serving</strong>  </li><li>Exposed REST API endpoints for real-time predictions  </li><li>Integrated anomaly detection into external systems</li></ul><hr><h2 id="2️⃣-Optimization-Best-Practices"><a href="#2️⃣-Optimization-Best-Practices" class="headerlink" title="2️⃣ Optimization &amp; Best Practices"></a>2️⃣ Optimization &amp; Best Practices</h2><ul><li>Spark optimizations for large-scale image data  </li><li>Databricks cluster configuration for <strong>cost efficiency</strong>  </li><li>Strategies for balancing performance and resource usage</li></ul><hr><h2 id="🛠-Technologies-Used"><a href="#🛠-Technologies-Used" class="headerlink" title="🛠 Technologies Used"></a>🛠 Technologies Used</h2><table><thead><tr><th>Step</th><th>Technology</th></tr></thead><tbody><tr><td>Data Processing</td><td>Apache Spark, Databricks</td></tr><tr><td>Deep Learning</td><td>PyTorch, Hugging Face</td></tr><tr><td>Experiment Mgmt</td><td>MLflow</td></tr><tr><td>Deployment</td><td>Databricks Model Registry</td></tr><tr><td>Serving</td><td>REST API, Databricks Serving</td></tr></tbody></table><hr><h2 id="💡-Key-Learnings"><a href="#💡-Key-Learnings" class="headerlink" title="💡 Key Learnings"></a>💡 Key Learnings</h2><ul><li>Full lifecycle ML on Databricks: ingestion → training → deployment → serving  </li><li>How to optimize Databricks for <strong>low-cost, high-performance workflows</strong>  </li><li>Practical experience with model versioning, reproducibility, and API integration</li></ul><hr><h2 id="🔗-GitHub-Repository"><a href="#🔗-GitHub-Repository" class="headerlink" title="🔗 GitHub Repository"></a>🔗 GitHub Repository</h2><p>📂 <a href="https://github.com/kish191919/Databricks_CV_Anomaly_Detection">View Project on GitHub</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;👁️-Databricks-Computer-Vision-Anomaly-Detection-Model-Deployment&quot;&gt;&lt;a href=&quot;#👁️-Databricks-Computer-Vision-Anomaly-Detection-Model-</summary>
      
    
    
    
    <category term="Showcase" scheme="https://kish191919.github.io/categories/Showcase/"/>
    
    
    <category term="Databricks" scheme="https://kish191919.github.io/tags/Databricks/"/>
    
    <category term="Apache Spark" scheme="https://kish191919.github.io/tags/Apache-Spark/"/>
    
    <category term="Computer Vision" scheme="https://kish191919.github.io/tags/Computer-Vision/"/>
    
    <category term="Deep Learning" scheme="https://kish191919.github.io/tags/Deep-Learning/"/>
    
    <category term="MLflow" scheme="https://kish191919.github.io/tags/MLflow/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS ML Associate (6) - Amazon S3 핵심 정리</title>
    <link href="https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-6/"/>
    <id>https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-6/</id>
    <published>2025-09-15T03:49:25.000Z</published>
    <updated>2025-09-15T04:13:20.934Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Amazon-S3-보안-Amazon-S3-Security"><a href="#Amazon-S3-보안-Amazon-S3-Security" class="headerlink" title="Amazon S3 보안 (Amazon S3 Security)"></a>Amazon S3 보안 (Amazon S3 Security)</h1><p>Amazon S3는 단순한 저장소 서비스지만, <strong>보안(Security)</strong> 을 제대로 설정하지 않으면 데이터 유출(Data Leak)과 같은 심각한 문제가 발생할 수 있습니다.  AWS Certified Machine Learning Engineer – Associate 시험에서도 자주 출제되는 주제이므로 꼭 이해해야 합니다.</p><hr><h2 id="1-S3-보안-유형"><a href="#1-S3-보안-유형" class="headerlink" title="1. S3 보안 유형"></a>1. S3 보안 유형</h2><h3 id="🔹-User-Based-IAM-기반"><a href="#🔹-User-Based-IAM-기반" class="headerlink" title="🔹 User-Based (IAM 기반)"></a>🔹 User-Based (IAM 기반)</h3><ul><li><strong>IAM Policies</strong><br>IAM(Identity and Access Management)에서 특정 사용자(User) 또는 그룹(Group)에 대해 어떤 API 호출(API Calls)을 허용할지 정의합니다.<br>→ 예: <code>s3:GetObject</code> 권한 부여.</li></ul><h3 id="🔹-Resource-Based-리소스-기반"><a href="#🔹-Resource-Based-리소스-기반" class="headerlink" title="🔹 Resource-Based (리소스 기반)"></a>🔹 Resource-Based (리소스 기반)</h3><ul><li><p><strong>Bucket Policies</strong>  </p><ul><li>JSON 기반 정책으로, 버킷 전체에 대한 접근 권한을 설정합니다.  </li><li><strong>Cross-Account Access</strong>(계정 간 접근)도 허용 가능.  </li><li>버킷 정책은 <strong>S3 콘솔</strong>에서 직접 작성&#x2F;관리.</li></ul></li><li><p><strong>Object ACL (Access Control List)</strong>  </p><ul><li>객체 단위로 세밀하게 접근 제어.  </li><li>하지만 현재는 <strong>비추천(Deprecated)</strong> → 대부분 <strong>버킷 정책</strong>으로 대체.</li></ul></li><li><p><strong>Bucket ACL</strong>  </p><ul><li>버킷 단위 ACL. 거의 사용하지 않으며 역시 비추천.</li></ul></li></ul><hr><h2 id="2-IAM-권한-평가-규칙"><a href="#2-IAM-권한-평가-규칙" class="headerlink" title="2. IAM 권한 평가 규칙"></a>2. IAM 권한 평가 규칙</h2><p>S3 객체에 접근하려면 다음 조건을 만족해야 합니다:</p><ul><li><strong>IAM 정책이 ALLOW</strong> 이거나 <strong>리소스 정책이 ALLOW</strong>  </li><li>그리고 <strong>명시적 DENY가 없어야 함</strong></li></ul><p>👉 즉, <code>ALLOW OR ALLOW</code> 이면서 동시에 <code>NO DENY</code> 조건이어야 함.</p><hr><h2 id="3-S3-버킷-정책-Bucket-Policies"><a href="#3-S3-버킷-정책-Bucket-Policies" class="headerlink" title="3. S3 버킷 정책 (Bucket Policies)"></a>3. S3 버킷 정책 (Bucket Policies)</h2><ul><li><strong>형식</strong>: JSON 기반 문서  </li><li><strong>구성 요소</strong><ul><li><strong>Resource</strong>: 적용 대상 (버킷&#x2F;객체 ARN)  </li><li><strong>Effect</strong>: <code>Allow</code> 또는 <code>Deny</code>  </li><li><strong>Action</strong>: 허용&#x2F;거부할 API 목록 (<code>s3:GetObject</code>, <code>s3:PutObject</code> 등)  </li><li><strong>Principal</strong>: 정책 적용 대상 (계정, 사용자, 역할, <code>*</code> &#x3D; 모든 사용자)</li></ul></li></ul><h3 id="예시-1-퍼블릭-읽기-Public-Access"><a href="#예시-1-퍼블릭-읽기-Public-Access" class="headerlink" title="예시 1: 퍼블릭 읽기 (Public Access)"></a>예시 1: 퍼블릭 읽기 (Public Access)</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;Version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2012-10-17&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;Statement&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;Effect&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Allow&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;Principal&quot;</span><span class="punctuation">:</span> <span class="string">&quot;*&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;Action&quot;</span><span class="punctuation">:</span> <span class="string">&quot;s3:GetObject&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;Resource&quot;</span><span class="punctuation">:</span> <span class="string">&quot;arn:aws:s3:::my-example-bucket/*&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><ul><li>이 정책은 <code>my-example-bucket</code> 안의 모든 객체(<code>*</code>)를 <strong>누구나 읽기 가능</strong>하도록 허용.</li></ul><hr><h2 id="4-보안-시나리오별-접근-방법"><a href="#4-보안-시나리오별-접근-방법" class="headerlink" title="4. 보안 시나리오별 접근 방법"></a>4. 보안 시나리오별 접근 방법</h2><ul><li><strong>퍼블릭 접근 (Public Access)</strong>  <ul><li>버킷 정책으로 <code>GetObject</code> 권한을 열어줌.  </li><li>단, <strong>Block Public Access 설정</strong>을 해제해야 함.</li></ul></li></ul><p align="center">  <img src="/images/aws-ml-02.png" width="80%"></p><ul><li><strong>내부 사용자 (IAM User)</strong>  <ul><li>IAM 정책으로 권한 부여 (<code>s3:ListBucket</code>, <code>s3:GetObject</code> 등).</li></ul></li></ul><p align="center">  <img src="/images/aws-ml-03.png" width="80%"></p><ul><li><strong>EC2 인스턴스에서 접근</strong>  <ul><li>IAM User 사용 ❌ → <strong>IAM Role</strong>을 EC2에 부여해야 함.</li></ul></li></ul><p align="center">  <img src="/images/aws-ml-04.png" width="80%"></p><ul><li><strong>Cross-Account Access (계정 간 접근)</strong>  <ul><li>다른 AWS 계정의 IAM User가 접근하려면 → <strong>버킷 정책</strong>으로 허용.</li></ul></li></ul><p align="center">  <img src="/images/aws-ml-05.png" width="80%"></p><hr><h2 id="5-Block-Public-Access-설정"><a href="#5-Block-Public-Access-설정" class="headerlink" title="5. Block Public Access 설정"></a>5. Block Public Access 설정</h2><ul><li>AWS가 <strong>데이터 유출 방지(Data Leak Prevention)</strong> 를 위해 도입한 기능.  </li><li>기본적으로 모든 퍼블릭 접근을 막음.  </li><li>✅ 시험 포인트:  <ul><li>버킷을 공개해야 한다면 반드시 <strong>Block Public Access를 해제</strong>해야 함.  </li><li>하지만 <strong>기업 환경에서는 대부분 항상 켜둔다</strong>.  </li><li>계정 레벨에서도 적용 가능 → <strong>모든 버킷이 퍼블릭 차단됨</strong>.</li></ul></li></ul><hr><h2 id="6-암호화-Encryption"><a href="#6-암호화-Encryption" class="headerlink" title="6. 암호화 (Encryption)"></a>6. 암호화 (Encryption)</h2><ul><li><strong>SSE-S3</strong>: S3가 자체적으로 키 관리 (간단, 기본 옵션).  </li><li><strong>SSE-KMS</strong>: AWS KMS(Key Management Service)를 사용해 키 관리 (더 세밀한 보안, 로깅 가능).  </li><li>시험에서는 <strong>SSE-S3와 SSE-KMS 차이점</strong>을 잘 물어봄.</li></ul><hr><h1 id="✅-시험-대비-핵심-정리"><a href="#✅-시험-대비-핵심-정리" class="headerlink" title="✅ 시험 대비 핵심 정리"></a>✅ 시험 대비 핵심 정리</h1><ol><li><p><strong>IAM Policy vs Bucket Policy</strong>  </p><ul><li>IAM Policy: 사용자(User) 관점에서 권한 관리.  </li><li>Bucket Policy: 리소스(Resource) 관점에서 권한 관리.</li></ul></li><li><p><strong>객체 접근 조건</strong>  </p><ul><li>ALLOW(사용자 정책 OR 리소스 정책) + NO DENY.</li></ul></li><li><p><strong>EC2에서 S3 접근</strong> → <strong>IAM Role 사용</strong>.  </p></li><li><p><strong>Cross-Account Access</strong> → <strong>버킷 정책 필요</strong>.  </p></li><li><p><strong>Block Public Access</strong>  </p><ul><li>기본 ON (데이터 유출 방지).  </li><li>시험에서는 “퍼블릭 버킷이 동작하지 않는다 → Block Public Access 때문” 자주 출제.</li></ul></li><li><p><strong>암호화 옵션</strong>  </p><ul><li>SSE-S3 (자동, 간단) vs SSE-KMS (보안·규제 요구사항 대응).</li></ul></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Amazon-S3-보안-Amazon-S3-Security&quot;&gt;&lt;a href=&quot;#Amazon-S3-보안-Amazon-S3-Security&quot; class=&quot;headerlink&quot; title=&quot;Amazon S3 보안 (Amazon S3 Securi</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_ML_ASSOCIATE_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-ML-ASSOCIATE-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
    <category term="AWS_ML_ASSOCIATE" scheme="https://kish191919.github.io/tags/AWS-ML-ASSOCIATE/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS ML Associate (5) - Amazon S3 핵심 정리</title>
    <link href="https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-5/"/>
    <id>https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-5/</id>
    <published>2025-09-15T02:33:24.000Z</published>
    <updated>2025-09-15T03:49:06.877Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Amazon-S3-핵심-정리"><a href="#Amazon-S3-핵심-정리" class="headerlink" title="Amazon S3 핵심 정리"></a>Amazon S3 핵심 정리</h1><blockquote><p><strong>왜 중요한가?</strong><br>Amazon S3(Simple Storage Service)는 AWS의 핵심 스토리지 서비스로, “사실상 무한대(virtually unlimited)” 확장성을 제공하는 <strong>객체 스토리지(Object Storage)</strong> 입니다. 대부분의 데이터&#x2F;AI 워크로드가 S3를 중심으로 연결되며, 다른 AWS 서비스와의 통합성이 매우 뛰어납니다.</p></blockquote><hr><h2 id="1-S3가-쓰이는-곳-Use-Cases"><a href="#1-S3가-쓰이는-곳-Use-Cases" class="headerlink" title="1) S3가 쓰이는 곳 (Use Cases)"></a>1) S3가 쓰이는 곳 (Use Cases)</h2><ul><li><strong>백업 &amp; 스토리지(Backup &amp; Storage)</strong>: 장기 보관, 스냅샷 저장.</li><li><strong>재해복구(Disaster Recovery, DR)</strong>: 다른 <strong>리전(Region)</strong> 으로 복제해 RTO&#x2F;RPO 개선.</li><li><strong>아카이브(Archive)</strong>: 저비용 보관(<strong>S3 Glacier</strong> 계열) 후 필요 시 복원.</li><li><strong>하이브리드 스토리지(Hybrid Cloud Storage)</strong>: 온프레미스 + 클라우드 연동.</li><li><strong>애플리케이션&#x2F;미디어 호스팅(App&#x2F;Media Hosting)</strong>: 이미지&#x2F;동영상&#x2F;정적 파일 제공.</li><li><strong>데이터 레이크(Data Lake) &amp; 빅데이터 분석(Big Data Analytics)</strong>: 원천 데이터 저장 후 <strong>Athena&#x2F;Glue&#x2F;Lake Formation</strong> 등으로 분석.</li><li><strong>소프트웨어 배포(Software Delivery)</strong>: 설치 파일, 모델 아티팩트 배포.</li><li><strong>정적 웹사이트(Static Website)</strong>: 정적 호스팅 + <strong>CloudFront(CDN)</strong> 로 가속.</li></ul><blockquote><p><strong>MLA-C01 포인트</strong>: S3는 <strong>SageMaker</strong>와 함께 자주 출제됩니다. 학습&#x2F;추론 데이터 저장, 모델 아티팩트 저장, <strong>Athena&#x2F;Glue</strong>와 연계한 피처 추출 파이프라인 등. S3 경로 표기(<strong>S3 URI</strong>)와 권한 모델을 익히세요.</p></blockquote><hr><h2 id="2-버킷-Bucket-—-최상위-네임스페이스"><a href="#2-버킷-Bucket-—-최상위-네임스페이스" class="headerlink" title="2) 버킷(Bucket) — 최상위 네임스페이스"></a>2) 버킷(Bucket) — 최상위 네임스페이스</h2><ul><li><strong>정의</strong>: 객체(파일)를 담는 <strong>컨테이너</strong>. UI가 폴더처럼 보여도, 실제로는 <strong>버킷&#x2F;키(key)</strong> 기반의 평면 구조.</li><li><strong>글로벌 유니크 이름(Global Unique Name)</strong>: <strong>전 세계 모든 계정&#x2F;리전에서 유일</strong>해야 함.</li><li><strong>리전 범위(Region-scoped)</strong>: 버킷은 <strong>특정 리전</strong>에 생성됩니다. (S3가 글로벌처럼 보여도 생성 위치는 리전)</li><li><strong>네이밍 규칙(Naming Rules)</strong> (대표 규칙만 발췌)<ul><li>영문 소문자&#x2F;숫자&#x2F;하이픈만 사용, <strong>대문자&#x2F;언더스코어 불가</strong></li><li>길이 3~63자</li><li>IP 형태 금지(예: <code>192.168.0.1</code>)</li><li><code>xn--</code> 로 시작 금지, <code>-s3alias</code> 로 끝 금지</li></ul></li><li><strong>권장 초기 설정</strong><ul><li><strong>ACL 비활성화(ACLs disabled, Bucket owner enforced)</strong>  </li><li><strong>퍼블릭 접근 차단(Block Public Access)</strong>: 기본 on  </li><li><strong>서버사이드 암호화(Server-Side Encryption, SSE)</strong>: 기본 <strong>SSE-S3</strong> 또는 <strong>SSE-KMS</strong></li></ul></li></ul><blockquote><p><strong>시험 포인트</strong>  </p><ul><li>“버킷 이름 글로벌 유일”과 “버킷은 리전에 종속”을 구분하세요.  </li><li>보안 기본값: <strong>Block Public Access &#x3D; ON</strong>, <strong>ACL 비권장</strong>, <strong>SSE 적용</strong>.</li></ul></blockquote><hr><h2 id="3-객체-Object-키-Key"><a href="#3-객체-Object-키-Key" class="headerlink" title="3) 객체(Object) &amp; 키(Key)"></a>3) 객체(Object) &amp; 키(Key)</h2><ul><li><strong>키(Key) &#x3D; 전체 경로(Full Path)</strong>  <ul><li>예: <code>s3://my-bucket/my_folder1/another_folder/my_file.txt</code>  </li><li><strong>Prefix + Object Name</strong> 조합 (디렉터리 개념은 UI 편의일 뿐, 실제로는 긴 문자열 경로)</li></ul></li><li><strong>크기 제한(Size Limits)</strong><ul><li><strong>최대 5TB</strong></li><li><strong>5GB 초과 업로드는 반드시 <em>멀티파트 업로드(Multi-part Upload)</em></strong> 사용</li></ul></li><li><strong>메타데이터(Metadata)</strong>: 시스템&#x2F;사용자 정의 Key-Value</li><li><strong>태그(Tags)</strong>: 최대 10쌍, 비용&#x2F;수명주기&#x2F;보안 정책에 유용</li><li><strong>버전 ID(Version ID)</strong>: <strong>버전 관리(Versioning)</strong> 활성화 시 부여</li></ul><blockquote><p><strong>시험 포인트</strong>  </p><ul><li><strong>5GB 초과 → Multi-part Upload 필수</strong>  </li><li><strong>Versioning</strong>: 삭제&#x2F;덮어쓰기 보호, <strong>MFA Delete</strong> 와 함께 보안 강화</li></ul></blockquote><hr><h2 id="4-접근-방법-퍼블릭-URL-vs-프리사인드-URL"><a href="#4-접근-방법-퍼블릭-URL-vs-프리사인드-URL" class="headerlink" title="4) 접근 방법: 퍼블릭 URL vs 프리사인드 URL"></a>4) 접근 방법: 퍼블릭 URL vs 프리사인드 URL</h2><ul><li><strong>Public URL</strong>: 객체가 <strong>퍼블릭</strong>이어야 접근 가능(기본은 차단됨).</li><li><strong>Pre-signed URL</strong>: <strong>임시 권한이 서명된 URL</strong>. 비공개 객체도 <strong>서명 만료 시간 동안</strong> 접근 가능. 안전한 1회성 공유에 적합.</li></ul><blockquote><p><strong>시험 포인트</strong>: “객체는 비공개인데 외부와 잠깐 공유하고 싶다” → <strong>Pre-signed URL</strong> 정답.</p></blockquote><hr><h2 id="5-필수-보안-운영-기능-Security-Operations"><a href="#5-필수-보안-운영-기능-Security-Operations" class="headerlink" title="5) 필수 보안&#x2F;운영 기능 (Security &amp; Operations)"></a>5) 필수 보안&#x2F;운영 기능 (Security &amp; Operations)</h2><ul><li><strong>암호화(Encryption)</strong><ul><li><strong>SSE-S3</strong>(Amazon S3 managed keys) — 가장 간단</li><li><strong>SSE-KMS</strong>(AWS KMS keys) — <strong>키 사용 권한&#x2F;감사</strong> 필요 시</li><li><strong>CSE(Client-Side Encryption)</strong> — 클라이언트에서 암호화 후 업로드</li></ul></li><li><strong>버전 관리(Versioning)</strong> + <strong>MFA Delete</strong>: 실수&#x2F;랜섬웨어 대응</li><li><strong>수명주기(Lifecycle) 정책</strong>: <strong>Standard → IA → Glacier</strong> 티어링, 자동 만료&#x2F;아카이브</li><li><strong>복제(Replication)</strong><ul><li><strong>CRR(Cross-Region Replication)</strong>: DR&#x2F;지연단축</li><li><strong>SRR(Same-Region Replication)</strong>: 멀티계정&#x2F;멀티버킷 분리</li></ul></li><li><strong>액세스 제어(Access Control)</strong><ul><li><strong>IAM 정책(IAM Policy)</strong>, <strong>버킷 정책(Bucket Policy)</strong> 중심</li><li><strong>S3 Access Points</strong>&#x2F;**VPC 엔드포인트(Interface&#x2F;Gateway)**로 네트워크 격리</li></ul></li><li><strong>감사&#x2F;로깅(Audit&#x2F;Logging)</strong>: <strong>CloudTrail</strong>, <strong>Server Access Logging</strong>, <strong>S3 Object Ownership</strong></li></ul><blockquote><p><strong>시험 포인트</strong>  </p><ul><li><strong>SSE-KMS</strong> 선택 시 <strong>KMS 키 권한</strong>(Encrypt&#x2F;Decrypt&#x2F;API호출)이 추가로 필요.  </li><li><strong>CRR</strong>은 <strong>버전닝이 양쪽 모두 활성화</strong>되어야 작동. 소유권&#x2F;권한 이슈 자주 출제.</li></ul></blockquote><hr><h2 id="6-정적-웹사이트-CDN"><a href="#6-정적-웹사이트-CDN" class="headerlink" title="6) 정적 웹사이트 &amp; CDN"></a>6) 정적 웹사이트 &amp; CDN</h2><ul><li><strong>Static Website Hosting</strong>: S3 정적 웹 사이트 엔드포인트 사용(퍼블릭 접근 필요).  </li><li><strong>CloudFront</strong> 앞단 배치 권장: OAC(Origin Access Control)로 <strong>S3는 비공개</strong>, <strong>CloudFront만 접근</strong> → 성능&#x2F;보안 모두 향상.</li></ul><blockquote><p><strong>시험 포인트</strong>: “S3를 퍼블릭으로 열지 않고 정적 사이트 제공?” → <strong>CloudFront + OAC</strong> 패턴.</p></blockquote><hr><h2 id="7-데이터-레이크-패턴-for-ML-Analytics"><a href="#7-데이터-레이크-패턴-for-ML-Analytics" class="headerlink" title="7) 데이터 레이크 패턴 (for ML&#x2F;Analytics)"></a>7) 데이터 레이크 패턴 (for ML&#x2F;Analytics)</h2><ul><li><strong>원천 저장</strong>: S3에 원본 데이터 적재(스키마 온 리드, <em>Schema-on-Read</em>).</li><li><strong>카탈로그</strong>: <strong>AWS Glue Data Catalog</strong></li><li><strong>쿼리&#x2F;탐색</strong>: <strong>Amazon Athena</strong>(서버리스 SQL), <strong>Redshift Spectrum</strong></li><li><strong>거버넌스</strong>: <strong>Lake Formation</strong>(권한&#x2F;데이터 액세스 제어)</li><li><strong>형식 최적화</strong>: <strong>Parquet&#x2F;ORC</strong> 등 <strong>컬럼나형(Columnar)</strong> 포맷 권장 (스캔&#x2F;비용 절감)</li></ul><blockquote><p><strong>시험 포인트</strong>: “S3 + Athena 비용 최적화?” → <strong>Parquet + 파티셔닝(Partitioning) + 프리픽스 설계</strong>.</p></blockquote><hr><h2 id="8-콘솔에서-자주-하는-작업-요약"><a href="#8-콘솔에서-자주-하는-작업-요약" class="headerlink" title="8) 콘솔에서 자주 하는 작업 요약"></a>8) 콘솔에서 자주 하는 작업 요약</h2><ol><li><strong>버킷 생성(Create Bucket)</strong>: 리전 선택 → 이름 지정(글로벌 유일) → <strong>Block Public Access ON</strong>, <strong>SSE 설정</strong>  </li><li><strong>객체 업로드(Upload)</strong>: 단일&#x2F;멀티파트 선택(5GB 초과 시 멀티파트)  </li><li><strong>폴더처럼 사용하기</strong>: 접두사(prefix)로 논리적 구분(실제 디렉터리는 아님)  </li><li><strong>프리사인드 URL 생성</strong>: 일시적 외부 공유  </li><li><strong>버킷 정책&#x2F;액세스 포인트</strong>: 세밀 권한&#x2F;네트워크 격리 설정</li></ol><hr><h2 id="9-자주-나오는-함정-Exam-Gotchas"><a href="#9-자주-나오는-함정-Exam-Gotchas" class="headerlink" title="9) 자주 나오는 함정(Exam Gotchas)"></a>9) 자주 나오는 함정(Exam Gotchas)</h2><ul><li><strong>디렉터리 개념 없음</strong>: 키 문자열에 <code>/</code>를 써서 <strong>prefix</strong>를 흉내낼 뿐.</li><li><strong>5GB 업로드 제한</strong>: 초과 시 <strong>Multi-part Upload</strong> 필수.</li><li><strong>CRR 조건</strong>: <strong>양쪽 버킷 Versioning ON</strong> + 권한&#x2F;소유권 고려.</li><li><strong>KMS 사용 시 권한 오류</strong>: KMS 키 정책&#x2F;Grant&#x2F;IAM 권한 누락 체크.</li><li><strong>퍼블릭 차단이 기본</strong>: 정적 사이트&#x2F;퍼블릭 파일 배포는 <strong>CloudFront</strong> 경유가 안전.</li></ul><hr><h2 id="10-ML-엔지니어를-위한-S3-빠른-체크리스트"><a href="#10-ML-엔지니어를-위한-S3-빠른-체크리스트" class="headerlink" title="10) ML 엔지니어를 위한 S3 빠른 체크리스트"></a>10) ML 엔지니어를 위한 S3 빠른 체크리스트</h2><ul><li><input disabled="" type="checkbox"> <strong>데이터 저장 포맷</strong>: CSV → <strong>Parquet</strong> 변환 고려(성능&#x2F;비용)  </li><li><input disabled="" type="checkbox"> <strong>접근 제어</strong>: IAM Role 기반 최소 권한(least privilege)  </li><li><input disabled="" type="checkbox"> <strong>암호화</strong>: SSE-KMS 기본, 키 권한 점검(파이프라인&#x2F;노트북&#x2F;배치)  </li><li><input disabled="" type="checkbox"> <strong>수명주기 정책</strong>: 학습 로그&#x2F;중간 산출물 자동 정리  </li><li><input disabled="" type="checkbox"> <strong>경로 규약</strong>: <code>s3://bucket/project/dataset/partition=.../</code> 일관성  </li><li><input disabled="" type="checkbox"> <strong>프리사인드 URL</strong>: 일시적 데이터 공유&#x2F;검수 자동화에 활용</li></ul><hr><h3 id="핵심-용어-요약-KR-EN"><a href="#핵심-용어-요약-KR-EN" class="headerlink" title="핵심 용어 요약 (KR&#x2F;EN)"></a>핵심 용어 요약 (KR&#x2F;EN)</h3><ul><li>버킷 <strong>Bucket</strong> &#x2F; 객체 <strong>Object</strong> &#x2F; 키 <strong>Key</strong> &#x2F; 접두사 <strong>Prefix</strong> &#x2F; 버전 관리 <strong>Versioning</strong>  </li><li>프리사인드 URL <strong>Pre-signed URL</strong> &#x2F; 수명주기 정책 <strong>Lifecycle Policy</strong>  </li><li>서버사이드 암호화 <strong>Server-Side Encryption (SSE-S3 &#x2F; SSE-KMS)</strong>  </li><li>교차 리전 복제 <strong>Cross-Region Replication (CRR)</strong> &#x2F; 동일 리전 복제 <strong>Same-Region Replication (SRR)</strong>  </li><li>데이터 레이크 <strong>Data Lake</strong> &#x2F; 스키마 온 리드 <strong>Schema-on-Read</strong> &#x2F; 컬럼나 <strong>Columnar</strong></li></ul><hr><h2 id="추가-참고-심화"><a href="#추가-참고-심화" class="headerlink" title="추가 참고(심화)"></a>추가 참고(심화)</h2><ul><li><strong>S3 Storage Classes</strong>: Standard &#x2F; Standard-IA &#x2F; One Zone-IA &#x2F; Intelligent-Tiering &#x2F; Glacier Instant&#x2F;Flx&#x2F;Deep Archive  </li><li><strong>네트워크 최적화</strong>: <strong>S3 Transfer Acceleration</strong>, 멀티파트 병렬 업로드, VPC 엔드포인트  </li><li><strong>비용 관리</strong>: S3 Storage Lens, Lifecycle&#x2F;Intelligent-Tiering, 파티셔닝&#x2F;프리픽스 설계</li></ul><hr><p><strong>요약</strong>: S3는 ML&#x2F;분석 워크로드의 “공용 데이터 허브”입니다. <strong>보안 기본값</strong>, <strong>멀티파트 업로드</strong>, <strong>Versioning&#x2F;CRR</strong>, <strong>SSE-KMS</strong>, <strong>Athena+Parquet</strong> 같은 패턴을 확실히 익히면 MLA-C01에서 고득점할 수 있습니다.</p><h1 id="Amazon-S3-암호화-방식-쉽게-설명하기"><a href="#Amazon-S3-암호화-방식-쉽게-설명하기" class="headerlink" title="Amazon S3 암호화 방식 쉽게 설명하기"></a>Amazon S3 암호화 방식 쉽게 설명하기</h1><p>Amazon S3에서 데이터를 저장할 때 보안을 위해 <strong>서버 사이드 암호화(Server-side encryption, SSE)</strong> 를 사용할 수 있습니다.<br>대표적으로 자주 쓰이는 두 가지 방식이 있습니다.</p><hr><h2 id="1-SSE-S3-Server-side-encryption-with-Amazon-S3-managed-keys"><a href="#1-SSE-S3-Server-side-encryption-with-Amazon-S3-managed-keys" class="headerlink" title="1. SSE-S3 (Server-side encryption with Amazon S3 managed keys)"></a>1. SSE-S3 (Server-side encryption with Amazon S3 managed keys)</h2><ul><li><p><strong>설명</strong><br>S3가 직접 암호화 키를 관리해주는 방식입니다.<br>사용자가 따로 키를 만들거나 관리할 필요가 없습니다.<br>데이터를 업로드하면 S3가 자동으로 암호화하고, 다운로드하면 자동으로 복호화해 줍니다.</p></li><li><p><strong>특징</strong></p><ul><li>사용하기 가장 쉽습니다 (추가 설정 거의 필요 없음).</li><li>암호화 키는 <strong>Amazon S3가 전적으로 관리</strong>합니다.</li><li><code>AES-256</code> 암호화 알고리즘을 사용합니다.</li><li>비용은 추가로 발생하지 않습니다.</li></ul></li><li><p><strong>시험 포인트 (AWS Certified ML Engineer Associate)</strong>  </p><ul><li><strong>SSE-S3는 S3가 키를 관리한다</strong>라는 점이 핵심.  </li><li>옵션을 활성화하기만 하면 끝 (운영 편리성 ↑).  </li><li>보안 규제가 강하지 않거나 단순 저장이 목적일 때 적합.</li></ul></li></ul><hr><h2 id="2-SSE-KMS-Server-side-encryption-with-AWS-Key-Management-Service-keys"><a href="#2-SSE-KMS-Server-side-encryption-with-AWS-Key-Management-Service-keys" class="headerlink" title="2. SSE-KMS (Server-side encryption with AWS Key Management Service keys)"></a>2. SSE-KMS (Server-side encryption with AWS Key Management Service keys)</h2><ul><li><p><strong>설명</strong><br>AWS Key Management Service(KMS)를 통해 암호화 키를 관리하는 방식입니다.<br>즉, 암호화 키를 직접 생성, 관리, 권한 제어할 수 있습니다.<br>더 세밀한 보안 관리가 필요한 경우에 사용됩니다.</p></li><li><p><strong>특징</strong></p><ul><li><strong>고객이 키를 직접 관리 (Customer managed keys)</strong> 가능.  </li><li>키 사용에 대한 <strong>CloudTrail 로그</strong>로 추적 가능 → 누가, 언제, 어떤 키를 사용했는지 알 수 있음.  </li><li>IAM 정책을 통해 세밀하게 접근 제어 가능 (예: 특정 사용자만 복호화 가능).  </li><li>KMS 호출 비용이 발생합니다.</li></ul></li><li><p><strong>시험 포인트</strong></p><ul><li><strong>SSE-KMS는 KMS와 통합되어 있어 세밀한 보안·감사 관리 가능</strong>.  </li><li>규제가 있는 산업(금융, 헬스케어 등)에서는 SSE-KMS가 요구될 수 있음.  </li><li>비용과 성능(추가 API 호출)도 고려해야 함.</li></ul></li></ul><hr><h2 id="비교-요약"><a href="#비교-요약" class="headerlink" title="비교 요약"></a>비교 요약</h2><table><thead><tr><th>항목</th><th>SSE-S3</th><th>SSE-KMS</th></tr></thead><tbody><tr><td>키 관리</td><td>Amazon S3 자동 관리</td><td>AWS KMS에서 직접 관리 가능</td></tr><tr><td>보안 수준</td><td>기본적 (단순 암호화)</td><td>고급 (세밀한 제어, 로깅)</td></tr><tr><td>비용</td><td>추가 비용 없음</td><td>KMS 사용 비용 발생</td></tr><tr><td>주요 특징</td><td>가장 간단, 자동 처리</td><td>IAM·CloudTrail 통합, 규제 준수에 적합</td></tr></tbody></table><hr><p>✅ <strong>시험 대비 핵심</strong>  </p><ul><li>SSE-S3: <strong>S3가 키 관리</strong>, 간단, 저비용  </li><li>SSE-KMS: <strong>KMS와 통합</strong>, 세밀한 제어, 감사 로그, 비용 발생</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Amazon-S3-핵심-정리&quot;&gt;&lt;a href=&quot;#Amazon-S3-핵심-정리&quot; class=&quot;headerlink&quot; title=&quot;Amazon S3 핵심 정리&quot;&gt;&lt;/a&gt;Amazon S3 핵심 정리&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;stro</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_ML_ASSOCIATE_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-ML-ASSOCIATE-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
    <category term="AWS_ML_ASSOCIATE" scheme="https://kish191919.github.io/tags/AWS-ML-ASSOCIATE/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS ML Associate (4) - ETL 파이프라인과 데이터 포맷 이해</title>
    <link href="https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-4/"/>
    <id>https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-4/</id>
    <published>2025-09-15T02:06:05.000Z</published>
    <updated>2025-09-15T02:32:58.595Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ETL-파이프라인과-데이터-포맷-이해"><a href="#ETL-파이프라인과-데이터-포맷-이해" class="headerlink" title="ETL 파이프라인과 데이터 포맷 이해"></a>ETL 파이프라인과 데이터 포맷 이해</h1><h2 id="1-ETL-파이프라인이란"><a href="#1-ETL-파이프라인이란" class="headerlink" title="1. ETL 파이프라인이란?"></a>1. ETL 파이프라인이란?</h2><ul><li><strong>ETL</strong>은 <strong>Extract, Transform, Load</strong>의 약자입니다.<br>→ 데이터를 <strong>추출 → 변환 → 적재</strong>하는 일련의 과정.</li><li>주로 **데이터 웨어하우스(DWH)**로 데이터를 옮길 때 사용됩니다.</li><li>데이터 레이크에서는 <strong>ELT</strong>(Extract → Load → Transform) 방식이 더 일반적입니다.</li></ul><hr><h2 id="2-Extract-추출"><a href="#2-Extract-추출" class="headerlink" title="2. Extract (추출)"></a>2. Extract (추출)</h2><ul><li><strong>정의</strong>: 원천 시스템에서 <strong>데이터를 가져오는 단계</strong></li><li><strong>데이터 출처</strong>:<ul><li>데이터베이스 (MySQL, PostgreSQL, Oracle 등)</li><li>CRM (예: Salesforce)</li><li>로그 파일</li><li>API</li><li>스트리밍 데이터 (Kafka, Kinesis 등)</li></ul></li><li><strong>중요 고려사항</strong>:<ul><li>데이터 무결성 보장 (중간에 손실&#x2F;에러 발생 시 재시도 정책 필요)</li><li>처리 방식: <strong>실시간, 근실시간(near real-time), 배치(batch)</strong></li></ul></li></ul><hr><h2 id="3-Transform-변환"><a href="#3-Transform-변환" class="headerlink" title="3. Transform (변환)"></a>3. Transform (변환)</h2><ul><li><strong>정의</strong>: 추출한 데이터를 <strong>분석&#x2F;저장하기 적합한 형태</strong>로 변환</li><li><strong>주요 작업</strong>:<ul><li>데이터 정제 (중복 제거, 오류 수정)</li><li>데이터 보강 (추가 정보 합치기)</li><li>포맷 변경 (문자열 → 날짜 형식 변환 등)</li><li>집계&#x2F;계산 (합계, 평균 등)</li><li>인코딩&#x2F;디코딩 (압축 해제, 암호 해제, 컬럼 포맷 변환 등)</li><li>결측치 처리 (제거, 평균값 대체, null 값 허용 여부 확인)</li></ul></li></ul><p><strong>시험 포인트</strong>:</p><ul><li><strong>결측치 처리 방식</strong>은 머신러닝 모델 품질과 직결 → <strong>평균&#x2F;중앙값 대체, 삭제, 예측 기반 보간(imputation)</strong> 방법 숙지</li><li>SageMaker <strong>Processing Job, Data Wrangler</strong> 같은 서비스 활용법도 시험에 자주 등장</li></ul><hr><h2 id="4-Load-적재"><a href="#4-Load-적재" class="headerlink" title="4. Load (적재)"></a>4. Load (적재)</h2><ul><li><strong>정의</strong>: 변환된 데이터를 **목적지(데이터 웨어하우스, 데이터 레이크 등)**에 저장</li><li><strong>방법</strong>:<ul><li>배치 적재: 일정 주기로 대량 데이터 적재</li><li>스트리밍 적재: 데이터가 들어오는 즉시 적재</li></ul></li><li><strong>중요 고려사항</strong>:<ul><li>적재 시 데이터 무결성 확인</li><li>적재 실패 시 복구 전략 필요</li></ul></li></ul><hr><h2 id="5-ETL-파이프라인-관리"><a href="#5-ETL-파이프라인-관리" class="headerlink" title="5. ETL 파이프라인 관리"></a>5. ETL 파이프라인 관리</h2><p>ETL 과정은 <strong>자동화</strong>와 <strong>오케스트레이션</strong>이 중요합니다.</p><ul><li><strong>AWS Glue</strong> – ETL 작업 자동화 및 스케줄링</li><li><strong>AWS Step Functions</strong> – 워크플로우 관리</li><li><strong>Amazon MWAA (Managed Apache Airflow)</strong> – 복잡한 데이터 파이프라인 관리</li><li><strong>Amazon EventBridge</strong> – 이벤트 기반 트리거</li><li><strong>AWS Lambda</strong> – 서버리스 기반 데이터 처리</li></ul><p><strong>시험 포인트</strong>:</p><ul><li>Glue는 <strong>서버리스 ETL</strong> 서비스, Spark 기반 동작</li><li>Step Functions는 <strong>상태 기반 워크플로우</strong> 관리</li><li>MWAA는 <strong>Apache Airflow 관리형 서비스</strong></li></ul><hr><h2 id="6-주요-데이터-소스-인터페이스"><a href="#6-주요-데이터-소스-인터페이스" class="headerlink" title="6. 주요 데이터 소스 인터페이스"></a>6. 주요 데이터 소스 인터페이스</h2><ul><li><strong>JDBC (Java Database Connectivity)</strong><ul><li>자바 기반, <strong>플랫폼 독립적</strong>, 하지만 <strong>언어(Java) 종속적</strong></li></ul></li><li><strong>ODBC (Open Database Connectivity)</strong><ul><li>드라이버 필요(플랫폼 종속), 하지만 <strong>언어 독립적</strong></li></ul></li><li><strong>API</strong> – 외부 시스템에서 데이터 가져오기</li><li><strong>로그 파일</strong> – 서버 로그, 애플리케이션 로그 등</li><li><strong>스트리밍 데이터</strong> – Kafka, Kinesis 등</li></ul><hr><h2 id="7-데이터-포맷-정리"><a href="#7-데이터-포맷-정리" class="headerlink" title="7. 데이터 포맷 정리"></a>7. 데이터 포맷 정리</h2><h3 id="CSV-Comma-Separated-Values"><a href="#CSV-Comma-Separated-Values" class="headerlink" title="CSV (Comma-Separated Values)"></a>CSV (Comma-Separated Values)</h3><ul><li><strong>특징</strong>: 텍스트 기반, 행 단위 데이터, 구분자는 <code>,</code> 또는 <code>\t</code></li><li><strong>장점</strong>: 사람이 읽기 쉬움, 이식성 높음</li><li><strong>단점</strong>: 대규모 데이터 처리 시 비효율적</li><li><strong>시험 포인트</strong>: Pandas, R, Excel 등에서 손쉽게 처리 가능</li></ul><h3 id="JSON-JavaScript-Object-Notation"><a href="#JSON-JavaScript-Object-Notation" class="headerlink" title="JSON (JavaScript Object Notation)"></a>JSON (JavaScript Object Notation)</h3><ul><li><strong>특징</strong>: 키-값 기반, <strong>반정형(semi-structured) 데이터</strong> 표현 가능</li><li><strong>장점</strong>: 유연한 스키마, 중첩 구조 지원</li><li><strong>활용</strong>: API 응답, 설정 파일, NoSQL DB(MongoDB 등)</li></ul><h3 id="Avro"><a href="#Avro" class="headerlink" title="Avro"></a>Avro</h3><ul><li><strong>특징</strong>: 바이너리 포맷, 데이터와 스키마를 함께 저장</li><li><strong>장점</strong>: 효율적인 직렬화(Serialization), <strong>스키마 진화(schema evolution)</strong> 지원</li><li><strong>활용</strong>: Kafka, Spark, Flink, Hadoop</li></ul><h3 id="Parquet"><a href="#Parquet" class="headerlink" title="Parquet"></a>Parquet</h3><ul><li><strong>특징</strong>: <strong>컬럼 지향(columnar)</strong> 저장 포맷</li><li><strong>장점</strong>: 특정 컬럼만 읽기 가능 → 대규모 분석에 최적화</li><li><strong>활용</strong>: Redshift Spectrum, Spark, Hive, Athena</li><li><strong>시험 포인트</strong>: <strong>분석용 최적화 포맷</strong>으로 자주 언급됨</li></ul><hr><h2 id="8-시험-대비-요약"><a href="#8-시험-대비-요약" class="headerlink" title="8. 시험 대비 요약"></a>8. 시험 대비 요약</h2><ul><li><strong>ETL vs ELT</strong>: DWH는 ETL, Data Lake는 ELT</li><li><strong>데이터 포맷 특징 비교</strong>: CSV(단순), JSON(유연), Avro(스키마 포함), Parquet(분석 최적화)</li><li><strong>AWS Glue, Step Functions, MWAA</strong>: ETL 관리 핵심 서비스</li><li><strong>스키마 온 라이트(schema-on-write)</strong> vs <strong>스키마 온 리드(schema-on-read)</strong>: 시험 단골</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ETL-파이프라인과-데이터-포맷-이해&quot;&gt;&lt;a href=&quot;#ETL-파이프라인과-데이터-포맷-이해&quot; class=&quot;headerlink&quot; title=&quot;ETL 파이프라인과 데이터 포맷 이해&quot;&gt;&lt;/a&gt;ETL 파이프라인과 데이터 포맷 이해&lt;/h1&gt;&lt;</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_ML_ASSOCIATE_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-ML-ASSOCIATE-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
    <category term="AWS_ML_ASSOCIATE" scheme="https://kish191919.github.io/tags/AWS-ML-ASSOCIATE/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS ML Associate (3) - 데이터의 세 가지 유형</title>
    <link href="https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-3/"/>
    <id>https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-3/</id>
    <published>2025-09-15T01:55:59.000Z</published>
    <updated>2025-09-15T04:13:20.934Z</updated>
    
    <content type="html"><![CDATA[<h1 id="데이터-웨어하우스-데이터-레이크-데이터-레이크하우스-데이터-메시-정리"><a href="#데이터-웨어하우스-데이터-레이크-데이터-레이크하우스-데이터-메시-정리" class="headerlink" title="데이터 웨어하우스, 데이터 레이크, 데이터 레이크하우스, 데이터 메시 정리"></a>데이터 웨어하우스, 데이터 레이크, 데이터 레이크하우스, 데이터 메시 정리</h1><h2 id="1-데이터-웨어하우스-Data-Warehouse"><a href="#1-데이터-웨어하우스-Data-Warehouse" class="headerlink" title="1. 데이터 웨어하우스 (Data Warehouse)"></a>1. 데이터 웨어하우스 (Data Warehouse)</h2><p><strong>정의</strong><br>데이터 웨어하우스는 <strong>여러 소스에서 수집된 데이터를 정제(ETL)하여 구조화된 형태로 저장</strong>하는 중앙 저장소입니다. 주로 분석과 BI(Business Intelligence)에 최적화되어 있습니다.</p><p><strong>특징</strong></p><ul><li>복잡한 쿼리와 분석 작업에 최적화  </li><li>사전에 스키마(schema)를 정의하고 데이터를 적재 (Schema-on-Write)  </li><li>주로 <strong>Star Schema</strong> 또는 <strong>Snowflake Schema</strong> 사용  </li><li>읽기(Read) 중심의 워크로드에 강함</li></ul><p><strong>예시</strong></p><ul><li>AWS: <strong>Amazon Redshift</strong>  </li><li>(비교) Google BigQuery, Azure Synapse</li></ul><p><strong>시험 포인트</strong></p><ul><li><strong>ETL (Extract → Transform → Load)</strong> 과정이 중요  </li><li>데이터 웨어하우스는 <strong>구조화된 데이터(Structured Data)</strong> 중심이라는 점 기억하기</li></ul><hr><h2 id="2-데이터-레이크-Data-Lake"><a href="#2-데이터-레이크-Data-Lake" class="headerlink" title="2. 데이터 레이크 (Data Lake)"></a>2. 데이터 레이크 (Data Lake)</h2><p><strong>정의</strong><br>데이터 레이크는 <strong>정형, 반정형, 비정형 데이터를 원본 그대로 저장</strong>하는 저장소입니다.  </p><p><strong>특징</strong></p><ul><li>데이터는 <strong>사전 스키마 정의 없이 원본(raw)</strong> 형태로 저장 (Schema-on-Read)  </li><li>대규모 데이터 저장에 유리 (저비용, 확장성)  </li><li>배치, 실시간, 스트리밍 데이터 모두 수용 가능  </li><li>필요할 때 데이터를 변환(ELT)하여 분석</li></ul><p><strong>예시</strong></p><ul><li>AWS: <strong>Amazon S3 (데이터 레이크로 사용)</strong>  </li><li>Azure Data Lake Storage, HDFS</li></ul><p><strong>시험 포인트</strong></p><ul><li>데이터 레이크는 <strong>ELT (Extract → Load → Transform)</strong> 방식  </li><li>로그 데이터, IoT 센서 데이터, 소셜 미디어 데이터 등 <strong>다양한 원천 데이터</strong> 저장 가능</li></ul><hr><h2 id="3-데이터-웨어하우스-vs-데이터-레이크"><a href="#3-데이터-웨어하우스-vs-데이터-레이크" class="headerlink" title="3. 데이터 웨어하우스 vs 데이터 레이크"></a>3. 데이터 웨어하우스 vs 데이터 레이크</h2><table><thead><tr><th>구분</th><th>데이터 웨어하우스</th><th>데이터 레이크</th></tr></thead><tbody><tr><td>스키마</td><td>Schema-on-Write (사전 정의)</td><td>Schema-on-Read (읽을 때 정의)</td></tr><tr><td>처리 방식</td><td>ETL</td><td>ELT 또는 단순 적재</td></tr><tr><td>데이터 형태</td><td>구조화된 데이터 중심</td><td>정형 + 비정형 모두</td></tr><tr><td>민첩성</td><td>낮음 (스키마 변경 어려움)</td><td>높음 (원본 그대로 저장)</td></tr><tr><td>비용</td><td>상대적으로 비쌈</td><td>저비용, 대규모 저장에 적합</td></tr></tbody></table><p><strong>시험에 자주 나오는 포인트</strong>  </p><ul><li>Redshift &#x3D; Data Warehouse  </li><li>S3 &#x3D; Data Lake  </li><li>Schema-on-Write ↔ Schema-on-Read 차이를 꼭 기억</li></ul><hr><h2 id="4-데이터-레이크하우스-Data-Lakehouse"><a href="#4-데이터-레이크하우스-Data-Lakehouse" class="headerlink" title="4. 데이터 레이크하우스 (Data Lakehouse)"></a>4. 데이터 레이크하우스 (Data Lakehouse)</h2><p><strong>정의</strong><br>데이터 웨어하우스와 데이터 레이크의 장점을 결합한 <strong>하이브리드 아키텍처</strong>입니다.  </p><p><strong>특징</strong></p><ul><li>정형 + 비정형 데이터 모두 지원  </li><li>Schema-on-Write, Schema-on-Read 모두 가능  </li><li>고성능 분석 + 머신러닝 활용 가능  </li><li>ACID 트랜잭션 보장 (데이터 정합성 유지)</li></ul><p><strong>예시</strong></p><ul><li>AWS: <strong>Lake Formation + S3 + Redshift Spectrum</strong>  </li><li>Databricks Lakehouse (Delta Lake)  </li><li>Azure Synapse Analytics</li></ul><p><strong>시험 포인트</strong></p><ul><li><strong>Lakehouse &#x3D; 데이터 분석(웨어하우스) + 머신러닝&#x2F;유연성(레이크) 결합</strong>  </li><li>Redshift Spectrum: <strong>S3에 저장된 데이터</strong>를 Redshift에서 직접 쿼리</li></ul><hr><h1 id="ACID-트랜잭션-보장"><a href="#ACID-트랜잭션-보장" class="headerlink" title="ACID 트랜잭션 보장"></a>ACID 트랜잭션 보장</h1><h2 id="1-Atomicity-원자성"><a href="#1-Atomicity-원자성" class="headerlink" title="1. Atomicity (원자성)"></a>1. Atomicity (원자성)</h2><ul><li>하나의 트랜잭션은 <strong>모두 실행되거나 전혀 실행되지 않아야 함</strong>을 의미합니다.</li><li>중간에 실패하면 이전까지 실행된 작업도 모두 롤백(취소)되어야 합니다</li><li>예: A 계좌에서 B 계좌로 10만원 송금 → A에서 출금만 되고 B에 입금이 안 되면 안 됨. 둘 다 실행되거나 둘 다 실행되지 않아야 함.</li></ul><h2 id="2-Consistency-일관성"><a href="#2-Consistency-일관성" class="headerlink" title="2. Consistency (일관성)"></a>2. Consistency (일관성)</h2><ul><li>트랜잭션 실행 전후에 <strong>데이터베이스의 제약조건과 규칙이 항상 지켜져야 함</strong>을 의미합니다.</li><li>잘못된 데이터 상태를 허용하지 않습니다.</li><li>예: 은행 계좌 잔액이 음수가 되면 안 된다는 규칙이 있을 때, 트랜잭션이 끝난 후에도 이 규칙은 항상 지켜져야 함.</li></ul><h2 id="3-Isolation-격리성"><a href="#3-Isolation-격리성" class="headerlink" title="3. Isolation (격리성)"></a>3. Isolation (격리성)</h2><ul><li>동시에 여러 트랜잭션이 실행되더라도 <strong>서로 간섭하지 않아야 함</strong>을 의미합니다.</li><li>마치 트랜잭션이 순차적으로 실행된 것처럼 결과가 나와야 합니다.</li><li>예: 두 사람이 동시에 같은 좌석을 예매할 때, 둘 다 예매 성공이 되면 안 됨. 하나는 성공, 하나는 실패해야 함.</li></ul><h2 id="4-Durability-지속성"><a href="#4-Durability-지속성" class="headerlink" title="4. Durability (지속성)"></a>4. Durability (지속성)</h2><ul><li>트랜잭션이 성공적으로 완료되면, 그 결과는 <strong>시스템 장애가 발생하더라도 영구적으로 보존</strong>되어야 합니다.</li><li>예: 돈을 이체하고 “성공” 메시지를 받았다면, 서버가 다운되더라도 그 결과는 반드시 반영되어 있어야 함.</li></ul><hr><h1 id="ACID와-분산-시스템-시험에-자주-나오는-부분"><a href="#ACID와-분산-시스템-시험에-자주-나오는-부분" class="headerlink" title="ACID와 분산 시스템 (시험에 자주 나오는 부분)"></a>ACID와 분산 시스템 (시험에 자주 나오는 부분)</h1><ul><li>전통적인 관계형 데이터베이스(RDBMS: MySQL, PostgreSQL, Oracle 등)는 ACID를 강하게 보장합니다.</li><li>하지만 **분산 시스템(빅데이터, NoSQL, 클라우드 환경)**에서는 성능과 확장성을 위해 일부 ACID 특성을 완화하기도 합니다.<ul><li>예: DynamoDB, Cassandra 같은 NoSQL DB는 완전한 ACID 대신 <strong>Eventually Consistent (최종 일관성)</strong> 모델을 제공하기도 함.</li></ul></li><li>최근에는 <strong>데이터 레이크&#x2F;레이크하우스 환경</strong>에서도 <strong>Delta Lake, Apache Iceberg, AWS Lake Formation</strong> 같은 기술이 <strong>ACID 트랜잭션 보장</strong>을 지원하면서, 대규모 분석 환경에서도 안정성을 확보할 수 있게 되었습니다.</li></ul><hr><h1 id="시험-포인트-AWS-Certified-ML-Engineer-Associate"><a href="#시험-포인트-AWS-Certified-ML-Engineer-Associate" class="headerlink" title="시험 포인트 (AWS Certified ML Engineer Associate)"></a>시험 포인트 (AWS Certified ML Engineer Associate)</h1><ol><li><strong>데이터 웨어하우스(Redshift)</strong> → ACID 보장 (RDBMS 기반).</li><li><strong>데이터 레이크(S3)</strong> → 원래는 ACID 보장 없음 → <strong>Delta Lake, Lake Formation</strong> 등을 통해 ACID 보장 추가 가능.</li><li><strong>트랜잭션 실패 시 롤백 &#x2F; 시스템 장애 시 지속성 보장</strong> 같은 개념이 시험에서 자주 언급됨.</li></ol><hr><h2 id="5-데이터-메시-Data-Mesh"><a href="#5-데이터-메시-Data-Mesh" class="headerlink" title="5. 데이터 메시 (Data Mesh)"></a>5. 데이터 메시 (Data Mesh)</h2><p><strong>정의</strong><br>데이터 메시(Data Mesh)는 <strong>특정 기술이 아니라 조직의 데이터 관리 방식</strong>을 의미합니다.  </p><p align="center">  <img src="/images/aws-ml-01.png" width="80%"></p><p><strong>핵심 개념</strong></p><ul><li><strong>도메인 기반 데이터 관리</strong>: 각 팀&#x2F;부서가 자기 데이터에 대한 “소유권”과 “책임”을 가짐  </li><li>데이터는 <strong>데이터 제품(Data Product)</strong> 형태로 다른 팀과 공유  </li><li>중앙에서 표준화된 거버넌스 제공 (보안, 품질, 권한 관리)  </li><li>AWS Glue Data Catalog, Lake Formation 등을 이용해 구현 가능</li></ul><p><strong>시험 포인트</strong></p><ul><li>시험에서는 “데이터 메시 &#x3D; 조직적&#x2F;운영적 개념”이라는 점을 구분해야 함  </li><li>“데이터 웨어하우스&#x2F;레이크&#x2F;레이크하우스”는 <strong>기술적 개념</strong>, “데이터 메시”는 <strong>조직적 패러다임</strong></li></ul><hr><h2 id="6-정리-–-언제-무엇을-쓸까"><a href="#6-정리-–-언제-무엇을-쓸까" class="headerlink" title="6. 정리 – 언제 무엇을 쓸까?"></a>6. 정리 – 언제 무엇을 쓸까?</h2><ul><li><p><strong>데이터 웨어하우스</strong>  </p><ul><li>정형 데이터  </li><li>빠르고 복잡한 쿼리  </li><li>BI&#x2F;리포팅 중심</li></ul></li><li><p><strong>데이터 레이크</strong>  </p><ul><li>정형 + 비정형 데이터 혼합  </li><li>머신러닝&#x2F;고급 분석 준비  </li><li>비용 효율적 저장소</li></ul></li><li><p><strong>데이터 레이크하우스</strong>  </p><ul><li>분석 + 머신러닝 모두 지원  </li><li>유연성 + 성능 모두 필요할 때</li></ul></li><li><p><strong>데이터 메시</strong>  </p><ul><li>조직 규모가 크고, 여러 부서가 데이터 관리  </li><li>팀별 데이터 소유권과 중앙 거버넌스 결합</li></ul></li></ul><hr><p>👉 <strong>시험 대비 핵심 키워드</strong>  </p><ul><li><strong>Schema-on-Write (Warehouse)</strong>  </li><li><strong>Schema-on-Read (Lake)</strong>  </li><li><strong>ETL ↔ ELT 차이</strong>  </li><li><strong>Redshift &#x3D; Data Warehouse &#x2F; S3 &#x3D; Data Lake</strong>  </li><li><strong>Redshift Spectrum &#x3D; Lakehouse 활용 예시</strong>  </li><li><strong>Data Mesh &#x3D; 기술이 아닌 조직적 거버넌스 패러다임</strong></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;데이터-웨어하우스-데이터-레이크-데이터-레이크하우스-데이터-메시-정리&quot;&gt;&lt;a href=&quot;#데이터-웨어하우스-데이터-레이크-데이터-레이크하우스-데이터-메시-정리&quot; class=&quot;headerlink&quot; title=&quot;데이터 웨어하우스, 데이터 레</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_ML_ASSOCIATE_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-ML-ASSOCIATE-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
    <category term="AWS_ML_ASSOCIATE" scheme="https://kish191919.github.io/tags/AWS-ML-ASSOCIATE/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS ML Associate (2) - 데이터의 세 가지 유형</title>
    <link href="https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-2/"/>
    <id>https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-2/</id>
    <published>2025-09-15T01:41:19.000Z</published>
    <updated>2025-09-15T02:05:30.557Z</updated>
    
    <content type="html"><![CDATA[<h1 id="데이터-엔지니어링-기초"><a href="#데이터-엔지니어링-기초" class="headerlink" title="데이터 엔지니어링 기초"></a>데이터 엔지니어링 기초</h1><p>이번 섹션은 AWS 서비스 자체보다는 <strong>데이터 엔지니어링의 기초 개념</strong>에 초점을 둡니다.<br>시험 가이드에서도 AWS 서비스뿐 아니라 데이터 관련 기본 개념을 알아야 한다고 명시되어 있습니다.  </p><hr><h2 id="1-데이터의-세-가지-유형"><a href="#1-데이터의-세-가지-유형" class="headerlink" title="1. 데이터의 세 가지 유형"></a>1. 데이터의 세 가지 유형</h2><h3 id="①-구조화-데이터-Structured-Data"><a href="#①-구조화-데이터-Structured-Data" class="headerlink" title="① 구조화 데이터 (Structured Data)"></a>① 구조화 데이터 (Structured Data)</h3><ul><li><strong>정의</strong>: 미리 정의된 스키마(열, 자료형 등)에 맞춰 정리된 데이터  </li><li><strong>특징</strong>: SQL로 쉽게 질의 가능, 행&#x2F;열 구조로 일관성 있음  </li><li><strong>예시</strong>:  <ul><li>관계형 데이터베이스 (MySQL, PostgreSQL, Amazon RDS, Amazon Redshift)  </li><li>잘 정리된 CSV 파일  </li><li>전형적인 엑셀 시트</li></ul></li></ul><p>👉 <strong>시험 포인트</strong>: RDB vs 데이터 레이크 차이를 구분해야 함. Redshift(OLAP)와 S3 기반 데이터 레이크 차이를 물을 수 있음.  </p><hr><h3 id="②-비구조화-데이터-Unstructured-Data"><a href="#②-비구조화-데이터-Unstructured-Data" class="headerlink" title="② 비구조화 데이터 (Unstructured Data)"></a>② 비구조화 데이터 (Unstructured Data)</h3><ul><li><strong>정의</strong>: 스키마가 없거나 일정하지 않은 데이터  </li><li><strong>특징</strong>: 바로 질의할 수 없음. 전처리&#x2F;메타데이터 추출 필요  </li><li><strong>예시</strong>:  <ul><li>텍스트 문서 (위키 문서, 전자책 등)  </li><li>오디오, 동영상, 이미지 파일  </li><li>이메일, 워드 문서</li></ul></li></ul><p>👉 <strong>시험 포인트</strong>: 이미지&#x2F;영상&#x2F;텍스트 → Amazon Rekognition, Transcribe, Comprehend 같은 서비스 활용.  </p><hr><h3 id="③-반구조화-데이터-Semi-structured-Data"><a href="#③-반구조화-데이터-Semi-structured-Data" class="headerlink" title="③ 반구조화 데이터 (Semi-structured Data)"></a>③ 반구조화 데이터 (Semi-structured Data)</h3><ul><li><strong>정의</strong>: 완전한 스키마는 없지만, 태그&#x2F;계층 구조 등 일부 구조적 특징 존재  </li><li><strong>예시</strong>:  <ul><li>JSON, XML  </li><li>로그 파일 (웹 서버 로그, 애플리케이션 로그 등)  </li><li>이메일 헤더</li></ul></li></ul><p>👉 <strong>시험 포인트</strong>: JSON&#x2F;로그 → Amazon Athena, Glue, OpenSearch로 쿼리 가능.  </p><hr><h2 id="2-데이터의-특성-–-3V-시험-중요"><a href="#2-데이터의-특성-–-3V-시험-중요" class="headerlink" title="2. 데이터의 특성 – 3V (시험 중요!)"></a>2. 데이터의 특성 – 3V (시험 중요!)</h2><p>AWS 시험에서 자주 등장하는 개념: <strong>데이터의 3V</strong><br>(Volume, Velocity, Variety)  </p><h3 id="①-Volume-데이터-양"><a href="#①-Volume-데이터-양" class="headerlink" title="① Volume (데이터 양)"></a>① Volume (데이터 양)</h3><ul><li><strong>정의</strong>: 데이터의 크기  </li><li><strong>예시</strong>:  <ul><li>SNS → 하루 수 TB 이상  </li><li>대형 리테일러 → 수년간 거래 기록 수 PB</li></ul></li><li><strong>AWS 관련 서비스</strong>:  <ul><li>대용량 마이그레이션 → <strong>Snowball, Snowmobile</strong>  </li><li>스토리지 → <strong>Amazon S3, EFS, FSx</strong></li></ul></li></ul><hr><h3 id="②-Velocity-데이터-생성-처리-속도"><a href="#②-Velocity-데이터-생성-처리-속도" class="headerlink" title="② Velocity (데이터 생성&#x2F;처리 속도)"></a>② Velocity (데이터 생성&#x2F;처리 속도)</h3><ul><li><strong>정의</strong>: 데이터가 생성&#x2F;수집&#x2F;처리되는 속도  </li><li><strong>예시</strong>:  <ul><li>IoT 센서 → 매 ms 단위 데이터 스트리밍  </li><li>주식 고빈도 거래(HFT) → 실시간 처리 필수</li></ul></li><li><strong>AWS 관련 서비스</strong>:  <ul><li>실시간 스트리밍 → <strong>Kinesis Data Streams</strong>  </li><li>근실시간(near real-time) 배치 → <strong>Kinesis Firehose, AWS Glue streaming ETL</strong></li></ul></li></ul><p>👉 <strong>시험 포인트</strong>: “실시간(real-time)” vs “근실시간(near real-time)” 서비스 구분 문제 자주 나옴.  </p><hr><h3 id="③-Variety-데이터-다양성"><a href="#③-Variety-데이터-다양성" class="headerlink" title="③ Variety (데이터 다양성)"></a>③ Variety (데이터 다양성)</h3><ul><li><strong>정의</strong>: 데이터의 형태와 출처의 다양성  </li><li><strong>예시</strong>:  <ul><li>구조화: 관계형 DB (RDS, Redshift)  </li><li>반구조화: JSON 로그 (CloudTrail 로그 등)  </li><li>비구조화: 환자 피드백 텍스트, 의료 영상</li></ul></li><li><strong>AWS 관련 서비스</strong>:  <ul><li>다양한 포맷 저장&#x2F;분석 → <strong>Lake Formation, Glue, Athena</strong></li></ul></li></ul><hr><h2 id="3-추가로-알아두면-좋은-개념"><a href="#3-추가로-알아두면-좋은-개념" class="headerlink" title="3. 추가로 알아두면 좋은 개념"></a>3. 추가로 알아두면 좋은 개념</h2><ul><li><p><strong>Veracity (진실성, 정확성)</strong>  </p><ul><li>공식 시험 가이드엔 없지만, 데이터의 신뢰성과 품질을 뜻함.  </li><li>AWS Glue DataBrew, SageMaker Data Wrangler를 통해 데이터 정제 가능.</li></ul></li><li><p><strong>데이터 품질 관리</strong>  </p><ul><li>Completeness(완전성), Accuracy(정확성), Consistency(일관성) 등은 시험에서 자주 출제.</li></ul></li><li><p><strong>로그와 반구조화 데이터 처리</strong>  </p><ul><li>CloudWatch Logs + Athena로 쿼리  </li><li>OpenSearch로 검색 및 분석</li></ul></li></ul><hr><h2 id="정리-시험-대비-포인트"><a href="#정리-시험-대비-포인트" class="headerlink" title="정리 (시험 대비 포인트)"></a>정리 (시험 대비 포인트)</h2><ul><li><p><strong>세 가지 데이터 유형</strong>  </p><ul><li>Structured (SQL 질의 가능)  </li><li>Semi-structured (JSON&#x2F;로그, 일부 구조)  </li><li>Unstructured (텍스트&#x2F;영상&#x2F;오디오, 전처리 필요)</li></ul></li><li><p><strong>데이터의 3V</strong>  </p><ul><li>Volume → 크기 (S3, Snowball)  </li><li>Velocity → 속도 (Kinesis, Firehose)  </li><li>Variety → 다양성 (RDS, S3, Glue, Athena 등)</li></ul></li><li><p><strong>시험에서 잘 나오는 부분</strong>  </p><ul><li>Kinesis Data Streams vs Firehose 차이  </li><li>Snowball vs Snowmobile 선택 기준  </li><li>데이터 레이크 vs 데이터 웨어하우스 (S3 + Athena vs Redshift)  </li><li>Glue &#x2F; Data Wrangler &#x2F; EMR 비교</li></ul></li></ul><hr><p>👉 이 섹션은 AWS 서비스 자체보다는 <strong>데이터 엔지니어링 기초 개념을 AWS 환경에 어떻게 적용하는지</strong> 묻는 문제가 출제될 가능성이 큽니다.  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;데이터-엔지니어링-기초&quot;&gt;&lt;a href=&quot;#데이터-엔지니어링-기초&quot; class=&quot;headerlink&quot; title=&quot;데이터 엔지니어링 기초&quot;&gt;&lt;/a&gt;데이터 엔지니어링 기초&lt;/h1&gt;&lt;p&gt;이번 섹션은 AWS 서비스 자체보다는 &lt;strong&gt;데</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_ML_ASSOCIATE_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-ML-ASSOCIATE-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
    <category term="AWS_ML_ASSOCIATE" scheme="https://kish191919.github.io/tags/AWS-ML-ASSOCIATE/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS ML Associate (1) - AWS ML 엔지니어 어소시에이트(MLA-C01) 한눈에 보기</title>
    <link href="https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-1/"/>
    <id>https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-1/</id>
    <published>2025-09-14T20:54:26.000Z</published>
    <updated>2025-09-14T21:05:52.193Z</updated>
    
    <content type="html"><![CDATA[<h1 id="AWS-ML-엔지니어-어소시에이트-MLA-C01-한눈에-보기"><a href="#AWS-ML-엔지니어-어소시에이트-MLA-C01-한눈에-보기" class="headerlink" title="AWS ML 엔지니어 어소시에이트(MLA-C01) 한눈에 보기"></a>AWS ML 엔지니어 어소시에이트(MLA-C01) 한눈에 보기</h1><p>이 과정에서는 <strong>데이터 수집→변환&#x2F;특징공학→모델 학습&#x2F;튜닝&#x2F;평가→생성형 AI→MLOps→보안&#x2F;거버넌스</strong>까지 실무 흐름을 따라가며, <strong>SageMaker 중심</strong>으로 AWS 서비스들을 연결해 이해합니다.</p><blockquote><h3 id="시험-포인트"><a href="#시험-포인트" class="headerlink" title="시험 포인트"></a>시험 포인트</h3><ul><li><strong>SageMaker 전반</strong>(Processing&#x2F;Training&#x2F;Inference&#x2F;Deployment)</li><li><strong>Glue, EMR, Kinesis, S3, EFS, EBS</strong> 활용</li><li><strong>데이터 변환·특징공학 기법</strong> (결측치, 이상치, 불균형 데이터 처리)</li><li><strong>기본 ML 알고리즘</strong> (XGBoost, Linear Learner 등 SageMaker 내장 알고리즘)</li><li><strong>성능 측정 지표</strong> (Precision, Recall, F1-score, Accuracy 등)</li><li><strong>하이퍼파라미터 튜닝</strong> (SageMaker Automatic Model Tuning)</li><li><strong>Bedrock, Jumpstart, RAG, Guardrails</strong> 등 생성형 AI 관련 신기능</li><li><strong>MLOps</strong> (CI&#x2F;CD, 파이프라인, 버전 관리, 모니터링, 재학습)</li><li><strong>보안·컴플라이언스</strong> (IAM, KMS, VPC, CloudTrail, Config 등)</li></ul></blockquote><hr><h2 id="1-데이터-수집-저장"><a href="#1-데이터-수집-저장" class="headerlink" title="1. 데이터 수집 &amp; 저장"></a>1. 데이터 수집 &amp; 저장</h2><ul><li><strong>형식</strong>: 정형&#x2F;비정형 데이터 (CSV, JSON, 이미지, 로그 등)</li><li><strong>저장소</strong>: <ul><li><strong>데이터 웨어하우스</strong>: Redshift</li><li><strong>데이터 레이크</strong>: S3</li><li><strong>데이터 레이크하우스</strong>: Lake Formation</li></ul></li><li><strong>스트리밍</strong>: Amazon Kinesis</li><li><strong>파일 스토리지</strong>: EFS, FSx</li><li><strong>블록 스토리지</strong>: EBS</li></ul><hr><h2 id="2-데이터-변환-특징공학"><a href="#2-데이터-변환-특징공학" class="headerlink" title="2. 데이터 변환 &amp; 특징공학"></a>2. 데이터 변환 &amp; 특징공학</h2><ul><li><strong>EMR</strong>: Hadoop, Spark 기반 대규모 데이터 처리</li><li><strong>결측치&#x2F;이상치 처리, 불균형 데이터 처리</strong></li><li><strong>SageMaker Processing, Data Wrangler</strong> 활용</li><li><strong>AWS Glue</strong>: ETL 파이프라인 자동화</li></ul><hr><h2 id="3-모델-학습-튜닝-평가"><a href="#3-모델-학습-튜닝-평가" class="headerlink" title="3. 모델 학습 &amp; 튜닝 &amp; 평가"></a>3. 모델 학습 &amp; 튜닝 &amp; 평가</h2><ul><li><strong>내장 알고리즘</strong>: XGBoost, Linear Learner, K-means, PCA 등</li><li><strong>딥러닝 기초</strong>: 뉴럴 네트워크, 옵티마이저, 학습률, 활성화 함수</li><li><strong>성능 지표</strong>: Precision, Recall, F1-score, Accuracy</li><li><strong>튜닝</strong>: SageMaker Automatic Model Tuning (Hyperparameter Optimization)</li></ul><hr><h2 id="4-생성형-AI"><a href="#4-생성형-AI" class="headerlink" title="4. 생성형 AI"></a>4. 생성형 AI</h2><ul><li><strong>Bedrock</strong>: 여러 파운데이션 모델 API 제공</li><li><strong>RAG (Retrieval Augmented Generation)</strong>: 외부 데이터 결합, 벡터 DB 활용</li><li><strong>Jumpstart</strong>: 사전 학습된 모델 빠른 활용</li><li><strong>Guardrails</strong>: 유해 콘텐츠 차단, PII 보호</li><li><strong>LLM Agent</strong>: 사용자 정의 툴과 코드 연동</li></ul><hr><h2 id="5-MLOps"><a href="#5-MLOps" class="headerlink" title="5. MLOps"></a>5. MLOps</h2><ul><li><strong>버전 관리</strong>: 데이터, 코드, 모델</li><li><strong>자동화</strong>: 데이터 수집, 전처리, 학습, 배포 파이프라인</li><li><strong>CI&#x2F;CD</strong>: CodePipeline, CodeBuild, CodeDeploy</li><li><strong>컨테이너화</strong>: EKS, ECR</li><li><strong>모니터링</strong>: CloudWatch, Model Monitor</li><li><strong>재학습</strong>: 지속적인 데이터 반영</li></ul><hr><h2 id="6-보안-거버넌스"><a href="#6-보안-거버넌스" class="headerlink" title="6. 보안 &amp; 거버넌스"></a>6. 보안 &amp; 거버넌스</h2><ul><li><strong>Shared Responsibility Model</strong><ul><li>AWS: 클라우드 인프라 보안</li><li>고객: 데이터, 접근 제어, 암호화</li></ul></li><li><strong>보안 서비스</strong>: IAM, KMS, Secrets Manager, Macie, WAF, Shield</li><li><strong>네트워크 보안</strong>: VPC, PrivateLink</li><li><strong>거버넌스 &amp; 비용 관리</strong>: CloudTrail, Config, Trusted Advisor, Budgets, Cost Explorer</li><li><strong>Well-Architected ML Lens</strong>: 모범 아키텍처 가이드라인</li></ul><hr><h2 id="시험-준비-팁"><a href="#시험-준비-팁" class="headerlink" title="시험 준비 팁"></a>시험 준비 팁</h2><ul><li>기출 및 유사 시험: <strong>ML Specialty, Data Engineer Associate</strong>와 겹치는 부분 많음</li><li>실제 경험 없어도 **핸즈온 랩(SageMaker Notebooks)**을 활용해 체험 필수</li><li>핵심 서비스: <strong>SageMaker, Bedrock, Glue, EMR, Kinesis, S3</strong></li><li>ML 기본기 (알고리즘, 지표, 전처리 기법) 반드시 숙지</li></ul><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;AWS-ML-엔지니어-어소시에이트-MLA-C01-한눈에-보기&quot;&gt;&lt;a href=&quot;#AWS-ML-엔지니어-어소시에이트-MLA-C01-한눈에-보기&quot; class=&quot;headerlink&quot; title=&quot;AWS ML 엔지니어 어소시에이트(MLA-C01</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_ML_ASSOCIATE_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-ML-ASSOCIATE-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
    <category term="AWS_ML_ASSOCIATE" scheme="https://kish191919.github.io/tags/AWS-ML-ASSOCIATE/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (41) - 거버넌스 &amp; 컴플라이언스의 중요성</title>
    <link href="https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-41/"/>
    <id>https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-41/</id>
    <published>2025-09-02T19:29:55.000Z</published>
    <updated>2025-09-02T19:55:57.955Z</updated>
    
    <content type="html"><![CDATA[<h1 id="거버넌스-컴플라이언스의-중요성"><a href="#거버넌스-컴플라이언스의-중요성" class="headerlink" title="거버넌스 &amp; 컴플라이언스의 중요성"></a>거버넌스 &amp; 컴플라이언스의 중요성</h1><ul><li><strong>조직의 AI 이니셔티브를 관리·최적화·확장</strong>하기 위한 기본 토대</li><li><strong>신뢰 구축</strong>: 책임 있는 AI 운영을 통해 내부·외부 이해관계자의 신뢰 확보</li><li><strong>위험 완화</strong>: 편향, 프라이버시 침해, 의도치 않은 결과 등</li><li><strong>정책·가이드·감독 체계</strong>로 법·규제 정합성 확보</li><li><strong>법적·평판 리스크</strong> 예방, <strong>대중 신뢰</strong> 제고</li></ul><blockquote><p>📌 <strong>시험 포인트(AWS&#x2F;클라우드 공통)</strong></p><ul><li>“책임 있는 AI(Responsible AI)”는 <strong>정책·감독·모니터링</strong>을 AI 수명주기 전반(설계→개발→배포→운영)에서 수행하는 것을 뜻함.</li><li><strong>공공·금융·의료</strong> 등은 규제 요건(감사·보관·추적성)이 강화됨.</li></ul></blockquote><hr><h1 id="거버넌스-프레임워크-예시"><a href="#거버넌스-프레임워크-예시" class="headerlink" title="거버넌스 프레임워크(예시)"></a>거버넌스 프레임워크(예시)</h1><ol><li><strong>AI 거버넌스 위원회 구성</strong><ul><li>법무, 컴플라이언스, 보안&#x2F;개인정보, 데이터, AI 개발 <strong>SME</strong>가 참여</li></ul></li><li><strong>역할과 책임 정의</strong><ul><li><strong>정책수립</strong>, <strong>리스크 평가</strong>, <strong>승인&#x2F;결정 절차</strong> 명확화</li></ul></li><li><strong>정책·프로세스 수립</strong><ul><li>데이터 관리 → 모델 개발&#x2F;검증 → <strong>배포&#x2F;모니터링</strong>까지 <strong>전 수명주기 표준화</strong></li></ul></li></ol><blockquote><p>🧩 <strong>AWS에서 도움 되는 서비스 예시</strong></p><ul><li><strong>AWS Config</strong>(설정 준수 추적), <strong>CloudTrail</strong>(감사 로그), <strong>Inspector</strong>(취약점), <strong>Audit Manager</strong>(감사용 증적 수집), <strong>Artifact</strong>(컴플라이언스 자료), <strong>Trusted Advisor</strong>(보안&#x2F;비용 권고).</li></ul></blockquote><p align="center">  <img src="/images/aws_basic_209.png" width="80%"></p><hr><h1 id="거버넌스-실행-전략"><a href="#거버넌스-실행-전략" class="headerlink" title="거버넌스 실행 전략"></a>거버넌스 실행 전략</h1><h2 id="1-정책"><a href="#1-정책" class="headerlink" title="1) 정책"></a>1) 정책</h2><ul><li>데이터 관리, 학습·검증, 출력 검수, 안전·휴먼 오버사이트</li><li><strong>IP&#x2F;저작권</strong>, <strong>편향 완화</strong>, <strong>개인정보 보호</strong> 포함</li></ul><h2 id="2-정기-리뷰-Review-Cadence"><a href="#2-정기-리뷰-Review-Cadence" class="headerlink" title="2) 정기 리뷰(Review Cadence)"></a>2) 정기 리뷰(Review Cadence)</h2><ul><li><strong>기술 리뷰</strong>: 성능, 데이터 품질, 알고리즘 강건성</li><li><strong>비기술 리뷰</strong>: 정책 준수, 책임 있는 AI 원칙, 규제 대응</li><li><strong>주기</strong>: 월간&#x2F;분기&#x2F;연간 + <strong>SME&#x2F;법무&#x2F;사용자</strong> 참여</li><li><strong>출시 전 테스트·검증 절차</strong>와 <strong>의사결정 기준</strong> 문서화</li></ul><h2 id="3-투명성-기준"><a href="#3-투명성-기준" class="headerlink" title="3) 투명성 기준"></a>3) 투명성 기준</h2><ul><li>모델&#x2F;데이터&#x2F;주요 의사결정 공개(가능 범위 내)</li><li><strong>한계·가능·적용사례</strong> 문서화, <strong>피드백 채널</strong> 운영</li></ul><h2 id="4-팀-교육"><a href="#4-팀-교육" class="headerlink" title="4) 팀 교육"></a>4) 팀 교육</h2><ul><li>정책·가이드·모범사례 교육, <strong>편향 완화&#x2F;Responsible AI</strong> 트레이닝</li><li><strong>교차 협업</strong> 장려, 내부 <strong>수료&#x2F;인증</strong> 제도</li></ul><hr><h1 id="데이터-거버넌스-전략"><a href="#데이터-거버넌스-전략" class="headerlink" title="데이터 거버넌스 전략"></a>데이터 거버넌스 전략</h1><ul><li><strong>Responsible AI 프레임워크</strong>: 공정성·투명성·책임성 지표 운영, <strong>GenAI 편향&#x2F;부작용 모니터링</strong></li><li><strong>조직 구조</strong>: 데이터 거버넌스 위원회, <strong>Data Steward&#x2F;Owner&#x2F;Custodian</strong> 역할 정의</li><li><strong>데이터 공유</strong>: 내부 보안 공유협약, <strong>가상화&#x2F;페더레이션</strong>으로 <strong>소유권 유지+접근성 제공</strong></li><li><strong>문화</strong>: 데이터 기반 의사결정, 공동 거버넌스 문화</li></ul><h2 id="📌-Data-Owner"><a href="#📌-Data-Owner" class="headerlink" title="📌 Data Owner"></a>📌 Data Owner</h2><ul><li><strong>정의</strong>: 데이터의 최종 책임자 (business 책임).</li><li><strong>주요 역할</strong>:<ul><li>데이터가 <strong>정확하고 적절히 사용</strong>되는지 보장.</li><li>데이터 사용 목적, 보존 기간, 보안 요구사항 등 <strong>정책적 결정</strong> 담당.</li><li>규제 및 법적 요구사항을 충족하도록 보장.</li></ul></li><li><strong>예시</strong>: 금융회사에서 고객 데이터의 Owner는 <strong>Compliance 팀장</strong> 또는 <strong>데이터 책임 부서장</strong>.</li></ul><hr><h2 id="📌-Data-Steward"><a href="#📌-Data-Steward" class="headerlink" title="📌 Data Steward"></a>📌 Data Steward</h2><ul><li><strong>정의</strong>: Data Owner가 정한 정책을 <strong>실제 관리하고 실행</strong>하는 사람.</li><li><strong>주요 역할</strong>:<ul><li>데이터의 <strong>품질 관리</strong> (정확성, 일관성, 최신성).</li><li>데이터 표준, 정의, 메타데이터 관리.</li><li>사용자들이 데이터를 올바르게 사용할 수 있도록 가이드 제공.</li></ul></li><li><strong>예시</strong>: 데이터 품질팀, 데이터 거버넌스 팀원.</li></ul><hr><h2 id="📌-Data-Custodian"><a href="#📌-Data-Custodian" class="headerlink" title="📌 Data Custodian"></a>📌 Data Custodian</h2><ul><li><strong>정의</strong>: 데이터를 <strong>기술적으로 보관·운영</strong>하는 사람.</li><li><strong>주요 역할</strong>:<ul><li>데이터 저장소(DB, Data Lake, Warehouse) <strong>보안·백업·권한 관리</strong>.</li><li>인프라, 접근 제어, 암호화 등 기술적 관리.</li><li>Data Owner&#x2F;Steward의 정책이 기술적으로 적용되도록 보장.</li></ul></li><li><strong>예시</strong>: DBA(Database Admin), 클라우드 엔지니어, 보안팀.</li></ul><h2 id="✅-세-역할의-차이-요약"><a href="#✅-세-역할의-차이-요약" class="headerlink" title="✅ 세 역할의 차이 요약"></a>✅ 세 역할의 차이 요약</h2><table><thead><tr><th>역할</th><th>책임 영역</th><th>주요 초점</th><th>예시 직무</th></tr></thead><tbody><tr><td><strong>Data Owner</strong></td><td>데이터에 대한 <strong>비즈니스적 책임</strong></td><td>법적&#x2F;규제 준수, 정책 수립</td><td>Compliance 책임자</td></tr><tr><td><strong>Data Steward</strong></td><td>데이터의 <strong>운영적 관리</strong></td><td>품질, 표준, 정의 관리</td><td>데이터 거버넌스 팀</td></tr><tr><td><strong>Data Custodian</strong></td><td>데이터의 <strong>기술적 관리</strong></td><td>보안, 저장, 접근 제어</td><td>DBA, 클라우드 엔지니어</td></tr></tbody></table><p>👉 쉽게 말하면:  </p><ul><li><strong>Owner</strong> &#x3D; “이 데이터의 주인은 누구인가?”  </li><li><strong>Steward</strong> &#x3D; “데이터를 잘 관리하고 있는가?”  </li><li><strong>Custodian</strong> &#x3D; “데이터를 안전하게 보관하고 있는가?”</li></ul><hr><h1 id="핵심-데이터-관리-개념"><a href="#핵심-데이터-관리-개념" class="headerlink" title="핵심 데이터 관리 개념"></a>핵심 데이터 관리 개념</h1><ul><li><strong>수명주기</strong>: 수집 → 처리 → 저장 → 소비 → 보관</li><li><strong>로그</strong>: 입력&#x2F;출력, 성능, 시스템 이벤트 추적</li><li><strong>데이터 레지던시</strong>: 저장&#x2F;처리 위치(법·프라이버시, <strong>데이터-연산 근접성</strong>)</li><li><strong>모니터링</strong>: 품질, 이상·드리프트 탐지</li><li><strong>분석</strong>: 통계&#x2F;시각화&#x2F;탐색</li><li><strong>보존</strong>: 규제, 재학습 히스토리, 비용 고려</li></ul><h3 id="데이터-라인리지-출처·이력"><a href="#데이터-라인리지-출처·이력" class="headerlink" title="데이터 라인리지(출처·이력)"></a>데이터 라인리지(출처·이력)</h3><ul><li><strong>출처 표시</strong>(데이터셋&#x2F;DB&#x2F;기타, 라이선스·이용약관)</li><li><strong>수집·정제·전처리 과정</strong> 문서화, <strong>카탈로그화</strong>로 추적성·책임성 강화</li></ul><p align="center">  <img src="/images/aws_basic_210.png" width="80%"></p>------------------------------------------------------------------------<h1 id="AI-시스템-보안·프라이버시"><a href="#AI-시스템-보안·프라이버시" class="headerlink" title="AI 시스템 보안·프라이버시"></a>AI 시스템 보안·프라이버시</h1><h2 id="위협-탐지"><a href="#위협-탐지" class="headerlink" title="위협 탐지"></a>위협 탐지</h2><ul><li>가짜 콘텐츠, 조작 데이터, 자동화 공격 탐지</li><li>네트워크 트래픽&#x2F;사용자 행태 등 <strong>AI 기반 탐지</strong> 적용</li></ul><h2 id="취약점-관리"><a href="#취약점-관리" class="headerlink" title="취약점 관리"></a>취약점 관리</h2><ul><li>소프트웨어 버그&#x2F;모델 약점 점검</li><li><strong>보안 점검·침투 테스트·코드 리뷰</strong>, <strong>패치&#x2F;업데이트</strong> 절차</li></ul><h2 id="인프라-보호"><a href="#인프라-보호" class="headerlink" title="인프라 보호"></a>인프라 보호</h2><ul><li>클라우드&#x2F;엣지&#x2F;데이터 저장소 보안</li><li><strong>접근통제</strong>, <strong>네트워크 분리</strong>, <strong>암호화</strong>, <strong>장애 내성</strong></li></ul><h2 id="프롬프트-인젝션-대응"><a href="#프롬프트-인젝션-대응" class="headerlink" title="프롬프트 인젝션 대응"></a>프롬프트 인젝션 대응</h2><ul><li><strong>필터링&#x2F;정화&#x2F;검증</strong> 가드레일</li><li><strong>정책 우회 시나리오</strong> 테스트(레드팀), 안전 출력 정책</li></ul><p align="center">  <img src="/images/aws_basic_211.png" width="80%"></p><h2 id="암호화·키관리"><a href="#암호화·키관리" class="headerlink" title="암호화·키관리"></a>암호화·키관리</h2><ul><li>저장&#x2F;전송 <strong>암호화</strong>, <strong>KMS 등 키보호</strong> 엄격 운영</li></ul><hr><h1 id="운영-모니터링-모델-인프라"><a href="#운영-모니터링-모델-인프라" class="headerlink" title="운영 모니터링(모델 &amp; 인프라)"></a>운영 모니터링(모델 &amp; 인프라)</h1><ul><li><strong>정확도(Accuracy)</strong>, <strong>정밀도(Precision)</strong>, <strong>재현율(Recall)</strong>, <strong>F1</strong></li><li><strong>지연시간</strong>(응답), <strong>CPU&#x2F;GPU&#x2F;네트워크&#x2F;스토리지</strong> 지표</li><li><strong>시스템 로그</strong>, <strong>편향&#x2F;공정성</strong>, <strong>규제·정책 준수</strong></li></ul><blockquote><p>📝 <strong>시험 포인트</strong></p><ul><li><strong>정밀도 vs 재현율</strong>: 불균형 데이터(사기탐지)에서 <strong>F1</strong>이 균형 지표로 자주 쓰임.</li><li>운영 중 <strong>데이터&#x2F;모델 드리프트</strong> → 재학습 또는 피처&#x2F;정책 재점검.</li></ul></blockquote><hr><h1 id="AWS-공유책임모델-Shared-Responsibility"><a href="#AWS-공유책임모델-Shared-Responsibility" class="headerlink" title="AWS 공유책임모델(Shared Responsibility)"></a>AWS 공유책임모델(Shared Responsibility)</h1><ul><li><strong>AWS(클라우드의 보안)</strong>: 인프라&#x2F;하이퍼바이저&#x2F;시설&#x2F;네트워크 및 <strong>관리형 서비스</strong>의 보안</li><li><strong>고객(클라우드 내 보안)</strong>: <strong>데이터 관리, 접근제어, 가드레일, 암호화</strong> 등 애플리케이션 측</li><li><strong>공유 통제</strong>: 패치&#x2F;구성&#x2F;보안 인식·교육</li></ul><blockquote><p>📌 <strong>시험 포인트</strong></p><ul><li><strong>Bedrock&#x2F;SageMaker 같은 관리형 서비스</strong>라도 <strong>데이터·접근·가드레일</strong>은 고객 책임.</li><li><strong>KMS, IAM, CloudTrail</strong>과의 연계 책임 구분 이해.</li></ul></blockquote><p align="center">  <img src="/images/aws_basic_212.png" width="80%"></p>------------------------------------------------------------------------<h1 id="보안형-데이터-엔지니어링-모범사례"><a href="#보안형-데이터-엔지니어링-모범사례" class="headerlink" title="보안형 데이터 엔지니어링 모범사례"></a>보안형 데이터 엔지니어링 모범사례</h1><ul><li><strong>데이터 품질</strong>: 완전성·정확성·적시성·일관성 <strong>프로파일링·모니터링</strong></li><li><strong>라인리지</strong>와 <strong>감사 추적</strong> 유지</li><li><strong>PETs(Privacy-Enhancing Tech)</strong>: 마스킹&#x2F;난독화, <strong>암호화&#x2F;토큰화</strong></li><li><strong>접근통제</strong>: 명확한 정책, <strong>RBAC&#x2F;세분권한</strong>, <strong>SSO&#x2F;MFA&#x2F;IAM</strong>, 접근 로깅·주기 점검(<strong>최소권한</strong>)</li><li><strong>무결성</strong>: 백업&#x2F;복구 전략, 통제 점검·테스트</li></ul><hr><h1 id="생성형-AI-보안-스코핑-매트릭스-요약"><a href="#생성형-AI-보안-스코핑-매트릭스-요약" class="headerlink" title="생성형 AI 보안 스코핑 매트릭스(요약)"></a>생성형 AI 보안 스코핑 매트릭스(요약)</h1><ul><li>GenAI 앱을 <strong>소유·책임 수준</strong>에 따라 5단계로 분류:<ol><li><strong>소비자 앱</strong>(공개 GenAI 사용) → 소유 낮음</li><li><strong>엔터프라이즈 SaaS 기능 활용</strong>(Einstein GPT 등)</li><li><strong>사전학습 모델 활용</strong>(Bedrock BM)</li><li><strong>파인튜닝 모델</strong>(Bedrock 커스텀, JumpStart)</li><li><strong>직접 학습 모델</strong>(SageMaker 훈련) → 소유 높음</li></ol></li><li>단계가 올라갈수록 <strong>거버넌스&#x2F;법·프라이버시&#x2F;리스크 통제</strong> 책임이 커짐.</li></ul><blockquote><p>📝 <strong>시험 포인트</strong></p><ul><li><strong>파인튜닝 도입 시</strong> 데이터 거버넌스·보안·규제 부담 <strong>상승</strong>.</li><li><strong>Self-host&#x2F;Training</strong>은 책임·비용·리스크 <strong>최대</strong>.</li></ul></blockquote><p align="center">  <img src="/images/aws_basic_213.png" width="80%"></p>------------------------------------------------------------------------<h1 id="MLOps-머신러닝-운영"><a href="#MLOps-머신러닝-운영" class="headerlink" title="MLOps(머신러닝 운영)"></a>MLOps(머신러닝 운영)</h1><ul><li><strong>개발→배포→감시→재학습</strong>을 <strong>자동·반복</strong></li><li><strong>핵심 원칙</strong><ul><li><strong>버전관리</strong>: 데이터&#x2F;코드&#x2F;모델 롤백 가능</li><li><strong>자동화</strong>: 수집·전처리·학습·검증·배포 파이프라인</li><li><strong>CI</strong>: 모델 테스트 자동화</li><li><strong>CD</strong>: 프로덕션 배포 자동화</li><li><strong>지속 재학습·모니터링</strong>: 드리프트·품질 감시</li></ul></li></ul><h3 id="전형적인-파이프라인"><a href="#전형적인-파이프라인" class="headerlink" title="전형적인 파이프라인"></a>전형적인 파이프라인</h3><ol><li><strong>데이터 준비</strong>(ETL&#x2F;Feature)</li><li><strong>모델 빌드&#x2F;학습</strong></li><li><strong>평가&#x2F;선정</strong></li><li><strong>배포(승인·승급)</strong></li><li><strong>모니터링&#x2F;경보 → 재학습 루프</strong></li></ol><p align="center">  <img src="/images/aws_basic_215.png" width="80%"></p><blockquote><p>🧪 <strong>AWS 연계 예시</strong></p><ul><li><strong>SageMaker Pipelines&#x2F;Model Registry&#x2F;Model Monitor</strong>, <strong>EventBridge + CodePipeline&#x2F;CodeBuild</strong>, <strong>CloudWatch</strong>, <strong>Step Functions</strong></li></ul></blockquote><h2 id="Phases-of-Machine-Learning-Project"><a href="#Phases-of-Machine-Learning-Project" class="headerlink" title="Phases of Machine Learning Project"></a>Phases of Machine Learning Project</h2><p align="center">  <img src="/images/aws_basic_214.png" width="80%"></p><hr><h2 id="요약-체크리스트-시험-대비"><a href="#요약-체크리스트-시험-대비" class="headerlink" title="요약 체크리스트(시험 대비)"></a>요약 체크리스트(시험 대비)</h2><ul><li><strong>Responsible AI</strong>: 공정성·설명가능성·투명성·안전·통제 가능성</li><li><strong>거버넌스 체계</strong>: 위원회, R&amp;R, 정책, 리뷰&#x2F;승인, 투명성, 교육</li><li><strong>데이터 거버넌스</strong>: 라인리지, 레지던시, 품질&#x2F;보존, 공유&#x2F;페더레이션</li><li><strong>보안</strong>: 프롬프트 인젝션 가드레일, 암호화·키관리, 취약점·패치, 인프라 보호</li><li><strong>모니터링 지표</strong>: Accuracy&#x2F;Precision&#x2F;Recall&#x2F;F1&#x2F;Latency + 인프라</li><li><strong>공유책임</strong>: 클라우드 <strong>of</strong> vs <strong>in</strong> 보안 구분</li><li><strong>MLOps</strong>: 버전·자동화·CI&#x2F;CD·재학습·모니터링</li><li><strong>GenAI 스코프</strong>: Pre-trained ↔ Fine-tuned ↔ Self-trained에 따른 <strong>책임 증가</strong></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;거버넌스-컴플라이언스의-중요성&quot;&gt;&lt;a href=&quot;#거버넌스-컴플라이언스의-중요성&quot; class=&quot;headerlink&quot; title=&quot;거버넌스 &amp;amp; 컴플라이언스의 중요성&quot;&gt;&lt;/a&gt;거버넌스 &amp;amp; 컴플라이언스의 중요성&lt;/h1&gt;&lt;ul&gt;
</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(41) - Governance &amp; Compliance in AI</title>
    <link href="https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-41/"/>
    <id>https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-41/</id>
    <published>2025-09-02T19:29:51.000Z</published>
    <updated>2025-09-02T19:55:57.955Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Governance-Compliance-in-AI"><a href="#Governance-Compliance-in-AI" class="headerlink" title="Governance &amp; Compliance in AI"></a>Governance &amp; Compliance in AI</h1><h2 id="Why-Governance-and-Compliance-Matter"><a href="#Why-Governance-and-Compliance-Matter" class="headerlink" title="Why Governance and Compliance Matter"></a>Why Governance and Compliance Matter</h2><p>Governance is about managing, optimizing, and scaling AI initiatives inside an organization.  </p><ul><li>It builds <strong>trust</strong> in AI systems.  </li><li>Ensures <strong>responsible and trustworthy practices</strong>.  </li><li>Mitigates risks such as bias, privacy violations, or unintended outcomes.  </li><li>Aligns AI systems with <strong>legal and regulatory requirements</strong>.  </li><li>Protects against <strong>legal and reputational risks</strong>.  </li><li>Fosters <strong>public trust and confidence</strong> in AI deployment.</li></ul><p>📌 <strong>Exam tip</strong>: Expect questions that connect governance with <em>trust, compliance, and risk management</em>. AWS often tests your understanding of <em>why</em> governance is necessary, not just <em>how</em>.</p><hr><h2 id="Governance-Framework"><a href="#Governance-Framework" class="headerlink" title="Governance Framework"></a>Governance Framework</h2><p>A typical governance approach includes:</p><ol><li><strong>AI Governance Board &#x2F; Committee</strong>  <ul><li>Cross-functional: legal, compliance, data privacy, and AI experts.</li></ul></li><li><strong>Defined Roles and Responsibilities</strong>  <ul><li>Oversight, policy-making, risk assessments, decision-making.</li></ul></li><li><strong>Policies &amp; Procedures</strong>  <ul><li>Covering the full AI lifecycle: data management → training → deployment → monitoring.</li></ul></li></ol><h3 id="AWS-Governance-Tools-likely-on-exam"><a href="#AWS-Governance-Tools-likely-on-exam" class="headerlink" title="AWS Governance Tools (likely on exam):"></a>AWS Governance Tools (likely on exam):</h3><ul><li><strong>AWS Config</strong> – continuous monitoring and compliance tracking.  </li><li><strong>Amazon Inspector</strong> – automated vulnerability management.  </li><li><strong>AWS CloudTrail</strong> – records API calls for auditing.  </li><li><strong>AWS Audit Manager</strong> – helps with compliance evidence collection.  </li><li><strong>AWS Trusted Advisor</strong> – best practice checks (cost, security, performance).</li></ul><p align="center">  <img src="/images/aws_basic_209.png" width="80%"></p><hr><h2 id="Governance-Strategies"><a href="#Governance-Strategies" class="headerlink" title="Governance Strategies"></a>Governance Strategies</h2><ul><li><strong>Policies</strong>: Responsible AI guidelines (data handling, training, bias mitigation, IP protection).  </li><li><strong>Review Cadence</strong>: Reviews monthly, quarterly, or annually, with technical + legal experts.  </li><li><strong>Review Types</strong>:  <ul><li><em>Technical</em>: model performance, data quality, robustness.  </li><li><em>Non-technical</em>: legal, compliance, ethical considerations.</li></ul></li><li><strong>Transparency</strong>: Publish model details, training data sources, decisions made, limitations.  </li><li><strong>Team Training</strong>: Policies, responsible AI, bias mitigation, cross-functional collaboration.</li></ul><hr><h2 id="Data-Governance"><a href="#Data-Governance" class="headerlink" title="Data Governance"></a>Data Governance</h2><ul><li><strong>Responsible AI Principles</strong>: fairness, accountability, transparency, bias monitoring.  </li><li><strong>Governance Roles</strong>:  <ul><li><em>Data Owner</em>: accountable for data.  </li><li><em>Data Steward</em>: ensures quality, compliance.  </li><li><em>Data Custodian</em>: manages technical storage&#x2F;security.</li></ul></li><li><strong>Data Sharing</strong>: secure sharing agreements, virtualization, federation.  </li><li><strong>Data Culture</strong>: encourage data-driven decision-making.</li></ul><h3 id="Data-Management-Concepts"><a href="#Data-Management-Concepts" class="headerlink" title="Data Management Concepts"></a>Data Management Concepts</h3><ul><li><strong>Lifecycle</strong>: collection → processing → storage → use → archival.  </li><li><strong>Logging</strong>: track inputs, outputs, metrics, events.  </li><li><strong>Residency</strong>: where data is stored&#x2F;processed (important for GDPR &amp; HIPAA).  </li><li><strong>Monitoring</strong>: quality, anomalies, drift.  </li><li><strong>Retention</strong>: meet regulations and manage storage costs.</li></ul><h3 id="Data-Lineage"><a href="#Data-Lineage" class="headerlink" title="Data Lineage"></a>Data Lineage</h3><ul><li><strong>Source citation</strong>: datasets, licenses, permissions.  </li><li><strong>Origins</strong>: collection, cleaning, transformations.  </li><li><strong>Cataloging</strong>: organize &amp; document datasets.  </li><li>Provides <strong>traceability &amp; accountability</strong>.</li></ul><p align="center">  <img src="/images/aws_basic_210.png" width="80%"></p><hr><h2 id="Security-Privacy-for-AI"><a href="#Security-Privacy-for-AI" class="headerlink" title="Security &amp; Privacy for AI"></a>Security &amp; Privacy for AI</h2><ul><li><strong>Threat Detection</strong>: fake content, manipulated data, automated attacks.  </li><li><strong>Vulnerability Management</strong>: penetration tests, code reviews, patching.  </li><li><strong>Infrastructure Protection</strong>: secure cloud platforms, access controls, encryption, redundancy.  </li><li><strong>Prompt Injection Defense</strong>: input sanitization, guardrails.  </li><li><strong>Encryption</strong>: always encrypt data at rest &amp; in transit; manage keys securely.</li></ul><p align="center">  <img src="/images/aws_basic_211.png" width="80%"></p><hr><h2 id="Monitoring-AI-Systems"><a href="#Monitoring-AI-Systems" class="headerlink" title="Monitoring AI Systems"></a>Monitoring AI Systems</h2><ul><li><strong>Model Metrics</strong>:  <ul><li>Accuracy  </li><li>Precision (true positives &#x2F; predicted positives)  </li><li>Recall (true positives &#x2F; actual positives)  </li><li>F1-score (balance between precision &amp; recall)  </li><li>Latency (response time)</li></ul></li><li><strong>Infrastructure Monitoring</strong>: CPU&#x2F;GPU, network, storage, logs.  </li><li><strong>Bias &amp; Fairness Monitoring</strong>: required for compliance.</li></ul><hr><h2 id="AWS-Shared-Responsibility-Model"><a href="#AWS-Shared-Responsibility-Model" class="headerlink" title="AWS Shared Responsibility Model"></a>AWS Shared Responsibility Model</h2><ul><li><strong>AWS responsibility – Security <em>of</em> the Cloud</strong><br>Infrastructure: hardware, networking, managed services like S3, SageMaker, Bedrock.  </li><li><strong>Customer responsibility – Security <em>in</em> the Cloud</strong><br>Data management, encryption, access controls, guardrails.  </li><li><strong>Shared controls</strong>: patch management, configuration management, training.</li></ul><p>📌 <strong>Exam tip</strong>: Always remember the <em>“of the cloud” vs. “in the cloud”</em> split.</p><p align="center">  <img src="/images/aws_basic_212.png" width="80%"></p><hr><h2 id="Secure-Data-Engineering-Best-Practices"><a href="#Secure-Data-Engineering-Best-Practices" class="headerlink" title="Secure Data Engineering Best Practices"></a>Secure Data Engineering Best Practices</h2><ul><li><strong>Data Quality</strong>: complete, accurate, timely, consistent.  </li><li><strong>Privacy Enhancements</strong>: masking, obfuscation, encryption, tokenization.  </li><li><strong>Access Control</strong>: RBAC (role-based access), fine-grained permissions, SSO, MFA.  </li><li><strong>Data Integrity</strong>: error-free, backed up, lineage maintained, audit trails in place.</li></ul><hr><h2 id="Generative-AI-Security-Scoping-Matrix"><a href="#Generative-AI-Security-Scoping-Matrix" class="headerlink" title="Generative AI Security Scoping Matrix"></a>Generative AI Security Scoping Matrix</h2><p>Levels of ownership and security responsibility:  </p><ol><li><strong>Consumer App</strong> – very low ownership (e.g., using ChatGPT directly).  </li><li><strong>Enterprise App</strong> – SaaS with GenAI features (e.g., Salesforce GPT).  </li><li><strong>Pre-trained Models</strong> – use Bedrock base models without training.  </li><li><strong>Fine-tuned Models</strong> – customize models with your data.  </li><li><strong>Self-trained Models</strong> – full ownership, trained from scratch.</li></ol><p>📌 <strong>Exam tip</strong>: The more control you have → the more <strong>security and compliance responsibility</strong> you carry.  </p><p align="center">  <img src="/images/aws_basic_213.png" width="80%"></p><hr><h2 id="MLOps-Machine-Learning-Operations"><a href="#MLOps-Machine-Learning-Operations" class="headerlink" title="MLOps (Machine Learning Operations)"></a>MLOps (Machine Learning Operations)</h2><p>Extension of DevOps for ML:  </p><ul><li><strong>Version Control</strong>: data, code, models.  </li><li><strong>Automation</strong>: pipelines for ingestion, preprocessing, training.  </li><li><strong>CI&#x2F;CD</strong>: continuous testing and delivery of models.  </li><li><strong>Retraining</strong>: incorporate new data.  </li><li><strong>Monitoring</strong>: catch drift, ensure fairness and performance.</li></ul><p>Example ML pipeline:  </p><ol><li>Data prep  </li><li>Build model  </li><li>Evaluate model  </li><li>Select best candidate  </li><li>Deploy to production  </li><li>Monitor + retrain</li></ol><p>📌 <strong>Exam tip</strong>: AWS may test your knowledge of <strong>SageMaker pipelines, model registry, and monitoring tools</strong> as part of MLOps.  </p><p align="center">  <img src="/images/aws_basic_215.png" width="80%"></p><h2 id="Phases-of-Machine-Learning-Project"><a href="#Phases-of-Machine-Learning-Project" class="headerlink" title="Phases of Machine Learning Project"></a>Phases of Machine Learning Project</h2><p align="center">  <img src="/images/aws_basic_214.png" width="80%"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Governance-Compliance-in-AI&quot;&gt;&lt;a href=&quot;#Governance-Compliance-in-AI&quot; class=&quot;headerlink&quot; title=&quot;Governance &amp;amp; Compliance in AI&quot;&gt;&lt;/a</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(40) - Generative AI Capabilities, Challenges, and Compliance</title>
    <link href="https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-40/"/>
    <id>https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-40/</id>
    <published>2025-09-02T19:05:58.000Z</published>
    <updated>2025-09-02T19:29:34.719Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Generative-AI-Capabilities-Challenges-and-Compliance"><a href="#Generative-AI-Capabilities-Challenges-and-Compliance" class="headerlink" title="Generative AI: Capabilities, Challenges, and Compliance"></a>Generative AI: Capabilities, Challenges, and Compliance</h1><h2 id="Capabilities-of-Generative-AI"><a href="#Capabilities-of-Generative-AI" class="headerlink" title="Capabilities of Generative AI"></a>Capabilities of Generative AI</h2><p>Generative AI (GenAI) has several strengths that make it powerful and attractive for businesses:</p><ul><li><strong>Adaptability</strong> – can quickly adjust to new tasks and domains.  </li><li><strong>Responsiveness</strong> – provides real-time answers and interactions.  </li><li><strong>Simplicity</strong> – users can interact with natural language prompts instead of coding.  </li><li><strong>Creativity &amp; Exploration</strong> – useful for brainstorming, content creation, and generating novel ideas.  </li><li><strong>Data Efficiency</strong> – can extract insights even from smaller datasets if pretrained well.  </li><li><strong>Personalization</strong> – adapts to individual user needs, preferences, or styles.  </li><li><strong>Scalability</strong> – works across millions of queries and users simultaneously.</li></ul><p>👉 <em>Exam tip</em>: Expect questions about how businesses benefit from these capabilities—especially scalability, personalization, and adaptability.</p><hr><h2 id="Challenges-of-Generative-AI"><a href="#Challenges-of-Generative-AI" class="headerlink" title="Challenges of Generative AI"></a>Challenges of Generative AI</h2><p>Despite its strengths, GenAI comes with risks:</p><ul><li><strong>Regulatory violations</strong> – hard to ensure compliance with laws (GDPR, HIPAA, etc.).  </li><li><strong>Social risks</strong> – spread of misinformation or harmful content.  </li><li><strong>Data security &amp; privacy</strong> – sensitive data may be leaked or misused.  </li><li><strong>Toxicity</strong> – generating offensive or inappropriate outputs.  </li><li><strong>Hallucinations</strong> – generating content that <em>sounds</em> correct but is false.  </li><li><strong>Interpretability</strong> – difficult to understand <em>why</em> the model produced an output.  </li><li><strong>Nondeterminism</strong> – the same prompt may return different results each time.  </li><li><strong>Plagiarism &amp; cheating</strong> – students or professionals misusing AI for essays, tests, or applications.</li></ul><p>👉 <em>Exam tip</em>: Be familiar with “hallucinations,” “toxicity,” and “nondeterminism” as common weaknesses of large language models.</p><hr><h2 id="Toxicity"><a href="#Toxicity" class="headerlink" title="Toxicity"></a>Toxicity</h2><ul><li><strong>Definition</strong>: AI generates content that is offensive, disturbing, or inappropriate.  </li><li><strong>Challenge</strong>: Deciding what counts as “toxic” vs. “free expression.” Even quoting harmful text can raise issues.  </li><li><strong>Mitigation</strong>:<ul><li>Curate training datasets to remove offensive content.  </li><li>Use <strong>guardrails</strong> (like <em>Guardrails for Amazon Bedrock</em>) to filter harmful or unwanted outputs.</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_200.png" width="80%"></p><hr><h2 id="Hallucinations"><a href="#Hallucinations" class="headerlink" title="Hallucinations"></a>Hallucinations</h2><ul><li><strong>Definition</strong>: Model produces content that <em>sounds correct</em> but is wrong.  </li><li><strong>Cause</strong>: Next-word probability sampling in LLMs.  </li><li><strong>Example</strong>: Claiming an author wrote books they never wrote.  </li><li><strong>Mitigation</strong>:<ul><li>Educate users: AI outputs must be verified.  </li><li>Cross-check with independent sources.  </li><li>Label outputs as <strong>“unverified.”</strong></li></ul></li></ul><p align="center">  <img src="/images/aws_basic_201.png" width="80%"></p><hr><h2 id="Plagiarism-Cheating"><a href="#Plagiarism-Cheating" class="headerlink" title="Plagiarism &amp; Cheating"></a>Plagiarism &amp; Cheating</h2><ul><li><strong>Concern</strong>: GenAI used to write essays, job applications, or exams.  </li><li><strong>Debate</strong>: Should this be embraced as new tech or banned?  </li><li><strong>Mitigation</strong>: Detection tools are being developed to identify AI-generated text.</li></ul><p align="center">  <img src="/images/aws_basic_202.png" width="80%"></p><hr><h2 id="Prompt-Misuses"><a href="#Prompt-Misuses" class="headerlink" title="Prompt Misuses"></a>Prompt Misuses</h2><ol><li><strong>Poisoning</strong> – malicious or biased data injected into training → harmful outputs.  <ul><li>Example: model suggests eating rocks due to poisoned data.</li></ul></li><li><strong>Hijacking &#x2F; Prompt Injection</strong> – attacker embeds hidden instructions in prompts.  <ul><li>Example: “Generate a Python script to delete files.”</li></ul></li></ol><p align="center">  <img src="/images/aws_basic_203.png" width="80%"></p><ol start="3"><li><strong>Exposure</strong> – risk of revealing private or sensitive data in outputs.</li></ol><p align="center">  <img src="/images/aws_basic_204.png" width="80%"></p><ol start="4"><li><strong>Prompt Leaking</strong> – model unintentionally exposes previous prompts or confidential information.</li></ol><p align="center">  <img src="/images/aws_basic_205.png" width="80%"></p><ol start="5"><li><strong>Jailbreaking</strong> – bypassing safety constraints to force restricted outputs.  <ul><li><strong>Many-shot jailbreaking</strong> (providing many examples) has been shown to trick models.</li></ul></li></ol><p align="center">  <img src="/images/aws_basic_206.png" width="80%"></p><p>👉 <em>Exam tip</em>: Know the definitions of <strong>prompt injection, jailbreaking, and poisoning</strong>. These are hot topics in AI security.</p><hr><h2 id="Regulated-Workloads"><a href="#Regulated-Workloads" class="headerlink" title="Regulated Workloads"></a>Regulated Workloads</h2><p>Some industries have stricter compliance requirements:</p><ul><li><strong>Financial services</strong> – mortgage, credit scoring.  </li><li><strong>Healthcare</strong> – patient records, diagnostics.  </li><li><strong>Aerospace &amp; defense</strong> – sensitive designs, federal oversight.</li></ul><p>👉 <em>Regulated workload</em> &#x3D; requires audits, reporting, or special security requirements.</p><hr><h2 id="Compliance-Challenges"><a href="#Compliance-Challenges" class="headerlink" title="Compliance Challenges"></a>Compliance Challenges</h2><p>AI compliance is difficult because:</p><ul><li><strong>Complexity &amp; opacity</strong> – hard to audit AI decision-making.  </li><li><strong>Dynamism</strong> – AI models evolve over time.  </li><li><strong>Emergent capabilities</strong> – models may do things they weren’t trained for.  </li><li><strong>Unique risks</strong> – bias, misinformation, privacy violations.  </li><li><strong>Algorithmic bias</strong> – skewed training data leads to discrimination.  </li><li><strong>Human bias</strong> – developers themselves can introduce bias.  </li><li><strong>Accountability</strong> – algorithms must be explainable, but often aren’t.</li></ul><h3 id="Regulatory-frameworks"><a href="#Regulatory-frameworks" class="headerlink" title="Regulatory frameworks"></a>Regulatory frameworks</h3><ul><li><strong>EU</strong>: <em>Artificial Intelligence Act</em> – fairness, human rights, non-discrimination.  </li><li><strong>US</strong>: Several states&#x2F;cities have their own AI regulations.</li></ul><p align="center">  <img src="/images/aws_basic_207.png" width="80%"></p><hr><h2 id="AWS-Compliance"><a href="#AWS-Compliance" class="headerlink" title="AWS Compliance"></a>AWS Compliance</h2><p>AWS supports compliance with <strong>140+ standards and certifications</strong>, including:  </p><ul><li><strong>NIST</strong> (National Institute of Standards and Technology)  </li><li><strong>ENISA</strong> (EU cybersecurity)  </li><li><strong>ISO</strong> (International Organization for Standardization)  </li><li><strong>SOC</strong> (System and Organization Controls)  </li><li><strong>HIPAA</strong> (healthcare)  </li><li><strong>GDPR</strong> (EU data privacy)  </li><li><strong>PCI DSS</strong> (payment card data)</li></ul><p>👉 <em>Exam tip</em>: AWS provides compliance-ready infrastructure, but <strong>you (the customer) are responsible</strong> for compliance of your applications (Shared Responsibility Model).</p><hr><h2 id="Model-Cards-AWS-AI-Service-Cards"><a href="#Model-Cards-AWS-AI-Service-Cards" class="headerlink" title="Model Cards &amp; AWS AI Service Cards"></a>Model Cards &amp; AWS AI Service Cards</h2><ul><li><strong>Model Cards</strong> &#x3D; standardized documentation for ML models.  <ul><li>Include datasets, sources, biases, training details, intended use, and risk ratings.  </li><li><em>Example</em>: SageMaker Model Cards help with audits.</li></ul></li><li><strong>AWS AI Service Cards</strong> &#x3D; AWS documentation about responsible AI practices in its services (e.g., Rekognition, Textract).</li></ul><p>👉 These improve <strong>transparency, trust, and accountability</strong>.</p><p align="center">  <img src="/images/aws_basic_208.png" width="80%"></p><hr><h2 id="Key-Takeaways-for-the-Exam"><a href="#Key-Takeaways-for-the-Exam" class="headerlink" title="Key Takeaways for the Exam"></a>Key Takeaways for the Exam</h2><ul><li>Understand <strong>capabilities vs. challenges</strong> of GenAI.  </li><li>Be able to explain <strong>toxicity, hallucinations, plagiarism, nondeterminism</strong>.  </li><li>Know <strong>prompt misuse techniques</strong> (poisoning, injection, exposure, jailbreaking).  </li><li>Be familiar with <strong>regulated workloads</strong> and compliance frameworks (HIPAA, GDPR, PCI DSS).  </li><li>Recognize <strong>Model Cards</strong> and <strong>AWS AI Service Cards</strong> as governance tools.</li></ul><hr><p>✅ With this, you’ll be ready for questions on <strong>responsible AI, compliance, and GenAI risks</strong> in AWS certification exams.  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Generative-AI-Capabilities-Challenges-and-Compliance&quot;&gt;&lt;a href=&quot;#Generative-AI-Capabilities-Challenges-and-Compliance&quot; class=&quot;headerl</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (40) - 생성형 AI의 역량과 과제</title>
    <link href="https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-40/"/>
    <id>https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-40/</id>
    <published>2025-09-02T19:05:54.000Z</published>
    <updated>2025-09-02T19:50:52.616Z</updated>
    
    <content type="html"><![CDATA[<h1 id="생성형-AI의-역량과-과제-시험-포인트-포함"><a href="#생성형-AI의-역량과-과제-시험-포인트-포함" class="headerlink" title="생성형 AI의 역량과 과제 (시험 포인트 포함)"></a>생성형 AI의 역량과 과제 (시험 포인트 포함)</h1><p>아래 내용은 강의자료와 대본을 바탕으로 <strong>쉽고 자연스럽게</strong> 정리&#x2F;확장한 것입니다. 특히 <strong>AWS 자격증(특히 AWS Certified AI Practitioner,ML–Specialty, SAP&#x2F;Architect)</strong> 대비에 유리하도록 <strong>시험에 자주 나오는 개념</strong>과 <strong>실무 팁</strong>을 함께 넣었습니다.</p><hr><h2 id="1-생성형-AI가-잘하는-것-Capabilities"><a href="#1-생성형-AI가-잘하는-것-Capabilities" class="headerlink" title="1) 생성형 AI가 잘하는 것 (Capabilities)"></a>1) 생성형 AI가 잘하는 것 (Capabilities)</h2><ul><li><strong>적응성(Adaptability)</strong>: 다양한 도메인과 태스크로 빠르게 전이·적용 가능</li><li><strong>반응성(Responsiveness)</strong>: 프롬프트에 즉시 응답, 대화형 인터페이스에 적합</li><li><strong>단순성(Simplicity)</strong>: 사용자 입장에선 프롬프트만 잘 쓰면 복잡한 작업도 가능</li><li><strong>창의성·탐색(Creativity &amp; Exploration)</strong>: 아이디어 발산, 초안&#x2F;프로토타이핑에 강함</li><li><strong>데이터 효율(Data Efficiency)</strong>: 사전학습 덕분에 비교적 적은 추가 데이터로도 튜닝 가능</li><li><strong>개인화(Personalization)</strong>: 프롬프트&#x2F;세션&#x2F;미세조정으로 사용자 맥락 반영</li><li><strong>확장성(Scalability)</strong>: 서버리스&#x2F;오토스케일링 조합으로 대규모 트래픽 처리 용이</li></ul><blockquote><p><strong>시험 포인트</strong><br>“생성형 AI의 장점”을 묻는 문항에서는 <em>창의성, 적응성, 개인화, 확장성</em> 등을 키워드로 기억하세요.</p></blockquote><hr><h2 id="2-생성형-AI의-주요-과제-Challenges"><a href="#2-생성형-AI의-주요-과제-Challenges" class="headerlink" title="2) 생성형 AI의 주요 과제 (Challenges)"></a>2) 생성형 AI의 주요 과제 (Challenges)</h2><ul><li><strong>규제 위반</strong>: 산업 규제(금융, 의료 등)와 지역 규정(GDPR 등) 미준수 위험</li><li><strong>사회적 리스크</strong>: 허위정보 확산, 차별&#x2F;편향 강화, 저작권 분쟁 등</li><li><strong>데이터 보안·개인정보</strong>: 프롬프트·로그·학습데이터에서의 PII 노출</li><li><strong>유해성(Toxicity)</strong>: 공격적·부적절한 발화 생성</li><li><strong>환각(Hallucination)</strong>: 그럴듯하지만 사실이 아닌 내용 생성</li><li><strong>해석가능성(Interpretability)</strong> 부족</li><li><strong>비결정성(Nondeterminism)</strong>: 같은 입력에도 출력이 매번 달라짐</li><li><strong>표절·부정행위</strong>: 에세이 대필, 코드 부정 사용 등</li></ul><blockquote><p><strong>시험 포인트</strong><br>“환각” 정의와 <strong>대응책(RAG, 출처명시, 검증 프로세스)</strong>, “비결정성” 제어(온도&#x2F;탑P&#x2F;디터미니스틱 디코딩) 같은 실무적 완화책을 자주 물어봅니다.</p></blockquote><hr><h2 id="3-유해성-Toxicity"><a href="#3-유해성-Toxicity" class="headerlink" title="3) 유해성(Toxicity)"></a>3) 유해성(Toxicity)</h2><ul><li><strong>문제</strong>: 공격적&#x2F;불쾌&#x2F;부적절 콘텐츠 생성. 인용(quote) 허용 여부 등 경계가 모호.</li><li><strong>대응</strong><ul><li><strong>데이터 정제</strong>: 학습·튜닝 데이터에서 유해표현 제거&#x2F;완화</li><li><strong>가드레일</strong>: <strong>Guardrails for Amazon Bedrock</strong>로 주제 차단, 욕설&#x2F;증오표현 필터, PII 마스킹</li><li><strong>휴먼 리뷰</strong>: <strong>Amazon A2I</strong>로 저신뢰 결과의 인간 검수</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_200.png" width="80%"></p>------------------------------------------------------------------------<h2 id="4-환각-Hallucinations"><a href="#4-환각-Hallucinations" class="headerlink" title="4) 환각(Hallucinations)"></a>4) 환각(Hallucinations)</h2><ul><li><strong>정의</strong>: 그럴듯하지만 <strong>사실이 아닌 주장</strong>을 생성(LLM의 확률적 샘플링 특성).</li><li><strong>대응</strong><ul><li><strong>RAG</strong>(Retrieval-Augmented Generation): <strong>벡터 검색 + 인용</strong>으로 최신·정확 근거 제시</li><li><strong>출력에 출처 표기&#x2F;“미검증(Needs Verification)” 라벨</strong></li><li>**온도(temperature)↓, 탑P↓**로 <strong>보수적 디코딩</strong></li><li><strong>중요 응답은 2차 검증(외부 소스&#x2F;사람)</strong></li><li><strong>SageMaker Clarify</strong>로 <strong>정확도&#x2F;강건성</strong> 평가 및 드리프트 감시</li></ul></li></ul><blockquote><p><strong>시험 포인트</strong><br>“환각을 줄이는 방법?” → <strong>RAG, 가드레일, 디코딩 파라미터 튜닝, 출처표기, 휴먼 검증</strong>.</p></blockquote><p align="center">  <img src="/images/aws_basic_201.png" width="80%"></p><hr><h2 id="5-표절·부정행위"><a href="#5-표절·부정행위" class="headerlink" title="5) 표절·부정행위"></a>5) 표절·부정행위</h2><ul><li><strong>이슈</strong>: 과제 대필, 작성 샘플 위조, 출처 추적 어려움</li><li><strong>대응</strong><ul><li><strong>출처 요구</strong>(참고문헌&#x2F;링크 의무화)</li><li><strong>검출기 병행</strong>(완벽하진 않음) + <strong>프로세스 기반 평가</strong>(면담·구술·버전관리)</li><li><strong>가드레일</strong>로 시험·채점 맥락에서 과도한 자동화 방지</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_202.png" width="80%"></p><hr><h2 id="6-프롬프트-오남용-공격-유형과-방어"><a href="#6-프롬프트-오남용-공격-유형과-방어" class="headerlink" title="6) 프롬프트 오남용(공격) 유형과 방어"></a>6) 프롬프트 오남용(공격) 유형과 방어</h2><h3 id="6-1-공격-유형"><a href="#6-1-공격-유형" class="headerlink" title="6-1) 공격 유형"></a>6-1) 공격 유형</h3><ul><li><strong>데이터 중독(Training&#x2F;Prompt Poisoning)</strong>: 악성·편향 데이터 주입</li><li><strong>프롬프트 인젝션&#x2F;하이재킹</strong>: 은밀 지시문으로 모델 행태 왜곡(허위정보, 악성코드 유도)</li></ul><p align="center">  <img src="/images/aws_basic_203.png" width="80%"></p><ul><li><strong>노출(Exposure)</strong>: 훈련·추론 중 민감정보 노출</li></ul><p align="center">  <img src="/images/aws_basic_204.png" width="80%"></p><ul><li><strong>프롬프트 리킹</strong>: 내부 프롬프트&#x2F;시스템 지침 유출</li></ul><p align="center">  <img src="/images/aws_basic_205.png" width="80%"></p><ul><li><strong>탈옥(Jailbreaking)</strong>: 안전장치 우회(다중 예시 “many-shot” 등 기법 활용)</li></ul><p align="center">  <img src="/images/aws_basic_206.png" width="80%"></p><h3 id="6-2-방어-전략-AWS-관점"><a href="#6-2-방어-전략-AWS-관점" class="headerlink" title="6-2) 방어 전략 (AWS 관점)"></a>6-2) 방어 전략 (AWS 관점)</h3><ul><li><strong>Bedrock Guardrails</strong>: 금지 주제&#x2F;욕설&#x2F;PII 필터, 톤·스타일 규칙</li><li><strong>네트워크·암호화</strong>: <strong>VPC 엔드포인트</strong>, <strong>AWS KMS</strong>로 저장&#x2F;전송 암호화</li><li><strong>최소권한(IAM)</strong> &amp; <strong>SageMaker Role Manager</strong>로 역할 기반 접근</li><li><strong>입력 정화</strong>: 시스템 프롬프트 분리, “<strong>지시보다 안전정책 우선</strong>“ 규칙 삽입</li><li><strong>출력 검증</strong>: 콘텐츠 필터, <strong>A2I 휴먼리뷰</strong></li><li><strong>로깅·감사</strong>: <strong>CloudWatch&#x2F;CloudTrail</strong>로 추적, 이상 징후 알림</li><li><strong>데이터 격리</strong>: <strong>SageMaker 네트워크 격리 모드</strong>(아웃바운드 차단), 민감 데이터 비노출</li></ul><blockquote><p><strong>시험 포인트</strong><br>“프롬프트 인젝션 대응책” → <strong>가드레일, 입력 정화, 최소권한, VPC·KMS, 로깅&#x2F;감사, 휴먼 리뷰</strong>.</p></blockquote><hr><h2 id="7-규제-대상-워크로드-Regulated-Workloads"><a href="#7-규제-대상-워크로드-Regulated-Workloads" class="headerlink" title="7) 규제 대상 워크로드(Regulated Workloads)"></a>7) 규제 대상 워크로드(Regulated Workloads)</h2><ul><li><strong>산업</strong>: 금융, 의료, 항공우주 등은 <strong>추가 규제&#x2F;감사&#x2F;보관&#x2F;보안요건</strong> 필요</li><li><strong>예시</strong>: 신용·대출 심사 결과(모델 출력)가 규제 대상 → <strong>결정근거 보관·설명 가능성</strong> 필수</li></ul><blockquote><p><strong>시험 포인트</strong><br><strong>공유 책임 모델</strong>(Shared Responsibility Model) 기억:</p><ul><li><strong>AWS</strong>: 클라우드 “<strong>of</strong>“ 보안(데이터센터·하드웨어·기본 서비스)</li><li><strong>고객</strong>: 클라우드 “<strong>in</strong>“ 보안(데이터 분류, 접근통제, 암호화 설정, 모델 거버넌스)</li></ul></blockquote><hr><h2 id="8-AI-표준·컴플라이언스-과제"><a href="#8-AI-표준·컴플라이언스-과제" class="headerlink" title="8) AI 표준·컴플라이언스 과제"></a>8) AI 표준·컴플라이언스 과제</h2><ul><li><strong>복잡성·불투명성</strong>: 의사결정 경로 감사 난이도</li><li><strong>동적 변화</strong>: 모델·데이터가 시간에 따라 변함(버전관리&#x2F;추적 필요)</li><li><strong>예기치 못한 능력</strong>: 의도치 않은 활용 가능성</li><li><strong>고유 위험</strong>: 알고리즘 편향, 프라이버시 침해, 허위정보</li><li><strong>책임성</strong>: <strong>설명가능성</strong> 요구(모델 내부&#x2F;외부 설명, 출력 근거 제공)</li><li><strong>규제 트렌드</strong>: EU <strong>AI Act</strong>, 미국(주·도시별) 규정 등 → <strong>공정·비차별·인권</strong> 강조</li></ul><p align="center">  <img src="/images/aws_basic_207.png" width="80%"></p><h3 id="AWS-컴플라이언스-생태계-대표"><a href="#AWS-컴플라이언스-생태계-대표" class="headerlink" title="AWS 컴플라이언스 생태계(대표)"></a>AWS 컴플라이언스 생태계(대표)</h3><ul><li><strong>ISO&#x2F;NIST&#x2F;ENISA&#x2F;SOC&#x2F;HIPAA&#x2F;GDPR&#x2F;PCI DSS</strong> 등 다수 인증(서비스별 지원 범위 상이)</li><li><strong>해야 할 일</strong>: 서비스 인증 확인 + <strong>자체 워크로드에 대한 추가 통제&#x2F;감사</strong> 설계</li></ul><hr><h2 id="9-해석가능성-vs-설명가능성"><a href="#9-해석가능성-vs-설명가능성" class="headerlink" title="9) 해석가능성 vs 설명가능성"></a>9) 해석가능성 vs 설명가능성</h2><ul><li><strong>해석가능성(Interpretability)</strong>: “<strong>왜&#x2F;어떻게</strong> 그 결정이 나왔는가”를 <strong>모델 구조 자체</strong>로 이해<ul><li>높을수록 보통 <strong>성능은 단순</strong>(선형&#x2F;의사결정나무 등)</li></ul></li><li><strong>설명가능성(Explainability)</strong>: 내부를 몰라도 <strong>입출력 관계 설명</strong>(특성 중요도, 부분의존 등)<ul><li><strong>SageMaker Clarify</strong>: <strong>SHAP 기반</strong> 중요도, 바이어스 측정·설명 제공</li><li><strong>PDP(Partial Dependence Plot)</strong>: 하나의 특성이 예측에 미치는 평균적 영향 시각화</li></ul></li></ul><blockquote><p><strong>시험 포인트</strong><br><strong>Clarify &#x3D; 바이어스 탐지 + 설명가능성 도구(특성기여&#x2F;SHAP, 데이터·모델 편향 측정)</strong>.</p></blockquote><hr><h2 id="10-모델-카드-서비스-카드"><a href="#10-모델-카드-서비스-카드" class="headerlink" title="10) 모델 카드 &amp; 서비스 카드"></a>10) 모델 카드 &amp; 서비스 카드</h2><ul><li><strong>모델 카드(Model Cards)</strong>: 모델의 <strong>의도된 사용, 위험등급, 데이터 출처&#x2F;라이선스&#x2F;편향, 학습·평가 지표</strong> 문서화<ul><li><strong>SageMaker Model Cards</strong>로 중앙화 관리 → <strong>감사·규제 대응</strong>에 유리</li></ul></li><li><strong>AWS AI Service Cards</strong>: Bedrock·Textract·Rekognition 등 <strong>서비스 수준의 책임감 있는 설계·한계·권장 사용</strong> 문서</li></ul><blockquote><p><strong>시험 포인트</strong><br>“감사 준비&#x2F;규제 대응 문서화?” → <strong>SageMaker Model Cards &#x2F; AWS AI Service Cards</strong>.</p></blockquote><p align="center">  <img src="/images/aws_basic_208.png" width="80%"></p><hr><h2 id="11-운영-중-품질·거버넌스"><a href="#11-운영-중-품질·거버넌스" class="headerlink" title="11) 운영 중 품질·거버넌스"></a>11) 운영 중 품질·거버넌스</h2><ul><li><strong>SageMaker Model Monitor</strong>: 데이터&#x2F;품질 드리프트 감시, 임계치 위반 알림 → <strong>재학습 트리거</strong></li><li><strong>SageMaker Model Registry</strong>: 모델 <strong>버전·메타데이터·승인 상태</strong> 관리, <strong>배포 자동화</strong> 연계</li><li><strong>SageMaker Pipelines</strong>: ML CI&#x2F;CD(처리→학습→튜닝→검증→등록→배포) 자동화</li><li><strong>SageMaker Role Manager</strong>: 페르소나(DS&#x2F;ML Ops 등)별 최소권한 설계</li></ul><hr><h2 id="12-데이터·편향-다루기"><a href="#12-데이터·편향-다루기" class="headerlink" title="12) 데이터·편향 다루기"></a>12) 데이터·편향 다루기</h2><ul><li><strong>SageMaker Data Wrangler</strong>: 전처리·시각화·품질점검, <strong>언더리프레젠티드 그룹 보강</strong>(데이터 증강)</li><li><strong>SageMaker Feature Store</strong>: 재사용 가능한 <strong>고품질 피처 카탈로그</strong>로 일관성 확보</li><li><strong>Clarify 바이어스 지표</strong>: 샘플링 편향·라벨 편향·성능 편향 등<br><strong>통계적 측정</strong></li></ul><hr><h2 id="13-실무-체크리스트-요약"><a href="#13-실무-체크리스트-요약" class="headerlink" title="13) 실무 체크리스트 (요약)"></a>13) 실무 체크리스트 (요약)</h2><ol><li><strong>요건 파악</strong>: 규제&#x2F;감사&#x2F;데이터 국외반출&#x2F;보관기간</li><li><strong>아키텍처 보안</strong>: VPC, KMS, 프라이빗 서브넷, 엔드포인트 정책</li><li><strong>가드레일</strong>: Bedrock Guardrails(주제&#x2F;PII&#x2F;톤), 콘텐츠 필터</li><li><strong>RAG</strong>: 최신성·정확성·출처 확보, <strong>“미검증” 라벨</strong></li><li><strong>로깅&#x2F;감사</strong>: CloudWatch&#x2F;CloudTrail, 프롬프트&#x2F;응답 감사 가능성</li><li><strong>거버넌스</strong>: Model Cards, Registry, Pipelines, Model Monitor</li><li><strong>설명가능성</strong>: Clarify(SHAP, 편향), PDP&#x2F;특성중요도 보고</li><li><strong>휴먼 인더루프</strong>: 저신뢰 케이스 A2I 라우팅</li><li><strong>비결정성 제어</strong>: temperature&#x2F;top-p&#x2F;beam 재현성 가이드(완전 결정적 보장은 어려움)</li><li><strong>교육</strong>: 사용자에게 환각·저작권·보안 인지 교육</li></ol><hr><h2 id="14-미니-퀴즈-시험-대비"><a href="#14-미니-퀴즈-시험-대비" class="headerlink" title="14) 미니 퀴즈(시험 대비)"></a>14) 미니 퀴즈(시험 대비)</h2><ol><li><p><strong>환각을 줄이는 가장 효과적인 아키텍처 패턴은?</strong><br>→ <strong>RAG + 출처표기 + 저온도 디코딩 + 휴먼검증</strong></p></li><li><p><strong>규제 산업에서 모델 결정을 설명·감사하려면 어떤 AWS 기능을 조합?</strong><br>→ <strong>Model Cards + Clarify(설명&#x2F;편향) + Model Monitor(드리프트) + Registry(버전&#x2F;승인)</strong></p></li><li><p><strong>프롬프트 인젝션&#x2F;탈옥 방지책 3가지?</strong><br>→ <strong>Guardrails</strong>, <strong>입력 정화·시스템프롬프트 보호</strong>, <strong>IAM 최소권한·VPC&#x2F;KMS</strong>, (필요 시 <strong>A2I</strong>)</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;생성형-AI의-역량과-과제-시험-포인트-포함&quot;&gt;&lt;a href=&quot;#생성형-AI의-역량과-과제-시험-포인트-포함&quot; class=&quot;headerlink&quot; title=&quot;생성형 AI의 역량과 과제 (시험 포인트 포함)&quot;&gt;&lt;/a&gt;생성형 AI의 역량과 </summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (39) - Responsible AI &amp; Security</title>
    <link href="https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-39/"/>
    <id>https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-39/</id>
    <published>2025-09-02T18:55:18.000Z</published>
    <updated>2025-09-02T19:05:30.690Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Responsible-AI-Security-책임-있는-AI와-보안"><a href="#Responsible-AI-Security-책임-있는-AI와-보안" class="headerlink" title="Responsible AI &amp; Security (책임 있는 AI와 보안)"></a>Responsible AI &amp; Security (책임 있는 AI와 보안)</h1><h2 id="1-Responsible-AI-책임-있는-AI"><a href="#1-Responsible-AI-책임-있는-AI" class="headerlink" title="1. Responsible AI (책임 있는 AI)"></a>1. Responsible AI (책임 있는 AI)</h2><ul><li><strong>목표</strong>: AI 시스템이 <strong>투명성</strong>과 <strong>신뢰성</strong>을 가지도록 설계  </li><li><strong>중요성</strong>: 사용자가 결과를 신뢰하고, 부정적 결과나 위험을 줄일 수 있음  </li><li><strong>적용 범위</strong>: AI <strong>전체 라이프사이클</strong>  <ul><li>설계(Design) → 개발(Development) → 배포(Deployment) → 모니터링(Monitoring) → 평가(Evaluation)</li></ul></li></ul><h2 id="2-Security-보안"><a href="#2-Security-보안" class="headerlink" title="2. Security (보안)"></a>2. Security (보안)</h2><ul><li><strong>3대 원칙</strong>: CIA 원칙  <ul><li><strong>Confidentiality (기밀성)</strong>: 민감한 데이터 보호  </li><li><strong>Integrity (무결성)</strong>: 데이터가 변조되지 않도록 보장  </li><li><strong>Availability (가용성)</strong>: 필요한 사람이 필요한 시점에 데이터 접근 가능</li></ul></li><li><strong>적용 대상</strong>: 조직의 데이터, 정보 자산, IT 인프라 전반</li></ul><hr><h1 id="Governance-Compliance"><a href="#Governance-Compliance" class="headerlink" title="Governance &amp; Compliance"></a>Governance &amp; Compliance</h1><h2 id="1-Governance-거버넌스"><a href="#1-Governance-거버넌스" class="headerlink" title="1. Governance (거버넌스)"></a>1. Governance (거버넌스)</h2><ul><li><strong>목적</strong>: 리스크 관리 + 비즈니스 운영에서 가치 창출  </li><li><strong>방법</strong>: 명확한 정책, 가이드라인, 감독 체계 필요  </li><li><strong>효과</strong>: AI 시스템이 법률 및 규제 요구사항에 부합하도록 하고, <strong>사용자 신뢰</strong>를 강화</li></ul><h2 id="2-Compliance-컴플라이언스"><a href="#2-Compliance-컴플라이언스" class="headerlink" title="2. Compliance (컴플라이언스)"></a>2. Compliance (컴플라이언스)</h2><ul><li><strong>정의</strong>: 규정과 지침을 준수하는 것  </li><li><strong>중요 분야</strong>: 금융, 의료, 법률 같은 민감한 영역에서는 <strong>법적 규제 준수</strong>가 핵심</li></ul><hr><h1 id="Core-Dimensions-of-Responsible-AI"><a href="#Core-Dimensions-of-Responsible-AI" class="headerlink" title="Core Dimensions of Responsible AI"></a>Core Dimensions of Responsible AI</h1><ol><li><strong>공정성(Fairness)</strong> – 차별 방지, 포용성 확보  </li><li><strong>설명 가능성(Explainability)</strong> – 모델이 어떤 이유로 결과를 냈는지 이해 가능  </li><li><strong>프라이버시 &amp; 보안(Privacy &amp; Security)</strong> – 개인이 자신의 데이터 사용 여부를 통제  </li><li><strong>투명성(Transparency)</strong> – 모델의 동작과 한계를 명확히 알 수 있어야 함  </li><li><strong>정확성 &amp; 강건성(Veracity &amp; Robustness)</strong> – 예기치 못한 상황에서도 안정적이어야 함  </li><li><strong>거버넌스(Governance)</strong> – 책임 있는 AI 운영 체계 수립  </li><li><strong>안전성(Safety)</strong> – 사회와 개인에게 안전하고 유익해야 함  </li><li><strong>제어 가능성(Controllability)</strong> – 인간의 가치와 의도를 반영할 수 있어야 함</li></ol><hr><h1 id="Responsible-AI-–-AWS-서비스-활용"><a href="#Responsible-AI-–-AWS-서비스-활용" class="headerlink" title="Responsible AI – AWS 서비스 활용"></a>Responsible AI – AWS 서비스 활용</h1><ul><li><p><strong>Amazon Bedrock</strong></p><ul><li>모델 성능 평가(사람&#x2F;자동)  </li><li><strong>Guardrails</strong>: 민감 데이터(PII) 마스킹, 유해 콘텐츠 차단</li></ul></li><li><p><strong>SageMaker Clarify</strong></p><ul><li>정확도, 강건성, 유해성(Toxicity) 평가  </li><li><strong>Bias 감지</strong>: 예) 데이터가 중년층에 치우쳐 있음</li></ul></li><li><p><strong>SageMaker Data Wrangler</strong></p><ul><li>편향된 데이터 보정 → <strong>데이터 증강(Augmentation)</strong> 기능</li></ul></li><li><p><strong>SageMaker Model Monitor</strong></p><ul><li>운영 중 모델 품질 모니터링 (드리프트 탐지)</li></ul></li><li><p><strong>Amazon Augmented AI (A2I)</strong></p><ul><li>모델이 내놓은 결과에 대해 <strong>사람이 직접 리뷰</strong> 가능</li></ul></li><li><p><strong>Governance 관련 기능</strong></p><ul><li>SageMaker Role Manager (권한 관리)  </li><li>Model Cards (모델 문서화)  </li><li>Model Dashboard (중앙화된 모델 관리)</li></ul></li><li><p><strong>AWS AI Service Cards</strong></p><ul><li>서비스별 책임 있는 AI 문서 제공  </li><li>사용 목적, 제한 사항, 최적화 Best Practice 포함  </li><li>시험에서 등장할 수 있음 → <strong>Service Cards &#x3D; Responsible AI 문서</strong></li></ul></li></ul><hr><h1 id="Interpretability-Explainability-해석-가능성과-설명-가능성"><a href="#Interpretability-Explainability-해석-가능성과-설명-가능성" class="headerlink" title="Interpretability &amp; Explainability (해석 가능성과 설명 가능성)"></a>Interpretability &amp; Explainability (해석 가능성과 설명 가능성)</h1><ul><li><p><strong>Interpretability (해석 가능성)</strong>  </p><ul><li>사람이 모델의 **결정 원인(Why &amp; How)**을 이해할 수 있는 정도  </li><li>해석성이 높을수록 성능은 낮아질 수 있음  </li><li>예: 선형 회귀 → 해석 용이하지만 단순 &#x2F; 신경망 → 성능 높지만 해석 어려움</li></ul></li><li><p><strong>Explainability (설명 가능성)</strong>  </p><ul><li>모델 내부를 완전히 알지 못해도 <strong>입력과 출력 관계를 설명</strong>할 수 있는 것  </li><li>시험 포인트: <strong>Explainability는 Interpretability보다 덜 구체적이지만 충분할 수 있다</strong></li></ul></li></ul><p align="center">  <img src="/images/aws_basic_197.png" width="80%"></p><hr><h1 id="High-Interpretability-모델-예시"><a href="#High-Interpretability-모델-예시" class="headerlink" title="High Interpretability 모델 예시"></a>High Interpretability 모델 예시</h1><h3 id="Decision-Trees"><a href="#Decision-Trees" class="headerlink" title="Decision Trees"></a>Decision Trees</h3><ul><li>분류(Classification) &amp; 회귀(Regression) 작업에 사용  </li><li>특징 값 기준으로 데이터 분리 (예: “나이 &gt; 30?”)  </li><li>시각적으로 이해하기 쉽지만 <strong>Overfitting 위험</strong> 존재</li></ul><p align="center">  <img src="/images/aws_basic_198.png" width="80%"></p><hr><h1 id="Partial-Dependence-Plots-PDP"><a href="#Partial-Dependence-Plots-PDP" class="headerlink" title="Partial Dependence Plots (PDP)"></a>Partial Dependence Plots (PDP)</h1><ul><li><strong>특정 피처가 결과에 어떤 영향을 주는지 시각화</strong>  </li><li>다른 피처는 고정한 상태에서 단일 피처 변화만 관찰  </li><li>“블랙박스 모델(Neural Network)” 해석에 유용</li></ul><p align="center">  <img src="/images/aws_basic_199.png" width="80%"></p><hr><h1 id="Human-Centered-Design-HCD-for-Explainable-AI"><a href="#Human-Centered-Design-HCD-for-Explainable-AI" class="headerlink" title="Human-Centered Design (HCD) for Explainable AI"></a>Human-Centered Design (HCD) for Explainable AI</h1><p>AI 시스템 설계 시 <strong>인간 중심</strong>으로 고려해야 할 사항:</p><ol><li><strong>의사결정 강화</strong> – 위험과 오류를 최소화  </li><li><strong>명확성·단순성·사용성</strong> – 복잡한 환경에서도 쉽게 사용 가능해야 함  </li><li><strong>책임성과 성찰(Reflexivity)</strong> – 의사결정 과정을 되돌아보고 책임질 수 있어야 함  </li><li><strong>편향 없는 결정</strong> – 데이터와 인간 모두의 편향을 최소화  </li><li><strong>인간 &amp; AI 학습</strong> – RLHF(인간 피드백 학습) + 개인화  </li><li><strong>사용자 중심 설계</strong> – 다양한 사용자층이 접근 가능하도록 설계</li></ol><hr><h1 id="📌-시험-대비-핵심-포인트"><a href="#📌-시험-대비-핵심-포인트" class="headerlink" title="📌 시험 대비 핵심 포인트"></a>📌 시험 대비 핵심 포인트</h1><ul><li>Responsible AI의 <strong>핵심 차원(Fairness, Explainability, Safety, Controllability 등)</strong> 기억  </li><li><strong>AWS Responsible AI 서비스 매핑</strong>:<ul><li>Clarify &#x3D; Bias 탐지 &amp; Explainability  </li><li>Data Wrangler &#x3D; 데이터 편향 수정  </li><li>Model Monitor &#x3D; 운영 중 품질 모니터링  </li><li>A2I &#x3D; 인간 검토  </li><li>Bedrock Guardrails &#x3D; 콘텐츠 필터링</li></ul></li><li><strong>Service Cards</strong> &#x3D; 책임 있는 AI 문서화 도구 (시험 단골)  </li><li>Interpretability vs Explainability 차이 반드시 숙지</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Responsible-AI-Security-책임-있는-AI와-보안&quot;&gt;&lt;a href=&quot;#Responsible-AI-Security-책임-있는-AI와-보안&quot; class=&quot;headerlink&quot; title=&quot;Responsible AI &amp;amp;</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(39) - Responsible AI, Security, Governance, and Compliance</title>
    <link href="https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-39/"/>
    <id>https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-39/</id>
    <published>2025-09-02T18:55:14.000Z</published>
    <updated>2025-09-02T19:27:42.927Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Responsible-AI-Security-Governance-and-Compliance"><a href="#Responsible-AI-Security-Governance-and-Compliance" class="headerlink" title="Responsible AI, Security, Governance, and Compliance"></a>Responsible AI, Security, Governance, and Compliance</h1><p>This section is less about building models and more about ensuring <strong>trust, safety, and compliance</strong> when deploying AI. While it may feel text-heavy, it’s very important for the <strong>AWS AI certification exam</strong>. Let’s go step by step.</p><hr><h2 id="Responsible-AI"><a href="#Responsible-AI" class="headerlink" title="Responsible AI"></a>Responsible AI</h2><p><strong>Definition:</strong> Responsible AI ensures that AI systems are <strong>transparent, trustworthy, and beneficial to society</strong>. It reduces risks and negative outcomes across the entire AI lifecycle:  </p><ul><li><strong>Design → Development → Deployment → Monitoring → Evaluation</strong></li></ul><h3 id="Key-Dimensions-of-Responsible-AI"><a href="#Key-Dimensions-of-Responsible-AI" class="headerlink" title="Key Dimensions of Responsible AI"></a>Key Dimensions of Responsible AI</h3><ol><li><strong>Fairness</strong> – Promote inclusion and prevent discrimination.  </li><li><strong>Explainability</strong> – Ensure humans can understand why a model made a decision.  </li><li><strong>Privacy &amp; Security</strong> – Individuals must control when and how their data is used.  </li><li><strong>Transparency</strong> – Clear visibility into how models operate and their limitations.  </li><li><strong>Veracity &amp; Robustness</strong> – Models should remain reliable even in unexpected scenarios.  </li><li><strong>Governance</strong> – Define, implement, and enforce responsible AI practices.  </li><li><strong>Safety</strong> – AI should benefit individuals and society, minimizing harm.  </li><li><strong>Controllability</strong> – Ensure models can be aligned with human values and intent.</li></ol><p>👉 <strong>Exam Tip:</strong> Expect questions about <strong>bias detection, explainability vs. interpretability, and fairness in AI systems</strong>.</p><hr><h2 id="Security"><a href="#Security" class="headerlink" title="Security"></a>Security</h2><p>For AI systems, security must uphold the <strong>CIA triad</strong>:  </p><ul><li><strong>Confidentiality</strong> – Data is protected from unauthorized access.  </li><li><strong>Integrity</strong> – Data and model predictions are reliable and unchanged.  </li><li><strong>Availability</strong> – AI services are accessible when needed.</li></ul><p>This applies not just to data, but also to <strong>infrastructure and organizational assets</strong>.</p><hr><h2 id="Governance-Compliance"><a href="#Governance-Compliance" class="headerlink" title="Governance &amp; Compliance"></a>Governance &amp; Compliance</h2><ul><li><strong>Governance</strong> – Defines policies, oversight, and processes to align AI with <strong>legal and regulatory requirements</strong>, while improving trust.  </li><li><strong>Compliance</strong> – Ensures adherence to regulations (critical in <strong>healthcare, finance, and legal sectors</strong>).</li></ul><p>👉 <strong>Exam Tip:</strong> If a question mentions <strong>regulations, risk management, or improving trust</strong>, the answer usually relates to <strong>governance and compliance</strong>.</p><hr><h2 id="AWS-Services-for-Responsible-AI"><a href="#AWS-Services-for-Responsible-AI" class="headerlink" title="AWS Services for Responsible AI"></a>AWS Services for Responsible AI</h2><p>AWS provides multiple tools to implement responsible AI:</p><ul><li><p><strong>Amazon Bedrock</strong>  </p><ul><li>Human or automated model evaluation.  </li><li><strong>Guardrails</strong>: block harmful content, filter undesirable topics, redact PII (Personally Identifiable Information).</li></ul></li><li><p><strong>SageMaker Clarify</strong>  </p><ul><li>Evaluate models for <strong>accuracy, robustness, and toxicity</strong>.  </li><li>Detect bias (e.g., data over-representing middle-aged groups).</li></ul></li><li><p><strong>SageMaker Data Wrangler</strong>  </p><ul><li>Fix dataset bias (e.g., use data augmentation for underrepresented groups).</li></ul></li><li><p><strong>SageMaker Model Monitor</strong>  </p><ul><li>Monitor model quality in production, detect drift, and trigger alerts.</li></ul></li><li><p><strong>Amazon Augmented AI (A2I)</strong>  </p><ul><li>Human review of low-confidence model predictions.</li></ul></li><li><p><strong>Governance Tools</strong>  </p><ul><li><strong>Model Cards</strong> – Document model details (intended use, risks, training data).  </li><li><strong>Model Dashboard</strong> – View and track all models in one place.  </li><li><strong>Role Manager</strong> – Define access controls for different personas (e.g., data scientist vs. MLOps engineer).</li></ul></li><li><p><strong>AWS AI Service Cards</strong>  </p><ul><li>Official documentation that describes intended use cases, limitations, and best practices for responsible AI.</li></ul></li></ul><hr><h2 id="Interpretability-vs-Explainability"><a href="#Interpretability-vs-Explainability" class="headerlink" title="Interpretability vs. Explainability"></a>Interpretability vs. Explainability</h2><h3 id="Interpretability"><a href="#Interpretability" class="headerlink" title="Interpretability"></a>Interpretability</h3><ul><li>The degree to which a human can <strong>understand the cause of a model’s decision</strong>.  </li><li>High interpretability &#x3D; models are transparent but often less powerful.  </li><li><strong>Trade-off:</strong>  <ul><li>Linear regression &#x3D; <strong>high interpretability, low performance</strong>.  </li><li>Neural networks &#x3D; <strong>low interpretability, high performance</strong>.</li></ul></li></ul><h3 id="Explainability"><a href="#Explainability" class="headerlink" title="Explainability"></a>Explainability</h3><ul><li>Explains <strong>inputs and outputs</strong> without knowing exactly how the model works.  </li><li>Example: “Given income and credit history, the model predicts loan approval.”  </li><li>Often enough for compliance and trust, even if the model itself is complex.</li></ul><p>👉 <strong>Exam Tip:</strong> If a question mentions <strong>“why and how” → interpretability</strong>, but if it says <strong>“explain results to stakeholders” → explainability</strong>.</p><p align="center">  <img src="/images/aws_basic_197.png" width="80%"></p><hr><h2 id="High-Interpretability-Models"><a href="#High-Interpretability-Models" class="headerlink" title="High Interpretability Models"></a>High Interpretability Models</h2><ul><li><strong>Decision Trees</strong>  <ul><li>Simple, rule-based splits (e.g., “Is income &gt; $50K?”).  </li><li>Easy to interpret and visualize.  </li><li>Risk: prone to <strong>overfitting</strong> if too many branches.</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_198.png" width="80%"></p><hr><h2 id="Tools-for-Black-Box-Models"><a href="#Tools-for-Black-Box-Models" class="headerlink" title="Tools for Black-Box Models"></a>Tools for Black-Box Models</h2><ul><li><strong>Partial Dependence Plots (PDPs)</strong>  <ul><li>Show how a single feature impacts predictions while holding others constant.  </li><li>Useful for black-box models like neural networks.  </li><li>Example: income vs. probability of loan approval.</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_199.png" width="80%"></p><hr><h2 id="Human-Centered-Design-HCD-for-AI"><a href="#Human-Centered-Design-HCD-for-AI" class="headerlink" title="Human-Centered Design (HCD) for AI"></a>Human-Centered Design (HCD) for AI</h2><p>AI should be designed with <strong>human needs first</strong>:</p><ol><li><strong>Amplify decision-making</strong> – Especially in stressful environments (e.g., healthcare).  </li><li><strong>Clarity &amp; simplicity</strong> – Easy-to-use AI interfaces.  </li><li><strong>Bias mitigation</strong> – Train decision-makers to recognize bias and ensure datasets are balanced.  </li><li><strong>Human + AI learning</strong>  <ul><li><strong>Cognitive apprenticeship</strong>: AI learns from human experts.  </li><li><strong>Personalization</strong>: adapt to user needs.</li></ul></li><li><strong>User-centered design</strong> – Accessible to a wide variety of users.</li></ol><hr><h2 id="Key-Takeaways-for-the-Exam"><a href="#Key-Takeaways-for-the-Exam" class="headerlink" title="Key Takeaways for the Exam"></a>Key Takeaways for the Exam</h2><ul><li><strong>Responsible AI</strong> &#x3D; fairness, transparency, explainability, bias mitigation.  </li><li><strong>Security</strong> &#x3D; confidentiality, integrity, availability.  </li><li><strong>Governance</strong> &#x3D; policies + oversight.  </li><li><strong>Compliance</strong> &#x3D; following regulations.  </li><li><strong>AWS Tools to Know</strong>: Bedrock Guardrails, SageMaker Clarify, Data Wrangler, Model Monitor, A2I, Model Cards, Model Dashboard, Role Manager.  </li><li><strong>Trade-off</strong>: High interpretability → low performance, and vice versa.  </li><li><strong>Decision Trees &amp; PDPs</strong> &#x3D; ways to improve explainability.  </li><li><strong>HCD</strong> ensures AI is human-friendly and trustworthy.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Responsible-AI-Security-Governance-and-Compliance&quot;&gt;&lt;a href=&quot;#Responsible-AI-Security-Governance-and-Compliance&quot; class=&quot;headerlink&quot; t</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(38) - ML Governance &amp; Productivity</title>
    <link href="https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-38/"/>
    <id>https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-38/</id>
    <published>2025-09-02T18:34:17.000Z</published>
    <updated>2025-09-02T18:54:53.776Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Amazon-SageMaker-–-ML-Governance-Productivity-Exam-friendly-Guide"><a href="#Amazon-SageMaker-–-ML-Governance-Productivity-Exam-friendly-Guide" class="headerlink" title="Amazon SageMaker – ML Governance &amp; Productivity (Exam-friendly Guide)"></a>Amazon SageMaker – ML Governance &amp; Productivity (Exam-friendly Guide)</h1><p>This rewrite keeps things simple, adds missing context, and highlights what typically shows up on AWS exams.</p><hr><h2 id="Why-“ML-Governance”-matters"><a href="#Why-“ML-Governance”-matters" class="headerlink" title="Why “ML Governance” matters"></a>Why “ML Governance” matters</h2><p>Once a model is in production, you need to <strong>know what it does, who can touch it, how it’s behaving, and how it changes over time</strong>. SageMaker gives you a set of tools to do exactly that.</p><hr><h2 id="Model-documentation-visibility"><a href="#Model-documentation-visibility" class="headerlink" title="Model documentation &amp; visibility"></a>Model documentation &amp; visibility</h2><h3 id="SageMaker-Model-Cards"><a href="#SageMaker-Model-Cards" class="headerlink" title="SageMaker Model Cards"></a>SageMaker <strong>Model Cards</strong></h3><ul><li>A living document for each model: <strong>intended use</strong>, <strong>risk rating</strong>, <strong>training data &amp; method</strong>, <strong>evaluation metrics</strong>, and <strong>owners</strong>.</li><li>Think of it as “README + audit sheet” for compliance and handoffs.</li></ul><p><strong>Exam tip:</strong> If a question mentions <em>“documenting model intent, risks, and lineage for auditors”</em>, the answer is <strong>Model Cards</strong>.</p><p align="center">  <img src="/images/aws_basic_187.png" width="80%"></p> <hr><h3 id="SageMaker-Model-Dashboard"><a href="#SageMaker-Model-Dashboard" class="headerlink" title="SageMaker Model Dashboard"></a>SageMaker <strong>Model Dashboard</strong></h3><ul><li>A <strong>central place</strong> to <strong>view, search, and explore</strong> every model across accounts&#x2F;teams (from the SageMaker console).</li><li>Lets you <strong>track which models are deployed</strong> to endpoints.</li><li>Surfaces <strong>warnings</strong> when thresholds are breached (data quality, model quality, bias, explainability drift).</li></ul><p><strong>Use it for:</strong> “Which models are live?” “Which ones are failing data-quality checks?”</p><p align="center">  <img src="/images/aws_basic_188.png" width="80%"></p> <hr><h3 id="SageMaker-Role-Manager"><a href="#SageMaker-Role-Manager" class="headerlink" title="SageMaker Role Manager"></a>SageMaker <strong>Role Manager</strong></h3><ul><li>Define <strong>least-privilege roles</strong> by <strong>persona</strong> (e.g., <em>data scientist</em>, <em>MLOps engineer</em>).</li><li>Speeds up secure access setup for Studio, training jobs, endpoints, registries, etc.</li></ul><p><strong>Exam tip:</strong> If you see <em>“quickly provision SageMaker permissions for different job functions”</em>, pick <strong>Role Manager</strong>.</p><hr><h2 id="Model-quality-lifecycle"><a href="#Model-quality-lifecycle" class="headerlink" title="Model quality &amp; lifecycle"></a>Model quality &amp; lifecycle</h2><h3 id="SageMaker-Model-Monitor"><a href="#SageMaker-Model-Monitor" class="headerlink" title="SageMaker Model Monitor"></a>SageMaker <strong>Model Monitor</strong></h3><ul><li>Continuously or on a schedule, checks <strong>data drift</strong> (inputs no longer look like training data), <strong>model drift</strong> (performance drops), <strong>bias&#x2F;explainability drift</strong>, and <strong>data quality</strong>.</li><li>Sends <strong>alerts</strong> so you can <strong>fix pipelines</strong> or <strong>retrain</strong>.</li></ul><p><strong>Example:</strong> A loan-approval model starts approving borrowers below the target credit score—Model Monitor flags drift → you retrain with recent data.</p><p><strong>Exam tip:</strong> <em>Detecting drift in production</em> → <strong>Model Monitor</strong>.</p><p align="center">  <img src="/images/aws_basic_189.png" width="80%"></p><hr><h3 id="SageMaker-Model-Registry"><a href="#SageMaker-Model-Registry" class="headerlink" title="SageMaker Model Registry"></a>SageMaker <strong>Model Registry</strong></h3><ul><li>Central repo to <strong>catalog, version, approve, deploy, and share</strong> models.</li><li>Supports <strong>approval states</strong> (e.g., <em>Pending</em>, <em>Approved</em>, <em>Rejected</em>), <strong>metadata</strong>, and <strong>automated deployments</strong> from the registry.</li></ul><p><strong>Exam tip:</strong> <em>Model versioning + approval workflow + promotion to prod</em> → <strong>Model Registry</strong>.</p><p align="center">  <img src="/images/aws_basic_190.png" width="80%"></p><hr><h2 id="CI-CD-for-ML"><a href="#CI-CD-for-ML" class="headerlink" title="CI&#x2F;CD for ML"></a>CI&#x2F;CD for ML</h2><h3 id="SageMaker-Pipelines"><a href="#SageMaker-Pipelines" class="headerlink" title="SageMaker Pipelines"></a>SageMaker <strong>Pipelines</strong></h3><p>Automates the path from data to deployment (MLOps). A pipeline is built from <strong>Steps</strong>:</p><ul><li><strong>Processing</strong> – data prep&#x2F;feature engineering (Data Wrangler&#x2F;processing jobs).</li><li><strong>Training</strong> – train a model.</li><li><strong>Tuning</strong> – hyperparameter optimization (HPO).</li><li><strong>AutoML</strong> – train automatically with Autopilot.</li><li><strong>Model</strong> – create&#x2F;register a SageMaker Model (often into <strong>Model Registry</strong>).</li><li><strong>ClarifyCheck</strong> – bias&#x2F;explainability checks vs baselines.</li><li><strong>QualityCheck</strong> – data&#x2F;model quality checks vs baselines.</li></ul><p><strong>Why Pipelines:</strong> Reproducible, faster iterations, fewer manual errors, and easy promotion Dev → Staging → Prod.</p><p><strong>Exam tip:</strong> <em>“Automate build&#x2F;train&#x2F;test&#x2F;deploy and attach gates for quality checks”</em> → <strong>Pipelines</strong> (+ <strong>ClarifyCheck&#x2F;QualityCheck</strong> steps).</p><p align="center">  <img src="/images/aws_basic_191.png" width="80%"></p><hr><h2 id="Build-faster-with-prebuilt-models-no-code-tools"><a href="#Build-faster-with-prebuilt-models-no-code-tools" class="headerlink" title="Build faster with prebuilt models &amp; no-code tools"></a>Build faster with prebuilt models &amp; no-code tools</h2><h3 id="SageMaker-JumpStart"><a href="#SageMaker-JumpStart" class="headerlink" title="SageMaker JumpStart"></a>SageMaker <strong>JumpStart</strong></h3><ul><li>An <strong>ML Hub</strong> of pre-trained <strong>foundation models (FMs)</strong> and task models (CV&#x2F;NLP) from providers like <strong>Hugging Face, Meta, Stability AI, Databricks</strong>, etc.</li><li>You can <strong>fine-tune on your data</strong>, then <strong>deploy on SageMaker</strong> with full control (instance types, autoscaling, serverless, etc.).</li><li>Also includes <strong>prebuilt solutions</strong> (demand forecasting, fraud detection, credit scoring, computer vision).</li></ul><p><strong>When to use:</strong> You need a strong baseline fast, or a packaged solution to customize.</p><p align="center">  <img src="/images/aws_basic_192.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_193.png" width="80%"></p><hr><h3 id="SageMaker-Canvas-No-code"><a href="#SageMaker-Canvas-No-code" class="headerlink" title="SageMaker Canvas (No-code)"></a>SageMaker <strong>Canvas</strong> (No-code)</h3><ul><li><strong>Visual interface</strong> to build models (classification, regression, forecasting) without writing code.</li><li>Can use <strong>Autopilot (AutoML)</strong> under the hood.</li><li>Integrates with <strong>Data Wrangler</strong> for prep and can <strong>pull ready-to-use models</strong> from <strong>Bedrock&#x2F;JumpStart</strong>.</li><li><strong>Ready-to-use models:</strong> Comprehend (sentiment, entities), Rekognition (vision), Textract (document OCR).</li></ul><p><strong>Use it for:</strong> Analysts and business users who want predictions without Python.</p><p><strong>Exam tip:</strong> <em>“No-code model building for business teams”</em> → <strong>Canvas</strong>.</p><p align="center">  <img src="/images/aws_basic_194.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_195.png" width="80%"></p><hr><h2 id="Responsible-AI-explainability"><a href="#Responsible-AI-explainability" class="headerlink" title="Responsible AI &amp; explainability"></a>Responsible AI &amp; explainability</h2><h3 id="SageMaker-Clarify"><a href="#SageMaker-Clarify" class="headerlink" title="SageMaker Clarify"></a>SageMaker <strong>Clarify</strong></h3><ul><li><strong>Bias detection</strong> (dataset &amp; model), <strong>explainability</strong> (global + per-prediction), and <strong>foundation-model evaluations</strong> (e.g., tone, helpfulness).</li><li>Works both <strong>pre-deployment</strong> (validate) and <strong>post-deployment</strong> (debug).</li></ul><p><strong>Typical questions:</strong><br>“Why was this loan denied?” → use Clarify <strong>SHAP-based</strong> explanations to rank influential features.<br>“Detect bias in a dataset&#x2F;model” → <strong>Clarify</strong> with statistical metrics.</p><p><strong>Bias types to recognize (human context):</strong> - <strong>Sampling bias</strong> – training data isn’t representative. - <strong>Measurement bias</strong> – flawed or skewed instrumentation&#x2F;labels. - <strong>Observer bias</strong> – human annotators influence labels. - <strong>Confirmation bias</strong> – interpreting data to fit expectations.</p><hr><h2 id="Human-in-the-loop-HITL"><a href="#Human-in-the-loop-HITL" class="headerlink" title="Human-in-the-loop (HITL)"></a>Human-in-the-loop (HITL)</h2><h3 id="SageMaker-Ground-Truth-and-Ground-Truth-Plus"><a href="#SageMaker-Ground-Truth-and-Ground-Truth-Plus" class="headerlink" title="SageMaker Ground Truth (and Ground Truth Plus)"></a>SageMaker <strong>Ground Truth</strong> (and Ground Truth Plus)</h3><ul><li><strong>Human feedback for ML</strong>: high-quality <strong>data labeling</strong>, <strong>model evaluation</strong>, and <strong>preference alignment</strong>.</li><li>Reviewers: <strong>your employees</strong>, <strong>vetted vendors</strong>, or <strong>Amazon Mechanical Turk</strong>.</li><li><strong>RLHF</strong> (Reinforcement Learning from Human Feedback) support: human preferences contribute to a <strong>reward</strong> signal for model alignment.</li><li><strong>Plus</strong> adds managed, expert labeling teams and project management.</li></ul><p><strong>Exam tip:</strong> <em>“Collect labeled data at scale with human reviewers”</em> → <strong>Ground Truth</strong> (or <strong>Ground Truth Plus</strong> if fully managed).</p><hr><h2 id="Open-source-tracking"><a href="#Open-source-tracking" class="headerlink" title="Open-source tracking"></a>Open-source tracking</h2><h3 id="MLflow-on-SageMaker"><a href="#MLflow-on-SageMaker" class="headerlink" title="MLflow on SageMaker"></a><strong>MLflow on SageMaker</strong></h3><ul><li>Launch <strong>MLflow Tracking Servers</strong> from Studio to <strong>track experiments&#x2F;runs</strong>, metrics, and artifacts.</li><li>Fully integrated with SageMaker resources.</li></ul><p><strong>When to use:</strong> Your team already uses MLflow but wants AWS-managed infra around it.</p><hr><h2 id="Extra-features-that-show-up-on-exams"><a href="#Extra-features-that-show-up-on-exams" class="headerlink" title="Extra features that show up on exams"></a>Extra features that show up on exams</h2><ul><li><p><strong>Network Isolation mode</strong><br>Run training&#x2F;inference <strong>containers without any outbound internet</strong> (no S3&#x2F;VPC&#x2F;Internet). Use this for <strong>strict data-exfiltration controls</strong>.<br><strong>Keyword:</strong> “<strong>No egress</strong>, fully isolated job”.</p></li><li><p><strong>DeepAR</strong> (built-in algorithm) For <strong>time-series forecasting</strong>, based on <strong>RNNs</strong>.<br><strong>Keyword match:</strong> “<strong>forecast time series</strong>“ → <strong>DeepAR</strong>.</p></li></ul><hr><h2 id="One-page-cheat-sheet-what-to-pick-when"><a href="#One-page-cheat-sheet-what-to-pick-when" class="headerlink" title="One-page cheat sheet (what to pick when)"></a>One-page cheat sheet (what to pick when)</h2><ul><li><strong>Document model purpose &amp; risks</strong> → <em>Model Cards</em></li><li><strong>See&#x2F;search all models, find violations</strong> → <em>Model Dashboard</em></li><li><strong>Detect drift&#x2F;quality issues in prod</strong> → <em>Model Monitor</em></li><li><strong>Versioning, approvals, promote to prod</strong> → <em>Model Registry</em></li><li><strong>Automate build→train→test→deploy</strong> → <em>Pipelines</em> (+Clarify&#x2F;Quality checks)</li><li><strong>Pretrained models &amp; packaged solutions</strong> → <em>JumpStart</em></li><li><strong>No-code model building</strong> → <em>Canvas</em> (uses Autopilot, integrates with Bedrock&#x2F;JumpStart)</li><li><strong>Bias &amp; explainability</strong> → <em>Clarify</em></li><li><strong>Human labeling&#x2F;evaluation&#x2F;RLHF</strong> → <em>Ground Truth &#x2F; Ground Truth Plus</em></li><li><strong>Strict security (no outbound)</strong> → <em>Network Isolation</em></li><li><strong>Time-series forecasting</strong> → <em>DeepAR</em></li></ul><hr><h2 id="Mini-scenario-practice-exam-style"><a href="#Mini-scenario-practice-exam-style" class="headerlink" title="Mini scenario practice (exam-style)"></a>Mini scenario practice (exam-style)</h2><ol><li><p><strong>“Auditors request one place to see each model’s purpose, training details, and risk.”</strong><br>→ <strong>Model Cards</strong></p></li><li><p><strong>“Alert when live model inputs diverge from training data distribution.”</strong><br>→ <strong>Model Monitor</strong> (data drift)</p></li><li><p><strong>“Promote a tested model from Staging to Prod with an approval gate.”</strong><br>→ <strong>Model Registry</strong> + <strong>Pipelines</strong></p></li><li><p><strong>“Business analysts want to build predictions with no code.”</strong><br>→ <strong>Canvas</strong> (Autopilot)</p></li><li><p><strong>“Fine-tune a foundation model and deploy on SageMaker.”</strong><br>→ <strong>JumpStart</strong></p></li><li><p><strong>“Ensure training job cannot reach the internet or S3.”</strong><br>→ <strong>Network Isolation mode</strong></p></li><li><p><strong>“Forecast sales for the next 30 days.”</strong><br>→ <strong>DeepAR</strong></p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Amazon-SageMaker-–-ML-Governance-Productivity-Exam-friendly-Guide&quot;&gt;&lt;a href=&quot;#Amazon-SageMaker-–-ML-Governance-Productivity-Exam-frie</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (38) - SageMaker ML 거버넌스 및 확장 기능</title>
    <link href="https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-38/"/>
    <id>https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-38/</id>
    <published>2025-09-02T18:34:11.000Z</published>
    <updated>2025-09-02T18:54:53.776Z</updated>
    
    <content type="html"><![CDATA[<h1 id="SageMaker-–-ML-거버넌스-및-확장-기능"><a href="#SageMaker-–-ML-거버넌스-및-확장-기능" class="headerlink" title="SageMaker – ML 거버넌스 및 확장 기능"></a>SageMaker – ML 거버넌스 및 확장 기능</h1><h2 id="SageMaker-거버넌스-도구"><a href="#SageMaker-거버넌스-도구" class="headerlink" title="SageMaker 거버넌스 도구"></a>SageMaker 거버넌스 도구</h2><p>머신러닝 모델을 실제 서비스에 배포했다면, <strong>거버넌스(Governance)</strong> 가 필수적입니다. SageMaker는 이를 위해 다양한 도구를 제공합니다.</p><h3 id="1-SageMaker-Model-Cards"><a href="#1-SageMaker-Model-Cards" class="headerlink" title="1. SageMaker Model Cards"></a>1. SageMaker Model Cards</h3><ul><li>모델의 <strong>필수 정보</strong>를 문서화하는 카드 형식</li><li>예시:<ul><li>모델의 의도된 사용 목적</li><li>모델 리스크 등급</li><li>학습 데이터 및 훈련 과정 상세</li></ul></li><li>시험 포인트: <strong>“Model Cards &#x3D; 모델 문서화”</strong></li></ul><p align="center">  <img src="/images/aws_basic_187.png" width="80%"></p> <hr><h3 id="2-SageMaker-Model-Dashboard"><a href="#2-SageMaker-Model-Dashboard" class="headerlink" title="2. SageMaker Model Dashboard"></a>2. SageMaker Model Dashboard</h3><ul><li><strong>모든 모델을 중앙에서 조회·검색·탐색</strong>할 수 있는 포털</li><li>예시:<ul><li>어떤 모델이 현재 배포되어 추론(Inference)에 사용되는지 추적 가능</li></ul></li><li>품질 관리:<ul><li>데이터 품질, 모델 품질, 편향(Bias), 설명 가능성(Explainability) 위반 여부 확인</li></ul></li><li>시험 포인트: <strong>“중앙 대시보드, 품질 및 편향 모니터링”</strong></li></ul><p align="center">  <img src="/images/aws_basic_188.png" width="80%"></p> ------------------------------------------------------------------------<h3 id="3-SageMaker-Role-Manager"><a href="#3-SageMaker-Role-Manager" class="headerlink" title="3. SageMaker Role Manager"></a>3. SageMaker Role Manager</h3><ul><li>사용자 역할과 권한을 정의하는 기능</li><li>예시:<ul><li>데이터 사이언티스트, MLOps 엔지니어, 데이터 엔지니어</li></ul></li><li><strong>거버넌스와 보안 관리</strong>를 위한 핵심 기능</li></ul><hr><h2 id="SageMaker-Model-Monitor"><a href="#SageMaker-Model-Monitor" class="headerlink" title="SageMaker Model Monitor"></a>SageMaker Model Monitor</h2><ul><li><strong>운영 환경에서 모델 품질을 모니터링</strong>하는 기능</li><li>연속적(Continuous) 또는 주기적(On-Schedule) 모니터링 가능</li><li>편차(Drift) 발생 시 알림 제공 → 데이터 수정·재학습 필요</li><li>예시:<ul><li>대출 승인 모델이 시간이 지나면서 잘못된 신용 점수 사용자에게 대출을 승인하는 경우</li></ul></li><li>시험 포인트: <strong>“Model Monitor &#x3D; 운영 중 모델 품질 모니터링 &amp; 드리프트 감지”</strong></li></ul><p align="center">  <img src="/images/aws_basic_189.png" width="80%"></p><hr><h2 id="SageMaker-Model-Registry"><a href="#SageMaker-Model-Registry" class="headerlink" title="SageMaker Model Registry"></a>SageMaker Model Registry</h2><ul><li><strong>모델 중앙 저장소</strong>: 버전 관리, 메타데이터 관리, 승인 상태 관리</li><li>주요 기능:<ul><li>모델 카탈로그화</li><li>모델 승인(Approval) 프로세스 적용</li><li>자동 배포 및 팀 공유</li></ul></li><li>시험 포인트: <strong>“Model Registry &#x3D; 버전 관리 + 승인 + 자동화”</strong></li></ul><p align="center">  <img src="/images/aws_basic_190.png" width="80%"></p>------------------------------------------------------------------------<h2 id="SageMaker-Pipelines"><a href="#SageMaker-Pipelines" class="headerlink" title="SageMaker Pipelines"></a>SageMaker Pipelines</h2><ul><li><strong>ML 워크플로우 자동화 도구</strong> (CI&#x2F;CD for ML)</li><li>데이터 준비 → 모델 학습 → 하이퍼파라미터 튜닝 → 배포까지 자동화</li><li>장점:<ul><li>빠른 반복(Iteration)</li><li>수동 작업 제거 → 오류 감소</li><li>재사용 가능한 워크플로우</li></ul></li><li>주요 Step 유형:<ul><li>Processing: 데이터 처리&#x2F;피처 엔지니어링</li><li>Training: 모델 학습</li><li>Tuning: 하이퍼파라미터 최적화</li><li>AutoML: 자동 학습</li><li>Model: 모델 생성·등록</li><li>ClarifyCheck: 데이터·모델 편향, 설명 가능성 확인</li><li>QualityCheck: 데이터·모델 품질 점검</li></ul></li><li>시험 포인트: <strong>“Pipelines &#x3D; CI&#x2F;CD for ML, Step 유형 구분”</strong></li></ul><p align="center">  <img src="/images/aws_basic_191.png" width="80%"></p>------------------------------------------------------------------------<h2 id="SageMaker-JumpStart"><a href="#SageMaker-JumpStart" class="headerlink" title="SageMaker JumpStart"></a>SageMaker JumpStart</h2><ul><li><strong>미리 학습된 모델 허브</strong></li><li>제공 모델:<ul><li>Hugging Face, Meta, Stability AI, Databricks 등</li></ul></li><li>사용 사례:<ul><li>수요 예측, 신용 점수 예측, 사기 탐지, 이미지 분류</li></ul></li><li>특징:<ul><li>커스터마이징 가능</li><li>SageMaker에서 직접 배포</li></ul></li><li>시험 포인트: <strong>“JumpStart &#x3D; 미리 학습된 모델 &amp; 솔루션”</strong></li></ul><p align="center">  <img src="/images/aws_basic_192.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_193.png" width="80%"></p><hr><h2 id="SageMaker-Canvas"><a href="#SageMaker-Canvas" class="headerlink" title="SageMaker Canvas"></a>SageMaker Canvas</h2><ul><li><strong>노코드(No-Code) 인터페이스</strong>로 ML 모델 구축 가능</li><li>기능:<ul><li>Bedrock&#x2F;JumpStart 모델 활용</li><li>AutoML(SageMaker Autopilot 기반)로 맞춤형 모델 생성</li><li>Data Wrangler와 연계된 데이터 준비 가능</li></ul></li><li>통합 모델:<ul><li>Rekognition(이미지 분석)</li><li>Comprehend(텍스트 분석)</li><li>Textract(문서 분석)</li></ul></li><li>시험 포인트: <strong>“Canvas &#x3D; 비개발자도 ML 모델 구축 가능”</strong></li></ul><p align="center">  <img src="/images/aws_basic_194.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_195.png" width="80%"></p><hr><h2 id="MLFlow-on-SageMaker"><a href="#MLFlow-on-SageMaker" class="headerlink" title="MLFlow on SageMaker"></a>MLFlow on SageMaker</h2><ul><li>오픈소스 <strong>ML 라이프사이클 관리 툴</strong></li><li>기능:<ul><li>실험 추적, 결과 관리</li><li>SageMaker Studio 내에서 MLFlow Tracking Server 실행 가능</li></ul></li><li>시험 포인트: <strong>“MLFlow &#x3D; 오픈소스 ML 실험 관리”</strong></li></ul><p align="center">  <img src="/images/aws_basic_196.png" width="80%"></p><hr><h2 id="SageMaker-추가-기능"><a href="#SageMaker-추가-기능" class="headerlink" title="SageMaker 추가 기능"></a>SageMaker 추가 기능</h2><ol><li><strong>Network Isolation Mode</strong><ul><li>외부 네트워크(심지어 S3도) 차단 → 데이터 유출 방지</li><li>시험 포인트: <strong>“Network Isolation &#x3D; 보안 강화, 외부 접근 불가”</strong></li></ul></li><li><strong>DeepAR Forecasting Algorithm</strong><ul><li><strong>시계열 예측</strong> 알고리즘</li><li>내부적으로 RNN(Recurrent Neural Network) 사용</li><li>시험 포인트: <strong>“DeepAR &#x3D; 시계열 예측”</strong></li></ul></li></ol><hr><h2 id="시험-대비-요약"><a href="#시험-대비-요약" class="headerlink" title="시험 대비 요약"></a>시험 대비 요약</h2><ul><li>Model Cards → 모델 문서화</li><li>Model Dashboard → 중앙 포털, 품질·편향 추적</li><li>Model Monitor → 운영 중 품질 모니터링 &amp; 드리프트 감지</li><li>Model Registry → 버전 관리 + 승인 + 자동 배포</li><li>Pipelines → CI&#x2F;CD for ML</li><li>JumpStart → 미리 학습된 모델 &amp; 솔루션</li><li>Canvas → 노코드 ML 모델링</li><li>Clarify → 모델 설명력 &amp; 편향 탐지</li><li>Ground Truth → RLHF, 데이터 라벨링</li><li>DeepAR → 시계열 예측</li><li>Network Isolation → 보안 강화</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;SageMaker-–-ML-거버넌스-및-확장-기능&quot;&gt;&lt;a href=&quot;#SageMaker-–-ML-거버넌스-및-확장-기능&quot; class=&quot;headerlink&quot; title=&quot;SageMaker – ML 거버넌스 및 확장 기능&quot;&gt;&lt;/a&gt;SageM</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (37) - SageMaker 데이터 준비 및 모델 신뢰성 도구</title>
    <link href="https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-37/"/>
    <id>https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-37/</id>
    <published>2025-09-02T18:04:41.000Z</published>
    <updated>2025-09-02T18:28:14.402Z</updated>
    
    <content type="html"><![CDATA[<h1 id="SageMaker-–-데이터-준비-및-모델-신뢰성-도구"><a href="#SageMaker-–-데이터-준비-및-모델-신뢰성-도구" class="headerlink" title="SageMaker – 데이터 준비 및 모델 신뢰성 도구"></a>SageMaker – 데이터 준비 및 모델 신뢰성 도구</h1><h2 id="1-SageMaker-Data-Wrangler"><a href="#1-SageMaker-Data-Wrangler" class="headerlink" title="1. SageMaker Data Wrangler"></a>1. SageMaker Data Wrangler</h2><p>머신러닝을 하기 전에 가장 중요한 단계는 <strong>데이터 준비</strong>입니다. SageMaker Data Wrangler는 표 형식 데이터(tabular)와 이미지 데이터를 손쉽게 준비할 수 있는 도구입니다.</p><p>주요 기능: - 데이터 선택, 정제, 탐색, 시각화, 처리까지 <strong>단일 인터페이스</strong>에서 수행</p><ul><li>데이터 변환 및 <strong>피처 엔지니어링(feature engineering)</strong> 지원</li><li>SQL 쿼리 지원 → 데이터 분석 경험이 있는 사람에게 친숙</li><li>데이터 품질(Data Quality) 도구 제공 → 결측치, 잘못된 포맷 탐지</li></ul><p align="center">  <img src="/images/aws_basic_174.png" width="80%"></p> <p>활용 단계: </p><ol><li><strong>데이터 불러오기 (Import)</strong> → S3, Redshift 등 다양한 소스에서 불러오기</li></ol><p align="center">  <img src="/images/aws_basic_175.png" width="80%"></p> <ol start="2"><li><strong>데이터 미리보기 (Preview)</strong> → 열 이름, 타입 확인</li></ol><p align="center">  <img src="/images/aws_basic_176.png" width="80%"></p> <ol start="3"><li><strong>데이터 시각화 (Visualize)</strong> → 분포도, 상관관계 그래프 생성</li></ol><p align="center">  <img src="/images/aws_basic_177.png" width="80%"></p> <ol start="4"><li><strong>데이터 변환 (Transform)</strong> → 불필요한 열 삭제, 새로운 열 추가 등</li></ol><p align="center">  <img src="/images/aws_basic_178.png" width="80%"></p> <ol start="5"><li><strong>빠른 모델 확인 (Quick Model)</strong> → 간단히 학습시켜 성능 미리 점검</li></ol><p align="center">  <img src="/images/aws_basic_179.png" width="80%"></p> <ol start="6"><li><strong>데이터 플로우 내보내기 (Export Flow)</strong> → 파이프라인에 통합 가능</li></ol><p align="center">  <img src="/images/aws_basic_180.png" width="80%"></p> <p>👉 <strong>시험 포인트</strong>: 데이터 전처리 및 피처 엔지니어링 도구로 <strong>SageMaker Data Wrangler</strong>가 주로 언급됨.</p><hr><h2 id="2-ML-Feature란"><a href="#2-ML-Feature란" class="headerlink" title="2. ML Feature란?"></a>2. ML Feature란?</h2><p>**피처(Feature)**는 머신러닝 모델이 학습하거나 추론할 때 사용하는<br><strong>입력값</strong>입니다.<br>예: 음악 추천 데이터셋 → 노래 평점, 청취 시간, 사용자 연령&#x2F;성별 등</p><p>특징: - 원시 데이터를 그대로 쓰기보다는 <strong>가공된 값</strong>이 효과적임.</p><ul><li>예: 생년월일 → <strong>나이(age)</strong> 로 변환하면 숫자형 피처로 활용 가능.</li><li>회사 차원에서 <strong>표준화된 피처 저장소</strong>가 있으면 재사용성이 높아짐.</li></ul><p align="center">  <img src="/images/aws_basic_181.png" width="80%"></p> <hr><h2 id="3-SageMaker-Feature-Store"><a href="#3-SageMaker-Feature-Store" class="headerlink" title="3. SageMaker Feature Store"></a>3. SageMaker Feature Store</h2><p><strong>Feature Store</strong>는 여러 소스에서 수집한 피처를 저장, 관리, 검색할 수<br>있는 중앙 저장소입니다.</p><p>특징: - 다양한 소스에서 피처를 수집(Ingest)</p><ul><li>Data Wrangler에서 만든 피처를 바로 Feature Store로 저장 가능</li><li>SageMaker Studio 내에서 쉽게 검색·활용 가능</li></ul><p>👉 <strong>시험 포인트</strong>: Feature Store &#x3D; <strong>재사용 가능한 피처를 저장·공유하는<br>중앙 저장소</strong></p><p align="center">  <img src="/images/aws_basic_182.png" width="80%"></p> ------------------------------------------------------------------------<h2 id="4-SageMaker-Clarify"><a href="#4-SageMaker-Clarify" class="headerlink" title="4. SageMaker Clarify"></a>4. SageMaker Clarify</h2><p>모델이 공정하고 투명하게 작동하는지 평가하는 도구입니다.</p><h3 id="1-모델-평가"><a href="#1-모델-평가" class="headerlink" title="(1) 모델 평가"></a>(1) 모델 평가</h3><ul><li>파운데이션 모델(예: 모델 A vs 모델 B)의 성능 비교</li><li>인간적인 요소(친근함, 유머 등)도 평가 가능</li><li>AWS 제공 팀, 사내 직원, 또는 직접 준비한 데이터셋 활용</li></ul><p align="center">  <img src="/images/aws_basic_183.png" width="80%"></p> <h3 id="2-모델-설명력-Explainability"><a href="#2-모델-설명력-Explainability" class="headerlink" title="(2) 모델 설명력 (Explainability)"></a>(2) 모델 설명력 (Explainability)</h3><ul><li><strong>모델이 왜 이런 예측을 내렸는지</strong> 설명하는 기능</li><li>모델 배포 전 전체 특성을 이해하거나, 배포 후 예측 결과를 디버깅할 때<br>활용</li><li>예: 대출 거절 예측 → 어떤 입력값(소득, 대출 금액, 신용 등급)이 가장<br>큰 영향을 미쳤는지 분석</li></ul><p>👉 <strong>시험 포인트</strong>: 모델의 신뢰성과 투명성 확보 → <strong>Clarify의<br>Explainability 기능</strong></p><p align="center">  <img src="/images/aws_basic_184.png" width="80%"></p> <h3 id="3-편향-탐지-Bias-Detection"><a href="#3-편향-탐지-Bias-Detection" class="headerlink" title="(3) 편향 탐지 (Bias Detection)"></a>(3) 편향 탐지 (Bias Detection)</h3><ul><li>데이터셋과 모델 내 <strong>편향(bias)</strong> 자동 탐지</li><li>통계적 지표를 활용해 불균형 확인</li></ul><p>주요 편향 유형: - <strong>샘플링 편향(Sampling Bias)</strong>: 데이터셋이 전체 집단을<br>대표하지 못함</p><ul><li><strong>측정 편향(Measurement Bias)</strong>: 데이터 수집 도구가 왜곡</li><li><strong>관찰자 편향(Observer Bias)</strong>: 수집자의 주관적 해석이 반영됨</li><li><strong>확증 편향(Confirmation Bias)</strong>: 기존 믿음을 뒷받침하는 데이터만 강조</li></ul><p>예: 특정 인종 집단만 주로 ‘부적합’으로 분류된다면 심각한 <strong>편향</strong> 발생</p><p>👉 <strong>시험 포인트</strong>: Clarify &#x3D; <strong>Bias 탐지 + Explainability 제공</strong></p><p align="center">  <img src="/images/aws_basic_185.png" width="80%"></p> <hr><h2 id="5-SageMaker-Ground-Truth"><a href="#5-SageMaker-Ground-Truth" class="headerlink" title="5. SageMaker Ground Truth"></a>5. SageMaker Ground Truth</h2><p>Ground Truth는 <strong>데이터 라벨링과 RLHF(Reinforcement Learning from Human<br>Feedback)</strong> 를 위한 서비스입니다.</p><p>주요 기능: - <strong>데이터 라벨링</strong>: 이미지, 텍스트, 오디오 등에 정답(레이블)<br>붙이기</p><ul><li><strong>인간 피드백 기반 강화학습(RLHF)</strong>: 모델의 출력에 대해 사람의<br>피드백을 반영 → 모델이 인간의 선호도와 맞도록 학습</li><li>리뷰어(라벨러):</li><li>Amazon Mechanical Turk 작업자</li><li>사내 직원</li><li>제3자 벤더</li></ul><p>추가 기능:</p><ul><li><strong>Ground Truth Plus</strong> → AWS가 제공하는 관리형 라벨링 서비스</li></ul><p>👉 <strong>시험 포인트</strong>: 시험에서 <strong>RLHF</strong>라는 키워드가 나오면 → <strong>SageMaker<br>Ground Truth</strong></p><p align="center">  <img src="/images/aws_basic_186.png" width="80%"></p> <hr><h1 id="요약"><a href="#요약" class="headerlink" title="요약"></a>요약</h1><ul><li><strong>Data Wrangler</strong>: 데이터 전처리, 피처 엔지니어링 도구</li><li><strong>Feature Store</strong>: 표준화된 피처 저장&#x2F;재사용</li><li><strong>Clarify</strong>: 모델 설명력(Explainability) + 편향 탐지(Bias<br>Detection)</li><li><strong>Ground Truth</strong>: 데이터 라벨링 + RLHF</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;SageMaker-–-데이터-준비-및-모델-신뢰성-도구&quot;&gt;&lt;a href=&quot;#SageMaker-–-데이터-준비-및-모델-신뢰성-도구&quot; class=&quot;headerlink&quot; title=&quot;SageMaker – 데이터 준비 및 모델 신뢰성 도구&quot;&gt;</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(37) - SageMaker Data Tools and Model Evaluation</title>
    <link href="https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-37/"/>
    <id>https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-37/</id>
    <published>2025-09-02T18:04:37.000Z</published>
    <updated>2025-09-02T18:28:14.402Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Amazon-SageMaker-Data-Tools-and-Model-Evaluation"><a href="#Amazon-SageMaker-Data-Tools-and-Model-Evaluation" class="headerlink" title="Amazon SageMaker Data Tools and Model Evaluation"></a>Amazon SageMaker Data Tools and Model Evaluation</h1><h2 id="SageMaker-Data-Wrangler"><a href="#SageMaker-Data-Wrangler" class="headerlink" title="SageMaker Data Wrangler"></a>SageMaker Data Wrangler</h2><p>SageMaker <strong>Data Wrangler</strong> is a tool designed to make data preparation easier before building machine learning (ML) models.</p><p>With Data Wrangler, you can: - Prepare <strong>tabular and image data</strong> for ML</p><ul><li>Perform <strong>data preparation, transformation, and feature engineering</strong></li><li>Use a <strong>single interface</strong> for: - Data selection - Cleansing - Exploration - Visualization - Processing</li><li>Run <strong>SQL queries</strong> directly</li><li>Use the <strong>Data Quality tool</strong> to check for missaing or inconsistent values</li></ul><p align="center">  <img src="/images/aws_basic_174.png" width="80%"></p> <h3 id="Key-Features"><a href="#Key-Features" class="headerlink" title="Key Features"></a>Key Features</h3><ul><li><strong>Import Data</strong>: Load from sources like Amazon S3.</li></ul><p align="center">  <img src="/images/aws_basic_175.png" width="80%"></p> <ul><li><strong>Preview Data</strong>: Inspect column names, types, and values.</li></ul><p align="center">  <img src="/images/aws_basic_176.png" width="80%"></p> <ul><li><strong>Visualize Data</strong>: Build charts to better understand the dataset.</li></ul><p align="center">  <img src="/images/aws_basic_177.png" width="80%"></p> <ul><li><strong>Transform Data</strong>: Apply functions, drop or add columns.</li></ul><p align="center">  <img src="/images/aws_basic_178.png" width="80%"></p> <ul><li><strong>Quick Model</strong>: Run a quick test to check model performance.</li></ul><p align="center">  <img src="/images/aws_basic_179.png" width="80%"></p> <ul><li><strong>Export Data Flow</strong>: Save transformations for reuse in pipelines.</li></ul><p align="center">  <img src="/images/aws_basic_180.png" width="80%"></p> <p><strong>Exam Tip</strong>: If you see a question about <em>data preparation and feature engineering</em> in SageMaker, think of <strong>Data Wrangler</strong>.</p><hr><h2 id="What-are-ML-Features"><a href="#What-are-ML-Features" class="headerlink" title="What are ML Features?"></a>What are ML Features?</h2><p><strong>Features</strong> are the inputs to ML models during training and inference.</p><p>Example:<br>For a <strong>music dataset</strong>, features might include:</p><ul><li>Song ratings</li><li>Listening duration</li><li>Listener demographics</li></ul><p>High-quality, reusable features are critical. They improve consistency across teams and projects within a company.</p><p align="center">  <img src="/images/aws_basic_181.png" width="80%"></p> <hr><h2 id="SageMaker-Feature-Store"><a href="#SageMaker-Feature-Store" class="headerlink" title="SageMaker Feature Store"></a>SageMaker Feature Store</h2><p>The <strong>Feature Store</strong> helps manage and reuse features.</p><ul><li>Ingest features from multiple sources.</li><li>Define transformations to convert raw data into usable features.</li><li>Publish features directly from <strong>Data Wrangler</strong> into <strong>Feature Store</strong>.</li><li>Features are <strong>searchable and shareable</strong> within SageMaker Studio.</li></ul><p><strong>Exam Tip</strong>: Feature Store &#x3D; centralized place to manage, discover, and reuse ML features.</p><p align="center">  <img src="/images/aws_basic_182.png" width="80%"></p> ------------------------------------------------------------------------<h2 id="SageMaker-Clarify"><a href="#SageMaker-Clarify" class="headerlink" title="SageMaker Clarify"></a>SageMaker Clarify</h2><p><strong>SageMaker Clarify</strong> is about <strong>trust and fairness</strong> in ML models. It helps with:</p><ol><li><strong>Model Evaluation</strong>: Compare performance of two models (e.g., Model A vs Model B).</li></ol><ul><li>Can evaluate human factors like <strong>friendliness</strong> or <strong>humor</strong> in a foundation model.</li><li>Use AWS-managed human reviewers or your own employees.</li><li>Use built-in datasets or bring your own.</li><li>Includes built-in metrics and algorithms.</li></ul><p align="center">  <img src="/images/aws_basic_183.png" width="80%"></p> <ol start="2"><li><strong>Model Explainability</strong>: Understand <em>why</em> a model made its predictions.<ul><li>Example: “Why was this loan rejected?”</li><li>Helps debug deployed models and build <strong>trust</strong>.</li><li>Exam Tip: Look for keywords like <strong>explain predictions</strong> or <strong>increase transparency</strong> → Clarify.</li></ul></li></ol><p align="center">  <img src="/images/aws_basic_184.png" width="80%"></p> <ol start="3"><li><strong>Bias Detection</strong>: Identify and measure bias in data or models using statistical metrics.<ul><li>Example: If your dataset heavily favors one group, Clarify can flag it.</li><li>Types of Bias:<ul><li><strong>Sampling Bias</strong>: Data doesn’t fairly represent the population.</li><li><strong>Measurement Bias</strong>: Errors in how data is measured.</li><li><strong>Observer Bias</strong>: Human judgment skews results.</li><li><strong>Confirmation Bias</strong>: Favoring information that supports preconceptions.</li></ul></li></ul></li></ol><p align="center">  <img src="/images/aws_basic_185.png" width="80%"></p> <p><strong>Exam Tip</strong>: If the question mentions <strong>detecting bias</strong> or <strong>explaining ML predictions</strong>, the answer is usually <strong>SageMaker Clarify</strong>.</p><hr><h2 id="SageMaker-Ground-Truth"><a href="#SageMaker-Ground-Truth" class="headerlink" title="SageMaker Ground Truth"></a>SageMaker Ground Truth</h2><p><strong>Ground Truth</strong> focuses on <strong>data labeling</strong> and <strong>human feedback</strong>.</p><ul><li>Supports <strong>RLHF</strong> (Reinforcement Learning from Human Feedback).</li><li>Use cases:<ul><li>Model review and evaluation</li><li>Aligning models to human preferences</li><li>Creating labeled datasets (e.g., tagging images)</li></ul></li></ul><h3 id="How-it-Works"><a href="#How-it-Works" class="headerlink" title="How it Works"></a>How it Works</h3><ul><li>Humans review and provide feedback, which is added to the model’s “reward” function.</li><li>Feedback improves model accuracy and aligns it with desired behavior.</li><li>Reviewers can be:<ul><li>Amazon Mechanical Turk workers</li><li>Your employees</li><li>Third-party vendors</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_186.png" width="80%"></p> <h3 id="Ground-Truth-Plus"><a href="#Ground-Truth-Plus" class="headerlink" title="Ground Truth Plus"></a>Ground Truth Plus</h3><ul><li>A managed option where AWS provides a workforce to label your data.</li></ul><h2 id="Exam-Tip-If-the-exam-mentions-data-labeling-or-RLHF-thinkGround-Truth"><a href="#Exam-Tip-If-the-exam-mentions-data-labeling-or-RLHF-thinkGround-Truth" class="headerlink" title="Exam Tip: If the exam mentions data labeling or RLHF, thinkGround Truth."></a><strong>Exam Tip</strong>: If the exam mentions <strong>data labeling</strong> or <strong>RLHF</strong>, think<br><strong>Ground Truth</strong>.</h2><h2 id="Key-Takeaways-for-the-Exam"><a href="#Key-Takeaways-for-the-Exam" class="headerlink" title="Key Takeaways for the Exam"></a>Key Takeaways for the Exam</h2><ul><li><strong>Data Wrangler</strong> &#x3D; data preparation and feature engineering.</li><li><strong>Feature Store</strong> &#x3D; manage and reuse ML features across teams.</li><li><strong>Clarify</strong> &#x3D; bias detection and explainability of models.</li><li><strong>Ground Truth</strong> &#x3D; human labeling and reinforcement learning from feedback.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Amazon-SageMaker-Data-Tools-and-Model-Evaluation&quot;&gt;&lt;a href=&quot;#Amazon-SageMaker-Data-Tools-and-Model-Evaluation&quot; class=&quot;headerlink&quot; tit</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(36) - SageMaker (AI)</title>
    <link href="https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-36/"/>
    <id>https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-36/</id>
    <published>2025-09-02T17:14:15.000Z</published>
    <updated>2025-09-02T17:31:21.381Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Amazon-SageMaker-AI"><a href="#Amazon-SageMaker-AI" class="headerlink" title="Amazon SageMaker AI"></a>Amazon SageMaker AI</h1><h2 id="What-is-Amazon-SageMaker"><a href="#What-is-Amazon-SageMaker" class="headerlink" title="What is Amazon SageMaker?"></a>What is Amazon SageMaker?</h2><ul><li><strong>Fully managed ML service</strong> for developers and data scientists.</li><li>Handles the entire machine learning lifecycle:<ul><li>Collect and prepare data</li><li>Build and train models</li><li>Deploy models and monitor predictions</li></ul></li><li>Removes the need to manually provision servers or manage infrastructure.</li><li>Example use case: predicting AWS exam scores using student history.</li></ul><p align="center">  <img src="/images/aws_basic_166.png" width="80%"></p> <p align="center">  <img src="/images/aws_basic_167.png" width="80%"></p> ------------------------------------------------------------------------<h2 id="Built-in-Algorithms"><a href="#Built-in-Algorithms" class="headerlink" title="Built-in Algorithms"></a>Built-in Algorithms</h2><p>SageMaker includes many pre-built algorithms so you don’t always need to code from scratch: </p><ul><li><strong>Supervised Learning</strong> - Linear regression&#x2F;classification</li><li>k-Nearest Neighbors (KNN)</li><li><strong>Unsupervised Learning</strong> - PCA (Principal Component Analysis) → feature reduction</li><li>K-means → find groups&#x2F;clusters in data</li><li>Anomaly detection → fraud or unusual behavior</li><li><strong>Text (NLP)</strong> → summarization, sentiment analysis, entity extraction</li><li><strong>Image processing</strong> → classification, object detection</li></ul><p>⚡ <strong>Exam Tip</strong>: You don’t need to memorize every algorithm, but know that SageMaker offers built-in supervised, unsupervised, NLP, and image ML options.</p><p align="center">  <img src="/images/aws_basic_168.png" width="80%"></p> <hr><h2 id="Automatic-Model-Tuning-AMT"><a href="#Automatic-Model-Tuning-AMT" class="headerlink" title="Automatic Model Tuning (AMT)"></a>Automatic Model Tuning (AMT)</h2><ul><li>Hyperparameter tuning is normally time-consuming.</li><li>AMT automates this by:<ul><li>Selecting hyperparameter ranges</li><li>Choosing a search strategy</li><li>Defining runtime and early stop conditions</li></ul></li><li><strong>Benefit</strong>: saves time and money, prevents wasted compute on bad configurations.</li></ul><p>⚡ <strong>Exam Tip</strong>: If you see “hyperparameter optimization” or “automated model tuning,” think <strong>SageMaker AMT</strong>.</p><p align="center">  <img src="/images/aws_basic_169.png" width="80%"></p> <hr><h2 id="Model-Deployment-Inference"><a href="#Model-Deployment-Inference" class="headerlink" title="Model Deployment &amp; Inference"></a>Model Deployment &amp; Inference</h2><p>SageMaker makes deploying models simple (no servers to manage, auto-scaling built in). There are <strong>four main deployment types</strong>:</p><h3 id="1-Real-Time-Inference"><a href="#1-Real-Time-Inference" class="headerlink" title="1. Real-Time Inference"></a>1. Real-Time Inference</h3><ul><li>Low latency (≈ milliseconds to seconds)</li><li>One prediction at a time</li><li>Good for small payloads (≤ 6MB, ≤ 60s processing)</li><li>Requires endpoint setup</li></ul><h3 id="2-Serverless-Inference"><a href="#2-Serverless-Inference" class="headerlink" title="2. Serverless Inference"></a>2. Serverless Inference</h3><ul><li>Similar to real-time, but <strong>no infrastructure management</strong></li><li>You only configure memory size; scaling handled automatically</li><li>May have <strong>cold start latency</strong> after idle periods</li></ul><p align="center">  <img src="/images/aws_basic_170.png" width="80%"></p> <h3 id="3-Asynchronous-Inference"><a href="#3-Asynchronous-Inference" class="headerlink" title="3. Asynchronous Inference"></a>3. Asynchronous Inference</h3><ul><li>For <strong>large payloads</strong> (up to 1 GB) or <strong>long processing times</strong> (≤ 1 hour)</li><li>Requests and responses stored in <strong>Amazon S3</strong></li><li>Suitable for near-real-time (not instant) use cases</li></ul><h3 id="4-Batch-Transform"><a href="#4-Batch-Transform" class="headerlink" title="4. Batch Transform"></a>4. Batch Transform</h3><ul><li>For entire datasets (many predictions at once)</li><li>Uses mini-batches (≤ 100MB each, multiple batches allowed)</li><li>Higher latency (minutes to hours)</li><li>Input&#x2F;output handled via <strong>Amazon S3</strong></li></ul><p align="center">  <img src="/images/aws_basic_171.png" width="80%"></p> <p>⚡ <strong>Exam Tip</strong>: - “Low latency, real-time” → Real-Time or Serverless</p><ul><li>“Cold start trade-off, no servers” → Serverless</li><li>“Near-real-time, up to 1GB” → Asynchronous</li><li>“Large datasets, multiple predictions” → Batch Transform</li></ul><p align="center">  <img src="/images/aws_basic_172.png" width="80%"></p><hr><h2 id="SageMaker-Studio"><a href="#SageMaker-Studio" class="headerlink" title="SageMaker Studio"></a>SageMaker Studio</h2><ul><li>A <strong>unified web-based interface</strong> for ML development.</li><li>Capabilities:<ul><li>Prepare, transform, and store data</li><li>Tune&#x2F;debug ML models</li><li>Deploy and manage endpoints</li><li>Collaborate with team members</li><li>Use AutoML, pipelines, and monitoring tools</li></ul></li><li>Integrates with popular tools like <strong>JupyterLab, TensorBoard, and MLflow</strong>.</li></ul><p>⚡ <strong>Exam Tip</strong>: If the question mentions “end-to-end ML workflow in a single interface,” the answer is <strong>SageMaker Studio</strong>.</p><p align="center">  <img src="/images/aws_basic_173.png" width="80%"></p> <hr><h2 id="Key-Takeaways-for-the-Exam"><a href="#Key-Takeaways-for-the-Exam" class="headerlink" title="Key Takeaways for the Exam"></a>Key Takeaways for the Exam</h2><ol><li><strong>SageMaker &#x3D; End-to-End ML service</strong> (data prep → training → deployment).</li><li><strong>AMT</strong> handles hyperparameter tuning automatically.</li><li><strong>Deployment types</strong>: Real-time, Serverless, Asynchronous, Batch.</li><li><strong>SageMaker Studio</strong> &#x3D; central interface for ML development.</li><li><strong>Built-in algorithms</strong> exist for supervised, unsupervised, NLP, and image tasks.</li><li>SageMaker focuses on <strong>ease of use, managed infrastructure, and scalability</strong>.</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Amazon-SageMaker-AI&quot;&gt;&lt;a href=&quot;#Amazon-SageMaker-AI&quot; class=&quot;headerlink&quot; title=&quot;Amazon SageMaker AI&quot;&gt;&lt;/a&gt;Amazon SageMaker AI&lt;/h1&gt;&lt;h2 i</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (36) - SageMaker (AI)</title>
    <link href="https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-36/"/>
    <id>https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-36/</id>
    <published>2025-09-02T17:14:09.000Z</published>
    <updated>2025-09-02T17:31:21.381Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Amazon-SageMaker-AI"><a href="#Amazon-SageMaker-AI" class="headerlink" title="Amazon SageMaker (AI)"></a>Amazon SageMaker (AI)</h1><h2 id="1-SageMaker-개요"><a href="#1-SageMaker-개요" class="headerlink" title="1. SageMaker 개요"></a>1. SageMaker 개요</h2><ul><li><strong>Amazon SageMaker</strong>는 개발자와 데이터 과학자를 위한 <strong>완전 관리형 머신러닝 서비스</strong>입니다.</li><li>머신러닝의 모든 과정을 한 곳에서 처리할 수 있도록 지원합니다:<ul><li>데이터 수집 및 준비</li><li>모델 학습 및 튜닝</li><li>모델 배포 및 성능 모니터링</li></ul></li><li>원래는 머신러닝을 하기 위해 직접 서버를 세팅하고, 환경을 구성해야 하지만 SageMaker는 이런 과정을 크게 단순화합니다.</li><li>예시: AWS 시험 점수를 예측하는 모델을 SageMaker로 쉽게 만들어볼 수 있습니다.</li></ul><p>👉 <strong>시험 포인트</strong>: SageMaker는 <strong>머신러닝 end-to-end 플랫폼</strong>이며, 관리형 서비스임을 기억하세요.</p><p align="center">  <img src="/images/aws_basic_166.png" width="80%"></p> <hr><h2 id="2-SageMaker-주요-기능"><a href="#2-SageMaker-주요-기능" class="headerlink" title="2. SageMaker 주요 기능"></a>2. SageMaker 주요 기능</h2><h3 id="1-End-to-End-ML-Service"><a href="#1-End-to-End-ML-Service" class="headerlink" title="(1) End-to-End ML Service"></a>(1) End-to-End ML Service</h3><ul><li><strong>데이터 준비</strong> → <strong>모델 학습&#x2F;튜닝</strong> → <strong>배포 및 모니터링</strong></li><li>데이터 파이프라인 전체 과정을 지원.</li></ul><p align="center">  <img src="/images/aws_basic_167.png" width="80%"></p> <h3 id="2-내장-알고리즘-Built-in-Algorithms"><a href="#2-내장-알고리즘-Built-in-Algorithms" class="headerlink" title="(2) 내장 알고리즘 (Built-in Algorithms)"></a>(2) 내장 알고리즘 (Built-in Algorithms)</h3><ul><li><strong>지도 학습 (Supervised)</strong><ul><li>선형 회귀, 분류 (Classification)</li><li>KNN (최근접 이웃) 분류</li></ul></li><li><strong>비지도 학습 (Unsupervised)</strong><ul><li>PCA (차원 축소, 특징 수 줄이기)</li><li>K-means (데이터 군집화)</li><li>이상치 탐지 (Anomaly Detection → 사기 탐지 등)</li></ul></li><li><strong>텍스트 처리 (NLP)</strong>: 요약, 감정 분석 등</li><li><strong>이미지 처리</strong>: 이미지 분류, 객체 탐지</li></ul><p>👉 시험에선 “SageMaker에서 제공하는 알고리즘”이 나올 수 있으니 <strong>지도&#x2F;비지도&#x2F;NLP&#x2F;이미지 처리</strong> 정도는 기억해두면 좋습니다.</p><p align="center">  <img src="/images/aws_basic_168.png" width="80%"></p> <hr><h2 id="3-Automatic-Model-Tuning-AMT"><a href="#3-Automatic-Model-Tuning-AMT" class="headerlink" title="3. Automatic Model Tuning (AMT)"></a>3. Automatic Model Tuning (AMT)</h2><ul><li>하이퍼파라미터 튜닝을 자동으로 실행.</li><li><strong>Objective Metric</strong>을 정의하면 SageMaker가 알아서:<ul><li>하이퍼파라미터 범위 설정</li><li>탐색 전략 (Search Strategy) 선택</li><li>최대 실행 시간 설정</li><li>성능이 안 나오면 <strong>Early Stopping</strong> 적용</li></ul></li><li>결과: 시간과 비용 절감, 불필요한 자원 낭비 방지</li></ul><p>👉 <strong>시험 포인트</strong>: “AMT는 자동으로 하이퍼파라미터 튜닝을 수행하여 시간과 비용을 절약한다.”</p><p align="center">  <img src="/images/aws_basic_169.png" width="80%"></p> ------------------------------------------------------------------------<h2 id="4-모델-배포-추론-Inference"><a href="#4-모델-배포-추론-Inference" class="headerlink" title="4. 모델 배포 &amp; 추론 (Inference)"></a>4. 모델 배포 &amp; 추론 (Inference)</h2><h3 id="1-실시간-Real-time"><a href="#1-실시간-Real-time" class="headerlink" title="(1) 실시간 (Real-time)"></a>(1) 실시간 (Real-time)</h3><ul><li><strong>한 건씩 빠른 추론</strong> (예: 웹 애플리케이션에서 즉각 응답 필요할 때)</li><li>Auto Scaling 지원, 서버 관리 불필요</li></ul><h3 id="2-서버리스-Serverless"><a href="#2-서버리스-Serverless" class="headerlink" title="(2) 서버리스 (Serverless)"></a>(2) 서버리스 (Serverless)</h3><ul><li>서버 관리 없이 메모리만 선택</li><li>트래픽이 없을 때 비용 발생 안 함</li><li>단점: <strong>Cold Start</strong>로 인해 첫 요청 시 지연 발생</li></ul><p align="center">  <img src="/images/aws_basic_170.png" width="80%"></p> <h3 id="3-비동기-Asynchronous"><a href="#3-비동기-Asynchronous" class="headerlink" title="(3) 비동기 (Asynchronous)"></a>(3) 비동기 (Asynchronous)</h3><ul><li>대용량 입력 (최대 <strong>1GB</strong>) 처리 가능</li><li>오래 걸리는 작업에 적합</li><li>요청&#x2F;응답은 <strong>Amazon S3</strong>를 통해 처리</li><li>응답은 즉시가 아니라 “Near Real-time”</li></ul><h3 id="4-배치-Batch-Transform"><a href="#4-배치-Batch-Transform" class="headerlink" title="(4) 배치 (Batch Transform)"></a>(4) 배치 (Batch Transform)</h3><ul><li><strong>대량 데이터셋</strong>에 대해 한 번에 예측</li><li>여러 레코드를 동시에 처리</li><li>결과는 Amazon S3에 저장</li><li><strong>고지연 (minutes~hours)</strong></li></ul><p align="center">  <img src="/images/aws_basic_171.png" width="80%"></p> <p>👉 <strong>시험 포인트 키워드</strong>: - Real-time: 빠른 응답, 작은 요청</p><ul><li>Serverless: Cold Start 가능, 서버 관리 X</li><li>Asynchronous: 1GB 대용량, 긴 처리 시간, Near Real-time</li><li>Batch: 여러 데이터셋 동시 예측, 고지연</li></ul><p align="center">  <img src="/images/aws_basic_172.png" width="80%"></p> ------------------------------------------------------------------------<h2 id="5-SageMaker-Studio"><a href="#5-SageMaker-Studio" class="headerlink" title="5. SageMaker Studio"></a>5. SageMaker Studio</h2><ul><li><strong>머신러닝 개발 통합 환경 (IDE)</strong></li><li>주요 기능:<ul><li>팀 협업</li><li>모델 튜닝 &amp; 디버깅</li><li>모델 배포</li><li>자동화된 워크플로우</li></ul></li><li>또한 <strong>JumpStart</strong>를 통해 Hugging Face, PyTorch, TensorFlow 등 다양한 모델을 바로 가져다 쓸 수 있음.</li></ul><p>👉 <strong>시험 포인트</strong>: SageMaker Studio는 <strong>엔드투엔드 머신러닝 개발 환경</strong>이다.</p><p align="center">  <img src="/images/aws_basic_173.png" width="80%"></p> ------------------------------------------------------------------------<h2 id="6-시험-대비-요약"><a href="#6-시험-대비-요약" class="headerlink" title="6. 시험 대비 요약"></a>6. 시험 대비 요약</h2><ul><li>EC2 대신 SageMaker를 사용하는 이유 → <strong>완전 관리형, 빠른 배포, 자동 튜닝 지원</strong></li><li><strong>AMT &#x3D; Automatic Model Tuning</strong></li><li><strong>Inference 방식</strong> → Real-time, Serverless, Asynchronous, Batch (키워드로 구분)</li><li><strong>Studio</strong> &#x3D; 협업 &amp; 통합 개발 환경</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Amazon-SageMaker-AI&quot;&gt;&lt;a href=&quot;#Amazon-SageMaker-AI&quot; class=&quot;headerlink&quot; title=&quot;Amazon SageMaker (AI)&quot;&gt;&lt;/a&gt;Amazon SageMaker (AI)&lt;/h1&gt;&lt;</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (35) - EC2</title>
    <link href="https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-35/"/>
    <id>https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-35/</id>
    <published>2025-09-02T17:05:35.000Z</published>
    <updated>2025-09-02T17:13:50.786Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Amazon-EC2-Elastic-Compute-Cloud"><a href="#Amazon-EC2-Elastic-Compute-Cloud" class="headerlink" title="Amazon EC2 (Elastic Compute Cloud)"></a>Amazon EC2 (Elastic Compute Cloud)</h1><h3 id="기본-개념"><a href="#기본-개념" class="headerlink" title="기본 개념"></a>기본 개념</h3><ul><li><strong>EC2 &#x3D; Elastic Compute Cloud</strong> → AWS의 대표적인 <strong>IaaS (Infrastructure as a Service)</strong> 서비스.</li><li>클라우드에서 <strong>가상 서버(인스턴스)를 임대</strong>하는 개념.</li><li>EC2를 이해하는 것은 클라우드 기본 개념을 이해하는 데 핵심.</li></ul><h3 id="주요-기능"><a href="#주요-기능" class="headerlink" title="주요 기능"></a>주요 기능</h3><ul><li><strong>가상 서버 임대 (EC2 Instance)</strong></li><li><strong>스토리지 연결</strong>: EBS(Elastic Block Store), EFS, 또는 인스턴스 스토어(하드웨어 기반).</li><li><strong>로드 밸런싱 (ELB)</strong>: 여러 서버에 트래픽 분산.</li><li><strong>오토 스케일링 (ASG)</strong>: 트래픽 변화에 따라 서버 자동 확장&#x2F;축소.</li></ul><hr><h1 id="EC2-인스턴스-설정-옵션"><a href="#EC2-인스턴스-설정-옵션" class="headerlink" title="EC2 인스턴스 설정 옵션"></a>EC2 인스턴스 설정 옵션</h1><ul><li><strong>운영체제 (OS)</strong>: Linux, Windows, macOS 지원.</li><li><strong>CPU</strong>: 코어 수와 연산 성능 선택 가능.</li><li><strong>메모리 (RAM)</strong>: 애플리케이션 요구사항에 맞게 조정.</li><li><strong>스토리지</strong>:<ul><li><strong>네트워크 연결 스토리지</strong> → EBS, EFS</li><li><strong>하드웨어 스토리지</strong> → EC2 Instance Store</li></ul></li><li><strong>네트워크 설정</strong>: 네트워크 카드 속도, 퍼블릭 IP 할당 여부.</li><li><strong>보안</strong>: Security Group(방화벽 역할).</li><li><strong>부트스트랩 스크립트</strong>: 인스턴스 최초 실행 시 자동 실행되는 <strong>User Data</strong> 스크립트.</li></ul><p>👉 <strong>시험 포인트</strong></p><ul><li>“EC2 User Data &#x3D; 인스턴스 최초 실행 시 자동 설정 스크립트”</li><li>“Security Group &#x3D; 인스턴스 방화벽 규칙”</li></ul><hr><h1 id="Amazon-EC2와-AI-관련-하드웨어"><a href="#Amazon-EC2와-AI-관련-하드웨어" class="headerlink" title="Amazon EC2와 AI 관련 하드웨어"></a>Amazon EC2와 AI 관련 하드웨어</h1><p>AI&#x2F;ML 워크로드에서는 일반 CPU보다 <strong>GPU&#x2F;전용 칩</strong>을 활용해야 효율적입니다.</p><h3 id="GPU-기반-인스턴스"><a href="#GPU-기반-인스턴스" class="headerlink" title="GPU 기반 인스턴스"></a>GPU 기반 인스턴스</h3><ul><li><strong>P 시리즈</strong> (P3, P4, P5): 고성능 머신러닝&#x2F;딥러닝 학습용.</li><li><strong>G 시리즈</strong> (G3~G6): 그래픽 처리, 딥러닝 추론, VDI(가상 데스크톱)용.</li></ul><h3 id="AWS-전용-AI-칩"><a href="#AWS-전용-AI-칩" class="headerlink" title="AWS 전용 AI 칩"></a>AWS 전용 AI 칩</h3><ol><li><strong>AWS Trainium (학습 전용)</strong><ul><li>대규모 딥러닝 모델(1000억+ 파라미터) 학습 최적화.</li><li><strong>Trn1 인스턴스</strong>: Trainium 칩 16개 포함.</li><li>GPU 대비 <strong>최대 50% 비용 절감</strong>.</li></ul></li><li><strong>AWS Inferentia (추론 전용)</strong><ul><li>고성능&#x2F;저비용 <strong>추론(Inference)</strong> 가속기.</li><li><strong>Inf1, Inf2 인스턴스</strong>에서 사용.</li><li>최대 <strong>4배 처리량, 70% 비용 절감</strong>.</li></ul></li></ol><p>👉 <strong>시험 포인트</strong></p><ul><li>“모델 학습 최적화, 비용 절감” → <strong>Trainium (Trn1)</strong></li><li>“추론 최적화, 비용 절감” → <strong>Inferentia (Inf1&#x2F;Inf2)</strong></li><li><strong>Trainium&#x2F;Inferentia &#x3D; AWS 자체 칩, 가장 친환경적(환경 발자국 최소화)</strong></li></ul><p align="center">  <img src="/images/aws_basic_165.png" width="80%"></p> ------------------------------------------------------------------------<h1 id="정리-시험-대비"><a href="#정리-시험-대비" class="headerlink" title="정리 (시험 대비)"></a>정리 (시험 대비)</h1><ul><li><strong>EC2 &#x3D; 클라우드 가상 서버</strong> (IaaS).</li><li><strong>EBS&#x2F;EFS</strong>: 네트워크 스토리지, <strong>Instance Store</strong>: 로컬 하드웨어 스토리지.</li><li><strong>ELB</strong>: 로드밸런싱, <strong>ASG</strong>: 자동 확장&#x2F;축소.</li><li><strong>Security Group</strong>: 방화벽, <strong>User Data</strong>: 초기 설정 스크립트.</li><li><strong>GPU 기반 인스턴스</strong>: P, G 시리즈 (ML 학습&#x2F;추론용).</li><li><strong>Trainium (Trn1)</strong>: 학습 전용 칩, 비용 절감.</li><li><strong>Inferentia (Inf1&#x2F;Inf2)</strong>: 추론 전용 칩, 성능+비용 효율.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Amazon-EC2-Elastic-Compute-Cloud&quot;&gt;&lt;a href=&quot;#Amazon-EC2-Elastic-Compute-Cloud&quot; class=&quot;headerlink&quot; title=&quot;Amazon EC2 (Elastic Compute </summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
</feed>
