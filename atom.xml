<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Danny&#39;s Blog</title>
  
  <subtitle>Data, AI, and Tech Insight</subtitle>
  <link href="https://kish191919.github.io/atom.xml" rel="self"/>
  
  <link href="https://kish191919.github.io/"/>
  <updated>2025-08-20T22:47:27.073Z</updated>
  <id>https://kish191919.github.io/</id>
  
  <author>
    <name>Danny Ki</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>AWS-Certified-AI-Practitioner(12)</title>
    <link href="https://kish191919.github.io/2025/08/20/AWS-Certified-AI-Practitioner-12/"/>
    <id>https://kish191919.github.io/2025/08/20/AWS-Certified-AI-Practitioner-12/</id>
    <published>2025-08-20T22:46:03.000Z</published>
    <updated>2025-08-20T22:47:27.073Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ“˜-Amazon-Bedrock-â€“-Pricing-Model-Improvement"><a href="#ğŸ“˜-Amazon-Bedrock-â€“-Pricing-Model-Improvement" class="headerlink" title="ğŸ“˜ Amazon Bedrock â€“ Pricing &amp; Model Improvement"></a>ğŸ“˜ Amazon Bedrock â€“ Pricing &amp; Model Improvement</h1><h2 id="1ï¸âƒ£-Pricing-Options"><a href="#1ï¸âƒ£-Pricing-Options" class="headerlink" title="1ï¸âƒ£ Pricing Options"></a>1ï¸âƒ£ Pricing Options</h2><h3 id="ğŸ”¹-On-Demand-Pay-as-you-go"><a href="#ğŸ”¹-On-Demand-Pay-as-you-go" class="headerlink" title="ğŸ”¹ On-Demand (Pay-as-you-go)"></a>ğŸ”¹ On-Demand (Pay-as-you-go)</h3><ul><li><strong>How it works</strong>: Pay only for what you use, like an electricity bill.  </li><li><strong>Pricing basis</strong>  <ul><li>Text Models â†’ Input&#x2F;Output token count  </li><li>Embedding Models â†’ Input token count  </li><li>Image Models â†’ Number of images generated</li></ul></li><li><strong>Available Models</strong>: Base Models only  </li><li>âœ… <strong>Pros</strong>: Flexible, good for unpredictable workloads  </li><li>âŒ <strong>Cons</strong>: Can become expensive if used continuously over time</li></ul><hr><h3 id="ğŸ”¹-Batch-Mode-Bulk-processing-up-to-50-discount"><a href="#ğŸ”¹-Batch-Mode-Bulk-processing-up-to-50-discount" class="headerlink" title="ğŸ”¹ Batch Mode (Bulk processing, up to 50% discount)"></a>ğŸ”¹ Batch Mode (Bulk processing, up to 50% discount)</h3><ul><li><strong>How it works</strong>: Group multiple requests together â†’ results stored as a single file in Amazon S3  </li><li><strong>Discount</strong>: Up to 50% cheaper  </li><li>âœ… <strong>Pros</strong>: Great for large-scale processing, strong cost savings  </li><li>âŒ <strong>Cons</strong>: No real-time response, results are delayed  </li><li><strong>Best use case</strong>: Large batch jobs where immediate results are not required</li></ul><hr><h3 id="ğŸ”¹-Provisioned-Throughput-Reserved-capacity-guaranteed-performance"><a href="#ğŸ”¹-Provisioned-Throughput-Reserved-capacity-guaranteed-performance" class="headerlink" title="ğŸ”¹ Provisioned Throughput (Reserved capacity, guaranteed performance)"></a>ğŸ”¹ Provisioned Throughput (Reserved capacity, guaranteed performance)</h3><ul><li><strong>How it works</strong>: Like a gym membership â€” reserve processing capacity for a set period (e.g., 1â€“6 months)  </li><li><strong>Guaranteed performance</strong>: Ensures a maximum number of input&#x2F;output tokens per minute  </li><li><strong>Available Models</strong>: Base, Fine-tuned, and Custom Models  </li><li>âœ… <strong>Pros</strong>: Stable performance and capacity, supports custom models  </li><li>âŒ <strong>Cons</strong>: Not a cost-saving option, purpose is <strong>performance guarantee</strong></li></ul><hr><h2 id="ğŸ“Š-Pricing-Options-Comparison-Table"><a href="#ğŸ“Š-Pricing-Options-Comparison-Table" class="headerlink" title="ğŸ“Š Pricing Options Comparison Table"></a>ğŸ“Š Pricing Options Comparison Table</h2><table><thead><tr><th>Option</th><th>Billing Method</th><th>Pricing Basis</th><th>Available Models</th><th>Pros</th><th>Cons</th><th>Best Use Case</th></tr></thead><tbody><tr><td><strong>On-Demand</strong></td><td>Pay-as-you-go</td><td>- Text: Input&#x2F;Output tokens<br>- Embedding: Input tokens<br>- Image: Generated images</td><td>Base Models only</td><td>High flexibility<br>Great for unpredictable workloads</td><td>Expensive for long-term use</td><td>Occasional use &#x2F; Unpredictable demand</td></tr><tr><td><strong>Batch Mode</strong></td><td>Bulk processing</td><td>Results stored in Amazon S3</td><td>Base Models only</td><td>Up to 50% discount<br>Efficient for large-scale jobs</td><td>No real-time response<br>Delayed results</td><td>Large requests &#x2F; No need for instant results</td></tr><tr><td><strong>Provisioned Throughput</strong></td><td>Reserved capacity (1â€“6 months)</td><td>Guaranteed tokens per minute</td><td>Base, Fine-tuned, Custom Models</td><td>Guaranteed stable performance<br>Supports custom models</td><td>Almost no cost savings</td><td>When using custom models &#x2F; Need guaranteed performance</td></tr></tbody></table><hr><h2 id="2ï¸âƒ£-Model-Improvement-Techniques-Low-â†’-High-Cost"><a href="#2ï¸âƒ£-Model-Improvement-Techniques-Low-â†’-High-Cost" class="headerlink" title="2ï¸âƒ£ Model Improvement Techniques (Low â†’ High Cost)"></a>2ï¸âƒ£ Model Improvement Techniques (Low â†’ High Cost)</h2><h3 id="1-Prompt-Engineering"><a href="#1-Prompt-Engineering" class="headerlink" title="1. Prompt Engineering"></a>1. Prompt Engineering</h3><ul><li>Improve results simply by optimizing prompts  </li><li>No extra computation â†’ <strong>Lowest cost</strong></li></ul><h3 id="2-Retrieval-Augmented-Generation-RAG"><a href="#2-Retrieval-Augmented-Generation-RAG" class="headerlink" title="2. Retrieval Augmented Generation (RAG)"></a>2. Retrieval Augmented Generation (RAG)</h3><ul><li>Uses an external knowledge database (Vector DB)  </li><li>No model retraining â†’ relatively low cost  </li><li>Additional cost for building and maintaining the database</li></ul><blockquote><p>RAG &#x3D; â€œModel + Search functionâ€ â†’ lets the model find external knowledge it doesnâ€™t already know.</p></blockquote><h3 id="3-Instruction-based-Fine-tuning"><a href="#3-Instruction-based-Fine-tuning" class="headerlink" title="3. Instruction-based Fine-tuning"></a>3. Instruction-based Fine-tuning</h3><ul><li>Fine-tune the model with labeled data and specific instructions  </li><li>Requires extra computation â†’ Higher cost</li></ul><h3 id="4-Domain-Adaptation-Fine-tuning"><a href="#4-Domain-Adaptation-Fine-tuning" class="headerlink" title="4. Domain Adaptation Fine-tuning"></a>4. Domain Adaptation Fine-tuning</h3><ul><li>Retrain the model with a large domain-specific dataset  </li><li>Requires extensive data preparation + heavy computation â†’ <strong>Highest cost</strong></li></ul><hr><h2 id="3ï¸âƒ£-Cost-Optimization-Tips"><a href="#3ï¸âƒ£-Cost-Optimization-Tips" class="headerlink" title="3ï¸âƒ£ Cost Optimization Tips"></a>3ï¸âƒ£ Cost Optimization Tips</h2><ul><li><strong>Token management</strong> â†’ main driver of cost savings  <ul><li>Keep prompts concise  </li><li>Limit output length to whatâ€™s necessary</li></ul></li><li><strong>Use Batch Mode</strong> â†’ up to 50% cheaper  </li><li><strong>Choose smaller models</strong> â†’ generally cheaper  </li><li><strong>Adjust hyperparameters (Temperature, Top-K, Top-P)</strong>  <ul><li>Affects model behavior but <strong>not pricing</strong></li></ul></li></ul><hr><h2 id="ğŸ“-Final-Summary-Exam-Practical-Points"><a href="#ğŸ“-Final-Summary-Exam-Practical-Points" class="headerlink" title="ğŸ“ Final Summary (Exam&#x2F;Practical Points)"></a>ğŸ“ Final Summary (Exam&#x2F;Practical Points)</h2><ul><li><strong>On-Demand</strong> &#x3D; Flexibility &#x2F; <strong>Batch</strong> &#x3D; Bulk &amp; Discounts &#x2F; <strong>Provisioned</strong> &#x3D; Guaranteed Performance  </li><li><strong>Cost order</strong>: Prompt Engineering &lt; RAG &lt; Instruction Fine-tuning &lt; Domain Adaptation  </li><li><strong>Cost-saving keys</strong>: Token management + Batch Mode</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ“˜-Amazon-Bedrock-â€“-Pricing-Model-Improvement&quot;&gt;&lt;a href=&quot;#ğŸ“˜-Amazon-Bedrock-â€“-Pricing-Model-Improvement&quot; class=&quot;headerlink&quot; title=&quot;ğŸ“˜</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="AI" scheme="https://kish191919.github.io/categories/Dev/AI/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Certification" scheme="https://kish191919.github.io/tags/Certification/"/>
    
  </entry>
  
  <entry>
    <title>(KO)AWS-Certified-AI-Practitioner(12)</title>
    <link href="https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-12/"/>
    <id>https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-12/</id>
    <published>2025-08-20T22:31:17.000Z</published>
    <updated>2025-08-20T22:45:45.927Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ“˜-Amazon-Bedrock-â€“-Pricing-Model-Improvement"><a href="#ğŸ“˜-Amazon-Bedrock-â€“-Pricing-Model-Improvement" class="headerlink" title="ğŸ“˜ Amazon Bedrock â€“ Pricing &amp; Model Improvement"></a>ğŸ“˜ Amazon Bedrock â€“ Pricing &amp; Model Improvement</h1><h2 id="1ï¸âƒ£-Pricing-Options"><a href="#1ï¸âƒ£-Pricing-Options" class="headerlink" title="1ï¸âƒ£ Pricing Options"></a>1ï¸âƒ£ Pricing Options</h2><h3 id="ğŸ”¹-On-Demand-ì¦‰ì‹œ-ì‚¬ìš©-ì‚¬ìš©ëŸ‰ë§Œí¼-ê²°ì œ"><a href="#ğŸ”¹-On-Demand-ì¦‰ì‹œ-ì‚¬ìš©-ì‚¬ìš©ëŸ‰ë§Œí¼-ê²°ì œ" class="headerlink" title="ğŸ”¹ On-Demand (ì¦‰ì‹œ ì‚¬ìš©, ì‚¬ìš©ëŸ‰ë§Œí¼ ê²°ì œ)"></a>ğŸ”¹ On-Demand (ì¦‰ì‹œ ì‚¬ìš©, ì‚¬ìš©ëŸ‰ë§Œí¼ ê²°ì œ)</h3><ul><li><strong>ë°©ì‹</strong>: ì „ê¸°ìš”ê¸ˆì²˜ëŸ¼ ì“´ ë§Œí¼ë§Œ ì§€ë¶ˆ (Pay-as-you-go)  </li><li><strong>ìš”ê¸ˆ ê¸°ì¤€</strong>  <ul><li>í…ìŠ¤íŠ¸ ëª¨ë¸ â†’ ì…ë ¥&#x2F;ì¶œë ¥ í† í° ìˆ˜  </li><li>ì„ë² ë”© ëª¨ë¸ â†’ ì…ë ¥ í† í° ìˆ˜  </li><li>ì´ë¯¸ì§€ ëª¨ë¸ â†’ ìƒì„±ëœ ì´ë¯¸ì§€ ìˆ˜</li></ul></li><li><strong>ì‚¬ìš© ê°€ëŠ¥ ëª¨ë¸</strong>: Base Models ì „ìš©  </li><li>âœ… <strong>ì¥ì </strong>: ìœ ì—°ì„±, ì‚¬ìš©ëŸ‰ ì˜ˆì¸¡ì´ ì–´ë ¤ìš´ ê²½ìš° ì í•©  </li><li>âŒ <strong>ë‹¨ì </strong>: ì¥ê¸°ê°„ ì‚¬ìš© ì‹œ ë¹„ìš© ë¶€ë‹´ â†‘</li></ul><hr><h3 id="ğŸ”¹-Batch-Mode-ë¬¶ìŒ-ì²˜ë¦¬-ìµœëŒ€-50-í• ì¸"><a href="#ğŸ”¹-Batch-Mode-ë¬¶ìŒ-ì²˜ë¦¬-ìµœëŒ€-50-í• ì¸" class="headerlink" title="ğŸ”¹ Batch Mode (ë¬¶ìŒ ì²˜ë¦¬, ìµœëŒ€ 50% í• ì¸)"></a>ğŸ”¹ Batch Mode (ë¬¶ìŒ ì²˜ë¦¬, ìµœëŒ€ 50% í• ì¸)</h3><ul><li><strong>ë°©ì‹</strong>: ì—¬ëŸ¬ ìš”ì²­ì„ í•œ ë²ˆì— ë¬¶ì–´ì„œ ì²˜ë¦¬ â†’ ê²°ê³¼ëŠ” Amazon S3ì— ë‹¨ì¼ íŒŒì¼ ì €ì¥  </li><li><strong>í• ì¸ í˜œíƒ</strong>: ìµœëŒ€ 50% ì €ë ´  </li><li>âœ… <strong>ì¥ì </strong>: ëŒ€ëŸ‰ ì²˜ë¦¬ì— ìœ ë¦¬, ë¹„ìš© ì ˆê° íš¨ê³¼ í¼  </li><li>âŒ <strong>ë‹¨ì </strong>: ì‹¤ì‹œê°„ ì‘ë‹µ ë¶ˆê°€, ê²°ê³¼ ì§€ì—° ë°œìƒ  </li><li><strong>ì í•© ìƒí™©</strong>: ì¦‰ê°ì ì¸ ì‘ë‹µ í•„ìš” ì—†ê³ , ëŒ€ëŸ‰ ìš”ì²­ì„ ì²˜ë¦¬í•  ë•Œ</li></ul><hr><h3 id="ğŸ”¹-Provisioned-Throughput-ì˜ˆì•½ì œ-ì•ˆì •ì -ì„±ëŠ¥-ë³´ì¥"><a href="#ğŸ”¹-Provisioned-Throughput-ì˜ˆì•½ì œ-ì•ˆì •ì -ì„±ëŠ¥-ë³´ì¥" class="headerlink" title="ğŸ”¹ Provisioned Throughput (ì˜ˆì•½ì œ, ì•ˆì •ì  ì„±ëŠ¥ ë³´ì¥)"></a>ğŸ”¹ Provisioned Throughput (ì˜ˆì•½ì œ, ì•ˆì •ì  ì„±ëŠ¥ ë³´ì¥)</h3><ul><li><strong>ë°©ì‹</strong>: í—¬ìŠ¤ì¥ ì •ì•¡ì œì²˜ëŸ¼ ì¼ì • ê¸°ê°„(1~6ê°œì›” ë“±) ì²˜ë¦¬ ìš©ëŸ‰ ì˜ˆì•½  </li><li><strong>ë³´ì¥ ì„±ëŠ¥</strong>: ë¶„ë‹¹ ìµœëŒ€ ì…ë ¥&#x2F;ì¶œë ¥ í† í° ìˆ˜ ë³´ì¥  </li><li><strong>ì‚¬ìš© ê°€ëŠ¥ ëª¨ë¸</strong>: Base, Fine-tuned, Custom Models  </li><li>âœ… <strong>ì¥ì </strong>: ì•ˆì •ì ì¸ ì„±ëŠ¥ ë° ìš©ëŸ‰ í™•ë³´, ì»¤ìŠ¤í…€ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥  </li><li>âŒ <strong>ë‹¨ì </strong>: ë¹„ìš© ì ˆê° íš¨ê³¼ëŠ” ê±°ì˜ ì—†ìŒ â†’ ëª©ì ì€ â€œì„±ëŠ¥ ë³´ì¥â€</li></ul><hr><h2 id="ğŸ“Š-ê°€ê²©-ì˜µì…˜-ë¹„êµí‘œ"><a href="#ğŸ“Š-ê°€ê²©-ì˜µì…˜-ë¹„êµí‘œ" class="headerlink" title="ğŸ“Š ê°€ê²© ì˜µì…˜ ë¹„êµí‘œ"></a>ğŸ“Š ê°€ê²© ì˜µì…˜ ë¹„êµí‘œ</h2><table><thead><tr><th>ì˜µì…˜</th><th>ê²°ì œ ë°©ì‹</th><th>ìš”ê¸ˆ ê¸°ì¤€</th><th>ì‚¬ìš© ê°€ëŠ¥ ëª¨ë¸</th><th>ì¥ì </th><th>ë‹¨ì </th><th>ì í•©í•œ ê²½ìš°</th></tr></thead><tbody><tr><td><strong>On-Demand</strong></td><td>ì‚¬ìš©í•œ ë§Œí¼ ê²°ì œ</td><td>- í…ìŠ¤íŠ¸: ì…ë ¥&#x2F;ì¶œë ¥ í† í°<br>- ì„ë² ë”©: ì…ë ¥ í† í°<br>- ì´ë¯¸ì§€: ìƒì„± ìˆ˜</td><td>Base Models ì „ìš©</td><td>ìœ ì—°ì„± â†‘<br>ì˜ˆì¸¡ ë¶ˆê°€ ì›Œí¬ë¡œë“œ ì í•©</td><td>ì¥ê¸° ì‚¬ìš© ì‹œ ë¹„ìš© â†‘</td><td>ê°€ë” ì‚¬ìš© &#x2F; ì‚¬ìš©ëŸ‰ ì˜ˆì¸¡ ì–´ë ¤ì›€</td></tr><tr><td><strong>Batch Mode</strong></td><td>ì—¬ëŸ¬ ìš”ì²­ ë¬¶ìŒ ì²˜ë¦¬</td><td>ê²°ê³¼ Amazon S3ì— ì €ì¥</td><td>Base Models ì „ìš©</td><td>ìµœëŒ€ 50% í• ì¸<br>ëŒ€ëŸ‰ ì²˜ë¦¬ ìœ ë¦¬</td><td>ì‹¤ì‹œê°„ ì²˜ë¦¬ ë¶ˆê°€<br>ì§€ì—° ë°œìƒ</td><td>ëŒ€ëŸ‰ ìš”ì²­ &#x2F; ì¦‰ê° ì‘ë‹µ ë¶ˆí•„ìš”</td></tr><tr><td><strong>Provisioned Throughput</strong></td><td>ì¼ì • ê¸°ê°„ ìš©ëŸ‰ ì˜ˆì•½</td><td>ë¶„ë‹¹ í† í° ì²˜ë¦¬ëŸ‰ ë³´ì¥</td><td>Base, Fine-tuned, Custom Models</td><td>ì•ˆì •ì  ì„±ëŠ¥ ë³´ì¥<br>ì»¤ìŠ¤í…€ ëª¨ë¸ ê°€ëŠ¥</td><td>ë¹„ìš© ì ˆì•½ íš¨ê³¼ ê±°ì˜ ì—†ìŒ</td><td>ì»¤ìŠ¤í…€ ëª¨ë¸ &#x2F; ì„±ëŠ¥ ë³´ì¥ í•„ìš”</td></tr></tbody></table><hr><h2 id="2ï¸âƒ£-Model-Improvement-Techniques-ì €ë¹„ìš©-â†’-ê³ ë¹„ìš©"><a href="#2ï¸âƒ£-Model-Improvement-Techniques-ì €ë¹„ìš©-â†’-ê³ ë¹„ìš©" class="headerlink" title="2ï¸âƒ£ Model Improvement Techniques (ì €ë¹„ìš© â†’ ê³ ë¹„ìš©)"></a>2ï¸âƒ£ Model Improvement Techniques (ì €ë¹„ìš© â†’ ê³ ë¹„ìš©)</h2><h3 id="1-Prompt-Engineering"><a href="#1-Prompt-Engineering" class="headerlink" title="1. Prompt Engineering"></a>1. Prompt Engineering</h3><ul><li>í”„ë¡¬í”„íŠ¸ ì„¤ê³„ ìµœì í™”ë§Œìœ¼ë¡œ ê°œì„   </li><li>ì¶”ê°€ ì—°ì‚° ì—†ìŒ â†’ <strong>ê°€ì¥ ì €ë ´</strong></li></ul><h3 id="2-Retrieval-Augmented-Generation-RAG"><a href="#2-Retrieval-Augmented-Generation-RAG" class="headerlink" title="2. Retrieval Augmented Generation (RAG)"></a>2. Retrieval Augmented Generation (RAG)</h3><ul><li>ì™¸ë¶€ ì§€ì‹ DB(Vector DB) í™œìš©  </li><li>ëª¨ë¸ ì¬í•™ìŠµ ì—†ìŒ â†’ ë¹„ìš© ì ìŒ  </li><li>ë‹¨, ë²¡í„° DB êµ¬ì¶•Â·ìš´ì˜ ë¹„ìš© ë°œìƒ</li></ul><blockquote><p>RAG &#x3D; â€œëª¨ë¸ + ê²€ìƒ‰ê¸°ëŠ¥â€ â†’ ëª¨ë¸ì´ ëª¨ë¥´ëŠ” ê²ƒë„ ì™¸ë¶€ì—ì„œ ì°¾ì•„ì„œ ë˜‘ë˜‘í•˜ê²Œ ë‹µí•˜ëŠ” ë°©ë²•ì´ì—ìš”.</p></blockquote><h3 id="3-Instruction-based-Fine-tuning"><a href="#3-Instruction-based-Fine-tuning" class="headerlink" title="3. Instruction-based Fine-tuning"></a>3. Instruction-based Fine-tuning</h3><ul><li>ë¼ë²¨ë§ëœ ë°ì´í„°ë¡œ ëª¨ë¸ì„ íŠ¹ì • ì§€ì¹¨ì— ë§ê²Œ ì¡°ì •  </li><li>ì¶”ê°€ ì—°ì‚° í•„ìš” â†’ ë¹„ìš© ì¦ê°€</li></ul><h3 id="4-Domain-Adaptation-Fine-tuning"><a href="#4-Domain-Adaptation-Fine-tuning" class="headerlink" title="4. Domain Adaptation Fine-tuning"></a>4. Domain Adaptation Fine-tuning</h3><ul><li>ë„ë©”ì¸ íŠ¹í™” ë°ì´í„°ì…‹ìœ¼ë¡œ ëŒ€ê·œëª¨ ì¬í•™ìŠµ  </li><li>ë°ì´í„° ì¤€ë¹„ + ì—°ì‚° ì§‘ì•½ì  â†’ <strong>ê°€ì¥ ë¹„ìš© ë†’ìŒ</strong></li></ul><hr><h2 id="3ï¸âƒ£-Cost-Optimization-Tips"><a href="#3ï¸âƒ£-Cost-Optimization-Tips" class="headerlink" title="3ï¸âƒ£ Cost Optimization Tips"></a>3ï¸âƒ£ Cost Optimization Tips</h2><ul><li><strong>í† í° ìˆ˜ ê´€ë¦¬</strong> â†’ ë¹„ìš© ì ˆê°ì˜ í•µì‹¬  <ul><li>í”„ë¡¬í”„íŠ¸ëŠ” ì§§ê³  ê°„ê²°í•˜ê²Œ  </li><li>ì¶œë ¥ë„ ë¶ˆí•„ìš”í•˜ê²Œ ê¸¸ì§€ ì•Šê²Œ</li></ul></li><li><strong>Batch Mode í™œìš©</strong> â†’ ìµœëŒ€ 50% ì ˆê°  </li><li><strong>ì‘ì€ ëª¨ë¸ ì„ íƒ</strong> â†’ ì¼ë°˜ì ìœ¼ë¡œ ë” ì €ë ´  </li><li><strong>í•˜ì´í¼íŒŒë¼ë¯¸í„°(Temperature, Top-K, Top-P) ì¡°ì •</strong>  <ul><li>ì„±ëŠ¥ì—ëŠ” ì˜í–¥ ì£¼ì§€ë§Œ ë¹„ìš©ì—ëŠ” ì˜í–¥ ì—†ìŒ</li></ul></li></ul><hr><h2 id="ğŸ“-ìµœì¢…-ì •ë¦¬-ì‹œí—˜-ì‹¤ë¬´-í¬ì¸íŠ¸"><a href="#ğŸ“-ìµœì¢…-ì •ë¦¬-ì‹œí—˜-ì‹¤ë¬´-í¬ì¸íŠ¸" class="headerlink" title="ğŸ“ ìµœì¢… ì •ë¦¬ (ì‹œí—˜&#x2F;ì‹¤ë¬´ í¬ì¸íŠ¸)"></a>ğŸ“ ìµœì¢… ì •ë¦¬ (ì‹œí—˜&#x2F;ì‹¤ë¬´ í¬ì¸íŠ¸)</h2><ul><li><strong>On-Demand</strong> &#x3D; ìœ ì—°ì„± &#x2F; <strong>Batch</strong> &#x3D; ëŒ€ëŸ‰Â·í• ì¸ &#x2F; <strong>Provisioned</strong> &#x3D; ì„±ëŠ¥ ë³´ì¥  </li><li><strong>ë¹„ìš© ìˆœì„œ</strong>: Prompt Engineering &lt; RAG &lt; Instruction Fine-tuning &lt; Domain Adaptation  </li><li><strong>ë¹„ìš© ì ˆê° í•µì‹¬</strong>: í† í° ìˆ˜ ê´€ë¦¬ + Batch í™œìš©</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ“˜-Amazon-Bedrock-â€“-Pricing-Model-Improvement&quot;&gt;&lt;a href=&quot;#ğŸ“˜-Amazon-Bedrock-â€“-Pricing-Model-Improvement&quot; class=&quot;headerlink&quot; title=&quot;ğŸ“˜</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="AI" scheme="https://kish191919.github.io/categories/Dev/AI/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Certification" scheme="https://kish191919.github.io/tags/Certification/"/>
    
    <category term="Korean" scheme="https://kish191919.github.io/tags/Korean/"/>
    
  </entry>
  
  <entry>
    <title>AWS-Certified-AI-Practitioner(11)</title>
    <link href="https://kish191919.github.io/2025/08/19/AWS-Certified-AI-Practitioner-11/"/>
    <id>https://kish191919.github.io/2025/08/19/AWS-Certified-AI-Practitioner-11/</id>
    <published>2025-08-19T11:53:04.000Z</published>
    <updated>2025-08-19T11:58:10.721Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ“Š-Amazon-Bedrock-CloudWatch"><a href="#ğŸ“Š-Amazon-Bedrock-CloudWatch" class="headerlink" title="ğŸ“Š Amazon Bedrock &amp; CloudWatch"></a>ğŸ“Š Amazon Bedrock &amp; CloudWatch</h1><h2 id="ğŸ“Œ-What-is-CloudWatch"><a href="#ğŸ“Œ-What-is-CloudWatch" class="headerlink" title="ğŸ“Œ What is CloudWatch?"></a>ğŸ“Œ What is CloudWatch?</h2><p><strong>Amazon CloudWatch</strong> is a monitoring service for AWS resources and applications.<br>It provides:</p><ul><li><strong>Logs</strong> â€“ Detailed records of events and invocations  </li><li><strong>Metrics</strong> â€“ Numerical measurements of system performance  </li><li><strong>Alarms</strong> â€“ Notifications when thresholds are crossed  </li><li><strong>Dashboards</strong> â€“ Visualizations for monitoring</li></ul><hr><h2 id="ğŸ”‘-Bedrock-CloudWatch-Integration"><a href="#ğŸ”‘-Bedrock-CloudWatch-Integration" class="headerlink" title="ğŸ”‘ Bedrock &amp; CloudWatch Integration"></a>ğŸ”‘ Bedrock &amp; CloudWatch Integration</h2><h3 id="1-Model-Invocation-Logging"><a href="#1-Model-Invocation-Logging" class="headerlink" title="1. Model Invocation Logging"></a>1. Model Invocation Logging</h3><ul><li>Logs <strong>all inputs and outputs</strong> from Bedrock model invocations.  </li><li>Data can include:  <ul><li>Text  </li><li>Images  </li><li>Embeddings</li></ul></li><li>Logs can be sent to:  <ul><li><strong>Amazon CloudWatch Logs</strong> (real-time monitoring)  </li><li><strong>Amazon S3</strong> (long-term storage)</li></ul></li><li><strong>Benefits:</strong>  <ul><li>Full history of model usage  </li><li>Debugging issues (e.g., latency, token count, configuration errors)  </li><li>Real-time log analysis with <strong>CloudWatch Logs Insights</strong></li></ul></li></ul><hr><h3 id="2-CloudWatch-Metrics"><a href="#2-CloudWatch-Metrics" class="headerlink" title="2. CloudWatch Metrics"></a>2. CloudWatch Metrics</h3><ul><li>Bedrock publishes key <strong>metrics</strong> into CloudWatch.  </li><li><strong>Examples:</strong>  <ul><li>Invocation count  </li><li>Invocation latency (how long the model takes to respond)  </li><li>Token usage  </li><li><strong>ContentFilteredCount</strong> â†’ shows how often Guardrails blocked unsafe content</li></ul></li><li><strong>Benefits:</strong>  <ul><li>Track model performance over time  </li><li>Identify bottlenecks (e.g., latency spikes)  </li><li>Ensure guardrails are working correctly  </li><li>Build <strong>CloudWatch Alarms</strong> to get alerts (e.g., if latency exceeds 5 seconds)</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_65.png" width="80%"></p><hr><h2 id="âš™ï¸-Example-Workflow"><a href="#âš™ï¸-Example-Workflow" class="headerlink" title="âš™ï¸ Example Workflow"></a>âš™ï¸ Example Workflow</h2><ol><li><p><strong>Enable Invocation Logging</strong> in Bedrock console.  </p><ul><li>Choose destination: CloudWatch or S3.  </li><li>Configure log group (e.g., <code>BedrockInvocationLogs</code>).  </li><li>Assign IAM role for Bedrock â†’ CloudWatch integration.</li></ul></li><li><p><strong>Run Model Invocation</strong>  </p><ul><li>Example: Bedrock model processes a text input.  </li><li>Logs show:  <ul><li>Model ID (e.g., <code>Amazon.Titan-Text-Express-V1</code>)  </li><li>Region  </li><li>Input &amp; output tokens  </li><li>Latency (e.g., 4,038 ms)</li></ul></li></ul></li><li><p><strong>Monitor in CloudWatch</strong>  </p><ul><li><strong>Logs</strong>: Inspect invocation details for debugging.  </li><li><strong>Metrics</strong>: View invocation trends, latency graphs.  </li><li><strong>Alarms</strong>: Trigger alerts when thresholds are exceeded.</li></ul></li></ol><hr><h2 id="ğŸ“-Summary-Table"><a href="#ğŸ“-Summary-Table" class="headerlink" title="ğŸ“ Summary Table"></a>ğŸ“ Summary Table</h2><table><thead><tr><th>Feature</th><th>Explanation</th><th>Example Use</th></tr></thead><tbody><tr><td><strong>Invocation Logging</strong></td><td>Capture all model inputs&#x2F;outputs</td><td>Save logs to CloudWatch or S3</td></tr><tr><td><strong>Supported Data</strong></td><td>Text, images, embeddings</td><td>Debug user queries</td></tr><tr><td><strong>Logs Insights</strong></td><td>Real-time log queries &amp; analysis</td><td>Track latency spikes</td></tr><tr><td><strong>Metrics</strong></td><td>Performance stats from Bedrock</td><td>Invocation count, latency, tokens</td></tr><tr><td><strong>ContentFilteredCount</strong></td><td>Guardrail monitoring</td><td>See how often harmful content is blocked</td></tr><tr><td><strong>Alarms</strong></td><td>Notify when thresholds exceed</td><td>Alert if latency &gt; 5s</td></tr></tbody></table><hr><h2 id="âœ…-Why-This-Matters"><a href="#âœ…-Why-This-Matters" class="headerlink" title="âœ… Why This Matters"></a>âœ… Why This Matters</h2><ul><li><strong>Transparency</strong> â†’ See exactly how Bedrock is used.  </li><li><strong>Reliability</strong> â†’ Detect performance issues early.  </li><li><strong>Compliance &amp; Safety</strong> â†’ Track Guardrail effectiveness.  </li><li><strong>Optimization</strong> â†’ Use metrics to fine-tune workloads.</li></ul><hr><p>ğŸ‘‰ <strong>In summary:</strong><br>Integrating <strong>Amazon Bedrock with CloudWatch</strong> provides full visibility into model usage, performance, and safety.<br>You can log invocations, analyze data, track metrics, and set alarms â€” ensuring your AI applications are <strong>secure, efficient, and reliable</strong>.  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ“Š-Amazon-Bedrock-CloudWatch&quot;&gt;&lt;a href=&quot;#ğŸ“Š-Amazon-Bedrock-CloudWatch&quot; class=&quot;headerlink&quot; title=&quot;ğŸ“Š Amazon Bedrock &amp;amp; CloudWatch&quot;&gt;</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="AI" scheme="https://kish191919.github.io/categories/Dev/AI/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Certification" scheme="https://kish191919.github.io/tags/Certification/"/>
    
  </entry>
  
  <entry>
    <title>AWS-Certified-AI-Practitioner(10)</title>
    <link href="https://kish191919.github.io/2025/08/19/AWS-Certified-AI-Practitioner-10/"/>
    <id>https://kish191919.github.io/2025/08/19/AWS-Certified-AI-Practitioner-10/</id>
    <published>2025-08-19T11:08:53.000Z</published>
    <updated>2025-08-19T11:15:07.712Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ¤–-Amazon-Bedrock-â€“-Agents"><a href="#ğŸ¤–-Amazon-Bedrock-â€“-Agents" class="headerlink" title="ğŸ¤– Amazon Bedrock â€“ Agents"></a>ğŸ¤– Amazon Bedrock â€“ Agents</h1><h2 id="ğŸ“Œ-What-Are-Agents"><a href="#ğŸ“Œ-What-Are-Agents" class="headerlink" title="ğŸ“Œ What Are Agents?"></a>ğŸ“Œ What Are Agents?</h2><p>Agents in <strong>Amazon Bedrock</strong> are advanced components that can <strong>think, plan, and act</strong> on multi-step tasks.<br>Unlike regular models that only provide answers, agents can perform real actions such as:</p><ul><li>Provisioning infrastructure  </li><li>Deploying applications  </li><li>Executing operations on systems  </li><li>Interacting with APIs, databases, and knowledge bases</li></ul><p align="center">  <img src="/images/aws_basic_63.png" width="80%"></p><hr><h2 id="ğŸ”‘-Key-Features-of-Bedrock-Agents"><a href="#ğŸ”‘-Key-Features-of-Bedrock-Agents" class="headerlink" title="ğŸ”‘ Key Features of Bedrock Agents"></a>ğŸ”‘ Key Features of Bedrock Agents</h2><ul><li><strong>Multi-step task execution</strong>: Agents can follow a sequence of steps to complete complex workflows.  </li><li><strong>Task coordination</strong>: Ensure actions are executed in the correct order and data is passed between tasks properly.  </li><li><strong>Action groups</strong>: Agents are configured with specific action groups (APIs, Lambda functions, etc.) to perform defined tasks.  </li><li><strong>System integration</strong>: Connect with databases, services, APIs, and AWS Lambda for real operations.  </li><li><strong>Knowledge base access</strong>: Retrieve business policies or FAQs (e.g., return policies) to give accurate answers.  </li><li><strong>RAG (Retrieval-Augmented Generation)</strong>: Fetch external data when necessary to enhance responses.  </li><li><strong>Tracing &amp; debugging</strong>: See step-by-step execution history to improve reliability.</li></ul><hr><h2 id="âš™ï¸-How-Agents-Work-Behind-the-Scenes"><a href="#âš™ï¸-How-Agents-Work-Behind-the-Scenes" class="headerlink" title="âš™ï¸ How Agents Work (Behind the Scenes)"></a>âš™ï¸ How Agents Work (Behind the Scenes)</h2><ol><li><strong>Task Received</strong> â€“ Agent looks at user request + conversation history.  </li><li><strong>Evaluate Context</strong> â€“ Agent checks available action groups, APIs, knowledge bases.  </li><li><strong>Plan (Chain of Thought)</strong> â€“ Bedrock model generates a step-by-step plan:  <ul><li>Step 1: Call API â†’ get purchase history  </li><li>Step 2: Query knowledge base â†’ check return policy  </li><li>Step 3: Use Lambda â†’ place order</li></ul></li><li><strong>Execute Steps</strong> â€“ Agent carries out the plan automatically.  </li><li><strong>Synthesize Final Answer</strong> â€“ Another model combines results into a clear user response.  </li><li><strong>Tracing Available</strong> â€“ Developers can view the steps for debugging.</li></ol><p align="center">  <img src="/images/aws_basic_64.png" width="80%"></p><hr><h2 id="ğŸ› ï¸-Example-Use-Cases"><a href="#ğŸ› ï¸-Example-Use-Cases" class="headerlink" title="ğŸ› ï¸ Example Use Cases"></a>ğŸ› ï¸ Example Use Cases</h2><h3 id="1-E-commerce-Assistant"><a href="#1-E-commerce-Assistant" class="headerlink" title="1. E-commerce Assistant"></a>1. E-commerce Assistant</h3><ul><li><strong>User asks</strong>: â€œWhat did I purchase last month, and can you recommend something new?â€  </li><li><strong>Agent actions</strong>:  <ul><li>Call API â†’ get purchase history  </li><li>Query recommendation system â†’ suggest new products  </li><li>Provide final recommendation to user</li></ul></li></ul><h3 id="2-Infrastructure-Automation"><a href="#2-Infrastructure-Automation" class="headerlink" title="2. Infrastructure Automation"></a>2. Infrastructure Automation</h3><ul><li><strong>User asks</strong>: â€œSet up a new application environment.â€  </li><li><strong>Agent actions</strong>:  <ul><li>Provision AWS infrastructure  </li><li>Deploy the app using Lambda functions  </li><li>Verify deployment status</li></ul></li></ul><hr><h2 id="ğŸ“-Summary-Table"><a href="#ğŸ“-Summary-Table" class="headerlink" title="ğŸ“ Summary Table"></a>ğŸ“ Summary Table</h2><table><thead><tr><th>Category</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td><strong>Purpose</strong></td><td>Automate multi-step tasks using AI</td><td>Provision servers, deploy apps</td></tr><tr><td><strong>Task Coordination</strong></td><td>Ensure correct order &amp; pass info between tasks</td><td>Step 1: Fetch â†’ Step 2: Deploy</td></tr><tr><td><strong>Action Groups</strong></td><td>Pre-defined sets of APIs or Lambda functions</td><td>Get Purchase History, Place Order</td></tr><tr><td><strong>Integration</strong></td><td>Works with systems, services, DBs, APIs</td><td>Call backend API, update DB</td></tr><tr><td><strong>Knowledge Base</strong></td><td>Fetch company policies or FAQs</td><td>Return policy lookup</td></tr><tr><td><strong>RAG</strong></td><td>Retrieve extra data for better responses</td><td>Pull shipping info dynamically</td></tr><tr><td><strong>Tracing</strong></td><td>View step-by-step execution</td><td>Debugging failed steps</td></tr></tbody></table><hr><h2 id="âœ…-Why-Use-Bedrock-Agents"><a href="#âœ…-Why-Use-Bedrock-Agents" class="headerlink" title="âœ… Why Use Bedrock Agents?"></a>âœ… Why Use Bedrock Agents?</h2><ul><li><strong>Automation</strong> â†’ Reduce manual work in infrastructure, apps, and operations.  </li><li><strong>Scalability</strong> â†’ Handle complex workflows with minimal coding.  </li><li><strong>Accuracy</strong> â†’ Use RAG + knowledge bases to give context-aware answers.  </li><li><strong>Flexibility</strong> â†’ Works with APIs, Lambda, and external systems.  </li><li><strong>Transparency</strong> â†’ Tracing ensures visibility and debugging.</li></ul><hr><p>ğŸ‘‰ <strong>In summary:</strong><br>Amazon Bedrock Agents are like <strong>AI-powered assistants</strong> that donâ€™t just answer questions, but <strong>take actions, follow multi-step plans, integrate with real systems, and provide trustworthy, automated outcomes</strong>.  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ¤–-Amazon-Bedrock-â€“-Agents&quot;&gt;&lt;a href=&quot;#ğŸ¤–-Amazon-Bedrock-â€“-Agents&quot; class=&quot;headerlink&quot; title=&quot;ğŸ¤– Amazon Bedrock â€“ Agents&quot;&gt;&lt;/a&gt;ğŸ¤– Amazo</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="AI" scheme="https://kish191919.github.io/categories/Dev/AI/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Certification" scheme="https://kish191919.github.io/tags/Certification/"/>
    
  </entry>
  
  <entry>
    <title>AWS-Certified-AI-Practitioner(9)</title>
    <link href="https://kish191919.github.io/2025/08/19/AWS-Certified-AI-Practitioner-9/"/>
    <id>https://kish191919.github.io/2025/08/19/AWS-Certified-AI-Practitioner-9/</id>
    <published>2025-08-19T10:53:35.000Z</published>
    <updated>2025-08-19T10:55:35.586Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ›¡ï¸-Amazon-Bedrock-â€“-Guardrails"><a href="#ğŸ›¡ï¸-Amazon-Bedrock-â€“-Guardrails" class="headerlink" title="ğŸ›¡ï¸ Amazon Bedrock â€“ Guardrails"></a>ğŸ›¡ï¸ Amazon Bedrock â€“ Guardrails</h1><h2 id="ğŸ“Œ-What-Are-Guardrails"><a href="#ğŸ“Œ-What-Are-Guardrails" class="headerlink" title="ğŸ“Œ What Are Guardrails?"></a>ğŸ“Œ What Are Guardrails?</h2><p>Guardrails in <strong>Amazon Bedrock</strong> are a way to control and filter interactions between users and Foundation Models (FMs).<br>They help ensure that AI responses are <strong>safe, reliable, and compliant</strong> with your requirements.</p><p align="center">  <img src="/images/aws_basic_62.png" width="80%"></p><hr><h2 id="ğŸ”‘-Key-Features-of-Guardrails"><a href="#ğŸ”‘-Key-Features-of-Guardrails" class="headerlink" title="ğŸ”‘ Key Features of Guardrails"></a>ğŸ”‘ Key Features of Guardrails</h2><ul><li><strong>Filter harmful content</strong>: Block hate speech, insults, sexual, violent, or misconduct content.  </li><li><strong>Block specific topics</strong>: Deny responses related to sensitive or restricted subjects (e.g., recipes, medical advice).  </li><li><strong>Protect privacy</strong>: Automatically detect and remove <strong>PII (Personally Identifiable Information)</strong> such as emails, phone numbers, or addresses.  </li><li><strong>Reduce hallucinations</strong>: Add contextual grounding so the model gives <strong>factual and relevant answers</strong>.  </li><li><strong>Custom word filters</strong>: Upload your own list of banned words or phrases.  </li><li><strong>Multiple guardrails</strong>: Apply different guardrails for different use cases and stack them together.  </li><li><strong>Monitoring &amp; analysis</strong>: Track user inputs that violate guardrails to improve system safety.</li></ul><hr><h2 id="âš™ï¸-Example-Use-Cases"><a href="#âš™ï¸-Example-Use-Cases" class="headerlink" title="âš™ï¸ Example Use Cases"></a>âš™ï¸ Example Use Cases</h2><h3 id="1-Block-Restricted-Topics"><a href="#1-Block-Restricted-Topics" class="headerlink" title="1. Block Restricted Topics"></a>1. Block Restricted Topics</h3><ul><li><strong>Scenario</strong>: You donâ€™t want your model to answer food recipe requests.  </li><li><strong>User prompt</strong>: â€œSuggest me something to cook tonight.â€  </li><li><strong>Guardrail response</strong>: â€œSorry, this is a restricted topic.â€</li></ul><h3 id="2-Mask-PII-Privacy-Protection"><a href="#2-Mask-PII-Privacy-Protection" class="headerlink" title="2. Mask PII (Privacy Protection)"></a>2. Mask PII (Privacy Protection)</h3><ul><li><strong>User prompt</strong>: â€œDraft an email to <a href="mailto:&#x73;&#116;&#x65;&#x70;&#x68;&#x61;&#x6e;&#x65;&#64;&#101;&#x78;&#x61;&#x6d;&#x70;&#108;&#x65;&#46;&#99;&#111;&#109;">stephane@example.com</a> and cc <a href="mailto:&#106;&#111;&#x68;&#x6e;&#64;&#101;&#120;&#x61;&#x6d;&#x70;&#x6c;&#x65;&#x2e;&#99;&#x6f;&#109;">john@example.com</a>.â€  </li><li><strong>Guardrail action</strong>: Automatically masks emails â†’<br>To: [PII Removed], CC: [PII Removed]</li></ul><p>This ensures <strong>user privacy is protected</strong>.</p><hr><h2 id="ğŸ› ï¸-How-to-Configure-a-Guardrail"><a href="#ğŸ› ï¸-How-to-Configure-a-Guardrail" class="headerlink" title="ğŸ› ï¸ How to Configure a Guardrail"></a>ğŸ› ï¸ How to Configure a Guardrail</h2><ol><li><strong>Create Guardrail</strong> â€“ Define a name and blocked message (e.g., <em>â€œSorry, the model cannot answer this question.â€</em>).  </li><li><strong>Set Filters</strong>  <ul><li>Content filters: hate, insults, sexual, violence, misconduct.  </li><li>Denied topics: e.g., recipes, sensitive domains.  </li><li>Word filters: add custom banned terms.  </li><li>PII filters: mask emails, phone numbers, etc.  </li><li>Regex filters: remove any pattern-based info (like credit card numbers).  </li><li>Grounding: reduce hallucinations by checking answer relevance.</li></ul></li><li><strong>Test the Guardrail</strong> â€“ Run a prompt and see if it blocks or masks correctly.  </li><li><strong>Apply to Models</strong> â€“ You can assign guardrails to any supported Foundation Model (e.g., Anthropic, Sonnet).  </li><li><strong>Stack Multiple Guardrails</strong> â€“ Combine several guardrails for stricter control.</li></ol><hr><h2 id="âœ…-Why-Use-Guardrails"><a href="#âœ…-Why-Use-Guardrails" class="headerlink" title="âœ… Why Use Guardrails?"></a>âœ… Why Use Guardrails?</h2><ul><li>Ensure <strong>responsible AI</strong> usage.  </li><li>Protect your business from <strong>legal, ethical, and compliance risks</strong>.  </li><li>Enhance <strong>user trust</strong> by safeguarding privacy and filtering harmful content.  </li><li>Maintain <strong>high-quality, relevant, and safe outputs</strong> from AI models.</li></ul><p>ğŸ‘‰ <strong>In summary:</strong><br>Amazon Bedrock Guardrails are like <strong>safety rules for your AI</strong>, helping you filter content, protect privacy, and keep AI responses accurate and responsible.</p><hr><h2 id="ğŸ“-Amazon-Bedrock-Guardrails-Summary-Table"><a href="#ğŸ“-Amazon-Bedrock-Guardrails-Summary-Table" class="headerlink" title="ğŸ“ Amazon Bedrock Guardrails Summary Table"></a>ğŸ“ Amazon Bedrock Guardrails Summary Table</h2><table><thead><tr><th>Category</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td><strong>Purpose</strong></td><td>Control and filter interactions between users and Foundation Models (FMs)</td><td>Prevent AI from producing unsafe or irrelevant outputs</td></tr><tr><td><strong>Content Filtering</strong></td><td>Blocks harmful categories (hate, violence, sexual, misconduct, insults)</td><td>User asks: â€œWrite a violent story.â€ â†’ Response blocked</td></tr><tr><td><strong>Denied Topics</strong></td><td>Restrict responses on specific topics you define</td><td>Recipes, medical advice, legal guidance</td></tr><tr><td><strong>PII Protection</strong></td><td>Detect and remove Personally Identifiable Information</td><td>Emails, phone numbers, credit cards masked</td></tr><tr><td><strong>Word Filters</strong></td><td>Custom banned words&#x2F;phrases can be uploaded</td><td>Block profanity or sensitive business terms</td></tr><tr><td><strong>Regex Patterns</strong></td><td>Remove data that matches a specific structure</td><td>Mask credit card numbers: 1234-5678-9012-3456</td></tr><tr><td><strong>Grounding (Reduce Hallucinations)</strong></td><td>Ensures responses are relevant and fact-based</td><td>Prevents AI from â€œmaking upâ€ answers</td></tr><tr><td><strong>Multiple Guardrails</strong></td><td>You can stack several guardrails together for stricter control</td><td>One for PII + one for harmful content</td></tr><tr><td><strong>Monitoring</strong></td><td>Logs violations to analyze and improve system safety</td><td>Track how often guardrails are triggered</td></tr><tr><td><strong>Blocked Response Message</strong></td><td>Customizable message shown when prompt is blocked</td><td>â€œSorry, this question cannot be answered.â€</td></tr></tbody></table><hr><h2 id="âœ…-Key-Benefits"><a href="#âœ…-Key-Benefits" class="headerlink" title="âœ… Key Benefits"></a>âœ… Key Benefits</h2><ul><li><strong>Responsible AI</strong> â†’ Prevents harmful or irrelevant responses  </li><li><strong>Enhanced Privacy</strong> â†’ Removes PII and sensitive data  </li><li><strong>Trust &amp; Compliance</strong> â†’ Keeps outputs aligned with regulations and ethics  </li><li><strong>Flexibility</strong> â†’ You can tailor guardrails to your business needs</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ›¡ï¸-Amazon-Bedrock-â€“-Guardrails&quot;&gt;&lt;a href=&quot;#ğŸ›¡ï¸-Amazon-Bedrock-â€“-Guardrails&quot; class=&quot;headerlink&quot; title=&quot;ğŸ›¡ï¸ Amazon Bedrock â€“ Guardrail</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="AI" scheme="https://kish191919.github.io/categories/Dev/AI/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Certification" scheme="https://kish191919.github.io/tags/Certification/"/>
    
  </entry>
  
  <entry>
    <title>AWS-Certified-AI-Practitioner(8)</title>
    <link href="https://kish191919.github.io/2025/08/15/AWS-Certified-AI-Practitioner-8/"/>
    <id>https://kish191919.github.io/2025/08/15/AWS-Certified-AI-Practitioner-8/</id>
    <published>2025-08-15T22:37:17.000Z</published>
    <updated>2025-08-15T22:45:17.194Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ“š-GenAI-Core-Concepts-â€“-Tokenization-Context-Window-Embeddings"><a href="#ğŸ“š-GenAI-Core-Concepts-â€“-Tokenization-Context-Window-Embeddings" class="headerlink" title="ğŸ“š GenAI Core Concepts â€“ Tokenization, Context Window, Embeddings"></a>ğŸ“š GenAI Core Concepts â€“ Tokenization, Context Window, Embeddings</h1><p>These are foundational concepts in Generative AI.<br>They appear frequently in exams and are critical to understanding how LLMs work.</p><hr><h2 id="1-ğŸ”¹-Tokenization"><a href="#1-ğŸ”¹-Tokenization" class="headerlink" title="1. ğŸ”¹ Tokenization"></a>1. ğŸ”¹ Tokenization</h2><p><strong>Definition</strong><br>The process of converting <strong>raw text</strong> into a sequence of smaller units called <strong>tokens</strong>.<br>Tokens are what the model processes internally.</p><p><strong>Types of Tokenization</strong></p><ol><li><strong>Word-based tokenization</strong>  <ul><li>Splits text into words.</li><li>Example: <code>&quot;The cat sat&quot;</code> â†’ <code>[&quot;The&quot;, &quot;cat&quot;, &quot;sat&quot;]</code></li></ul></li><li><strong>Subword tokenization</strong>  <ul><li>Breaks words into smaller meaningful parts.</li><li>Helps handle long or rare words more efficiently.  </li><li>Example: <code>&quot;unacceptable&quot;</code> â†’ <code>&quot;un&quot;</code> + <code>&quot;acceptable&quot;</code></li></ul></li></ol><p><strong>Why it matters</strong></p><ul><li>Each token has an <strong>ID</strong> so the model works with numbers, not raw text.</li><li>Tokenization impacts <strong>cost</strong> and <strong>context window usage</strong> (fewer tokens â†’ more space for content).</li><li>Punctuation and symbols are also tokens.</li></ul><p><strong>Example</strong><br>Sentence: <code>&quot;Danny, Good job!! Learning AI technology is incredibly difficult, but it&#39;s worth it.&quot;</code>  </p><ul><li><code>&quot;Danny&quot;</code> &#x3D; token  </li><li><code>&quot;,&quot;</code> &#x3D; token</li></ul><p align="center">  <img src="/images/aws_basic_58.png" width="80%"></p><p><strong>Exam Tip</strong></p><ul><li>Try the <a href="https://platform.openai.com/tokenizer">OpenAI Tokenizer</a> to see how text is split.</li><li>Models charge and limit based on <strong>token count</strong>, not word count.</li></ul><hr><h2 id="2-ğŸ”¹-Context-Window"><a href="#2-ğŸ”¹-Context-Window" class="headerlink" title="2. ğŸ”¹ Context Window"></a>2. ğŸ”¹ Context Window</h2><p><strong>Definition</strong><br>The number of tokens an LLM can process at once for generating a response.<br>This includes both <strong>input tokens</strong> (your prompt) and <strong>output tokens</strong> (modelâ€™s answer).</p><p><strong>Why it matters</strong></p><ul><li>Larger context windows â†’ more information â†’ more coherent answers.</li><li>But larger windows require <strong>more memory, more processing power</strong>, and <strong>higher cost</strong>.</li></ul><p><strong>Context Window Examples</strong></p><table><thead><tr><th>Model</th><th>Context Window (tokens)</th><th>Approx. Words</th></tr></thead><tbody><tr><td>GPT-4 Turbo</td><td>128,000</td><td>~96,000 words</td></tr><tr><td>Claude 2.1</td><td>200,000</td><td>~150,000 words</td></tr><tr><td>Google Gemini 1.5 Pro</td><td>1,000,000</td><td>~700,000 words</td></tr><tr><td>Research versions</td><td>10,000,000</td><td>~7M words</td></tr></tbody></table><p><strong>Perspective</strong></p><ul><li>1M tokens â‰ˆ 1 hour of video, 11 hours of audio, 30,000+ lines of code, or ~700k words.</li></ul><p align="center">  <img src="/images/aws_basic_59.png" width="60%"></p><p><strong>Exam Tip</strong></p><ul><li>When choosing a model for your use case, <strong>context window size</strong> is often the <strong>first factor</strong> to check.</li></ul><hr><h2 id="3-ğŸ”¹-Embeddings"><a href="#3-ğŸ”¹-Embeddings" class="headerlink" title="3. ğŸ”¹ Embeddings"></a>3. ğŸ”¹ Embeddings</h2><p><strong>Definition</strong><br>A way to represent data (text, images, audio) as <strong>high-dimensional numeric vectors</strong>.<br>Each vector stores multiple features about the input.</p><p><strong>Process</strong></p><ol><li><strong>Tokenization</strong> â€“ Convert text into tokens.</li><li><strong>Token IDs</strong> â€“ Assign each token a numeric ID.</li><li><strong>Embedding Model</strong> â€“ Convert each token ID into a <strong>vector</strong> (list of numbers).</li></ol><p>Example: <code>&quot;The cat sat on the mat&quot;</code>  </p><ul><li><code>&quot;cat&quot;</code> â†’ <code>[0.025, -0.12, 0.33, ...]</code> (100+ dimensions possible)</li></ul><p align="center">  <img src="/images/aws_basic_60.png" width="80%"></p><p><strong>Why High-Dimensional Vectors?</strong></p><ul><li>Can store multiple features per token:<ul><li><strong>Semantic meaning</strong> (what it means)</li><li><strong>Syntactic role</strong> (function in sentence â€“ subject, verb, etc.)</li><li><strong>Sentiment</strong> (positive&#x2F;negative&#x2F;neutral tone)</li><li>Other learned features</li></ul></li><li>Enables <strong>similarity search</strong>: tokens with similar meaning have similar embeddings.</li></ul><hr><h3 id="3-1-Visualizing-Embeddings"><a href="#3-1-Visualizing-Embeddings" class="headerlink" title="3.1. Visualizing Embeddings"></a>3.1. Visualizing Embeddings</h3><p>Humans can visualize <strong>2D or 3D</strong>, but embeddings are often <strong>100+ dimensions</strong>.<br>We use <strong>dimensionality reduction</strong> to make them viewable:</p><p><strong>Example in 2D</strong>:</p><ul><li><code>&quot;dog&quot;</code> and <code>&quot;puppy&quot;</code> â†’ close together (semantic similarity)</li><li><code>&quot;cat&quot;</code> â†’ nearby (animal)</li><li><code>&quot;house&quot;</code> â†’ far away (different concept)</li></ul><p><strong>Example with colors</strong>:</p><ul><li>Assign colors based on embedding values.</li><li>Similar colors &#x3D; similar meaning.</li></ul><p align="center">  <img src="/images/aws_basic_61.png" width="80%"></p><hr><h3 id="3-2-Embeddings-in-RAG-Search"><a href="#3-2-Embeddings-in-RAG-Search" class="headerlink" title="3.2. Embeddings in RAG &amp; Search"></a>3.2. Embeddings in RAG &amp; Search</h3><ul><li>Stored in a <strong>vector database</strong> (e.g., OpenSearch, Pinecone, FAISS, Redis Vector).</li><li>Used for <strong>KNN search</strong> (k-nearest neighbors) to find the closest semantic matches.</li><li>Power search applications:  <ul><li>Input <code>&quot;dog&quot;</code> â†’ retrieves <code>&quot;puppy&quot;</code>, <code>&quot;canine&quot;</code>, <code>&quot;pet&quot;</code>.</li></ul></li></ul><p><strong>Exam Tip</strong></p><ul><li>Vector similarity search &#x3D; <strong>KNN Search</strong> in vector DBs.</li><li>In AWS context, OpenSearch Serverless is common for storing and querying embeddings.</li></ul><hr><h2 id="4-ğŸ“Œ-Quick-Summary-Table"><a href="#4-ğŸ“Œ-Quick-Summary-Table" class="headerlink" title="4. ğŸ“Œ Quick Summary Table"></a>4. ğŸ“Œ Quick Summary Table</h2><table><thead><tr><th>Concept</th><th>What it is</th><th>Why it matters</th><th>Example</th></tr></thead><tbody><tr><td>Tokenization</td><td>Split text into tokens</td><td>Tokens are the unit LLMs process; affects cost&#x2F;context</td><td><code>&quot;unacceptable&quot;</code> â†’ <code>&quot;un&quot;</code>, <code>&quot;acceptable&quot;</code></td></tr><tr><td>Context Window</td><td>Max tokens LLM can handle at once</td><td>Larger &#x3D; more info but higher cost</td><td>GPT-4 Turbo: 128k tokens</td></tr><tr><td>Embeddings</td><td>Numeric vector representation of data</td><td>Enables semantic search &amp; RAG</td><td><code>&quot;dog&quot;</code> vector close to <code>&quot;puppy&quot;</code></td></tr></tbody></table><hr><p>âœ… <strong>Key Exam Pointers</strong>:</p><ul><li>Token &#x3D; smallest processing unit in LLMs (words, subwords, punctuation).</li><li>Context window &#x3D; total input + output tokens model can handle.</li><li>Embeddings store multiple features in high-dimensional space for search &amp; retrieval.</li><li>KNN search is the standard for finding similar embeddings in vector DBs.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ“š-GenAI-Core-Concepts-â€“-Tokenization-Context-Window-Embeddings&quot;&gt;&lt;a href=&quot;#ğŸ“š-GenAI-Core-Concepts-â€“-Tokenization-Context-Window-Embe</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="AI" scheme="https://kish191919.github.io/categories/Dev/AI/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Certification" scheme="https://kish191919.github.io/tags/Certification/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(7)</title>
    <link href="https://kish191919.github.io/2025/08/15/AWS-Certified-AI-Practitioner-7/"/>
    <id>https://kish191919.github.io/2025/08/15/AWS-Certified-AI-Practitioner-7/</id>
    <published>2025-08-15T21:07:36.000Z</published>
    <updated>2025-08-15T22:52:15.195Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ“š-Amazon-Bedrock-â€“-Setting-up-RAG-Knowledge-Base-Hands-on"><a href="#ğŸ“š-Amazon-Bedrock-â€“-Setting-up-RAG-Knowledge-Base-Hands-on" class="headerlink" title="ğŸ“š Amazon Bedrock â€“ Setting up RAG &amp; Knowledge Base (Hands-on)"></a>ğŸ“š Amazon Bedrock â€“ Setting up RAG &amp; Knowledge Base (Hands-on)</h1><p>This guide explains how to set up a <strong>Retrieval-Augmented Generation (RAG)</strong> pipeline and a <strong>Knowledge Base</strong> in Amazon Bedrock, using Amazon S3 for storage and Amazon OpenSearch Serverless as the vector database.</p><hr><h2 id="1-ğŸ”-Prerequisites"><a href="#1-ğŸ”-Prerequisites" class="headerlink" title="1. ğŸ” Prerequisites"></a>1. ğŸ” Prerequisites</h2><ul><li><strong>IAM User</strong> (not root user)</li><li><strong>Administrator Access</strong> policy for the IAM user</li><li>AWS services:<ul><li>Amazon Bedrock</li><li>Amazon S3</li><li>Amazon OpenSearch Serverless (or external vector DB)</li></ul></li><li>PDF or text document to upload (e.g., <code>evolution_of_the_internet_detailed.pdf</code>)</li></ul><hr><h2 id="2-ğŸ› -Step-by-Step-Setup"><a href="#2-ğŸ› -Step-by-Step-Setup" class="headerlink" title="2. ğŸ›  Step-by-Step Setup"></a>2. ğŸ›  Step-by-Step Setup</h2><h3 id="Step-1-â€“-Create-an-IAM-User"><a href="#Step-1-â€“-Create-an-IAM-User" class="headerlink" title="Step 1 â€“ Create an IAM User"></a>Step 1 â€“ Create an IAM User</h3><ol><li><p>Go to <strong>IAM Console â†’ Users â†’ Create User</strong>.</p></li><li><p>Enter a username (e.g., <code>stephane</code>).</p></li><li><p>Enable <strong>AWS Management Console Access</strong>.</p></li><li><p>Set a custom password.</p></li><li><p>Attach the <strong>AdministratorAccess</strong> policy.</p></li><li><p>Save the sign-in URL, username, and password.</p></li><li><p>Log in as the IAM user (not root).</p> <p align="center"></li></ol>  <img src="/images/aws_basic_31.png" width="70%">  </p><hr><h3 id="Step-2-â€“-Create-a-Knowledge-Base-in-Amazon-Bedrock"><a href="#Step-2-â€“-Create-a-Knowledge-Base-in-Amazon-Bedrock" class="headerlink" title="Step 2 â€“ Create a Knowledge Base in Amazon Bedrock"></a>Step 2 â€“ Create a Knowledge Base in Amazon Bedrock</h3><ol><li>In <strong>Amazon Bedrock</strong>, go to <strong>Knowledge Bases â†’ Create Knowledge Base</strong>.</li><li>Set the name (default is fine).</li></ol><p align="center">  <img src="/images/aws_basic_36.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_37.png" width="70%"></p><ol start="3"><li><strong>IAM permissions</strong> â†’ <em>Create and use a new service role</em>.</li><li><strong>Data Source</strong> â†’ Select <strong>Amazon S3</strong>.</li><li>Alternative sources (optional):<ul><li>Web crawler (webpages)</li><li>Confluence</li><li>Salesforce</li><li>SharePoint</li></ul></li></ol><p align="center">  <img src="/images/aws_basic_32.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_33.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_34.png" width="20%"></p><p align="center">  <img src="/images/aws_basic_35.png" width="20%"></p><hr><h3 id="Step-3-â€“-Create-an-Amazon-S3-Bucket-Upload-Documents"><a href="#Step-3-â€“-Create-an-Amazon-S3-Bucket-Upload-Documents" class="headerlink" title="Step 3 â€“ Create an Amazon S3 Bucket &amp; Upload Documents"></a>Step 3 â€“ Create an Amazon S3 Bucket &amp; Upload Documents</h3><ol><li>Go to <strong>Amazon S3 â†’ Create bucket</strong>.<ul><li>Region: <strong>us-east-1</strong></li><li>Bucket name: <strong>must be globally unique</strong> (e.g., <code>my-demo-bucket-knowledgebase-danny</code>)</li></ul></li><li>Upload your document:<ul><li>Example: <code>evolution_of_the_internet_detailed.pdf</code></li></ul></li><li>Confirm the object appears in the bucket.</li></ol><p align="center">  <img src="/images/aws_basic_38.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_39.png" width="70%"></p><hr><h3 id="Step-4-â€“-Connect-S3-to-Bedrock-Knowledge-Base"><a href="#Step-4-â€“-Connect-S3-to-Bedrock-Knowledge-Base" class="headerlink" title="Step 4 â€“ Connect S3 to Bedrock Knowledge Base"></a>Step 4 â€“ Connect S3 to Bedrock Knowledge Base</h3><ol><li>In Bedrock KB creation:<ul><li>Select your S3 bucket as the <strong>data source</strong>.</li><li>Click <strong>Next</strong>.</li></ul></li></ol><p align="center">  <img src="/images/aws_basic_40.png" width="70%"></p><ol start="2"><li><strong>Embedding Model</strong>:<ul><li>Select <strong>Amazon Titan Text Embeddings V2</strong> (default dimensions).</li></ul></li><li><strong>Vector Database</strong>:<ul><li>For AWS exam â†’ <strong>Amazon OpenSearch Serverless</strong> is the common choice.</li><li>External free option â†’ <strong>Pinecone</strong> (free tier available).</li></ul></li><li>Complete the KB creation.</li></ol><p>âš ï¸ <strong>Cost Warning</strong>:<br>Amazon OpenSearch Serverless minimum cost is ~<strong>$172&#x2F;month</strong> (2 OCUs at $0.24&#x2F;hour).<br>Delete resources after use to avoid charges.</p><p align="center">  <img src="/images/aws_basic_41.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_42.png" width="70%"></p><hr><h3 id="Step-5-â€“-Sync-Data-to-Vector-Database"><a href="#Step-5-â€“-Sync-Data-to-Vector-Database" class="headerlink" title="Step 5 â€“ Sync Data to Vector Database"></a>Step 5 â€“ Sync Data to Vector Database</h3><ol><li>Open your Knowledge Base.</li><li>Click <strong>Sync</strong> to push S3 data â†’ embeddings â†’ vector database.</li><li>In OpenSearch Service:<ul><li>View your <strong>collection</strong> and <strong>indexes</strong>.</li><li>Each chunk of your document is stored as a vector.</li></ul></li></ol><p align="center">  <img src="/images/aws_basic_43.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_44.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_45.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_46.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_47.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_48.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_49.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_50.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_51.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_52.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_53.png" width="70%"></p><hr><h3 id="Step-6-â€“-Test-the-Knowledge-Base"><a href="#Step-6-â€“-Test-the-Knowledge-Base" class="headerlink" title="Step 6 â€“ Test the Knowledge Base"></a>Step 6 â€“ Test the Knowledge Base</h3><ol><li>Configure a model (e.g., <strong>Anthropic Claude Haiku</strong>).</li><li>Ask a question (e.g., <code>&quot;Who invented the World Wide Web?&quot;</code>).</li><li>Bedrock will:<ul><li>Perform <strong>vector similarity search</strong> (KNN search).</li><li>Retrieve relevant chunks from the KB.</li><li>Augment the prompt with retrieved text.</li><li>Generate an answer with <strong>source citations</strong>.</li></ul></li><li>Click the source link â†’ View the PDF in S3.</li></ol><p align="center">  <img src="/images/aws_basic_54.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_55.png" width="70%"></p><hr><h2 id="3-ğŸ§ -How-It-Works-Internally"><a href="#3-ğŸ§ -How-It-Works-Internally" class="headerlink" title="3. ğŸ§  How It Works Internally"></a>3. ğŸ§  How It Works Internally</h2><h2 id="ğŸ“ˆ-RAG-Data-Flow-Diagram"><a href="#ğŸ“ˆ-RAG-Data-Flow-Diagram" class="headerlink" title="ğŸ“ˆ RAG Data Flow Diagram"></a>ğŸ“ˆ RAG Data Flow Diagram</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">flowchart TD</span><br><span class="line">    A[ğŸ“‚ Amazon S3 PDF] --&gt; B[âœ‚ï¸ Chunking &amp; Embedding Creation&lt;br/&gt;(Amazon Titan)]</span><br><span class="line">    B --&gt; C[ğŸ—„ Vector Database&lt;br/&gt;OpenSearch Serverless]</span><br><span class="line">    C --&gt; D[ğŸ” KNN Similarity Search]</span><br><span class="line">    D --&gt; E[ğŸ“‘ Relevant Chunks Retrieved]</span><br><span class="line">    E --&gt; F[ğŸ“ Combined with Original Query&lt;br/&gt;â†’ Augmented Prompt]</span><br><span class="line">    F --&gt; G[ğŸ¤– Foundation Model Generates Answer]</span><br></pre></td></tr></table></figure><ul><li><strong>Chunking</strong>: Splits the document into smaller parts.</li><li><strong>Embeddings</strong>: Numeric vector representation of text.</li><li><strong>KNN Search</strong>: Finds the <code>k</code> most semantically similar chunks.</li><li><strong>Augmented Prompt</strong>: Original query + retrieved text â†’ better answer.</li></ul><hr><h2 id="4-ğŸ›‘-Cleanup-Avoid-Unnecessary-Costs"><a href="#4-ğŸ›‘-Cleanup-Avoid-Unnecessary-Costs" class="headerlink" title="4. ğŸ›‘ Cleanup (Avoid Unnecessary Costs)"></a>4. ğŸ›‘ Cleanup (Avoid Unnecessary Costs)</h2><p>After testing:</p><ol><li><strong>Delete Knowledge Base</strong> in Bedrock.</li><li><strong>Delete OpenSearch Serverless collection</strong>.</li><li>(Optional) Keep S3 bucket (low cost) or delete it.</li></ol><p align="center">  <img src="/images/aws_basic_56.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_57.png" width="80%"></p><hr><h2 id="5-ğŸ“Œ-Exam-Tips"><a href="#5-ğŸ“Œ-Exam-Tips" class="headerlink" title="5. ğŸ“Œ Exam Tips"></a>5. ğŸ“Œ Exam Tips</h2><ul><li><strong>Always use IAM user</strong> (root user cannot create Bedrock KB).</li><li><strong>Vector DB Options in AWS</strong>:<ul><li>OpenSearch (real-time search, KNN)</li><li>Aurora PostgreSQL (pgvector)</li><li>Neptune Analytics (graph-based RAG)</li><li>S3 Vectors (low cost, sub-second search)</li></ul></li><li><strong>External</strong>: Pinecone, Redis, MongoDB Atlas Vector Search.</li><li>Bedrock KB supports multiple data sources, not just S3.</li><li><strong>Remember</strong>: RAG &#x3D; Retrieve external data + Augment prompt + Generate answer.</li></ul><hr><p>âœ… <strong>Summary</strong>:<br>Youâ€™ve created a Bedrock Knowledge Base with Amazon S3 + OpenSearch, generated embeddings with Titan, performed KNN search, and tested retrieval-augmented responses with citations.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ“š-Amazon-Bedrock-â€“-Setting-up-RAG-Knowledge-Base-Hands-on&quot;&gt;&lt;a href=&quot;#ğŸ“š-Amazon-Bedrock-â€“-Setting-up-RAG-Knowledge-Base-Hands-on&quot; cl</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="AI" scheme="https://kish191919.github.io/categories/Dev/AI/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Certification" scheme="https://kish191919.github.io/tags/Certification/"/>
    
  </entry>
  
  <entry>
    <title>AWS-Certified-AI-Practitioner(6)</title>
    <link href="https://kish191919.github.io/2025/08/15/AWS-Certified-AI-Practitioner-6/"/>
    <id>https://kish191919.github.io/2025/08/15/AWS-Certified-AI-Practitioner-6/</id>
    <published>2025-08-15T20:21:28.000Z</published>
    <updated>2025-08-15T21:07:12.986Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ“š-Amazon-Bedrock-â€“-RAG-Knowledge-Base"><a href="#ğŸ“š-Amazon-Bedrock-â€“-RAG-Knowledge-Base" class="headerlink" title="ğŸ“š Amazon Bedrock â€“ RAG &amp; Knowledge Base"></a>ğŸ“š Amazon Bedrock â€“ RAG &amp; Knowledge Base</h1><h2 id="1-ğŸ”-What-is-RAG"><a href="#1-ğŸ”-What-is-RAG" class="headerlink" title="1. ğŸ” What is RAG?"></a>1. ğŸ” What is RAG?</h2><p><strong>RAG (Retrieval-Augmented Generation)</strong> &#x3D;  </p><blockquote><p><strong>Retrieve</strong> information from an external data source â†’ <strong>Augment</strong> the prompt â†’ <strong>Generate</strong> a more accurate answer.</p></blockquote><ul><li><strong>Retrieval</strong>: Searches for latest or domain-specific data outside the modelâ€™s training set.</li><li><strong>Augmented Generation</strong>: Combines retrieved data with the original query before sending it to the model.</li><li><strong>No Fine-tuning Required</strong>: Can inject up-to-date information without retraining the model.</li></ul><hr><h2 id="2-ğŸ—-How-It-Works-Step-by-Step"><a href="#2-ğŸ—-How-It-Works-Step-by-Step" class="headerlink" title="2. ğŸ— How It Works (Step-by-Step)"></a>2. ğŸ— How It Works (Step-by-Step)</h2><ol><li><strong>Data Storage</strong><ul><li>Store documents in Amazon S3, Confluence, SharePoint, Salesforce, webpages, etc.</li></ul></li><li><strong>Vector Embedding Creation</strong><ul><li>Bedrock automatically chunks data into smaller parts.</li><li>Uses embedding models like Amazon Titan or Cohere to convert text into vectors.</li></ul></li><li><strong>Vector Database Storage</strong><ul><li>Stores embeddings in a vector database (e.g., OpenSearch, Aurora, Neptune, S3 Vectors).</li></ul></li><li><strong>Query Processing</strong><ul><li>User enters a question â†’ RAG searches for semantically similar vectors in the DB.</li></ul></li><li><strong>Prompt Augmentation</strong><ul><li>Search results are combined with the original query â†’ <strong>Augmented Prompt</strong>.</li></ul></li><li><strong>Answer Generation</strong><ul><li>A Foundation Model (Claude, Titan Text, Llama, etc.) generates a final answer with citations.</li></ul></li></ol>  <p align="center">  <img src="/images/aws_basic_27.png" width="100%">  </p><hr><h2 id="3-ğŸ› -Key-Components"><a href="#3-ğŸ› -Key-Components" class="headerlink" title="3. ğŸ›  Key Components"></a>3. ğŸ›  Key Components</h2><table><thead><tr><th>Component</th><th>Description</th><th>AWS &#x2F; External Options</th></tr></thead><tbody><tr><td><strong>Data Source</strong></td><td>Location where source data is stored</td><td>Amazon S3, Confluence, SharePoint, Salesforce, webpages</td></tr><tr><td><strong>Embedding Model</strong></td><td>Converts text into vector embeddings</td><td>Amazon Titan, Cohere</td></tr><tr><td><strong>Vector Database</strong></td><td>Stores and retrieves vector data</td><td><strong>AWS:</strong> OpenSearch, Aurora, Neptune Analytics, S3 Vectors<br><strong>External:</strong> MongoDB, Redis, Pinecone</td></tr><tr><td><strong>Foundation Model</strong></td><td>Generates the final answer</td><td>Claude, Titan Text, Llama, etc.</td></tr></tbody></table><hr><h2 id="4-ğŸ“Š-AWS-Vector-Database-Comparison-Exam-Focused"><a href="#4-ğŸ“Š-AWS-Vector-Database-Comparison-Exam-Focused" class="headerlink" title="4. ğŸ“Š AWS Vector Database Comparison (Exam-Focused)"></a>4. ğŸ“Š AWS Vector Database Comparison (Exam-Focused)</h2><table><thead><tr><th>Service</th><th>Key Features</th><th>Best For</th></tr></thead><tbody><tr><td><strong>Amazon OpenSearch Service</strong></td><td>Real-time search, KNN, serverless&#x2F;managed modes</td><td>Large-scale real-time search &amp; analytics</td></tr><tr><td><strong>Aurora PostgreSQL</strong></td><td>Relational DB with vector search</td><td>Integrating RAG into RDBMS systems</td></tr><tr><td><strong>Neptune Analytics</strong></td><td>Graph-based RAG (GraphRAG)</td><td>Relationship-focused or graph analytics</td></tr><tr><td><strong>S3 Vectors</strong></td><td>Low cost, high durability, sub-second queries</td><td>Cost-effective, long-term storage</td></tr></tbody></table>  <p align="center">  <img src="/images/aws_basic_28.png" width="100%">  </p><hr><h2 id="5-ğŸ“ˆ-Data-Flow-Example"><a href="#5-ğŸ“ˆ-Data-Flow-Example" class="headerlink" title="5. ğŸ“ˆ Data Flow Example"></a>5. ğŸ“ˆ Data Flow Example</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">flowchart TD</span><br><span class="line">    A[ğŸ“‚ Data Source&lt;br/&gt;Amazon S3 / Confluence / SharePoint / Salesforce / Webpages]</span><br><span class="line">    B[ğŸ”¹ Chunking &amp; Embedding Creation&lt;br/&gt;Split docs + Generate vector embeddings&lt;br/&gt;(Amazon Titan, Cohere)]</span><br><span class="line">    C[ğŸ—„ Vector Database Storage&lt;br/&gt;OpenSearch / Aurora / Neptune / S3 Vectors]</span><br><span class="line">    D[ğŸ” Similarity Search&lt;br/&gt;Convert query to vector &amp; run KNN search]</span><br><span class="line">    E[ğŸ“‘ Relevant Documents Retrieved]</span><br><span class="line">    F[ğŸ“ Augmented Prompt Creation&lt;br/&gt;Merge query + retrieved content]</span><br><span class="line">    G[ğŸ¤– Foundation Model Generates Answer&lt;br/&gt;Context-aware response with citations]</span><br><span class="line"></span><br><span class="line">    A --&gt; B --&gt; C --&gt; D --&gt; E --&gt; F --&gt; G</span><br></pre></td></tr></table></figure><h2 id="ğŸ“Œ-Why-KNN-Search-Appears-in-the-RAG-Data-Flow"><a href="#ğŸ“Œ-Why-KNN-Search-Appears-in-the-RAG-Data-Flow" class="headerlink" title="ğŸ“Œ Why KNN Search Appears in the RAG Data Flow"></a>ğŸ“Œ Why KNN Search Appears in the RAG Data Flow</h2><p>In Amazon Bedrockâ€™s RAG workflow, <strong>KNN (k-Nearest Neighbors) search</strong> is used because it is the core method for retrieving the most relevant documents from a vector database.</p><h3 id="1-Vector-Embeddings"><a href="#1-Vector-Embeddings" class="headerlink" title="1) Vector Embeddings"></a>1) Vector Embeddings</h3><ul><li>Documents and queries are converted into <strong>vector embeddings</strong> (arrays of numbers) using an embedding model such as <strong>Amazon Titan</strong> or <strong>Cohere</strong>.</li><li>Each vector represents the semantic meaning of the text.</li></ul><h3 id="2-Similarity-Comparison"><a href="#2-Similarity-Comparison" class="headerlink" title="2) Similarity Comparison"></a>2) Similarity Comparison</h3><ul><li>To find the most relevant document for a query, the system compares the <strong>query vector</strong> with <strong>document vectors</strong> stored in the database.</li><li><strong>Distance metrics</strong> (e.g., Cosine Similarity, Euclidean Distance) measure how close two vectors are in the vector space.</li></ul><h3 id="3-KNN-Search"><a href="#3-KNN-Search" class="headerlink" title="3) KNN Search"></a>3) KNN Search</h3><ul><li><strong>KNN (k-Nearest Neighbors)</strong> search retrieves the top <strong>k</strong> most similar vectors to the query vector.</li><li>â€œNearestâ€ means smallest distance (highest similarity score).</li><li>This step ensures the retrieved documents are the most contextually relevant to the userâ€™s question.</li></ul><h3 id="4-AWS-External-Database-Support"><a href="#4-AWS-External-Database-Support" class="headerlink" title="4) AWS &amp; External Database Support"></a>4) AWS &amp; External Database Support</h3><ul><li><strong>AWS Native</strong>: Amazon OpenSearch Service (supports Approximate k-NN), Aurora PostgreSQL (with pgvector), Neptune Analytics, S3 Vectors.</li><li><strong>External</strong>: Pinecone, MongoDB with Atlas Vector Search, Redis with Vector capabilities.</li></ul><h3 id="5-Exam-Tip"><a href="#5-Exam-Tip" class="headerlink" title="5) Exam Tip"></a>5) Exam Tip</h3><ul><li>In AWS exam contexts, if you see â€œvector similarity searchâ€ or â€œsemantic searchâ€ mentioned, it usually refers to <strong>k-NN search</strong>.</li><li>OpenSearch Serviceâ€™s <strong>Approximate k-NN</strong> is often the recommended choice for large-scale, real-time semantic search in RAG architectures.</li></ul><p><strong>Summary</strong>:<br>KNN search is in the RAG workflow because itâ€™s the standard method for <strong>finding the most semantically relevant documents</strong> from a vector database before augmenting the prompt for the foundation model.</p><hr><h2 id="6-ğŸ’¡-Common-Use-Cases"><a href="#6-ğŸ’¡-Common-Use-Cases" class="headerlink" title="6. ğŸ’¡ Common Use Cases"></a>6. ğŸ’¡ Common Use Cases</h2><ol><li><strong>Customer Service Chatbot</strong><ul><li>KB: Product manuals, FAQs, troubleshooting guides</li><li>Retrieves and answers product-related queries</li></ul></li><li><strong>Legal Research</strong><ul><li>KB: Laws, case precedents, regulations</li><li>Answers legal questions with precise citations</li></ul></li><li><strong>Healthcare Q&amp;A</strong><ul><li>KB: Diseases, treatments, research papers</li><li>Provides medical information based on trusted documents</li></ul></li></ol><hr><h2 id="7-ğŸ§ª-Hands-On-Example-â€“-Chat-with-Your-Document"><a href="#7-ğŸ§ª-Hands-On-Example-â€“-Chat-with-Your-Document" class="headerlink" title="7. ğŸ§ª Hands-On Example â€“ Chat with Your Document"></a>7. ğŸ§ª Hands-On Example â€“ Chat with Your Document</h2><ul><li><p><strong>Goal</strong>: Build a Q&amp;A system based on uploaded documents</p></li><li><p><strong>Steps</strong></p><ol><li>Navigate to <strong>Builder Tools â†’ Knowledge Bases</strong></li><li>Select <strong>Chat with your document</strong></li><li>Upload a document</li><li>Ask a question:  <ul><li><em>Example:</em> â€œWho invented the World Wide Web?â€</li></ul></li><li>The model searches the document, finds relevant chunks, and generates a response with citations</li></ol></li><li><p><strong>Error Handling</strong>: If the document doesnâ€™t contain relevant info, the model should respond with â€œI cannot find the answer in the provided data.â€</p><p align="center"><img src="/images/aws_basic_29.png" width="100%"></p>  <p align="center"><img src="/images/aws_basic_30.png" width="100%"></p></li></ul><hr><h2 id="8-ğŸ“Œ-Key-Points-for-the-Exam"><a href="#8-ğŸ“Œ-Key-Points-for-the-Exam" class="headerlink" title="8. ğŸ“Œ Key Points for the Exam"></a>8. ğŸ“Œ Key Points for the Exam</h2><ul><li><strong>Definition</strong>: RAG &#x3D; Retrieve external data + augment the prompt â†’ better answers</li><li><strong>Bedrockâ€™s Role</strong>: Automates embedding creation, KB management, and FM connection</li><li><strong>AWS Vector DB Options</strong>: OpenSearch, Aurora, Neptune, S3 Vectors</li><li><strong>Data Sources</strong>: Amazon S3, Confluence, SharePoint, Salesforce, webpages</li><li><strong>Use Cases</strong>: Chatbots, legal research, healthcare Q&amp;A</li><li><strong>Practice Tip</strong>: Use â€œChat with your documentâ€ to understand KB operations</li></ul><hr><p>âœ… <strong>Extra Exam Tip</strong>  </p><ul><li><strong>OpenSearch</strong> â†’ large-scale search &amp; analytics  </li><li><strong>Neptune</strong> â†’ relationship&#x2F;graph-based data  </li><li><strong>S3 Vectors</strong> â†’ low cost &amp; durability  </li><li>Bedrock allows <strong>real-time data integration without fine-tuning</strong></li></ul><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ“š-Amazon-Bedrock-â€“-RAG-Knowledge-Base&quot;&gt;&lt;a href=&quot;#ğŸ“š-Amazon-Bedrock-â€“-RAG-Knowledge-Base&quot; class=&quot;headerlink&quot; title=&quot;ğŸ“š Amazon Bedroc</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="AI" scheme="https://kish191919.github.io/categories/Dev/AI/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Certification" scheme="https://kish191919.github.io/tags/Certification/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(5)</title>
    <link href="https://kish191919.github.io/2025/08/15/AWS-Certified-AI-Practitioner-5/"/>
    <id>https://kish191919.github.io/2025/08/15/AWS-Certified-AI-Practitioner-5/</id>
    <published>2025-08-15T19:09:05.000Z</published>
    <updated>2025-08-15T20:10:32.134Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ“Š-Amazon-Bedrock-â€“-Model-Evaluation-Guide"><a href="#ğŸ“Š-Amazon-Bedrock-â€“-Model-Evaluation-Guide" class="headerlink" title="ğŸ“Š Amazon Bedrock â€“ Model Evaluation Guide"></a>ğŸ“Š Amazon Bedrock â€“ Model Evaluation Guide</h1><p>Evaluating a Foundation Model (FM) is essential for <strong>quality control</strong>, <strong>business impact measurement</strong>, and <strong>bias detection</strong>. Amazon Bedrock offers multiple ways to evaluate modelsâ€”both automatically and through human feedbackâ€”along with technical and business metrics.</p><hr><h2 id="1-ğŸ”„-Automatic-Evaluation"><a href="#1-ğŸ”„-Automatic-Evaluation" class="headerlink" title="1. ğŸ”„ Automatic Evaluation"></a>1. ğŸ”„ Automatic Evaluation</h2><p>Amazon Bedrock can <strong>automatically score</strong> a modelâ€™s performance on predefined tasks.</p><p><strong>Built-in Task Types</strong></p><ul><li>Text summarization</li><li>Question answering</li><li>Text classification</li><li>Open-ended text generation</li></ul><p><strong>How It Works</strong></p><ol><li><strong>Benchmark Dataset</strong>  <ul><li>Curated datasets with <strong>questions</strong> and <strong>ideal answers</strong>.</li><li>Can be AWS-provided or custom-made for your business.</li></ul></li><li><strong>Model Testing</strong>  <ul><li>Model receives the benchmark questions.</li><li>Generates answers for each.</li></ul></li><li><strong>Automated Comparison</strong>  <ul><li>Another â€œjudge modelâ€ compares the modelâ€™s answers to benchmark answers.</li><li>Produces a <strong>score</strong> using metrics like ROUGE, BLEU, or BERTScore.</li></ul></li></ol><p><strong>Benefits</strong></p><ul><li>Fast and consistent scoring.</li><li>Detects bias, inefficiency, and scalability issues.</li><li>Minimal administrative effort.</li></ul><p align="center">  <img src="/images/aws_basic_20.png" width="100%"></p><hr><h2 id="2-ğŸ§‘-Human-Evaluation"><a href="#2-ğŸ§‘-Human-Evaluation" class="headerlink" title="2. ğŸ§‘ Human Evaluation"></a>2. ğŸ§‘ Human Evaluation</h2><p>Human reviewers assess the modelâ€™s answers against benchmarks.</p><p><strong>Who Can Review?</strong></p><ul><li>Internal employees</li><li>Subject Matter Experts (SMEs)</li></ul><p><strong>Evaluation Methods</strong></p><ul><li>Thumbs up&#x2F;down</li><li>Ranking answers</li><li>Custom scoring systems</li></ul><p><strong>Advantages</strong></p><ul><li>Handles nuanced, domain-specific judgment.</li><li>Flexible â€” supports both built-in and custom tasks.</li></ul><p align="center">  <img src="/images/aws_basic_23.png" width="100%"></p><hr><h2 id="3-ğŸ“-Automated-Evaluation-Metrics"><a href="#3-ğŸ“-Automated-Evaluation-Metrics" class="headerlink" title="3. ğŸ“ Automated Evaluation Metrics"></a>3. ğŸ“ Automated Evaluation Metrics</h2><h3 id="ROUGE-â€“-Recall-Oriented-Understudy-for-Gisting-Evaluation"><a href="#ROUGE-â€“-Recall-Oriented-Understudy-for-Gisting-Evaluation" class="headerlink" title="ROUGE â€“ Recall-Oriented Understudy for Gisting Evaluation"></a><strong>ROUGE</strong> â€“ <em>Recall-Oriented Understudy for Gisting Evaluation</em></h3><ul><li>Measures overlap between reference and generated text.</li><li><strong>ROUGE-N:</strong> Matches n-grams (sequence of N words).</li><li><strong>ROUGE-L:</strong> Longest common word sequence between texts.</li><li><strong>Best for:</strong> Summarization and translation evaluation.</li></ul><h3 id="BLEU-â€“-Bilingual-Evaluation-Understudy"><a href="#BLEU-â€“-Bilingual-Evaluation-Understudy" class="headerlink" title="BLEU â€“ Bilingual Evaluation Understudy"></a><strong>BLEU</strong> â€“ <em>Bilingual Evaluation Understudy</em></h3><ul><li>Evaluates translation quality.</li><li>Considers <strong>precision</strong> and penalizes overly short outputs.</li><li>Uses combinations of 1â€“4 n-grams.</li><li><strong>Best for:</strong> Machine translation.</li></ul><h3 id="BERTScore"><a href="#BERTScore" class="headerlink" title="BERTScore"></a><strong>BERTScore</strong></h3><ul><li>Measures <strong>semantic similarity</strong> using BERT embeddings.</li><li>Compares meaning, not just words.</li><li>Uses <strong>cosine similarity</strong> to quantify closeness.</li><li><strong>Best for:</strong> Capturing nuance and context in text.</li></ul><h3 id="Perplexity"><a href="#Perplexity" class="headerlink" title="Perplexity"></a><strong>Perplexity</strong></h3><ul><li>How well the model predicts the next token.</li><li><strong>Lower is better</strong> â†’ More confident and accurate predictions.</li><li><strong>Best for:</strong> Language fluency evaluation.</li></ul><p align="center">  <img src="/images/aws_basic_21.png" width="100%"></p><hr><h2 id="4-ğŸ’¼-Business-Metrics"><a href="#4-ğŸ’¼-Business-Metrics" class="headerlink" title="4. ğŸ’¼ Business Metrics"></a>4. ğŸ’¼ Business Metrics</h2><table><thead><tr><th>Metric</th><th>Purpose</th><th>Example</th></tr></thead><tbody><tr><td><strong>User Satisfaction</strong></td><td>Gauge user happiness with model outputs</td><td>Survey results for an e-commerce chatbot</td></tr><tr><td><strong>ARPU (Average Revenue Per User)</strong></td><td>Track revenue per user from AI features</td><td>Monitor sales after AI recommendations</td></tr><tr><td><strong>Cross-Domain Performance</strong></td><td>Test ability to handle varied domains&#x2F;tasks</td><td>Multi-category product recommendations</td></tr><tr><td><strong>Conversion Rate</strong></td><td>Measure success in driving actions</td><td>% of clicks leading to purchases</td></tr><tr><td><strong>Efficiency</strong></td><td>Check computational and resource efficiency</td><td>Reduce infrastructure costs while keeping accuracy</td></tr></tbody></table><hr><h2 id="5-ğŸ“š-RAG-Knowledge-Base-in-Bedrock"><a href="#5-ğŸ“š-RAG-Knowledge-Base-in-Bedrock" class="headerlink" title="5. ğŸ“š RAG &amp; Knowledge Base in Bedrock"></a>5. ğŸ“š RAG &amp; Knowledge Base in Bedrock</h2><p><strong>RAG (Retrieval-Augmented Generation)</strong></p><ul><li>Lets the model <strong>pull external, real-time data</strong> beyond its training.</li><li>Bedrock automatically creates <strong>vector embeddings</strong> from your data and stores them in your chosen database.</li><li><strong>Use Case:</strong> Keeping responses updated with the latest inventory, market data, or news.</li></ul><p><strong>Flow:</strong></p><ol><li>Convert documents â†’ embeddings.</li><li>Store in vector DB.</li><li>At query time, retrieve relevant data.</li><li>Inject into prompt â†’ model generates enriched answer.</li></ol><p align="center">  <img src="/images/aws_basic_22.png" width="100%"></p><hr><h2 id="6-ğŸ“-Why-This-Matters-for-Exams-Real-Projects"><a href="#6-ğŸ“-Why-This-Matters-for-Exams-Real-Projects" class="headerlink" title="6. ğŸ“ Why This Matters for Exams &amp; Real Projects"></a>6. ğŸ“ Why This Matters for Exams &amp; Real Projects</h2><ul><li><strong>Exams:</strong> Expect questions on evaluation metrics (ROUGE, BLEU, BERTScore, Perplexity), benchmark datasets, and bias detection.</li><li><strong>Real-world:</strong> Proper evaluation ensures your AI system is accurate, fair, efficient, and profitable.</li></ul><hr><h2 id="ğŸ”-Quick-Visual-Summary"><a href="#ğŸ”-Quick-Visual-Summary" class="headerlink" title="ğŸ” Quick Visual Summary"></a>ğŸ” Quick Visual Summary</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">flowchart TD</span><br><span class="line">    A[Benchmark Questions + Answers] --&gt; B[Model Generates Answers]</span><br><span class="line">    B --&gt; C[Judge Model or Human Reviewer]</span><br><span class="line">    C --&gt; D[Calculate Metrics: ROUGE, BLEU, BERTScore, Perplexity]</span><br><span class="line">    D --&gt; E[Business Metrics: Satisfaction, ARPU, Conversion, Efficiency]</span><br><span class="line">    E --&gt; F[Continuous Feedback Loop for Model Improvement]</span><br></pre></td></tr></table></figure><p>âœ… With this evaluation framework, you can ensure your Amazon Bedrock-powered models are not only technically sound but also deliver measurable business value.</p><h2 id="7-ğŸš€-How-to-Perform-an-Evaluation-in-Amazon-Bedrock"><a href="#7-ğŸš€-How-to-Perform-an-Evaluation-in-Amazon-Bedrock" class="headerlink" title="7. ğŸš€ How to Perform an Evaluation in Amazon Bedrock"></a>7. ğŸš€ How to Perform an Evaluation in Amazon Bedrock</h2><p>Once you understand the theory behind model evaluation, hereâ€™s how to <strong>actually run</strong> an evaluation in AWS Bedrock.</p><h3 id="Step-by-Step-Guide"><a href="#Step-by-Step-Guide" class="headerlink" title="Step-by-Step Guide"></a>Step-by-Step Guide</h3><ol><li><p><strong>Go to the Evaluations Page</strong></p><ul><li>In the AWS Management Console, open <strong>Amazon Bedrock</strong>.</li><li>From the left-hand menu, click <strong>Evaluations</strong>.</li></ul><p align="center"></li></ol>  <img src="/images/aws_basic_24.png" width="100%">  </p><ol start="2"><li><p><strong>Click â€œCreate Evaluationâ€</strong></p><ul><li>This starts the setup process.</li><li>You will choose <strong>Automatic</strong> or <strong>Human</strong> evaluation here.</li><li>For a quick start, select <strong>Automatic</strong>.</li></ul></li><li><p><strong>Select Model(s) to Evaluate</strong></p><ul><li>Choose the foundation model(s) you want to test.</li><li>You can select multiple models if you want a performance comparison.</li></ul></li><li><p><strong>Choose Task Type</strong></p><ul><li>Pick from built-in tasks:<ul><li>Text summarization</li><li>Question answering</li><li>Text classification</li><li>Open-ended text generation</li></ul></li><li>Or upload a <strong>custom prompt dataset</strong>.</li></ul></li><li><p><strong>Select Dataset</strong></p><ul><li><strong>Option 1:</strong> Use AWS <strong>curated benchmark datasets</strong> (fast and standardized).</li><li><strong>Option 2:</strong> <strong>Upload your own dataset</strong> (CSV or JSONL format).<ul><li>Make sure it contains promptâ€“answer pairs for accurate scoring.</li></ul></li></ul></li><li><p><strong>Set Evaluation Metrics</strong></p><ul><li>AWS will automatically use metrics like:<ul><li>ROUGE</li><li>BLEU</li><li>BERTScore</li><li>Perplexity</li></ul></li><li>You can adjust depending on your evaluation goal.</li></ul></li></ol>  <p align="center">  <img src="/images/aws_basic_25.png" width="100%">  </p>  <p align="center">  <img src="/images/aws_basic_26.png" width="100%">  </p><ol start="7"><li><p><strong>Run the Evaluation</strong></p><ul><li>Click <strong>Start Evaluation</strong>.</li><li>AWS will:<ol><li>Send your prompts to the model.</li><li>Collect generated answers.</li><li>Compare against reference answers.</li><li>Generate a score report.</li></ol></li></ul></li><li><p><strong>View Results</strong></p><ul><li>Once complete, view the <strong>Evaluation Report</strong>.</li><li>Report includes:<ul><li>Score by metric (e.g., ROUGE-L &#x3D; 0.82)</li><li>Response examples</li><li>Any detected bias signals</li></ul></li><li>Use results to fine-tune your prompts or model choice.</li></ul></li></ol><hr><h3 id="ğŸ“Œ-Pro-Tips"><a href="#ğŸ“Œ-Pro-Tips" class="headerlink" title="ğŸ“Œ Pro Tips"></a>ğŸ“Œ Pro Tips</h3><ul><li><strong>Compare Multiple Models</strong><br>Running the same dataset on different models helps you choose the best for your use case.</li><li><strong>Test with Business Data</strong><br>Use real company data to see how the model performs in your specific domain.</li><li><strong>Iterate</strong><br>Re-run evaluations after prompt engineering or fine-tuning to measure improvements.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ“Š-Amazon-Bedrock-â€“-Model-Evaluation-Guide&quot;&gt;&lt;a href=&quot;#ğŸ“Š-Amazon-Bedrock-â€“-Model-Evaluation-Guide&quot; class=&quot;headerlink&quot; title=&quot;ğŸ“Š Amazo</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="AI" scheme="https://kish191919.github.io/categories/Dev/AI/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Certification" scheme="https://kish191919.github.io/tags/Certification/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(4)</title>
    <link href="https://kish191919.github.io/2025/08/14/AWS-Certified-AI-Practitioner-4/"/>
    <id>https://kish191919.github.io/2025/08/14/AWS-Certified-AI-Practitioner-4/</id>
    <published>2025-08-15T00:12:51.000Z</published>
    <updated>2025-08-15T02:33:16.269Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ“š-Amazon-Bedrock-Fine-Tuning-Model-Selection"><a href="#ğŸ“š-Amazon-Bedrock-Fine-Tuning-Model-Selection" class="headerlink" title="ğŸ“š Amazon Bedrock Fine-Tuning &amp; Model Selection"></a>ğŸ“š Amazon Bedrock Fine-Tuning &amp; Model Selection</h1><hr><h2 id="1-Different-Providers-Model-Capabilities"><a href="#1-Different-Providers-Model-Capabilities" class="headerlink" title="1. Different Providers &amp; Model Capabilities"></a>1. Different Providers &amp; Model Capabilities</h2><ul><li><strong>Providers</strong>: Anthropic, Amazon, DeepSeek, Stability AI, etc.</li><li>Models vary in strengths:<ul><li><strong>Claude 3.5 Haiku</strong> â†’ Best for text tasks.</li><li><strong>Amazon Nova Reel</strong> â†’ Text-to-video &#x2F; Image-to-video.</li></ul></li><li><strong>Exam Tip</strong>: You will not be tested on <em>which is best</em>, only on <strong>what each can or cannot do</strong>.</li></ul><hr><h2 id="2-Comparing-Models"><a href="#2-Comparing-Models" class="headerlink" title="2. Comparing Models"></a>2. Comparing Models</h2><ul><li><strong>Compare Mode</strong>: Test models side-by-side in Bedrock playground.</li><li>Compare by:<ul><li>âœ… Capabilities (text, image, video)</li><li>âœ… Output style&#x2F;format</li><li>âœ… Speed (latency)</li><li>âœ… Cost (token usage)</li></ul></li><li>Example:<ul><li><strong>Nova Micro</strong>: âŒ No image upload, faster, shorter responses.</li><li><strong>Claude 3.5 Sonnet</strong>: âœ… Image support, longer&#x2F;more detailed answers.</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_11.png" width="100%"></p><hr><h2 id="3-Fine-Tuning-Methods-â€“-Comparison-Table"><a href="#3-Fine-Tuning-Methods-â€“-Comparison-Table" class="headerlink" title="3. Fine-Tuning Methods â€“ Comparison Table"></a>3. Fine-Tuning Methods â€“ Comparison Table</h2><table><thead><tr><th>Feature</th><th>Instruction-Based Fine-Tuning</th><th>Continued Pre-Training</th><th>Transfer Learning</th></tr></thead><tbody><tr><td><strong>Data Type</strong></td><td>Labeled (promptâ€“response pairs)</td><td>Unlabeled (raw text)</td><td>Labeled or Unlabeled</td></tr><tr><td><strong>Goal</strong></td><td>Improve performance on domain-specific tasks</td><td>Make model expert in a specific domain</td><td>Adapt a pre-trained model to a new but related task</td></tr><tr><td><strong>Example</strong></td><td>Train chatbot to respond in a specific tone</td><td>Feed all AWS docs to become AWS expert</td><td>Adapt GPT for medical text classification</td></tr><tr><td><strong>Changes Model Weights?</strong></td><td>âœ… Yes</td><td>âœ… Yes</td><td>âœ… Yes</td></tr><tr><td><strong>Complexity</strong></td><td>Medium</td><td>High</td><td>Varies</td></tr><tr><td><strong>Cost</strong></td><td>Lower (less data)</td><td>Higher (more data)</td><td>Varies</td></tr><tr><td><strong>Exam Keyword</strong></td><td><strong>â€œLabeled dataâ€</strong>, â€œprompt-responseâ€</td><td><strong>â€œUnlabeled dataâ€</strong>, â€œdomain adaptationâ€</td><td>â€œAdapt model to new taskâ€</td></tr><tr><td><strong>Bedrock Support</strong></td><td>Supported on some models</td><td>Supported on some models</td><td>General ML concept (not Bedrock-specific)</td></tr></tbody></table><blockquote><p>Instruction-based Fine Tuning</p></blockquote><p align="center">  <img src="/images/aws_basic_16.png" width="100%"></p><blockquote><p>Continued Pre-training</p></blockquote><p align="center">  <img src="/images/aws_basic_17.png" width="100%"></p>---<h2 id="4-Messaging-Fine-Tuning"><a href="#4-Messaging-Fine-Tuning" class="headerlink" title="4. Messaging Fine-Tuning"></a>4. Messaging Fine-Tuning</h2><ul><li><strong>Single-Turn Messaging</strong>:<ul><li>One Q â†’ One A</li><li>Optional <code>system</code> context</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_18.png" width="100%"></p><ul><li><strong>Multi-Turn Messaging</strong>:<ul><li>Full conversations, alternating <code>user</code> and <code>assistant</code></li><li>Used for chatbot training in multi-step dialog</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_19.png" width="100%"></p><hr><h2 id="5-Transfer-Learning"><a href="#5-Transfer-Learning" class="headerlink" title="5. Transfer Learning"></a>5. Transfer Learning</h2><ul><li><strong>Definition</strong>: Using a pre-trained model for a new but related task.</li><li>Common in:<ul><li>Image classification</li><li>NLP (BERT, GPT)</li></ul></li><li><strong>Exam Tip</strong>: If question is general ML â†’ choose <em>Transfer Learning</em> as the answer.<br>If itâ€™s about Bedrock &amp; domain-specific â†’ choose <em>Fine-Tuning</em>.</li></ul><hr><h2 id="6-Fine-Tuning-Requirements-in-Amazon-Bedrock"><a href="#6-Fine-Tuning-Requirements-in-Amazon-Bedrock" class="headerlink" title="6. Fine-Tuning Requirements in Amazon Bedrock"></a>6. Fine-Tuning Requirements in Amazon Bedrock</h2><ul><li>Training data <strong>must</strong>:<ul><li>Be in <strong>Amazon S3</strong></li><li>Follow specific formatting</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_15.png" width="100%"></p><ul><li><strong>Provisioned Throughput</strong> is required for:<ul><li>Creating the custom model</li><li>Using the custom model</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_12.png" width="100%"></p><p align="center">  <img src="/images/aws_basic_13.png" width="100%"></p><p align="center">  <img src="/images/aws_basic_14.png" width="100%"></p><ul><li>Not all models can be fine-tuned (usually open-source models are supported).</li></ul><hr><h2 id="7-Common-Use-Cases"><a href="#7-Common-Use-Cases" class="headerlink" title="7. Common Use Cases"></a>7. Common Use Cases</h2><ul><li>Chatbot with specific <strong>persona</strong>, <strong>tone</strong>, or <strong>target audience</strong></li><li>Adding <strong>up-to-date knowledge</strong></li><li>Integrating <strong>exclusive private data</strong> (customer logs, internal documents)</li><li>Improving <strong>categorization</strong>, <strong>accuracy</strong>, or <strong>response style</strong></li></ul><hr><h2 id="8-Exam-Tips"><a href="#8-Exam-Tips" class="headerlink" title="8. Exam Tips"></a>8. Exam Tips</h2><ul><li><strong>Keyword Mapping</strong>:<ul><li>â€œLabeled dataâ€ â†’ <strong>Instruction-based Fine-Tuning</strong></li><li>â€œUnlabeled dataâ€ &#x2F; â€œDomain adaptationâ€ â†’ <strong>Continued Pre-Training</strong></li><li>â€œAdapt to a new related taskâ€ â†’ <strong>Transfer Learning</strong></li></ul></li><li><strong>Provisioned Throughput</strong> is a must for custom models in Bedrock.</li><li>Fine-tuning changes <strong>weights</strong> of the base model â†’ creates a private version.</li><li>Compare models not just on quality, but also <strong>latency</strong> and <strong>token cost</strong>.</li></ul><h2 id="9-Good-to-know"><a href="#9-Good-to-know" class="headerlink" title="9. Good to know"></a>9. Good to know</h2><ul><li>Re-training an FM requires a higher budget</li><li>Instruction-based fine-tuning is usually cheaper as computations are less intense and the amount of data required usually less</li><li>It also requires experienced ML engineers to perform the task</li><li>You must prepare the data, do the fine-tuning, evaluate the model</li><li>Running a fine-tuned model is also more expensive (provisioned throughput)</li></ul><h2 id="10-Provisioned-Throughput-AWS-Bedrock"><a href="#10-Provisioned-Throughput-AWS-Bedrock" class="headerlink" title="10. Provisioned Throughput (AWS Bedrock)"></a>10. Provisioned Throughput (AWS Bedrock)</h2><p><strong>Definition:</strong><br>Reserving a fixed amount of processing capacity for your custom (fine-tuned) model.</p><h3 id="Why-Needed"><a href="#Why-Needed" class="headerlink" title="Why Needed"></a>Why Needed</h3><ul><li>Fine-tuned models run on <strong>dedicated resources</strong>.</li><li>Ensures <strong>consistent speed</strong>, <strong>low latency</strong>, and <strong>predictable costs</strong>.</li><li>Prevents slowdowns during high demand.</li></ul><h3 id="With-vs-Without"><a href="#With-vs-Without" class="headerlink" title="With vs Without"></a>With vs Without</h3><ul><li><strong>Without:</strong> Performance can drop when traffic spikes.</li><li><strong>With:</strong> Guaranteed performance for the reserved capacity.</li></ul><blockquote><p><strong>Exam Tip:</strong> For custom models in Bedrock, provisioned throughput is <strong>required</strong>.</p></blockquote><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ“š-Amazon-Bedrock-Fine-Tuning-Model-Selection&quot;&gt;&lt;a href=&quot;#ğŸ“š-Amazon-Bedrock-Fine-Tuning-Model-Selection&quot; class=&quot;headerlink&quot; title=&quot;ğŸ“š</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="AI" scheme="https://kish191919.github.io/categories/Dev/AI/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Certification" scheme="https://kish191919.github.io/tags/Certification/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(3)</title>
    <link href="https://kish191919.github.io/2025/08/14/AWS-Certified-AI-Practitioner-3/"/>
    <id>https://kish191919.github.io/2025/08/14/AWS-Certified-AI-Practitioner-3/</id>
    <published>2025-08-14T23:48:47.000Z</published>
    <updated>2025-08-14T23:55:24.025Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ§ -Generative-AI-Amazon-Bedrock-â€“-Simple-Summary"><a href="#ğŸ§ -Generative-AI-Amazon-Bedrock-â€“-Simple-Summary" class="headerlink" title="ğŸ§  Generative AI &amp; Amazon Bedrock â€“ Simple Summary"></a>ğŸ§  Generative AI &amp; Amazon Bedrock â€“ Simple Summary</h1><h2 id="1-What-is-Generative-AI"><a href="#1-What-is-Generative-AI" class="headerlink" title="1. What is Generative AI?"></a>1. What is Generative AI?</h2><ul><li><strong>Generative AI (Gen-AI)</strong>: A type of deep learning that <strong>creates new data</strong> similar to what it learned.</li><li>Can generate:<ul><li>Text</li><li>Images</li><li>Audio</li><li>Code</li><li>Video</li></ul></li><li>Example: ChatGPT generating human-like text.</li></ul><hr><h2 id="2-Foundation-Models-FM"><a href="#2-Foundation-Models-FM" class="headerlink" title="2. Foundation Models (FM)"></a>2. Foundation Models (FM)</h2><ul><li>Large AI models trained on diverse datasets.</li><li>Expensive to build (can cost tens of millions of dollars).</li><li>Examples:<ul><li><strong>OpenAI</strong> (GPT-4o)</li><li><strong>Meta</strong> (LLaMA)</li><li><strong>Google</strong> (BERT)</li><li><strong>Amazon</strong> (Titan)</li><li><strong>Anthropic</strong> (Claude)</li></ul></li><li>Some are <strong>open-source</strong> (free), others <strong>commercial</strong> (paid).</li></ul><hr><h2 id="3-Large-Language-Models-LLMs"><a href="#3-Large-Language-Models-LLMs" class="headerlink" title="3. Large Language Models (LLMs)"></a>3. Large Language Models (LLMs)</h2><ul><li>Special AI for <strong>human-like text generation</strong>.</li><li>Trained on huge text datasets (books, websites, articles).</li><li>Billions of parameters.</li><li>Tasks:<ul><li>Translation</li><li>Summarization</li><li>Q&amp;A</li><li>Content creation</li></ul></li></ul><hr><h2 id="4-How-Generative-Language-Models-Work"><a href="#4-How-Generative-Language-Models-Work" class="headerlink" title="4. How Generative Language Models Work"></a>4. How Generative Language Models Work</h2><ol><li><strong>Prompt</strong>: You give an instruction.</li><li><strong>Processing</strong>: The model predicts possible next words.</li><li><strong>Output</strong>: Chooses words based on probability.</li><li><strong>Non-deterministic</strong>: Same prompt â†’ different answers.</li></ol><hr><h2 id="5-Amazon-Bedrock-Overview"><a href="#5-Amazon-Bedrock-Overview" class="headerlink" title="5. Amazon Bedrock Overview"></a>5. Amazon Bedrock Overview</h2><ul><li>AWS service for building Gen-AI apps.</li><li><strong>No server management</strong> â€“ fully managed.</li><li>Pay-per-use.</li><li>Unified API for multiple foundation models.</li><li>Built-in features:<ul><li>RAG (Retrieval-Augmented Generation)</li><li>LLM Agents</li></ul></li><li>Strong focus on security, privacy, and responsible AI.</li></ul><p align="center">  <img src="/images/aws_basic_5.png" width="100%"></p><hr><h2 id="6-Amazon-Bedrock-Foundation-Models"><a href="#6-Amazon-Bedrock-Foundation-Models" class="headerlink" title="6. Amazon Bedrock &amp; Foundation Models"></a>6. Amazon Bedrock &amp; Foundation Models</h2><ul><li>Gives you a <strong>private copy</strong> of the model.</li><li>You can fine-tune it with your data.</li><li>Your data is <strong>not</strong> used to train the public model.</li><li><strong>Amazon Titan</strong>:<ul><li>AWSâ€™s high-performance FM.</li><li>Supports text, image, multimodal.</li><li>Customizable.</li><li>Smaller models &#x3D; more cost-effective.</li></ul></li></ul><hr><h2 id="7-How-to-Use-Amazon-Bedrock"><a href="#7-How-to-Use-Amazon-Bedrock" class="headerlink" title="7. How to Use Amazon Bedrock"></a>7. How to Use Amazon Bedrock</h2><ol><li><strong>Request model access</strong>.</li></ol><p align="center">  <img src="/images/aws_basic_6.png" width="70%"></p><ol start="2"><li>Test with a <strong>single prompt</strong>.</li></ol><p align="center">  <img src="/images/aws_basic_7.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_8.png" width="70%"></p><ol start="3"><li>Try <strong>image generation playground</strong>.</li></ol><p align="center">  <img src="/images/aws_basic_9.png" width="70%"></p><hr><h2 id="8-Example-Models"><a href="#8-Example-Models" class="headerlink" title="8. Example Models"></a>8. Example Models</h2><ul><li><strong>Amazon Titan</strong></li><li><strong>Meta LLaMA</strong></li><li><strong>Anthropic Claude</strong></li><li><strong>Stable Diffusion</strong> (image generation)</li></ul><p align="center">  <img src="/images/aws_basic_10.png" width="70%"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ§ -Generative-AI-Amazon-Bedrock-â€“-Simple-Summary&quot;&gt;&lt;a href=&quot;#ğŸ§ -Generative-AI-Amazon-Bedrock-â€“-Simple-Summary&quot; class=&quot;headerlink&quot; tit</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="AI" scheme="https://kish191919.github.io/categories/Dev/AI/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Certification" scheme="https://kish191919.github.io/tags/Certification/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(2)</title>
    <link href="https://kish191919.github.io/2025/08/14/AWS-Certified-AI-Practitioner-2/"/>
    <id>https://kish191919.github.io/2025/08/14/AWS-Certified-AI-Practitioner-2/</id>
    <published>2025-08-14T14:17:53.000Z</published>
    <updated>2025-08-14T14:23:24.934Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ’°-AWS-Cost-and-Budget-Setup-Simplified"><a href="#ğŸ’°-AWS-Cost-and-Budget-Setup-Simplified" class="headerlink" title="ğŸ’° AWS Cost and Budget Setup (Simplified)"></a>ğŸ’° AWS Cost and Budget Setup (Simplified)</h1><h2 id="1-Access-for-IAM-Users"><a href="#1-Access-for-IAM-Users" class="headerlink" title="1. Access for IAM Users"></a>1. Access for IAM Users</h2><ul><li>To let an <strong>IAM user</strong> view <strong>Billing and Cost Management</strong>,<br>the <strong>administrator</strong> must enable:<br><strong>â€œIAM user and role access to Billing informationâ€</strong>.</li></ul><p align="center">  <img src="/images/aws_basic_3.png" width="100%"></p>---<h2 id="2-Key-Billing-Tools"><a href="#2-Key-Billing-Tools" class="headerlink" title="2. Key Billing Tools"></a>2. Key Billing Tools</h2><ul><li><strong>Bills</strong>: Shows a detailed breakdown of usage and charges.  </li><li><strong>Free Tier</strong>: Displays remaining Free Tier usage on a dashboard.  </li><li><strong>Budgets</strong>: Sends email alerts if your spending exceeds the set budget.</li></ul><p align="center">  <img src="/images/aws_basic_4.png" width="100%"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ’°-AWS-Cost-and-Budget-Setup-Simplified&quot;&gt;&lt;a href=&quot;#ğŸ’°-AWS-Cost-and-Budget-Setup-Simplified&quot; class=&quot;headerlink&quot; title=&quot;ğŸ’° AWS Cost an</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="AI" scheme="https://kish191919.github.io/categories/Dev/AI/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Certification" scheme="https://kish191919.github.io/tags/Certification/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(1)</title>
    <link href="https://kish191919.github.io/2025/08/14/AWS-Certified-AI-Practitioner-1/"/>
    <id>https://kish191919.github.io/2025/08/14/AWS-Certified-AI-Practitioner-1/</id>
    <published>2025-08-14T11:59:43.000Z</published>
    <updated>2025-08-14T14:22:08.787Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ“š-IT-AWS-Basics-Summary"><a href="#ğŸ“š-IT-AWS-Basics-Summary" class="headerlink" title="ğŸ“š IT &amp; AWS Basics Summary"></a>ğŸ“š IT &amp; AWS Basics Summary</h1><h2 id="1-Basic-IT-Terms"><a href="#1-Basic-IT-Terms" class="headerlink" title="1. Basic IT Terms"></a>1. Basic IT Terms</h2><ul><li><strong>Network</strong>: A connection of cables, routers, and servers.  </li><li><strong>Router</strong>: A device that decides where to send data packets over the internet.  </li><li><strong>Switch</strong>: Sends a packet to the correct server or client within the network.</li></ul><p align="center">  <img src="/images/aws_basic_1.png" width="60%"></p><hr><h2 id="2-Five-Key-Characteristics-of-Cloud-Computing"><a href="#2-Five-Key-Characteristics-of-Cloud-Computing" class="headerlink" title="2. Five Key Characteristics of Cloud Computing"></a>2. Five Key Characteristics of Cloud Computing</h2><ol><li><strong>On-demand self service</strong> â€“ Instantly get resources without human help.  </li><li><strong>Broad network access</strong> â€“ Access resources from different devices via the internet.  </li><li><strong>Multi-tenancy &amp; Resource pooling</strong> â€“ Multiple users share the same resources securely.  </li><li><strong>Rapid elasticity &amp; Scalability</strong> â€“ Quickly scale up or down when needed.  </li><li><strong>Measured service</strong> â€“ Pay only for the resources you use.</li></ol><hr><h2 id="3-Six-Advantages-of-Cloud-Computing"><a href="#3-Six-Advantages-of-Cloud-Computing" class="headerlink" title="3. Six Advantages of Cloud Computing"></a>3. Six Advantages of Cloud Computing</h2><ul><li>No need to buy hardware; pay only for what you use.  </li><li>Lower costs through large-scale efficiency.  </li><li>Scale based on real usage.  </li><li>Faster development and deployment.  </li><li>No need to run and maintain your own data center.  </li><li>Go global within minutes.</li></ul><hr><h2 id="4-Problems-Solved-by-the-Cloud"><a href="#4-Problems-Solved-by-the-Cloud" class="headerlink" title="4. Problems Solved by the Cloud"></a>4. Problems Solved by the Cloud</h2><ul><li><strong>Flexibility</strong>: Change resource types anytime.  </li><li><strong>Cost-effectiveness</strong>: Pay-as-you-go model.  </li><li><strong>Scalability</strong>: Handle higher loads by adding or upgrading hardware.  </li><li><strong>Elasticity</strong>: Scale in and out when needed.  </li><li><strong>High availability &amp; Fault tolerance</strong>: Spread across multiple data centers.  </li><li><strong>Agility</strong>: Develop and launch quickly.</li></ul><hr><h2 id="5-Cloud-Service-Types-â€“-Examples"><a href="#5-Cloud-Service-Types-â€“-Examples" class="headerlink" title="5. Cloud Service Types â€“ Examples"></a>5. Cloud Service Types â€“ Examples</h2><ul><li><strong>IaaS</strong>: AWS EC2, GCP, Azure.  </li><li><strong>PaaS</strong>: AWS Elastic Beanstalk, Heroku.  </li><li><strong>SaaS</strong>: Gmail, Dropbox, Zoom.</li></ul><p align="center">  <img src="/images/aws_basic_2.png" width="60%"></p><hr><h2 id="6-AWS-Pricing-Basics"><a href="#6-AWS-Pricing-Basics" class="headerlink" title="6. AWS Pricing Basics"></a>6. AWS Pricing Basics</h2><ul><li><strong>Compute</strong>: Pay for the time you use computing resources.  </li><li><strong>Storage</strong>: Pay for the data stored in the cloud.  </li><li><strong>Data Transfer</strong>: Pay for data going <strong>out</strong> of the cloud (incoming is free).</li></ul><hr><h2 id="7-AWS-Regions"><a href="#7-AWS-Regions" class="headerlink" title="7. AWS Regions"></a>7. AWS Regions</h2><ul><li>A <strong>region</strong> is a cluster of data centers around the world.  </li><li>Choosing a region depends on:<ul><li>Legal &amp; compliance requirements.  </li><li>Distance to customers (lower latency).  </li><li>Services available in the region.  </li><li>Pricing differences.</li></ul></li></ul><hr><h2 id="8-AWS-Availability-Zones-AZ"><a href="#8-AWS-Availability-Zones-AZ" class="headerlink" title="8. AWS Availability Zones (AZ)"></a>8. AWS Availability Zones (AZ)</h2><ul><li>Each region has 3â€“6 independent data centers.  </li><li>Redundant power, networking, and connectivity.  </li><li>Separated to avoid disasters and connected with high-speed, low-latency links.</li></ul><hr><h2 id="9-AWS-Edge-Locations-Points-of-Presence"><a href="#9-AWS-Edge-Locations-Points-of-Presence" class="headerlink" title="9. AWS Edge Locations (Points of Presence)"></a>9. AWS Edge Locations (Points of Presence)</h2><ul><li>400+ locations in over 90 cities across 40+ countries.  </li><li>Deliver content to users with lower latency.</li></ul><hr><h2 id="10-AWS-Service-Scope"><a href="#10-AWS-Service-Scope" class="headerlink" title="10. AWS Service Scope"></a>10. AWS Service Scope</h2><ul><li><strong>Global services</strong>: IAM, Route 53, CloudFront, WAF.  </li><li><strong>Region-specific services</strong>: EC2, Elastic Beanstalk, Lambda, Rekognition.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ“š-IT-AWS-Basics-Summary&quot;&gt;&lt;a href=&quot;#ğŸ“š-IT-AWS-Basics-Summary&quot; class=&quot;headerlink&quot; title=&quot;ğŸ“š IT &amp;amp; AWS Basics Summary&quot;&gt;&lt;/a&gt;ğŸ“š IT &amp;a</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="AI" scheme="https://kish191919.github.io/categories/Dev/AI/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Certification" scheme="https://kish191919.github.io/tags/Certification/"/>
    
  </entry>
  
  <entry>
    <title>Spooky-Author-Identification</title>
    <link href="https://kish191919.github.io/2025/08/13/Spooky-Author-Identification/"/>
    <id>https://kish191919.github.io/2025/08/13/Spooky-Author-Identification/</id>
    <published>2025-08-14T01:16:10.000Z</published>
    <updated>2025-08-14T01:26:36.838Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ğŸ‘»-Spooky-Author-Identification"><a href="#ğŸ‘»-Spooky-Author-Identification" class="headerlink" title="ğŸ‘» Spooky Author Identification"></a>ğŸ‘» Spooky Author Identification</h2><p><em>Who wrote this sentence? Classifying authors from a single line of text</em></p><blockquote><p>â€œLet the words tell you who wrote them.â€</p></blockquote><p>ğŸ“ <strong>Full Analysis</strong>:<br><a href="https://nbviewer.org/github/kish191919/Spooky_Author_Identification_by_Python/blob/master/Spooky_Author_Identification.ipynb">ğŸ‘‰ View Jupyter Notebook on GitHub</a></p><p>ğŸ“ <strong>Kaggle Competition</strong>:<br><a href="https://www.kaggle.com/c/spooky-author-identification">ğŸ‘‰ Spooky Author Identification (2017 Halloween)</a></p><p align="center">  <img src="/images/portfolio/project6_1.png" alt="Spooky Author Identification" width="30%"></p><hr><h3 id="ğŸ“Œ-One-Line-Summary"><a href="#ğŸ“Œ-One-Line-Summary" class="headerlink" title="ğŸ“Œ One-Line Summary"></a>ğŸ“Œ One-Line Summary</h3><p>Given a sentence, predict which of <strong>Edgar Allan Poe (EAP)</strong>, <strong>H. P. Lovecraft (HPL)</strong>, or <strong>Mary W. Shelley (MWS)</strong> wrote it.<br>With light preprocessing and <strong>BoW&#x2F;TFâ€‘IDF features + Naive Bayes</strong>, the model achieves strong accuracy and stable generalization.</p><hr><h2 id="1ï¸âƒ£-Problem-Data"><a href="#1ï¸âƒ£-Problem-Data" class="headerlink" title="1ï¸âƒ£ Problem &amp; Data"></a>1ï¸âƒ£ Problem &amp; Data</h2><ul><li><strong>Task</strong>: Multi-class author classification (EAP&#x2F;HPL&#x2F;MWS) for a single sentence.  </li><li><strong>Metric</strong>: <em>Multi-class Logarithmic Loss</em> (submit probabilities for each author).  </li><li><strong>Files</strong><ul><li><code>train.csv</code>: id, text, author  </li><li><code>test.csv</code>: id, text  </li><li><code>sample_submission.csv</code>: example submission format</li></ul></li><li><strong>Source</strong>: Public-domain fiction, sentence-split with CoreNLPâ€™s MaxEnt tokenizer.</li></ul><hr><h2 id="2ï¸âƒ£-How-It-Was-Built"><a href="#2ï¸âƒ£-How-It-Was-Built" class="headerlink" title="2ï¸âƒ£ How It Was Built"></a>2ï¸âƒ£ How It Was Built</h2><ol><li><strong>Preprocessing</strong><ul><li>Lowercasing, light cleanup of punctuation&#x2F;numbers, minimal stopword handling.</li></ul></li><li><strong>Feature Extraction</strong><ul><li><strong>Bag-of-Words &#x2F; TFâ€‘IDF</strong> vectors (suited for short sentences).</li></ul></li><li><strong>Modeling</strong><ul><li>Tried <strong>Random Forest</strong>, <strong>AdaBoost</strong>, <strong>SVM</strong>, <strong>Naive Bayes</strong>.</li><li>Evaluated with <strong>10â€‘fold Crossâ€‘Validation</strong> for robustness.</li></ul></li><li><strong>Final Choice</strong><ul><li><strong>Naive Bayes</strong> selected for best balance of accuracy and stability.</li></ul></li><li><strong>Submission</strong><ul><li>Output calibrated probabilities for each class and submit to Kaggle.</li></ul></li></ol><p><strong>Architecture</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[text] â†’ [cleaning] â†’ [BoW / TFâ€‘IDF] â†’ [Classifier] â†’ P(EAP), P(HPL), P(MWS)</span><br></pre></td></tr></table></figure><hr><h2 id="3ï¸âƒ£-Results"><a href="#3ï¸âƒ£-Results" class="headerlink" title="3ï¸âƒ£ Results"></a>3ï¸âƒ£ Results</h2><table><thead><tr><th>Model</th><th align="right">Training Score</th><th align="right">10â€‘Fold CV (avg&#x2F;total F1)</th><th>Notes</th></tr></thead><tbody><tr><td>Random Forest</td><td align="right">0.4311</td><td align="right">0.31</td><td>Struggles with sparse text features</td></tr><tr><td>AdaBoost</td><td align="right">0.6293</td><td align="right">0.65</td><td>Better than RF; still volatile</td></tr><tr><td>SVM</td><td align="right">0.4035</td><td align="right">0.23</td><td>Overfits a single class in this setup</td></tr><tr><td><strong>Naive Bayes (Final)</strong></td><td align="right"><strong>0.8329</strong></td><td align="right"><strong>0.90</strong></td><td>Fast, simple, strong on sparse TFâ€‘IDF âœ…</td></tr></tbody></table><p><strong>Kaggle Leaderboard</strong></p><ul><li><strong>LogLoss</strong>: <strong>0.48767</strong>  </li><li><strong>Rank</strong>: <strong>793 &#x2F; 1244 (63.7%)</strong></li></ul><hr><h2 id="4ï¸âƒ£-Why-Naive-Bayes"><a href="#4ï¸âƒ£-Why-Naive-Bayes" class="headerlink" title="4ï¸âƒ£ Why Naive Bayes?"></a>4ï¸âƒ£ Why Naive Bayes?</h2><ul><li>Excels with <strong>sparse word distributions</strong> and short texts.  </li><li>Few hyperparameters â†’ <strong>stable generalization</strong> and fast iteration.  </li><li>Simple pipeline makes <strong>experimentation</strong> (nâ€‘grams, charâ€‘grams) easy.</li></ul><hr><h2 id="5ï¸âƒ£-Realâ€‘World-Use"><a href="#5ï¸âƒ£-Realâ€‘World-Use" class="headerlink" title="5ï¸âƒ£ Realâ€‘World Use"></a>5ï¸âƒ£ Realâ€‘World Use</h2><ul><li><strong>Stylometry</strong> (author identification), plagiarism detection, style recommendation.  </li><li>Brand&#x2F;author <strong>tone-of-voice</strong> classification and content routing.</li></ul><hr><h2 id="ğŸ› -Technologies-Used"><a href="#ğŸ› -Technologies-Used" class="headerlink" title="ğŸ›  Technologies Used"></a>ğŸ›  Technologies Used</h2><table><thead><tr><th>Step</th><th>Technology</th></tr></thead><tbody><tr><td>Data &#x2F; EDA</td><td>Python, Pandas, NumPy</td></tr><tr><td>NLP Features</td><td>scikit-learn (Count &#x2F; TFâ€‘IDF)</td></tr><tr><td>Models</td><td>scikit-learn (NB, SVM, RF, AdaBoost)</td></tr><tr><td>Environment</td><td>Jupyter Notebook</td></tr></tbody></table><hr><h2 id="ğŸ’¡-Key-Learnings"><a href="#ğŸ’¡-Key-Learnings" class="headerlink" title="ğŸ’¡ Key Learnings"></a>ğŸ’¡ Key Learnings</h2><ul><li><strong>TFâ€‘IDF + Naive Bayes</strong> remains a strong baseline for short-text classification.  </li><li>Improving leaderboard LogLoss benefits from <strong>probability calibration</strong> and <strong>nâ€‘gram &#x2F; charâ€‘gram</strong> features.  </li><li>For imbalanced, sparse text, simpler models can beat complex ensembles.</li></ul><hr><h2 id="ğŸ”—-GitHub-Repository"><a href="#ğŸ”—-GitHub-Repository" class="headerlink" title="ğŸ”— GitHub Repository"></a>ğŸ”— GitHub Repository</h2><p>ğŸ“‚ <a href="https://github.com/kish191919/Spooky_Author_Identification_by_Python">View Project on GitHub</a></p><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;ğŸ‘»-Spooky-Author-Identification&quot;&gt;&lt;a href=&quot;#ğŸ‘»-Spooky-Author-Identification&quot; class=&quot;headerlink&quot; title=&quot;ğŸ‘» Spooky Author Identificatio</summary>
      
    
    
    
    <category term="Showcase" scheme="https://kish191919.github.io/categories/Showcase/"/>
    
    
    <category term="Python" scheme="https://kish191919.github.io/tags/Python/"/>
    
    <category term="NLP" scheme="https://kish191919.github.io/tags/NLP/"/>
    
    <category term="Kaggle" scheme="https://kish191919.github.io/tags/Kaggle/"/>
    
  </entry>
  
  <entry>
    <title>News Keyword Trend Analyzer</title>
    <link href="https://kish191919.github.io/2025/08/13/News-Keyword-Trend-Analyzer/"/>
    <id>https://kish191919.github.io/2025/08/13/News-Keyword-Trend-Analyzer/</id>
    <published>2025-08-14T00:45:31.000Z</published>
    <updated>2025-08-14T01:03:08.689Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ğŸ“°-Real-Time-News-Keyword-Trend-Analyzer"><a href="#ğŸ“°-Real-Time-News-Keyword-Trend-Analyzer" class="headerlink" title="ğŸ“° Real-Time News Keyword Trend Analyzer"></a>ğŸ“° Real-Time News Keyword Trend Analyzer</h2><p><em>Tracking trending keywords in news articles using real-time data<br>pipelines</em></p><blockquote><p>â€œSee the worldâ€™s breaking news trends â€” live.â€</p></blockquote><p align="center">  <img src="/images/portfolio/project5_1.png" alt="News Keyword Trend Analyzer" width="80%"></p><hr><h3 id="ğŸ“Œ-One-Line-Summary"><a href="#ğŸ“Œ-One-Line-Summary" class="headerlink" title="ğŸ“Œ One-Line Summary"></a>ğŸ“Œ One-Line Summary</h3><p>A <strong>real-time news keyword trend analyzer</strong> that collects live news<br>headlines, processes them to extract popular keywords, and visualizes<br>their trends in real time using <strong>Kafka, Apache Flink, Elasticsearch,<br>and Kibana</strong>.</p><hr><h2 id="1ï¸âƒ£-How-It-Works"><a href="#1ï¸âƒ£-How-It-Works" class="headerlink" title="1ï¸âƒ£ How It Works"></a>1ï¸âƒ£ How It Works</h2><h3 id="1-Data-Collection-â€”-Kafka-Producer-news-producer-py"><a href="#1-Data-Collection-â€”-Kafka-Producer-news-producer-py" class="headerlink" title="1. Data Collection â€” Kafka Producer (news_producer.py)"></a><strong>1. Data Collection â€” Kafka Producer (<code>news_producer.py</code>)</strong></h3><ul><li>Fetches top news headlines from <strong>NewsAPI.org</strong></li><li>Sends news titles to the Kafka topic <strong><code>news</code></strong> every 30 seconds</li><li>Uses environment variables for API key and EC2 host configuration</li></ul><hr><h3 id="2-Real-Time-Processing-â€”-Flink-Consumer-keyword-trend-analyzer-py"><a href="#2-Real-Time-Processing-â€”-Flink-Consumer-keyword-trend-analyzer-py" class="headerlink" title="2. Real-Time Processing â€” Flink Consumer (keyword_trend_analyzer.py)"></a><strong>2. Real-Time Processing â€” Flink Consumer (<code>keyword_trend_analyzer.py</code>)</strong></h3><ul><li>Consumes news data from Kafka</li><li>Cleans titles (lowercasing, removing special characters)</li><li>Extracts <strong>keywords</strong> (words with â‰¥4 letters)</li><li>Counts keyword frequencies in real-time</li><li>Sends processed results to <strong>Elasticsearch</strong></li></ul><hr><h3 id="3-Storage-Visualization-â€”-Elasticsearch-Kibana"><a href="#3-Storage-Visualization-â€”-Elasticsearch-Kibana" class="headerlink" title="3. Storage &amp; Visualization â€” Elasticsearch &amp; Kibana"></a><strong>3. Storage &amp; Visualization â€” Elasticsearch &amp; Kibana</strong></h3><ul><li>Stores keyword counts in Elasticsearch index <code>news_keywords</code></li><li>Visualizes trends in Kibana dashboards<ul><li><strong>Keyword frequency charts</strong></li><li><strong>Trend over time graphs</strong></li></ul></li></ul><hr><h2 id="2ï¸âƒ£-System-Architecture"><a href="#2ï¸âƒ£-System-Architecture" class="headerlink" title="2ï¸âƒ£ System Architecture"></a>2ï¸âƒ£ System Architecture</h2><pre><code>[NewsAPI] â†’ [Kafka Producer] â†’ [Kafka Topic: news] â†’ [Flink Consumer] â†’ [Elasticsearch] â†’ [Kibana Dashboard]</code></pre><p align="center">  <img src="/images/portfolio/project5_2.png" alt="News Keyword Trend Analyzer" width="80%"></p><hr><h2 id="ğŸš€-Quick-Start"><a href="#ğŸš€-Quick-Start" class="headerlink" title="ğŸš€ Quick Start"></a>ğŸš€ Quick Start</h2><ol><li><strong>Clone &amp; Install</strong> â€” Download the repository and install<br>dependencies\</li><li><strong>Start Services</strong> â€” Launch Kafka, Flink, Elasticsearch, and<br>Kibana\</li><li><strong>Run Scripts</strong> â€” Start the Kafka producer and Flink consumer\</li><li><strong>Visualize</strong> â€” Open Kibana to see real-time keyword trends</li></ol><p>ğŸ“ <strong>Full setup guide</strong>: <a href="https://github.com/your-username/real-time-news-keyword-trend-analyzer">View on<br>GitHub</a></p><hr><h2 id="4ï¸âƒ£-Usage"><a href="#4ï¸âƒ£-Usage" class="headerlink" title="4ï¸âƒ£ Usage"></a>4ï¸âƒ£ Usage</h2><ul><li>The Kafka Producer streams news data to Flink.</li><li>Flink processes titles â†’ extracts keywords â†’ counts occurrences.</li><li>Elasticsearch indexes keyword trends.</li><li>Kibana displays <strong>live keyword frequency and trend graphs</strong>.</li></ul><hr><h2 id="ğŸ› -Technologies-Used"><a href="#ğŸ› -Technologies-Used" class="headerlink" title="ğŸ›  Technologies Used"></a>ğŸ›  Technologies Used</h2><p>  Step            Technology</p><hr><p>  Data Source     NewsAPI.org<br>  Streaming       Apache Kafka<br>  Processing      Apache Flink<br>  Storage         Elasticsearch<br>  Visualization   Kibana<br>  Language        Python</p><hr><h2 id="ğŸ’¡-Key-Learnings"><a href="#ğŸ’¡-Key-Learnings" class="headerlink" title="ğŸ’¡ Key Learnings"></a>ğŸ’¡ Key Learnings</h2><ul><li>Apache Flinkâ€™s stream processing is powerful for <strong>real-time<br>analytics</strong>.</li><li>Kafka ensures scalable and fault-tolerant data streaming.</li><li>Elasticsearch + Kibana make it easy to explore and visualize trends<br>instantly.</li></ul><hr><h2 id="ğŸ”—-GitHub-Repository"><a href="#ğŸ”—-GitHub-Repository" class="headerlink" title="ğŸ”— GitHub Repository"></a>ğŸ”— GitHub Repository</h2><p>ğŸ“‚ <a href="https://github.com/kish191919/realTimeNewsKeywordTrendAnalyzer">View Project on<br>GitHub</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;ğŸ“°-Real-Time-News-Keyword-Trend-Analyzer&quot;&gt;&lt;a href=&quot;#ğŸ“°-Real-Time-News-Keyword-Trend-Analyzer&quot; class=&quot;headerlink&quot; title=&quot;ğŸ“° Real-Time</summary>
      
    
    
    
    <category term="Showcase" scheme="https://kish191919.github.io/categories/Showcase/"/>
    
    
    <category term="Python" scheme="https://kish191919.github.io/tags/Python/"/>
    
    <category term="Apache_Flink" scheme="https://kish191919.github.io/tags/Apache-Flink/"/>
    
    <category term="Kafka" scheme="https://kish191919.github.io/tags/Kafka/"/>
    
    <category term="Elasticsearch" scheme="https://kish191919.github.io/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>House Price Prediction</title>
    <link href="https://kish191919.github.io/2025/08/13/House-Price-Prediction/"/>
    <id>https://kish191919.github.io/2025/08/13/House-Price-Prediction/</id>
    <published>2025-08-14T00:20:03.000Z</published>
    <updated>2025-08-14T00:27:45.889Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ğŸ -House-Price-Prediction-in-Ames-Iowa"><a href="#ğŸ -House-Price-Prediction-in-Ames-Iowa" class="headerlink" title="ğŸ  House Price Prediction in Ames, Iowa"></a>ğŸ  House Price Prediction in Ames, Iowa</h2><p><em>Predicting real estate prices using advanced regression techniques</em></p><blockquote><p>â€œAccurate home valuation â€” powered by data.â€</p></blockquote><p>ğŸ“ <strong>Full Analysis</strong>:<br><a href="https://nbviewer.org/github/kish191919/House_Price_Project_by_Python/blob/master/House_Prediction_Project_OLS_Model.ipynb">ğŸ‘‰ View Jupyter Notebook on GitHub</a></p><p>ğŸ“ <strong>Competition Source</strong>:<br><a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques">ğŸ‘‰ Kaggle: House Prices - Advanced Regression Techniques</a></p><p align="center">  <img src="/images/portfolio/House_Price.png" alt="House Price Prediction" width="60%"></p><hr><h3 id="ğŸ“Œ-One-Line-Summary"><a href="#ğŸ“Œ-One-Line-Summary" class="headerlink" title="ğŸ“Œ One-Line Summary"></a>ğŸ“Œ One-Line Summary</h3><p>This project predicts house prices in <strong>Ames, Iowa</strong> using <strong>81 property features</strong> such as area, location, condition, and building type.<br>It applies <strong>data preprocessing</strong>, <strong>feature engineering</strong>, and <strong>regression modeling</strong> to estimate realistic sale prices.</p><hr><h2 id="1ï¸âƒ£-How-It-Was-Built"><a href="#1ï¸âƒ£-How-It-Was-Built" class="headerlink" title="1ï¸âƒ£ How It Was Built"></a>1ï¸âƒ£ How It Was Built</h2><h3 id="1-Data-Collection"><a href="#1-Data-Collection" class="headerlink" title="1. Data Collection"></a><strong>1. Data Collection</strong></h3><ul><li><strong>Train Data</strong>: 1,460 records, 81 features  </li><li><strong>Test Data</strong>: 1,459 records, 80 features (SalePrice excluded)  </li><li>Total: <strong>2,919 property listings</strong></li><li>Data from Kaggle competition dataset</li></ul><hr><h3 id="2-Data-Preparation"><a href="#2-Data-Preparation" class="headerlink" title="2. Data Preparation"></a><strong>2. Data Preparation</strong></h3><ul><li>Checked missing values (e.g., <code>LotFrontage</code>, <code>MasVnrArea</code>)</li><li>Filled missing values using median or mode depending on the feature type</li><li>Removed outliers (e.g., extreme <code>GrLivArea</code> values)</li><li>Applied <strong>log transformation</strong> to <code>SalePrice</code> to normalize skewed distribution</li><li>Converted categorical features into numerical form using one-hot encoding</li></ul><hr><h3 id="3-Exploratory-Data-Analysis-EDA"><a href="#3-Exploratory-Data-Analysis-EDA" class="headerlink" title="3. Exploratory Data Analysis (EDA)"></a><strong>3. Exploratory Data Analysis (EDA)</strong></h3><ul><li><strong>Numerical features</strong>: Plotted scatter graphs with <code>SalePrice</code> to detect trends<br>â†’ Found <code>GrLivArea</code> has strong linear correlation with price</li><li><strong>Categorical features</strong>: Compared median prices across categories (e.g., neighborhood)</li><li>Observed that <strong>larger living area</strong> and <strong>better overall quality</strong> strongly increase house price</li></ul><hr><h3 id="4-Feature-Engineering"><a href="#4-Feature-Engineering" class="headerlink" title="4. Feature Engineering"></a><strong>4. Feature Engineering</strong></h3><ul><li>Created new features such as:<ul><li><code>TotalSF</code> &#x3D; Total square footage (basement + 1st floor + 2nd floor)</li><li><code>Age</code> &#x3D; Years since construction</li></ul></li><li>Dropped low-impact or highly correlated redundant features</li></ul><hr><h3 id="5-Model-Training-OLS-Regression"><a href="#5-Model-Training-OLS-Regression" class="headerlink" title="5. Model Training (OLS Regression)"></a><strong>5. Model Training (OLS Regression)</strong></h3><ul><li>Used <strong>Ordinary Least Squares (OLS)</strong> regression to predict prices</li><li>Checked multicollinearity using Variance Inflation Factor (VIF)</li><li>Selected final set of features after removing high-VIF variables</li></ul><p>ğŸ“Š <strong>Evaluation Metric</strong>:  </p><ul><li><strong>Root Mean Squared Error (RMSE)</strong> used for performance check  </li><li>Final RMSE (log-transformed target): <strong>~0.12</strong> on validation set</li></ul><hr><h3 id="6-Results"><a href="#6-Results" class="headerlink" title="6. Results"></a><strong>6. Results</strong></h3><table><thead><tr><th>Feature</th><th>Impact on Price</th></tr></thead><tbody><tr><td><code>OverallQual</code></td><td>Very High</td></tr><tr><td><code>GrLivArea</code></td><td>High</td></tr><tr><td><code>GarageCars</code></td><td>High</td></tr><tr><td><code>TotalSF</code></td><td>High</td></tr><tr><td><code>Neighborhood</code></td><td>Moderate</td></tr></tbody></table><p>Example Prediction:  </p><ul><li><strong>House</strong>: 2-story, built in 2005, 2,000 sqft, good neighborhood  </li><li><strong>Predicted Price</strong>: ~$197,500</li></ul><hr><h2 id="2ï¸âƒ£-Real-World-Use"><a href="#2ï¸âƒ£-Real-World-Use" class="headerlink" title="2ï¸âƒ£ Real-World Use"></a>2ï¸âƒ£ Real-World Use</h2><ul><li>The OLS model can be used by real estate agencies to <strong>estimate property prices</strong></li><li>Buyers &amp; sellers can check if a listing is <strong>fairly priced</strong></li><li>Government agencies can use it for <strong>property tax assessment</strong></li></ul><hr><h2 id="ğŸ› -Technologies-Used"><a href="#ğŸ› -Technologies-Used" class="headerlink" title="ğŸ›  Technologies Used"></a>ğŸ›  Technologies Used</h2><table><thead><tr><th>Step</th><th>Technology</th></tr></thead><tbody><tr><td>Data Storage</td><td>CSV (Kaggle Dataset)</td></tr><tr><td>Model Dev</td><td>Python, Pandas, NumPy, statsmodels</td></tr><tr><td>Visualization</td><td>Matplotlib, Seaborn</td></tr><tr><td>Environment</td><td>Jupyter Notebook</td></tr></tbody></table><hr><h2 id="ğŸ’¡-Key-Learnings"><a href="#ğŸ’¡-Key-Learnings" class="headerlink" title="ğŸ’¡ Key Learnings"></a>ğŸ’¡ Key Learnings</h2><ul><li>Log-transforming skewed price data improves model performance</li><li>Removing multicollinear features increases stability of regression coefficients</li><li>Even simple linear models can perform well with good feature engineering</li></ul><hr><h2 id="ğŸ”—-GitHub-Repository"><a href="#ğŸ”—-GitHub-Repository" class="headerlink" title="ğŸ”— GitHub Repository"></a>ğŸ”— GitHub Repository</h2><p>ğŸ“‚ <a href="https://github.com/kish191919/House_Price_Project_by_Python">View Project on GitHub</a></p><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;ğŸ -House-Price-Prediction-in-Ames-Iowa&quot;&gt;&lt;a href=&quot;#ğŸ -House-Price-Prediction-in-Ames-Iowa&quot; class=&quot;headerlink&quot; title=&quot;ğŸ  House Price P</summary>
      
    
    
    
    <category term="Showcase" scheme="https://kish191919.github.io/categories/Showcase/"/>
    
    
    <category term="Python" scheme="https://kish191919.github.io/tags/Python/"/>
    
    <category term="Machine Learning" scheme="https://kish191919.github.io/tags/Machine-Learning/"/>
    
    <category term="Regression" scheme="https://kish191919.github.io/tags/Regression/"/>
    
  </entry>
  
  <entry>
    <title>AI Stock Analysis App</title>
    <link href="https://kish191919.github.io/2025/08/10/AI-Stock-Analysis-App/"/>
    <id>https://kish191919.github.io/2025/08/10/AI-Stock-Analysis-App/</id>
    <published>2025-08-10T20:25:18.000Z</published>
    <updated>2025-08-12T20:19:34.694Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ğŸ“ˆ-AI-Stock-Analysis-App"><a href="#ğŸ“ˆ-AI-Stock-Analysis-App" class="headerlink" title="ğŸ“ˆ AI Stock Analysis App"></a>ğŸ“ˆ AI Stock Analysis App</h2><p><em>AI-powered iOS app for real-time stock market insights</em></p><blockquote><p>â€œReal-time stock prices meet AI-powered analysis â€” in your language.â€</p></blockquote><p>ğŸ“ <strong>Demo Video</strong>:  </p><p align="center"><video width="40%" autoplay muted playsinline loop>  <source src="/videos/project3.mp4" type="video/mp4">  Your browser does not support the video tag.</video></p><hr><h3 id="ğŸ“Œ-One-Line-Summary"><a href="#ğŸ“Œ-One-Line-Summary" class="headerlink" title="ğŸ“Œ One-Line Summary"></a>ğŸ“Œ One-Line Summary</h3><p>An iPhone app that collects <strong>real-time stock data</strong> and uses <strong>AI</strong> to provide clear investment insights in multiple languages.<br>It also stores your past analyses so you can track trends over time.</p><hr><h2 id="1ï¸âƒ£-How-It-Works"><a href="#1ï¸âƒ£-How-It-Works" class="headerlink" title="1ï¸âƒ£ How It Works"></a>1ï¸âƒ£ How It Works</h2><h3 id="1-Live-Stock-Data"><a href="#1-Live-Stock-Data" class="headerlink" title="1. Live Stock Data"></a><strong>1. Live Stock Data</strong></h3><ul><li>Pulls stock prices from <strong>Yahoo Finance API</strong></li><li>Shows:<ul><li><strong>15-minute interval prices</strong> (last 3 days)</li><li><strong>Daily prices</strong> (last month)</li><li>Pre-market, regular, and after-hours prices</li></ul></li><li>Includes related news and market mood indicators (VIX, Fear &amp; Greed Index)</li></ul><hr><h3 id="2-AI-Powered-Analysis"><a href="#2-AI-Powered-Analysis" class="headerlink" title="2. AI-Powered Analysis"></a><strong>2. AI-Powered Analysis</strong></h3><ul><li>Uses <strong>OpenAI GPT-4</strong> to:<ul><li>Predict <strong>BULLISH</strong>, <strong>BEARISH</strong>, or <strong>NEUTRAL</strong> market direction</li><li>Show a confidence percentage</li><li>Explain the reasoning in your chosen language</li><li>Predict tomorrowâ€™s closing price</li></ul></li><li>Tracks AI usage and shows the <strong>cost in real time</strong></li></ul><hr><h3 id="3-Analysis-History"><a href="#3-Analysis-History" class="headerlink" title="3. Analysis History"></a><strong>3. Analysis History</strong></h3><ul><li>Saves past analysis results on your phone:<ul><li>Stock symbol</li><li>Current price</li><li>Prediction &amp; confidence</li><li>Expected price</li><li>Reason for prediction</li><li>Date &amp; time of analysis</li><li>Language used</li></ul></li></ul><hr><h3 id="4-Simple-Navigation"><a href="#4-Simple-Navigation" class="headerlink" title="4. Simple Navigation"></a><strong>4. Simple Navigation</strong></h3><ul><li><strong>Home</strong> â†’ Search and view live prices  </li><li><strong>Analysis</strong> â†’ Run AI prediction  </li><li><strong>History</strong> â†’ Review saved analyses</li></ul><hr><h2 id="2ï¸âƒ£-Cost-Tracking"><a href="#2ï¸âƒ£-Cost-Tracking" class="headerlink" title="2ï¸âƒ£ Cost Tracking"></a>2ï¸âƒ£ Cost Tracking</h2><ul><li>Uses GPT-4 Turbo pricing (as of 2024):<ul><li><strong>$0.01</strong> per 1,000 prompt tokens</li><li><strong>$0.03</strong> per 1,000 completion tokens</li></ul></li><li>The app logs each request and shows how much youâ€™ve spent</li></ul><hr><h2 id="ğŸ› -Technologies-Used"><a href="#ğŸ› -Technologies-Used" class="headerlink" title="ğŸ›  Technologies Used"></a>ğŸ›  Technologies Used</h2><table><thead><tr><th>Step</th><th>Technology</th></tr></thead><tbody><tr><td>iOS UI</td><td>Swift, SwiftUI</td></tr><tr><td>Data Storage</td><td>Core Data</td></tr><tr><td>API Calls</td><td>URLSession, JSONDecoder</td></tr><tr><td>Data Source</td><td>Yahoo Finance API</td></tr><tr><td>AI Analysis</td><td>OpenAI GPT-4</td></tr></tbody></table><hr><h2 id="ğŸ’¡-Key-Benefits"><a href="#ğŸ’¡-Key-Benefits" class="headerlink" title="ğŸ’¡ Key Benefits"></a>ğŸ’¡ Key Benefits</h2><ul><li>Get instant AI-powered stock insights in your own language</li><li>Track both prices and reasoning over time</li><li>Manage and monitor your AI usage costs</li><li>Clean, mobile-friendly design for quick decisions</li></ul><hr><h2 id="ğŸ”—-GitHub-Repository"><a href="#ğŸ”—-GitHub-Repository" class="headerlink" title="ğŸ”— GitHub Repository"></a>ğŸ”— GitHub Repository</h2><p>ğŸ“‚ <a href="https://github.com/kish191919/AIStockAnalysis">View Project on GitHub</a></p><hr><div style="display: flex; justify-content: center; gap: 10px; flex-wrap: nowrap;">  <img src="/images/portfolio/project3_1.png" alt="Screen 1" style="width:24%;">  <img src="/images/portfolio/project3_2.png" alt="Screen 2" style="width:24%;">  <img src="/images/portfolio/project3_3.png" alt="Screen 3" style="width:24%;">  <img src="/images/portfolio/project3_4.png" alt="Screen 4" style="width:24%;"></div>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;ğŸ“ˆ-AI-Stock-Analysis-App&quot;&gt;&lt;a href=&quot;#ğŸ“ˆ-AI-Stock-Analysis-App&quot; class=&quot;headerlink&quot; title=&quot;ğŸ“ˆ AI Stock Analysis App&quot;&gt;&lt;/a&gt;ğŸ“ˆ AI Stock An</summary>
      
    
    
    
    <category term="Showcase" scheme="https://kish191919.github.io/categories/Showcase/"/>
    
    
    <category term="OpenAI" scheme="https://kish191919.github.io/tags/OpenAI/"/>
    
    <category term="Swift" scheme="https://kish191919.github.io/tags/Swift/"/>
    
  </entry>
  
  <entry>
    <title>Real Time Crypto Dashboard</title>
    <link href="https://kish191919.github.io/2025/07/24/Real-Time-Crypto-Dashboard/"/>
    <id>https://kish191919.github.io/2025/07/24/Real-Time-Crypto-Dashboard/</id>
    <published>2025-07-24T23:57:22.000Z</published>
    <updated>2025-08-12T20:19:34.694Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ğŸ’¹-Real-Time-Crypto-Dashboard"><a href="#ğŸ’¹-Real-Time-Crypto-Dashboard" class="headerlink" title="ğŸ’¹ Real-Time Crypto Dashboard"></a>ğŸ’¹ Real-Time Crypto Dashboard</h2><p><em>Live Bitcoin &amp; Ethereum tracking with predictions</em></p><blockquote><p>â€œWatch crypto markets move in real time â€” and see tomorrowâ€™s trend today.â€</p></blockquote><p>ğŸ“ <strong>Demo Video</strong>:<br><video width="100%" autoplay muted playsinline loop><br>  <source src="/videos/project2.mp4" type="video/mp4"><br>  Your browser does not support the video tag.<br></video></p><hr><h3 id="ğŸ“Œ-One-Line-Summary"><a href="#ğŸ“Œ-One-Line-Summary" class="headerlink" title="ğŸ“Œ One-Line Summary"></a>ğŸ“Œ One-Line Summary</h3><p>A live dashboard that tracks <strong>Bitcoin (BTC)</strong> and <strong>Ethereum (ETH)</strong> prices in real time, predicts short-term trends, and displays everything visually.<br>Built entirely with <strong>open-source tools</strong> on AWS.</p><hr><h2 id="1ï¸âƒ£-How-It-Works"><a href="#1ï¸âƒ£-How-It-Works" class="headerlink" title="1ï¸âƒ£ How It Works"></a>1ï¸âƒ£ How It Works</h2><p><strong>Data Flow:</strong><br>Live Prices â†’ Kafka (data streaming) â†’ PostgreSQL (storage) â†’ Grafana (dashboard)</p><hr><h3 id="1-Live-Price-Collection"><a href="#1-Live-Price-Collection" class="headerlink" title="1. Live Price Collection"></a><strong>1. Live Price Collection</strong></h3><ul><li>Uses the <strong>CryptoCompare API</strong> to fetch BTC and ETH prices</li><li>Updates every <strong>5 seconds</strong></li><li>Includes both current market prices and short-term history</li></ul><hr><h3 id="2-Real-Time-Streaming"><a href="#2-Real-Time-Streaming" class="headerlink" title="2. Real-Time Streaming"></a><strong>2. Real-Time Streaming</strong></h3><ul><li><strong>Apache Kafka</strong> moves live data instantly from the producer (data collector) to the consumer (data inserter)</li><li>Ensures zero delays between data collection and dashboard updates</li></ul><hr><h3 id="3-Database-Storage"><a href="#3-Database-Storage" class="headerlink" title="3. Database Storage"></a><strong>3. Database Storage</strong></h3><ul><li><strong>PostgreSQL</strong> stores:<ul><li>Current prices</li><li>Predicted prices (using a Simple Moving Average)</li></ul></li><li>Keeps historical records for trend analysis</li></ul><hr><h3 id="4-AI-Style-Predictions"><a href="#4-AI-Style-Predictions" class="headerlink" title="4. AI-Style Predictions"></a><strong>4. AI-Style Predictions</strong></h3><ul><li>A <strong>Simple Moving Average (SMA)</strong> model predicts prices 5 minutes ahead</li><li>Predictions are stored alongside actual prices for comparison</li></ul><hr><h3 id="5-Visual-Dashboard"><a href="#5-Visual-Dashboard" class="headerlink" title="5. Visual Dashboard"></a><strong>5. Visual Dashboard</strong></h3><ul><li><strong>Grafana</strong> shows:<ul><li>Real-time price charts</li><li>Overlay of predicted vs. actual prices</li><li>24-hour high&#x2F;low values</li><li>24-hour % change bar charts</li></ul></li></ul><hr><h2 id="ğŸ› -Technologies-Used"><a href="#ğŸ› -Technologies-Used" class="headerlink" title="ğŸ›  Technologies Used"></a>ğŸ›  Technologies Used</h2><table><thead><tr><th>Step</th><th>Technology</th></tr></thead><tbody><tr><td>Data Source</td><td>CryptoCompare API</td></tr><tr><td>Streaming</td><td>Apache Kafka</td></tr><tr><td>Storage</td><td>PostgreSQL</td></tr><tr><td>Prediction</td><td>Python (SMA)</td></tr><tr><td>Visualization</td><td>Grafana</td></tr><tr><td>Environment</td><td>AWS EC2 (Ubuntu 22.04)</td></tr></tbody></table><hr><h2 id="ğŸ’¡-Key-Benefits"><a href="#ğŸ’¡-Key-Benefits" class="headerlink" title="ğŸ’¡ Key Benefits"></a>ğŸ’¡ Key Benefits</h2><ul><li>Watch BTC &amp; ETH prices update instantly</li><li>Compare AI-predicted vs. actual prices in real time</li><li>Access from anywhere via AWS-hosted Grafana</li><li>Fully open-source â€” no paid tools required</li></ul><hr><h2 id="ğŸ”—-GitHub-Repository"><a href="#ğŸ”—-GitHub-Repository" class="headerlink" title="ğŸ”— GitHub Repository"></a>ğŸ”— GitHub Repository</h2><p>ğŸ“‚ <a href="https://github.com/kish191919/Crypto">View Project on GitHub</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;ğŸ’¹-Real-Time-Crypto-Dashboard&quot;&gt;&lt;a href=&quot;#ğŸ’¹-Real-Time-Crypto-Dashboard&quot; class=&quot;headerlink&quot; title=&quot;ğŸ’¹ Real-Time Crypto Dashboard&quot;&gt;&lt;/a</summary>
      
    
    
    
    <category term="Showcase" scheme="https://kish191919.github.io/categories/Showcase/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Python" scheme="https://kish191919.github.io/tags/Python/"/>
    
    <category term="Kafka" scheme="https://kish191919.github.io/tags/Kafka/"/>
    
    <category term="PostgreSQL" scheme="https://kish191919.github.io/tags/PostgreSQL/"/>
    
    <category term="Grafana" scheme="https://kish191919.github.io/tags/Grafana/"/>
    
  </entry>
  
  <entry>
    <title>Used Car Price Prediction</title>
    <link href="https://kish191919.github.io/2025/07/24/Used-Car-Price-Prediction-in-Virginia/"/>
    <id>https://kish191919.github.io/2025/07/24/Used-Car-Price-Prediction-in-Virginia/</id>
    <published>2025-07-24T23:31:06.000Z</published>
    <updated>2025-08-12T20:19:34.694Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ğŸš—-Used-Car-Price-Prediction-in-Virginia"><a href="#ğŸš—-Used-Car-Price-Prediction-in-Virginia" class="headerlink" title="ğŸš— Used Car Price Prediction in Virginia"></a>ğŸš— Used Car Price Prediction in Virginia</h2><p><em>Predicting the price of used cars with AI and data analysis</em>  </p><blockquote><p>â€œDonâ€™t guess the price â€” let the data tell you.â€</p></blockquote><p>ğŸ“ <strong>Full Analysis</strong>:<br><a href="https://nbviewer.org/github/yesmanki81/Portfolio_Projects/blob/master/Predict_Used_Car_Price_by_Python/Data_analysis_and_machine_learning_model.ipynb">ğŸ‘‰ View Jupyter Notebook on GitHub</a></p><p align="center">  <img src="/images/portfolio/project1_1.png" alt="Web App" width="60%"></p><hr><h3 id="ğŸ“Œ-One-Line-Summary"><a href="#ğŸ“Œ-One-Line-Summary" class="headerlink" title="ğŸ“Œ One-Line Summary"></a>ğŸ“Œ One-Line Summary</h3><p>This project predicts the prices of used cars in <strong>Virginia</strong> using a dataset of over <strong>46,000 listings</strong>.<br>By analyzing details like <strong>year, mileage, brand, and fuel type</strong>, the AI model can estimate a realistic market price.</p><hr><h2 id="1ï¸âƒ£-How-It-Was-Built"><a href="#1ï¸âƒ£-How-It-Was-Built" class="headerlink" title="1ï¸âƒ£ How It Was Built"></a>1ï¸âƒ£ How It Was Built</h2><h3 id="1-Data-Collection"><a href="#1-Data-Collection" class="headerlink" title="1. Data Collection"></a><strong>1. Data Collection</strong></h3><ul><li>Collected real car sales data from the web</li><li>Stored in an <strong>AWS cloud MySQL database</strong></li><li>Accessed using <strong>Python</strong> and shared via <strong>Flask API</strong></li></ul><hr><h3 id="2-Data-Preparation"><a href="#2-Data-Preparation" class="headerlink" title="2. Data Preparation"></a><strong>2. Data Preparation</strong></h3><ul><li>Filled missing values (e.g., unknown mileage)</li><li>Removed unrealistic values (e.g., mileage over 1 million km)</li><li>Converted text data (brand, fuel type) into numbers</li><li>Applied <strong>log transformation</strong> to balance skewed data</li></ul><hr><h3 id="3-Data-Analysis-EDA"><a href="#3-Data-Analysis-EDA" class="headerlink" title="3. Data Analysis (EDA)"></a><strong>3. Data Analysis (EDA)</strong></h3><ul><li>Visualized the relationship between price and year&#x2F;mileage</li><li>Found <strong>year</strong> and <strong>mileage</strong> to be the most influential features</li></ul><hr><h3 id="4-AI-Model-Training"><a href="#4-AI-Model-Training" class="headerlink" title="4. AI Model Training"></a><strong>4. AI Model Training</strong></h3><p>Tested several machine learning models:</p><ul><li><strong>Linear Regression</strong></li><li><strong>Decision Tree</strong></li><li><strong>Random Forest</strong></li><li><strong>Support Vector Regression (SVR)</strong></li><li><strong>XGBoost</strong> (winner)</li></ul><p>ğŸ“Š <strong>Best Model</strong>: <strong>XGBoost</strong></p><ul><li>Accuracy (RÂ²): <strong>0.89</strong></li><li>Average Error (RMSE): <strong>$5,474</strong></li></ul><hr><h3 id="5-Results"><a href="#5-Results" class="headerlink" title="5. Results"></a><strong>5. Results</strong></h3><table><thead><tr><th>Model</th><th>RÂ² Score</th><th>RMSE</th></tr></thead><tbody><tr><td>Linear Regression</td><td>0.58</td><td>14,085</td></tr><tr><td>Decision Tree</td><td>0.73</td><td>9,022</td></tr><tr><td>Random Forest</td><td>0.84</td><td>7,021</td></tr><tr><td>SVR</td><td>0.11</td><td>14,328</td></tr><tr><td><strong>XGBoost</strong></td><td><strong>0.89</strong></td><td><strong>5,474</strong></td></tr></tbody></table><hr><h3 id="6-Real-World-Test"><a href="#6-Real-World-Test" class="headerlink" title="6. Real-World Test"></a><strong>6. Real-World Test</strong></h3><ul><li><strong>2016 Honda Odyssey</strong> â†’ Predicted price: <strong>$18,738</strong><br>Matched closely with actual market data.</li></ul><hr><h2 id="2ï¸âƒ£-Real-World-Use"><a href="#2ï¸âƒ£-Real-World-Use" class="headerlink" title="2ï¸âƒ£ Real-World Use"></a>2ï¸âƒ£ Real-World Use</h2><ul><li>Final model saved as a <strong>Pickle</strong> file</li><li>Deployed via <strong>Flask API</strong> for real-time predictions</li><li>Created a simplified version (Year, Mileage, Brand, Model) for web app integration</li></ul><hr><h2 id="ğŸ› -Technologies-Used"><a href="#ğŸ› -Technologies-Used" class="headerlink" title="ğŸ›  Technologies Used"></a>ğŸ›  Technologies Used</h2><table><thead><tr><th>Step</th><th>Technology</th></tr></thead><tbody><tr><td>Data Storage</td><td>AWS MySQL</td></tr><tr><td>Model Dev</td><td>Python, scikit-learn, XGBoost</td></tr><tr><td>Deployment</td><td>Flask API, Pickle</td></tr><tr><td>Environment</td><td>AWS EC2 (Ubuntu)</td></tr></tbody></table><hr><h2 id="ğŸ’¡-Key-Learnings"><a href="#ğŸ’¡-Key-Learnings" class="headerlink" title="ğŸ’¡ Key Learnings"></a>ğŸ’¡ Key Learnings</h2><ul><li>Log transformation improves accuracy for skewed data</li><li>Tree-based models handle mixed data types effectively</li><li>Even with only 4 features, accurate real-time predictions are possible</li></ul><hr><h2 id="ğŸ”—-GitHub-Repository"><a href="#ğŸ”—-GitHub-Repository" class="headerlink" title="ğŸ”— GitHub Repository"></a>ğŸ”— GitHub Repository</h2><p>ğŸ“‚ <a href="https://github.com/kish191919/Predict_Used_Car_Price_by_Python">View Project on GitHub</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;ğŸš—-Used-Car-Price-Prediction-in-Virginia&quot;&gt;&lt;a href=&quot;#ğŸš—-Used-Car-Price-Prediction-in-Virginia&quot; class=&quot;headerlink&quot; title=&quot;ğŸš— Used Car </summary>
      
    
    
    
    <category term="Showcase" scheme="https://kish191919.github.io/categories/Showcase/"/>
    
    
    <category term="Python" scheme="https://kish191919.github.io/tags/Python/"/>
    
    <category term="Machine Learning" scheme="https://kish191919.github.io/tags/Machine-Learning/"/>
    
    <category term="XGBoost" scheme="https://kish191919.github.io/tags/XGBoost/"/>
    
  </entry>
  
  <entry>
    <title>[Algorithm] Quick Sort â€” Divide and Conquer!</title>
    <link href="https://kish191919.github.io/2025/07/24/Algorithm-Quick-Sort/"/>
    <id>https://kish191919.github.io/2025/07/24/Algorithm-Quick-Sort/</id>
    <published>2025-07-24T21:34:19.000Z</published>
    <updated>2025-08-12T01:55:33.710Z</updated>
    
    <content type="html"><![CDATA[<h1 id="âš¡-Quick-Sort-Divide-and-Conquer"><a href="#âš¡-Quick-Sort-Divide-and-Conquer" class="headerlink" title="âš¡ Quick Sort: Divide and Conquer!"></a>âš¡ Quick Sort: Divide and Conquer!</h1><blockquote><p>â€œDivide each difficulty into as many parts as is feasible and necessary to resolve it.â€<br>â€” <em>RenÃ© Descartes</em></p></blockquote><p align="center">  <img src="/images/Quick_Sort.png" alt="RenÃ© Descartes" width="60%"></p><p>In life, as in sorting algorithms, you donâ€™t have to solve a complex problem all at once.<br>Break it down into smaller pieces, and it becomes much easier to handle.<br><strong>Quick Sort</strong> is an algorithm built exactly on that philosophy.</p><p>Imagine organizing your bookshelf.<br>You pick one book in the middle as a reference point â€”<br>thinner books go to the left, thicker books to the right.<br>Then, you repeat the same process for each group until the shelf is neatly organized.<br>Thatâ€™s essentially how Quick Sort works!</p><hr><h2 id="ğŸ§ -How-Quick-Sort-Works"><a href="#ğŸ§ -How-Quick-Sort-Works" class="headerlink" title="ğŸ§  How Quick Sort Works"></a>ğŸ§  How Quick Sort Works</h2><ol><li>Choose a pivot element from the array.</li><li>Place elements smaller than the pivot to the left, and elements greater than the pivot to the right.</li><li>Recursively apply the same process to both the left and right groups.</li></ol><video width="100%" autoplay muted playsinline loop>  <source src="/videos/Quick_Sort_demo.mp4" type="video/mp4">  Your browser does not support the video tag.</video><hr><h2 id="ğŸ§ª-Python-Example"><a href="#ğŸ§ª-Python-Example" class="headerlink" title="ğŸ§ª Python Example"></a>ğŸ§ª Python Example</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">quick_sort</span>(<span class="params">arr</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(arr) &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> arr</span><br><span class="line">    pivot = arr[<span class="built_in">len</span>(arr) // <span class="number">2</span>]</span><br><span class="line">    left = [x <span class="keyword">for</span> x <span class="keyword">in</span> arr <span class="keyword">if</span> x &lt; pivot]</span><br><span class="line">    middle = [x <span class="keyword">for</span> x <span class="keyword">in</span> arr <span class="keyword">if</span> x == pivot]</span><br><span class="line">    right = [x <span class="keyword">for</span> x <span class="keyword">in</span> arr <span class="keyword">if</span> x &gt; pivot]</span><br><span class="line">    <span class="keyword">return</span> quick_sort(left) + middle + quick_sort(right)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Example usage</span></span><br><span class="line">numbers = [<span class="number">10</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">7</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">9</span>]</span><br><span class="line">sorted_numbers = quick_sort(numbers)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Sorted result:&quot;</span>, sorted_numbers)</span><br></pre></td></tr></table></figure><hr><h2 id="ğŸ¯-Wrapping-Up"><a href="#ğŸ¯-Wrapping-Up" class="headerlink" title="ğŸ¯ Wrapping Up"></a>ğŸ¯ Wrapping Up</h2><p>Quick Sort teaches us that <strong>even the biggest problems can be solved beautifully</strong> -<br>if you break them down and tackle them step-by-step.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;âš¡-Quick-Sort-Divide-and-Conquer&quot;&gt;&lt;a href=&quot;#âš¡-Quick-Sort-Divide-and-Conquer&quot; class=&quot;headerlink&quot; title=&quot;âš¡ Quick Sort: Divide and Conqu</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="Algorithm" scheme="https://kish191919.github.io/categories/Dev/Algorithm/"/>
    
    
    <category term="Sorting" scheme="https://kish191919.github.io/tags/Sorting/"/>
    
    <category term="Python" scheme="https://kish191919.github.io/tags/Python/"/>
    
    <category term="Quick Sort" scheme="https://kish191919.github.io/tags/Quick-Sort/"/>
    
  </entry>
  
</feed>
