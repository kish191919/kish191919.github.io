<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Danny&#39;s Blog</title>
  
  <subtitle>Data, AI, and Tech Insight</subtitle>
  <link href="https://kish191919.github.io/atom.xml" rel="self"/>
  
  <link href="https://kish191919.github.io/"/>
  <updated>2025-08-22T22:47:49.874Z</updated>
  <id>https://kish191919.github.io/</id>
  
  <author>
    <name>Danny Ki</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (16) - 프롬프트 엔지니어링 기법</title>
    <link href="https://kish191919.github.io/2025/08/22/KO-AWS-Certified-AI-Practitioner-16/"/>
    <id>https://kish191919.github.io/2025/08/22/KO-AWS-Certified-AI-Practitioner-16/</id>
    <published>2025-08-22T22:40:34.658Z</published>
    <updated>2025-08-22T22:47:49.874Z</updated>
    
    <content type="html"><![CDATA[<h1 id="🎯-프롬프트-엔지니어링-기법-Prompt-Engineering-Techniques"><a href="#🎯-프롬프트-엔지니어링-기법-Prompt-Engineering-Techniques" class="headerlink" title="🎯 프롬프트 엔지니어링 기법 (Prompt Engineering Techniques)"></a>🎯 프롬프트 엔지니어링 기법 (Prompt Engineering Techniques)</h1><p>프롬프트 엔지니어링은 **생성형 AI(LLM)**이 원하는 방식으로 답변을 하도록 유도하는 핵심 기술입니다. 단순히 질문을 던지는 것이 아니라, <strong>프롬프트를 설계·최적화</strong>하여 모델이 더 정확하고 일관된 결과를 내도록 만드는 과정이죠.  </p><p>AWS 자격증 시험에서도 종종 <strong>프롬프트 엔지니어링 기법</strong>(Zero-Shot, Few-Shot, Chain-of-Thought, RAG 등)이 언급되므로 꼭 이해해 두어야 합니다.  </p><hr><h2 id="1️⃣-Zero-Shot-Prompting-제로샷-프롬프트"><a href="#1️⃣-Zero-Shot-Prompting-제로샷-프롬프트" class="headerlink" title="1️⃣ Zero-Shot Prompting (제로샷 프롬프트)"></a>1️⃣ Zero-Shot Prompting (제로샷 프롬프트)</h2><ul><li><strong>정의</strong>: 예시를 전혀 주지 않고, 모델의 일반 지식만 활용해 답변을 얻는 방식.  </li><li><strong>예시</strong>  <ul><li>프롬프트: <em>“개가 미스터리를 해결하는 짧은 이야기를 써줘.”</em>  </li><li>응답: 모델이 스스로 개연성 있는 이야기를 생성.</li></ul></li></ul><p>👉 <strong>특징</strong>  </p><ul><li>대형 언어모델(LLM, Foundation Model)일수록 좋은 결과가 나옴.  </li><li>시험 포인트: <em>“Zero-Shot &#x3D; 예시 없이, 모델 자체의 일반 지식에 의존한다.”</em></li></ul><p align="center">  <img src="/images/aws_basic_71.png" width="80%"></p>---<h2 id="2️⃣-Few-Shot-Prompting-퓨샷-프롬프트"><a href="#2️⃣-Few-Shot-Prompting-퓨샷-프롬프트" class="headerlink" title="2️⃣ Few-Shot Prompting (퓨샷 프롬프트)"></a>2️⃣ Few-Shot Prompting (퓨샷 프롬프트)</h2><ul><li><strong>정의</strong>: 모델에게 몇 가지 예시(샷, shots)를 제공하여 원하는 패턴을 학습시키는 방식.  </li><li><strong>예시</strong>  <ul><li>프롬프트:  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">예시 1) 고양이가 사라진 쿠키를 찾아내는 이야기</span><br><span class="line">예시 2) 새가 정원 꽃이 사라진 이유를 찾아내는 이야기</span><br><span class="line">이제 개가 미스터리를 해결하는 짧은 이야기를 써줘.</span><br></pre></td></tr></table></figure></li><li>응답: 제공한 예시 패턴을 따라 개에 대한 미스터리 해결 이야기를 작성.</li></ul></li></ul><p>👉 <strong>특징</strong>  </p><ul><li>예시가 1개뿐이라면 <strong>One-Shot Prompting</strong>이라고도 부름.  </li><li>원하는 <strong>출력 스타일</strong>이나 <strong>형식</strong>을 모델에 학습시키는 데 유용.  </li><li>시험 포인트: <em>“Few-Shot &#x3D; 몇 개의 예시 제공 → 모델이 패턴을 따라감.”</em></li></ul><p align="center">  <img src="/images/aws_basic_72.png" width="80%"></p><hr><h2 id="3️⃣-Chain-of-Thought-Prompting-체인-오브-쏘트-프롬프트"><a href="#3️⃣-Chain-of-Thought-Prompting-체인-오브-쏘트-프롬프트" class="headerlink" title="3️⃣ Chain-of-Thought Prompting (체인 오브 쏘트 프롬프트)"></a>3️⃣ Chain-of-Thought Prompting (체인 오브 쏘트 프롬프트)</h2><ul><li><strong>정의</strong>: 문제 해결 과정을 여러 단계로 나누어 <strong>“step by step”</strong> 추론하도록 유도하는 방식.  </li><li><strong>예시</strong>  <ul><li>프롬프트:  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">개가 미스터리를 해결하는 이야기를 써줘.</span><br><span class="line">1. 먼저 배경과 개를 설명해줘.</span><br><span class="line">2. 그 다음 미스터리를 소개해줘.</span><br><span class="line">3. 개가 단서를 찾는 과정을 설명해줘.</span><br><span class="line">4. 마지막으로 미스터리를 해결하는 장면을 써줘.</span><br></pre></td></tr></table></figure></li><li>응답: 위 단계를 따라 체계적으로 이야기를 구성.</li></ul></li></ul><p>👉 <strong>특징</strong>  </p><ul><li>복잡한 문제(수학, 추론, 논리 문제)에 특히 효과적.  </li><li>Zero-Shot 또는 Few-Shot과 결합 가능.  </li><li>시험 포인트: <em>“Chain-of-Thought &#x3D; 단계별 추론을 유도, ‘Think step by step’ 문구 기억하기.”</em></li></ul><p align="center">  <img src="/images/aws_basic_73.png" width="80%"></p><hr><h2 id="4️⃣-RAG-Retrieval-Augmented-Generation-검색-증강-생성"><a href="#4️⃣-RAG-Retrieval-Augmented-Generation-검색-증강-생성" class="headerlink" title="4️⃣ RAG (Retrieval-Augmented Generation, 검색 증강 생성)"></a>4️⃣ RAG (Retrieval-Augmented Generation, 검색 증강 생성)</h2><ul><li><p><strong>정의</strong>: 모델 자체 지식만 활용하는 것이 아니라, **외부 데이터(지식 베이스, 문서 등)**를 불러와 프롬프트에 추가해 더 정확하고 최신 정보를 포함하는 답변을 생성하는 기법.  </p></li><li><p><strong>동작 과정</strong>  </p><ol><li>외부 데이터 저장 (예: Amazon S3, Confluence, Salesforce)  </li><li>텍스트를 **벡터 임베딩(Embedding)**으로 변환  </li><li><strong>벡터 DB</strong>(예: OpenSearch, Pinecone)에서 유사 문서 검색  </li><li>검색된 내용을 프롬프트에 추가 (<strong>Augmented Prompt</strong>)  </li><li>최종 답변 생성</li></ol></li><li><p><strong>예시</strong>  </p><ul><li>프롬프트:  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">개가 미스터리를 해결하는 짧은 이야기를 써줘.</span><br><span class="line">단, 아래 정보를 반영해서 작성해:</span><br><span class="line">- 개는 뛰어난 후각으로 냄새를 추적한다.</span><br><span class="line">- 동네 미스터리의 흔한 사례는 도난이나 분실이다.</span><br><span class="line">- 개는 하루가 지난 냄새도 추적할 수 있다.</span><br></pre></td></tr></table></figure></li><li>응답: 외부 지식을 반영해 더 사실적이고 설득력 있는 스토리 생성.</li></ul></li></ul><p>👉 <strong>특징</strong>  </p><ul><li><strong>최신성 보장</strong>: 모델 학습 이후 생긴 정보도 반영 가능.  </li><li>Bedrock에서는 <strong>Knowledge Base + RAG</strong>를 통한 실제 서비스 구현이 시험 단골 주제.  </li><li>시험 포인트: <em>“RAG &#x3D; 외부 데이터 검색 + 프롬프트 보강 → 최신&#x2F;정확한 답변.”</em></li></ul><p align="center">  <img src="/images/aws_basic_74.png" width="80%"></p><hr><h2 id="✅-정리-시험-대비-핵심-포인트"><a href="#✅-정리-시험-대비-핵심-포인트" class="headerlink" title="✅ 정리 (시험 대비 핵심 포인트)"></a>✅ 정리 (시험 대비 핵심 포인트)</h2><table><thead><tr><th>기법</th><th>정의</th><th>시험 키워드</th></tr></thead><tbody><tr><td>Zero-Shot</td><td>예시 없이 모델의 일반 지식으로 답변</td><td>“No examples”, “General knowledge”</td></tr><tr><td>Few-Shot</td><td>몇 가지 예시 제공 후 유도</td><td>“Pattern learning”, “One-Shot &#x3D; 1 example”</td></tr><tr><td>Chain-of-Thought</td><td>단계별 추론 유도</td><td>“Think step by step”</td></tr><tr><td>RAG</td><td>외부 데이터 검색 + 보강</td><td>“Knowledge Base”, “Augmented Prompt”</td></tr></tbody></table><hr><p>👉 <strong>한 줄 요약</strong>:<br>프롬프트 엔지니어링은 단순 질문이 아니라 **“어떻게 질문하느냐”**에 따라 결과가 크게 달라진다.<br>AWS 시험에서는 특히 <strong>Zero-Shot, Few-Shot, Chain-of-Thought, RAG</strong>의 개념과 활용 포인트를 구분해서 알아두는 것이 중요하다.  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;🎯-프롬프트-엔지니어링-기법-Prompt-Engineering-Techniques&quot;&gt;&lt;a href=&quot;#🎯-프롬프트-엔지니어링-기법-Prompt-Engineering-Techniques&quot; class=&quot;headerlink&quot; title=&quot;</summary>
      
    
    
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(15) - Prompt Engineering Techniques</title>
    <link href="https://kish191919.github.io/2025/08/22/AWS-Certified-AI-Practitioner-16/"/>
    <id>https://kish191919.github.io/2025/08/22/AWS-Certified-AI-Practitioner-16/</id>
    <published>2025-08-22T22:40:29.000Z</published>
    <updated>2025-08-22T22:47:49.874Z</updated>
    
    <content type="html"><![CDATA[<h1 id="🎯-Prompt-Engineering-Techniques"><a href="#🎯-Prompt-Engineering-Techniques" class="headerlink" title="🎯 Prompt Engineering Techniques"></a>🎯 Prompt Engineering Techniques</h1><p>Understanding different <strong>prompting techniques</strong> is essential for getting the most out of Large Language Models (LLMs). These concepts are also important for AWS certification exams, especially when dealing with Amazon Bedrock and generative AI.</p><hr><h2 id="1-🔹-Zero-Shot-Prompting"><a href="#1-🔹-Zero-Shot-Prompting" class="headerlink" title="1. 🔹 Zero-Shot Prompting"></a>1. 🔹 Zero-Shot Prompting</h2><p><strong>Definition</strong>:<br>Present a task to the model <strong>without providing any examples or prior training</strong> for that specific task.</p><p><strong>Prompt Example</strong>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Write a short story about a dog that helps solve a mystery.</span><br></pre></td></tr></table></figure><p><strong>Response Example</strong>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Once upon a time, there was a clever dog named Max. One day, Max noticed something strange happening at the park...</span><br></pre></td></tr></table></figure><ul><li>Relies entirely on the model’s <strong>general knowledge</strong>.  </li><li>The <strong>larger and more capable</strong> the Foundation Model (FM), the better the results.  </li><li>Called <em>zero-shot</em> because the model receives no prior examples (“shots”).</li></ul><p align="center">  <img src="/images/aws_basic_71.png" width="80%"></p><hr><h2 id="2-🔹-Few-Shot-Prompting"><a href="#2-🔹-Few-Shot-Prompting" class="headerlink" title="2. 🔹 Few-Shot Prompting"></a>2. 🔹 Few-Shot Prompting</h2><p><strong>Definition</strong>:<br>Provide the model with <strong>a few examples</strong> to guide its output.  </p><p><strong>Prompt Example</strong>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Here are two examples of stories where animals help solve mysteries:</span><br><span class="line">1. Whiskers the Cat noticed missing cookies...</span><br><span class="line">2. Buddy the Bird saw that garden flowers were disappearing...</span><br><span class="line"></span><br><span class="line">Now write a short story about a dog that helps solve a mystery.</span><br></pre></td></tr></table></figure><p><strong>Response Example</strong>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Rover the dog was playing in the yard when he noticed the neighbor’s garden gnome was missing...</span><br></pre></td></tr></table></figure><ul><li>Helps the model <strong>mimic the style and structure</strong> of given examples.  </li><li><strong>One-Shot Prompting</strong> &#x3D; providing only one example.  </li><li>Effective when you need <strong>consistent formatting or tone</strong> in the output.</li></ul><p align="center">  <img src="/images/aws_basic_72.png" width="80%"></p><hr><h2 id="3-🔹-Chain-of-Thought-CoT-Prompting"><a href="#3-🔹-Chain-of-Thought-CoT-Prompting" class="headerlink" title="3. 🔹 Chain-of-Thought (CoT) Prompting"></a>3. 🔹 Chain-of-Thought (CoT) Prompting</h2><p><strong>Definition</strong>:<br>Guide the model by dividing the task into <strong>step-by-step reasoning</strong>.  </p><p><strong>Prompt Example</strong>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Let’s write a story about a dog solving a mystery.</span><br><span class="line">1. Describe the setting and the dog.</span><br><span class="line">2. Introduce the mystery.</span><br><span class="line">3. Show how the dog discovers clues.</span><br><span class="line">4. Reveal how the dog solves the mystery.</span><br><span class="line">Write the story step by step.</span><br></pre></td></tr></table></figure><p><strong>Response Example</strong>:</p><ol><li>Rover, a curious dog, lives in a quiet neighborhood.  </li><li>One day, a necklace goes missing…  </li><li>Rover follows footprints to the park…  </li><li>He finds the necklace hidden by a magpie…</li></ol><ul><li>Produces more <strong>structured and logical</strong> responses.  </li><li>Useful for <strong>problem-solving</strong> tasks like math, reasoning, or multi-step workflows.  </li><li>Can be combined with <strong>Zero-Shot</strong> or <strong>Few-Shot</strong> prompting.</li></ul><p align="center">  <img src="/images/aws_basic_73.png" width="80%"></p><hr><h2 id="4-🔹-Retrieval-Augmented-Generation-RAG"><a href="#4-🔹-Retrieval-Augmented-Generation-RAG" class="headerlink" title="4. 🔹 Retrieval-Augmented Generation (RAG)"></a>4. 🔹 Retrieval-Augmented Generation (RAG)</h2><p><strong>Definition</strong>:<br>Combine the model’s generative ability with <strong>external data sources</strong> to create more accurate, context-aware responses.  </p><p><strong>How it works</strong>:</p><ol><li>Query is sent to the model.  </li><li>Relevant information is <strong>retrieved</strong> from an external source (e.g., Amazon S3, vector DB).  </li><li>The retrieved data is <strong>augmented into the prompt</strong>.  </li><li>The model generates a <strong>context-rich answer</strong>.</li></ol><p><strong>Prompt Example</strong>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Write a short story about a dog solving a mystery.</span><br><span class="line">Use the following details:</span><br><span class="line">- Dogs have an excellent sense of smell to track scents.</span><br><span class="line">- Neighborhood mysteries often involve missing items.</span><br><span class="line">- Dogs can detect scents even if they are a day old.</span><br></pre></td></tr></table></figure><p><strong>Response Example</strong>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Rover sniffed the ground and followed the trail of a missing toy hidden in a bush...</span><br></pre></td></tr></table></figure><ul><li>Ensures outputs are <strong>grounded in real or domain-specific knowledge</strong>.  </li><li>In AWS Bedrock, RAG is often implemented with a <strong>Knowledge Base</strong> and <strong>vector search (KNN)</strong>.</li></ul><p align="center">  <img src="/images/aws_basic_74.png" width="80%"></p><hr><h2 id="📌-Exam-Tips"><a href="#📌-Exam-Tips" class="headerlink" title="📌 Exam Tips"></a>📌 Exam Tips</h2><ul><li><strong>Zero-Shot</strong> &#x3D; no examples, rely on model’s knowledge.  </li><li><strong>Few-Shot</strong> &#x3D; provide examples to guide responses (One-Shot &#x3D; just one example).  </li><li><strong>Chain-of-Thought</strong> &#x3D; “Think step by step” for logical reasoning.  </li><li><strong>RAG</strong> &#x3D; augment with external data → ensures up-to-date and factual answers.</li></ul><hr><p>✅ <strong>Summary</strong>:<br>Prompt Engineering techniques allow you to <strong>control and optimize LLM behavior</strong>.  </p><ul><li>Use <strong>Zero-Shot</strong> when you want quick general answers.  </li><li>Use <strong>Few-Shot</strong> for consistent style and formatting.  </li><li>Use <strong>CoT Prompting</strong> for structured, logical reasoning.  </li><li>Use <strong>RAG</strong> when accuracy and domain-specific knowledge are critical.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;🎯-Prompt-Engineering-Techniques&quot;&gt;&lt;a href=&quot;#🎯-Prompt-Engineering-Techniques&quot; class=&quot;headerlink&quot; title=&quot;🎯 Prompt Engineering Techni</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(15) - LLM Text Generation &amp; Prompt Optimizatio</title>
    <link href="https://kish191919.github.io/2025/08/22/AWS-Certified-AI-Practitioner-15/"/>
    <id>https://kish191919.github.io/2025/08/22/AWS-Certified-AI-Practitioner-15/</id>
    <published>2025-08-22T22:22:07.000Z</published>
    <updated>2025-08-22T22:47:49.876Z</updated>
    
    <content type="html"><![CDATA[<h1 id="🤖-LLM-Text-Generation-Prompt-Optimization"><a href="#🤖-LLM-Text-Generation-Prompt-Optimization" class="headerlink" title="🤖 LLM Text Generation &amp; Prompt Optimization"></a>🤖 LLM Text Generation &amp; Prompt Optimization</h1><h2 id="1-How-Text-is-Generated-in-an-LLM"><a href="#1-How-Text-is-Generated-in-an-LLM" class="headerlink" title="1. How Text is Generated in an LLM"></a>1. How Text is Generated in an LLM</h2><p>When a model generates text, it predicts the <strong>next word</strong> based on probabilities.</p><p>Example:<br><em>“After the rain, the streets were…”</em><br>Possible next words and probabilities:  </p><ul><li>wet (0.40)  </li><li>flooded (0.25)  </li><li>slippery (0.15)  </li><li>empty (0.10)  </li><li>muddy (0.05)  </li><li>clean (0.03)  </li><li>blocked (0.02)</li></ul><p>The model randomly selects a word according to these probabilities.  </p><hr><h2 id="2-Prompt-Performance-Optimization"><a href="#2-Prompt-Performance-Optimization" class="headerlink" title="2. Prompt Performance Optimization"></a>2. Prompt Performance Optimization</h2><h3 id="🔹-System-Prompts"><a href="#🔹-System-Prompts" class="headerlink" title="🔹 System Prompts"></a>🔹 System Prompts</h3><ul><li>Define how the model should behave and reply.  </li><li>Example: <em>“You are a teacher in AWS Cloud.”</em></li></ul><h3 id="🔹-Temperature-0-to-1"><a href="#🔹-Temperature-0-to-1" class="headerlink" title="🔹 Temperature (0 to 1)"></a>🔹 Temperature (0 to 1)</h3><ul><li>Controls <strong>creativity</strong>.  </li><li>Low (e.g., 0.2): Conservative, repetitive, focused on likely answers.  </li><li>High (e.g., 1.0): More diverse, creative, unpredictable, less coherent.</li></ul><h3 id="🔹-Top-P-Nucleus-Sampling"><a href="#🔹-Top-P-Nucleus-Sampling" class="headerlink" title="🔹 Top P (Nucleus Sampling)"></a>🔹 Top P (Nucleus Sampling)</h3><ul><li>Value: 0–1.  </li><li>Low (e.g., 0.25): Only top 25% likely words → coherent output.  </li><li>High (e.g., 0.99): Considers more words → diverse, creative output.</li></ul><h3 id="🔹-Top-K"><a href="#🔹-Top-K" class="headerlink" title="🔹 Top K"></a>🔹 Top K</h3><ul><li>Limits number of candidate words.  </li><li>Low (e.g., 10): Considers top 10 words → focused, coherent output.  </li><li>High (e.g., 500): Considers many → more variety, creativity.</li></ul><h3 id="🔹-Length"><a href="#🔹-Length" class="headerlink" title="🔹 Length"></a>🔹 Length</h3><ul><li>Maximum output length.</li></ul><h3 id="🔹-Stop-Sequences"><a href="#🔹-Stop-Sequences" class="headerlink" title="🔹 Stop Sequences"></a>🔹 Stop Sequences</h3><ul><li>Tokens that signal the model to stop generating.</li></ul><p>✅ <strong>Exam Tip (AWS AI Practitioner)</strong>:<br>Know the definitions of <strong>System Prompts, Temperature, Top P, Top K, Length, Stop Sequences</strong> and what happens with low vs. high values.  </p><hr><h2 id="3-Prompt-Latency"><a href="#3-Prompt-Latency" class="headerlink" title="3. Prompt Latency"></a>3. Prompt Latency</h2><p>Latency &#x3D; how fast the model responds.<br>Impacted by:  </p><ul><li><strong>Model size</strong> (larger &#x3D; slower).  </li><li><strong>Model type</strong> (e.g., LLaMA vs Claude).  </li><li><strong>Input tokens</strong> (longer prompt &#x3D; slower).  </li><li><strong>Output tokens</strong> (longer generation &#x3D; slower).</li></ul><p>⚠️ <strong>Not impacted by</strong>: Temperature, Top P, or Top K.  </p><p>✅ <strong>Exam Tip</strong>: Expect a question about what affects latency and what does not.  </p><hr><h2 id="4-Practical-Example"><a href="#4-Practical-Example" class="headerlink" title="4. Practical Example"></a>4. Practical Example</h2><p>Prompt: <em>“Write a short story about a robot learning to cook.”</em>  </p><ul><li><strong>Low Creativity (Temp&#x3D;0.2, Top P&#x3D;0.25, Top K&#x3D;10)</strong> → Safe, repetitive story.  </li><li><strong>High Creativity (Temp&#x3D;1.0, Top P&#x3D;0.99, Top K&#x3D;500)</strong> → Imaginative, unique story (e.g., robot making crepes with optical sensors).</li></ul><p align="center">  <img src="/images/aws_basic_70.png" width="90%"></p><hr><h2 id="5-Key-Takeaways"><a href="#5-Key-Takeaways" class="headerlink" title="5. Key Takeaways"></a>5. Key Takeaways</h2><ul><li><strong>Temperature</strong> &#x3D; randomness&#x2F;creativity.  </li><li><strong>Top P</strong> &#x3D; probability threshold (percentile of words).  </li><li><strong>Top K</strong> &#x3D; number of candidate words.  </li><li><strong>System Prompt</strong> &#x3D; role&#x2F;behavior definition.  </li><li><strong>Length&#x2F;Stop Sequences</strong> &#x3D; control output size and ending.  </li><li><strong>Latency</strong> &#x3D; depends on model size, type, and token count (not sampling parameters).</li></ul><hr><p>📘 <strong>Good to Remember for AWS Exam</strong>:  </p><ul><li>Be clear about how each parameter influences output.  </li><li>Understand latency factors.  </li><li>Expect scenario questions like: <em>“Which parameter ensures more coherent answers?”</em> or <em>“What does not affect latency?”</em>.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;🤖-LLM-Text-Generation-Prompt-Optimization&quot;&gt;&lt;a href=&quot;#🤖-LLM-Text-Generation-Prompt-Optimization&quot; class=&quot;headerlink&quot; title=&quot;🤖 LLM T</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (15) - LLM에서 텍스트 생성 과정 &amp; 프롬프트 최적화</title>
    <link href="https://kish191919.github.io/2025/08/22/KO-AWS-Certified-AI-Practitioner-15/"/>
    <id>https://kish191919.github.io/2025/08/22/KO-AWS-Certified-AI-Practitioner-15/</id>
    <published>2025-08-22T22:22:03.000Z</published>
    <updated>2025-08-22T22:47:49.876Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📖-LLM에서-텍스트-생성-과정-프롬프트-최적화"><a href="#📖-LLM에서-텍스트-생성-과정-프롬프트-최적화" class="headerlink" title="📖 LLM에서 텍스트 생성 과정 &amp; 프롬프트 최적화"></a>📖 LLM에서 텍스트 생성 과정 &amp; 프롬프트 최적화</h1><h2 id="1️⃣-텍스트-생성-원리"><a href="#1️⃣-텍스트-생성-원리" class="headerlink" title="1️⃣ 텍스트 생성 원리"></a>1️⃣ 텍스트 생성 원리</h2><p>LLM(대규모 언어 모델)은 <strong>다음 단어가 무엇일지 확률적으로 계산</strong>해서 문장을 만들어 갑니다.<br>예를 들어,<br>“After the rain, the streets were …” 뒤에 올 수 있는 후보 단어와 확률이 있다고 할 때:</p><ul><li>wet (0.40)  </li><li>flooded (0.25)  </li><li>slippery (0.15)  </li><li>empty (0.10)  </li><li>muddy (0.05)</li></ul><p>모델은 이 확률을 기반으로 <strong>무작위 선택(random sampling)</strong> 하여 다음 단어를 생성합니다.<br>즉, LLM의 출력은 항상 확률적이므로, 같은 질문을 여러 번 해도 결과가 조금씩 달라질 수 있습니다.</p><hr><h2 id="2️⃣-프롬프트-성능-최적화-Prompt-Performance-Optimization"><a href="#2️⃣-프롬프트-성능-최적화-Prompt-Performance-Optimization" class="headerlink" title="2️⃣ 프롬프트 성능 최적화 (Prompt Performance Optimization)"></a>2️⃣ 프롬프트 성능 최적화 (Prompt Performance Optimization)</h2><p>Amazon Bedrock 같은 서비스에서는 <strong>출력 품질</strong>을 조절할 수 있는 여러 파라미터를 제공합니다.</p><h3 id="🔹-System-Prompt"><a href="#🔹-System-Prompt" class="headerlink" title="🔹 System Prompt"></a>🔹 System Prompt</h3><ul><li>모델이 <strong>어떤 역할을 해야 하는지</strong> 미리 정의합니다.  </li><li>예: <em>“너는 AWS 클라우드 선생님처럼 대답해줘.”</em>  </li><li>톤과 답변 스타일을 설정할 수 있어, 일관된 답변을 얻는 데 유용합니다.</li></ul><p align="center">  <img src="/images/aws_basic_70.png" width="90%"></p><hr><h3 id="🔹-Temperature-0-1"><a href="#🔹-Temperature-0-1" class="headerlink" title="🔹 Temperature (0~1)"></a>🔹 Temperature (0~1)</h3><ul><li><strong>창의성(랜덤성)</strong> 조절  </li><li>낮음 (예: 0.2) → 보수적, 반복적, 가장 가능성 높은 답변 선택  </li><li>높음 (예: 1.0) → 다양하고 창의적인 답변, 하지만 가끔은 덜 일관적일 수 있음</li></ul><p>👉 <strong>시험 포인트:</strong> Temperature 값이 낮으면 일관성↑, 높으면 창의성↑</p><hr><h3 id="🔹-Top-P-Nucleus-Sampling"><a href="#🔹-Top-P-Nucleus-Sampling" class="headerlink" title="🔹 Top P (Nucleus Sampling)"></a>🔹 Top P (Nucleus Sampling)</h3><ul><li><strong>확률 분포 상위 몇 %의 단어만 고려할지</strong> 정하는 값  </li><li>Low P (0.25) → 상위 25% 단어만 선택 → 더 일관적  </li><li>High P (0.99) → 거의 모든 단어 고려 → 더 다양하고 창의적</li></ul><p>👉 <strong>시험 포인트:</strong> Top P는 <strong>확률 누적 기준(percentile)</strong>  </p><hr><h3 id="🔹-Top-K"><a href="#🔹-Top-K" class="headerlink" title="🔹 Top K"></a>🔹 Top K</h3><ul><li><strong>몇 개의 후보 단어만 고려할지</strong> 숫자로 제한  </li><li>Low K (10) → 상위 10개 단어만 → 더 예측 가능, 안정적  </li><li>High K (500) → 상위 500개 단어 고려 → 더 다양하고 창의적</li></ul><p>👉 <strong>시험 포인트:</strong> Top P는 비율(%), Top K는 개수(N)</p><hr><h3 id="🔹-Length"><a href="#🔹-Length" class="headerlink" title="🔹 Length"></a>🔹 Length</h3><ul><li>생성되는 답변의 <strong>최대 길이</strong> 제한</li></ul><h3 id="🔹-Stop-Sequences"><a href="#🔹-Stop-Sequences" class="headerlink" title="🔹 Stop Sequences"></a>🔹 Stop Sequences</h3><ul><li>특정 토큰(문자열)을 만나면 <strong>생성을 중단</strong></li></ul><hr><h2 id="3️⃣-프롬프트-지연시간-Prompt-Latency"><a href="#3️⃣-프롬프트-지연시간-Prompt-Latency" class="headerlink" title="3️⃣ 프롬프트 지연시간 (Prompt Latency)"></a>3️⃣ 프롬프트 지연시간 (Prompt Latency)</h2><p><strong>Latency &#x3D; 모델이 응답하는 속도</strong>  </p><p>영향 받는 요소:  </p><ul><li>모델 크기 (큰 모델일수록 느림)  </li><li>모델 종류 (예: LLaMA vs Claude → 성능 차이 있음)  </li><li>입력 토큰 수 (입력이 길면 느려짐)  </li><li>출력 토큰 수 (많이 생성할수록 느려짐)</li></ul><p>👉 <strong>시험 포인트:</strong>  </p><ul><li><strong>Latency에 영향을 주지 않는 것:</strong> Temperature, Top P, Top K</li></ul><hr><h2 id="4️⃣-정리-표"><a href="#4️⃣-정리-표" class="headerlink" title="4️⃣ 정리 표"></a>4️⃣ 정리 표</h2><table><thead><tr><th>파라미터</th><th>의미</th><th>낮은 값</th><th>높은 값</th></tr></thead><tbody><tr><td><strong>System Prompt</strong></td><td>모델 역할 지정</td><td>제한적 답변</td><td>유연한 답변 가능</td></tr><tr><td><strong>Temperature</strong></td><td>창의성</td><td>보수적, 일관적</td><td>다양, 창의적</td></tr><tr><td><strong>Top P</strong></td><td>확률 누적 비율</td><td>일관성↑</td><td>창의성↑</td></tr><tr><td><strong>Top K</strong></td><td>후보 단어 개수</td><td>안정적</td><td>다양, 창의적</td></tr><tr><td><strong>Length</strong></td><td>최대 출력 길이</td><td>짧은 답변</td><td>긴 답변</td></tr><tr><td><strong>Stop Sequences</strong></td><td>생성 중단 조건</td><td>필요 시 제어</td><td>필요 시 제어</td></tr><tr><td><strong>Latency 영향 요소</strong></td><td>속도 결정</td><td>모델 크기, 토큰 수</td><td>동일</td></tr><tr><td><strong>Latency 비영향 요소</strong></td><td>속도와 무관</td><td>Temp, Top P, Top K</td><td>동일</td></tr></tbody></table><hr><h2 id="5️⃣-시험에-자주-나오는-포인트"><a href="#5️⃣-시험에-자주-나오는-포인트" class="headerlink" title="5️⃣ 시험에 자주 나오는 포인트"></a>5️⃣ 시험에 자주 나오는 포인트</h2><ul><li><strong>Temperature &#x2F; Top P &#x2F; Top K 차이점</strong> (시험에서 자주 비교 문제 나옴)  </li><li><strong>Latency에 영향을 주는 요소 vs 주지 않는 요소</strong>  </li><li><strong>System Prompt</strong>는 모델의 역할과 톤을 지정할 수 있음  </li><li><strong>Length &#x2F; Stop Sequence</strong>는 출력 제어 방법으로 자주 언급됨</li></ul><hr><p>👉 요약하자면,<br>LLM의 텍스트 생성은 확률적 과정이며,<br><strong>Temperature, Top P, Top K</strong> 같은 설정으로 <strong>창의성과 일관성을 조절</strong>할 수 있습니다.<br>또한 <strong>Latency</strong>는 모델 크기와 토큰 수에 따라 달라지지만,<br><strong>Sampling 관련 파라미터(Temp, Top P, Top K)</strong> 에는 영향을 받지 않습니다.  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📖-LLM에서-텍스트-생성-과정-프롬프트-최적화&quot;&gt;&lt;a href=&quot;#📖-LLM에서-텍스트-생성-과정-프롬프트-최적화&quot; class=&quot;headerlink&quot; title=&quot;📖 LLM에서 텍스트 생성 과정 &amp;amp; 프롬프트 최적화&quot;&gt;&lt;/a</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(14) - Prompt Engineering</title>
    <link href="https://kish191919.github.io/2025/08/22/AWS-Certified-AI-Practitioner-14/"/>
    <id>https://kish191919.github.io/2025/08/22/AWS-Certified-AI-Practitioner-14/</id>
    <published>2025-08-22T22:01:33.000Z</published>
    <updated>2025-08-22T22:05:47.806Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📘-Prompt-Engineering"><a href="#📘-Prompt-Engineering" class="headerlink" title="📘 Prompt Engineering"></a>📘 Prompt Engineering</h1><h2 id="What-is-Prompt-Engineering"><a href="#What-is-Prompt-Engineering" class="headerlink" title="What is Prompt Engineering?"></a>What is Prompt Engineering?</h2><p>Prompt Engineering is the process of <strong>designing, refining, and<br>optimizing prompts</strong> to guide a foundation model (FM) or large language<br>model (LLM) toward producing the best possible output for your needs.</p><p>A <strong>naïve prompt</strong> gives little guidance and leaves interpretation up to<br>the model.<br>Example: <em>“Summarize what is AWS.”</em><br>This works, but the answer may not be clear or focused.</p><p>By contrast, <strong>Prompt Engineering</strong> uses a structured approach to<br>improve results.</p><hr><h2 id="Components-of-an-Effective-Prompt"><a href="#Components-of-an-Effective-Prompt" class="headerlink" title="Components of an Effective Prompt"></a>Components of an Effective Prompt</h2><ol><li><strong>Instructions</strong> – What the model should do (e.g., summarize,<br>explain, compare).\</li><li><strong>Context</strong> – Additional background that helps guide the response.\</li><li><strong>Input Data</strong> – The text, question, or data you want the model to<br>work with.\</li><li><strong>Output Indicator</strong> – The desired format or style of the answer<br>(e.g., 2–3 sentences, bullet points, JSON).</li></ol><hr><h2 id="Example-Enhanced-Prompt"><a href="#Example-Enhanced-Prompt" class="headerlink" title="Example: Enhanced Prompt"></a>Example: Enhanced Prompt</h2><p><strong>Naïve Prompt</strong>: “Summarize what is AWS.”</p><p><strong>Enhanced Prompt</strong>:<br><em>“Write a concise summary that captures the main points of an article<br>about learning AWS (Amazon Web Services).<br>Ensure that the summary is clear and informative, focusing on key<br>services relevant to beginners.<br>Include details about learning resources and career benefits.<br>I am teaching a beginner’s AWS course.<br>Provide a 2–3 sentence summary that captures the essence of the<br>article.”</em></p><p>This approach makes the task more precise and tailored to the user’s<br>goal.</p><hr><h2 id="Negative-Prompting"><a href="#Negative-Prompting" class="headerlink" title="Negative Prompting"></a>Negative Prompting</h2><p>Negative prompting explicitly tells the model what <strong>not</strong> to include.<br>This helps: - <strong>Avoid Unwanted Content</strong> – Prevents irrelevant or<br>unnecessary details.\</p><ul><li><strong>Maintain Focus</strong> – Keeps the response on-topic.\</li><li><strong>Enhance Clarity</strong> – Avoids complex jargon or deep technical detail<br>if not needed.</li></ul><p><strong>Example with Negative Prompting:</strong><br><em>“Summarize an article about AWS for beginners.<br>Focus on key services, learning resources, and career benefits.<br>Do <strong>not</strong> include technical configurations, in-depth tutorials, or<br>personal anecdotes.<br>Provide a clear, beginner-friendly 2–3 sentence summary.”</em></p><hr><h2 id="Why-It-Matters-AWS-Exam-Relevance"><a href="#Why-It-Matters-AWS-Exam-Relevance" class="headerlink" title="Why It Matters (AWS Exam Relevance)"></a>Why It Matters (AWS Exam Relevance)</h2><p>For AWS AI Practitioner and related certifications, you should know: -<br><strong>Prompt Engineering</strong> improves AI model accuracy and usefulness.\</p><ul><li>AWS exams may ask about the difference between <strong>naïve prompts,<br>enhanced prompts, and negative prompts</strong>.\</li><li>Understanding how to <strong>guide model behavior</strong> is key in real-world AI<br>applications, from summarization to chatbots.</li></ul><hr><h2 id="Key-Takeaways"><a href="#Key-Takeaways" class="headerlink" title="Key Takeaways"></a>Key Takeaways</h2><ul><li>Naïve prompts &#x3D; vague and open-ended.\</li><li>Enhanced prompts &#x3D; structured with instructions, context, input, and<br>output format.\</li><li>Negative prompts &#x3D; control what <strong>not</strong> to generate.\</li><li>Together, these techniques ensure <strong>clearer, more accurate, and<br>useful outputs</strong>.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📘-Prompt-Engineering&quot;&gt;&lt;a href=&quot;#📘-Prompt-Engineering&quot; class=&quot;headerlink&quot; title=&quot;📘 Prompt Engineering&quot;&gt;&lt;/a&gt;📘 Prompt Engineering&lt;/</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (14) - Prompt Engineering</title>
    <link href="https://kish191919.github.io/2025/08/22/KO-AWS-Certified-AI-Practitioner-14/"/>
    <id>https://kish191919.github.io/2025/08/22/KO-AWS-Certified-AI-Practitioner-14/</id>
    <published>2025-08-22T22:01:25.000Z</published>
    <updated>2025-08-22T22:05:50.629Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📝-프롬프트-엔지니어링-Prompt-Engineering"><a href="#📝-프롬프트-엔지니어링-Prompt-Engineering" class="headerlink" title="📝 프롬프트 엔지니어링 (Prompt Engineering)"></a>📝 프롬프트 엔지니어링 (Prompt Engineering)</h1><p>프롬프트 엔지니어링은 <strong>AI 모델이 더 정확하고 원하는 답변을 내도록 질문(프롬프트)을 설계하고 최적화하는 기술</strong>을 말합니다.<br>단순히 “AWS를 요약해줘” 같은 질문을 던지는 것보다, 구체적으로 <strong>지시, 맥락, 입력 데이터, 출력 형식</strong>을 포함하면 훨씬 좋은 결과를 얻을 수 있습니다.</p><hr><h2 id="1-기본-개념-Naive-Prompt-vs-개선된-Prompt"><a href="#1-기본-개념-Naive-Prompt-vs-개선된-Prompt" class="headerlink" title="1. 기본 개념 (Naïve Prompt vs. 개선된 Prompt)"></a>1. 기본 개념 (Naïve Prompt vs. 개선된 Prompt)</h2><ul><li><p><strong>Naïve Prompt (단순 프롬프트)</strong><br>예: “AWS를 요약해줘.”<br>👉 모델이 알아서 답하긴 하지만, 원하는 수준의 답변이 아닐 수 있음.</p></li><li><p><strong>Prompt Engineering (프롬프트 엔지니어링)</strong><br>👉 프롬프트를 설계하고 개선하여 원하는 답변을 얻는 방법.<br>👉 4가지 핵심 요소:</p><ol><li><strong>Instructions (지시사항)</strong> – 모델이 어떤 일을 해야 하는지 (예: “요약문 작성”)  </li><li><strong>Context (맥락)</strong> – 모델이 참고할 추가 정보 (예: “AWS 초보자를 가르치는 상황”)  </li><li><strong>Input Data (입력 데이터)</strong> – 요약하거나 분석할 실제 데이터  </li><li><strong>Output Indicator (출력 형식)</strong> – 원하는 결과 형태 (예: “2~3문장으로 요약”)</li></ol></li></ul><hr><h2 id="2-예시-–-개선된-프롬프트"><a href="#2-예시-–-개선된-프롬프트" class="headerlink" title="2. 예시 – 개선된 프롬프트"></a>2. 예시 – 개선된 프롬프트</h2><p><strong>향상된 프롬프트 예시</strong></p><p>“아마존 웹 서비스(AWS)에 대해 초보자를 위한 2~3문장 요약을 작성하라.<br>주요 서비스(EC2, S3, RDS, Lambda, Redshift)를 포함하고, 학습 자료와 자격증의 커리어 장점도 언급하라.”</p><p>👉 이렇게 하면 결과는:</p><ul><li>AWS의 핵심 서비스 나열  </li><li>초보자에게 유용한 학습 리소스 설명  </li><li>자격증 취득의 커리어 장점 강조</li></ul><hr><h2 id="3-네거티브-프롬프트-Negative-Prompting"><a href="#3-네거티브-프롬프트-Negative-Prompting" class="headerlink" title="3. 네거티브 프롬프트 (Negative Prompting)"></a>3. 네거티브 프롬프트 (Negative Prompting)</h2><p><strong>네거티브 프롬프트</strong>는 모델에게 **“포함하지 말 것”**을 지시하는 기법입니다.</p><p>예시:<br>“초보자용 AWS 학습 내용을 요약하라.<br>주요 서비스, 학습 리소스, 자격증 장점을 언급하되, <strong>세부 기술 설정, 특정 튜토리얼, 개인 경험</strong>은 제외하라.”</p><p>➡️ 장점:</p><ul><li><strong>불필요한 내용 방지</strong> – 관련 없는 정보 제거  </li><li><strong>집중력 유지</strong> – 주제에서 벗어나지 않음  </li><li><strong>가독성 향상</strong> – 초보자도 쉽게 이해 가능</li></ul><hr><h2 id="4-시험-대비-포인트-AWS-자격증-관점"><a href="#4-시험-대비-포인트-AWS-자격증-관점" class="headerlink" title="4. 시험 대비 포인트 (AWS 자격증 관점)"></a>4. 시험 대비 포인트 (AWS 자격증 관점)</h2><p>AWS AI Practitioner 시험에서도 <strong>프롬프트 엔지니어링 기본 개념</strong>이 출제될 수 있습니다.<br>특히 기억해야 할 것:</p><ul><li><strong>좋은 프롬프트 &#x3D; Instructions + Context + Input + Output</strong>  </li><li><strong>Negative Prompting</strong>은 원하지 않는 답변을 방지하는 핵심 기법  </li><li><strong>실무 예시</strong>: 고객 지원 챗봇에서 불필요한 기술 설명을 배제 → 사용자 친화적 답변 제공 가능</li></ul><hr><h2 id="5-요약"><a href="#5-요약" class="headerlink" title="5. 요약"></a>5. 요약</h2><ul><li>프롬프트 엔지니어링 &#x3D; 질문을 잘 설계하는 기술  </li><li>좋은 프롬프트 &#x3D; 지시 + 맥락 + 입력 데이터 + 출력 형식  </li><li>네거티브 프롬프트 &#x3D; “하지 말아야 할 것”을 명확히 지시  </li><li>AWS 시험에서는 <strong>이 개념들을 이해하고 실제 예시로 설명할 수 있는 능력</strong>이 중요</li></ul><hr><p>✅ <strong>Tip</strong>: 연습할 때, 같은 질문을 단순하게&#x2F;개선된 방식으로 각각 작성해보고 결과를 비교해보세요!</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📝-프롬프트-엔지니어링-Prompt-Engineering&quot;&gt;&lt;a href=&quot;#📝-프롬프트-엔지니어링-Prompt-Engineering&quot; class=&quot;headerlink&quot; title=&quot;📝 프롬프트 엔지니어링 (Prompt Engine</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(13) - End-to-End Use Case (AI Stylist Demo)</title>
    <link href="https://kish191919.github.io/2025/08/20/AWS-Certified-AI-Practitioner-13/"/>
    <id>https://kish191919.github.io/2025/08/20/AWS-Certified-AI-Practitioner-13/</id>
    <published>2025-08-21T01:15:23.000Z</published>
    <updated>2025-08-21T04:38:32.220Z</updated>
    
    <content type="html"><![CDATA[<h1 id="👗-Amazon-Bedrock-End-to-End-Use-Case-AI-Stylist-Demo"><a href="#👗-Amazon-Bedrock-End-to-End-Use-Case-AI-Stylist-Demo" class="headerlink" title="👗 Amazon Bedrock End-to-End Use Case (AI Stylist Demo)"></a>👗 Amazon Bedrock End-to-End Use Case (AI Stylist Demo)</h1><h2 id="📌-Why-This-Demo-Matters"><a href="#📌-Why-This-Demo-Matters" class="headerlink" title="📌 Why This Demo Matters"></a>📌 Why This Demo Matters</h2><p>So far, we’ve explored many features of Amazon Bedrock. But in reality, using Bedrock isn’t just about clicking around in the console.<br>To build a <strong>real-world application</strong>, you need to make <strong>API calls</strong> to Bedrock and integrate those capabilities directly into your service.  </p><p>To demonstrate this, AWS provides an <strong>AI Stylist</strong> demo application.<br>This demo shows how <strong>end users actually experience an application built on top of Bedrock</strong>.  </p><p>🔗 <a href="https://aistylist.awsplayer.com/">Try the AI Stylist Demo</a></p><p>📎 <strong>Demo Video</strong>:  </p><p align="center"><video width="60%" autoplay muted playsinline loop>  <source src="/videos/AWS_Practitioner_1.mp4" type="video/mp4">  Your browser does not support the video tag.</video></p><hr><h2 id="👠-How-the-AI-Stylist-Works"><a href="#👠-How-the-AI-Stylist-Works" class="headerlink" title="👠 How the AI Stylist Works"></a>👠 How the AI Stylist Works</h2><ol><li>The <strong>user asks a question</strong><br>Example: <em>“I’m a consultant traveling to New York next week. What outfit should I wear on my first day in the office?”</em></li></ol><p align="center">  <img src="/images/aws_basic_66.png" width="80%"></p><ol start="2"><li>A <strong>Bedrock Agent</strong> is triggered.  <ul><li>The agent doesn’t just return a static answer. Instead, it connects to multiple <strong>Knowledge Bases</strong>.  </li><li>Examples:  <ul><li><strong>Product catalog</strong> (private company data)  </li><li><strong>Fashion trends</strong> (public dataset)  </li><li><strong>Order history</strong> (user-specific data)  </li><li><strong>Customer reviews</strong> (private company data)</li></ul></li></ul></li></ol><p align="center">  <img src="/images/aws_basic_67.png" width="80%"></p><ol start="3"><li>The agent pulls the necessary data and generates a response.  <ul><li>Example: Suggests two outfit options: <strong>Business Formal</strong> and <strong>Business Casual</strong>  </li><li>Uses image generation to create realistic outfit visuals</li></ul></li></ol><p align="center">  <img src="/images/aws_basic_68.png" width="80%"></p><ol start="4"><li>The user asks <strong>follow-up questions</strong>.  <ul><li>Example: <em>“What do customers say about this jacket?”</em>  </li><li>→ The agent queries the <strong>customer reviews knowledge base</strong> and summarizes:<br><em>“Customers like the quality, color, and fabric. There are 325 reviews.”</em></li></ul></li></ol><p align="center">  <img src="/images/aws_basic_69.png" width="80%"></p><ol start="5"><li>The process continues into <strong>ordering</strong>.  <ul><li>Size recommendation: Based on previous order history → <em>“We recommend size M.”</em>  </li><li>Cart management: The agent calls APIs to add items to the shopping cart  </li><li>Checkout: The agent finalizes the purchase with an API call</li></ul></li></ol><hr><h2 id="🔑-Key-AWS-Concepts-Certification-Focus"><a href="#🔑-Key-AWS-Concepts-Certification-Focus" class="headerlink" title="🔑 Key AWS Concepts (Certification Focus)"></a>🔑 Key AWS Concepts (Certification Focus)</h2><ul><li><strong>Bedrock Agent</strong> → Handles <strong>multi-step tasks</strong> (not just single answers).  </li><li><strong>Knowledge Base Integration</strong> → Connects AI with real business data (orders, reviews, catalogs).  </li><li><strong>RAG (Retrieval-Augmented Generation)</strong> → Improves responses by pulling in external data (e.g., current fashion trends).  </li><li><strong>API Integration</strong> → Goes beyond chat, enabling <strong>real system actions</strong> (add to cart, checkout, update records).  </li><li><strong>IAM Roles &amp; Permissions</strong> → Securely grant Bedrock access to knowledge bases or APIs (common exam topic).  </li><li><strong>CloudWatch Monitoring</strong> → Track metrics like latency, invocation counts, and token usage.</li></ul><hr><h2 id="📝-Summary"><a href="#📝-Summary" class="headerlink" title="📝 Summary"></a>📝 Summary</h2><p>Amazon Bedrock isn’t just a <strong>Q&amp;A chatbot</strong>.<br>👉 It enables you to build <strong>AI agents</strong> that connect to knowledge bases and backend systems (APIs, databases, Lambda) to perform <strong>real business actions</strong>.  </p><p>The <strong>AI Stylist demo</strong> is a simple but powerful example. In real-world use cases, similar architectures can power:  </p><ul><li>E-commerce recommendation engines  </li><li>Customer support chatbots  </li><li>IT automation agents  </li><li>Personalized learning or healthcare coaches</li></ul><hr><p>👉 <strong>One-Line Takeaway:</strong><br>With Amazon Bedrock, you can go beyond simple AI responses and build <strong>intelligent agents</strong> that integrate with <strong>Knowledge Bases, APIs, IAM security, and CloudWatch monitoring</strong>—all of which are key concepts for AWS certification exams.  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;👗-Amazon-Bedrock-End-to-End-Use-Case-AI-Stylist-Demo&quot;&gt;&lt;a href=&quot;#👗-Amazon-Bedrock-End-to-End-Use-Case-AI-Stylist-Demo&quot; class=&quot;heade</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (12) - Pricing &amp; Model Improvement</title>
    <link href="https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-13/"/>
    <id>https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-13/</id>
    <published>2025-08-21T00:54:02.000Z</published>
    <updated>2025-08-21T04:38:32.185Z</updated>
    
    <content type="html"><![CDATA[<h1 id="👗-Amazon-Bedrock-End-to-End-Use-Case-AI-Stylist-Demo"><a href="#👗-Amazon-Bedrock-End-to-End-Use-Case-AI-Stylist-Demo" class="headerlink" title="👗 Amazon Bedrock End-to-End Use Case (AI Stylist Demo)"></a>👗 Amazon Bedrock End-to-End Use Case (AI Stylist Demo)</h1><h2 id="📌-왜-이-데모가-중요한가"><a href="#📌-왜-이-데모가-중요한가" class="headerlink" title="📌 왜 이 데모가 중요한가?"></a>📌 왜 이 데모가 중요한가?</h2><p>앞에서 Amazon Bedrock의 여러 기능을 살펴봤지만, 실제로는 <strong>콘솔에서 클릭만 하는 것</strong>으로 끝나지 않습니다.<br>실제 애플리케이션에서 Bedrock을 활용하려면 <strong>API 호출</strong>을 통해 Bedrock 기능을 불러오고, 이를 기반으로 서비스를 만들어야 합니다.  </p><p>AWS에서는 이를 보여주기 위해 <strong>AI Stylist</strong>라는 데모 애플리케이션을 제공합니다.<br>이 데모를 통해 <strong>실제 사용자가 어떻게 Bedrock 기반 앱을 경험하는지</strong> 확인할 수 있습니다.  </p><p>🔗 <a href="https://aistylist.awsplayer.com/">Try the AI Stylist Demo</a></p><p>📎 <strong>Demo Video</strong>:  </p><p align="center"><video width="60%" autoplay muted playsinline loop>  <source src="/videos/AWS_Practitioner_1.mp4" type="video/mp4">  Your browser does not support the video tag.</video></p><hr><h2 id="👠-AI-Stylist-동작-방식"><a href="#👠-AI-Stylist-동작-방식" class="headerlink" title="👠 AI Stylist 동작 방식"></a>👠 AI Stylist 동작 방식</h2><ol><li>사용자가 질문을 입력합니다.  <ul><li>예: <em>“저는 컨설턴트인데, 다음 주 뉴욕 출장을 가는데 첫 출근 날 무슨 옷을 입으면 좋을까요?”</em></li></ul></li></ol><p align="center">  <img src="/images/aws_basic_66.png" width="80%"></p><ol start="2"><li><strong>Bedrock Agent</strong>가 동작합니다.  <ul><li>Agent는 단순 답변이 아니라, 여러 **Knowledge Base(지식 저장소)**와 연결됩니다.  </li><li>예:  <ul><li><strong>상품 카탈로그</strong> (회사 내부 데이터)  </li><li><strong>패션 트렌드</strong> (공개 데이터셋)  </li><li><strong>주문 내역</strong> (개인 맞춤형 데이터)  </li><li><strong>고객 리뷰</strong> (내부 데이터)</li></ul></li></ul></li></ol><p align="center">  <img src="/images/aws_basic_67.png" width="80%"></p><ol start="3"><li>Agent가 필요한 데이터를 가져와 응답을 생성합니다.  <ul><li>예:  <ul><li>“비즈니스 정장 스타일”과 “비즈니스 캐주얼 스타일” 2가지를 제안  </li><li>이미지 생성 모델을 통해 실제 코디 이미지 생성</li></ul></li></ul></li></ol><p align="center">  <img src="/images/aws_basic_68.png" width="80%"></p><ol start="4"><li>사용자가 추가 질문을 합니다.  <ul><li>예: <em>“이 정장 재킷에 대해 고객들이 뭐라고 하나요?”</em>  </li><li>→ Agent가 고객 리뷰 데이터베이스를 조회 후, “품질, 색상, 원단이 좋다고 합니다. 리뷰 수는 325개입니다.” 라고 요약</li></ul></li></ol><p align="center">  <img src="/images/aws_basic_69.png" width="80%"></p><ol start="5"><li>주문 프로세스까지 연결됩니다.  <ul><li>사이즈 추천: 이전 주문 내역을 참고 → <em>“M 사이즈를 추천합니다”</em>  </li><li>장바구니 추가: Agent가 API 호출을 통해 직접 장바구니에 상품 추가  </li><li>결제 진행: “주문을 완료하시겠습니까?” → API 연동으로 주문 최종 확정</li></ul></li></ol><hr><h2 id="🔑-여기서-중요한-AWS-개념-시험-대비용"><a href="#🔑-여기서-중요한-AWS-개념-시험-대비용" class="headerlink" title="🔑 여기서 중요한 AWS 개념 (시험 대비용)"></a>🔑 여기서 중요한 AWS 개념 (시험 대비용)</h2><ul><li><strong>Bedrock Agent</strong> → 단순 응답이 아니라 <strong>멀티스텝 작업</strong>(multi-step tasks)을 수행할 수 있음  </li><li><strong>Knowledge Base 연동</strong> → 비즈니스 데이터(주문내역, 고객 리뷰 등)를 AI가 직접 활용 가능  </li><li><strong>RAG (Retrieval Augmented Generation)</strong> → 외부 데이터(예: 최신 패션 트렌드)를 가져와 응답 품질 향상  </li><li><strong>API 통합</strong> → 단순 대화형 서비스가 아니라, **실제 시스템 변경(장바구니 추가, 결제 등)**까지 수행  </li><li><strong>보안 &amp; 권한 관리</strong> → IAM Role을 통해 Bedrock이 Knowledge Base나 API에 안전하게 접근해야 함 (시험 단골 질문)  </li><li><strong>CloudWatch 모니터링</strong> → Bedrock Agent의 호출 내역과 성능(지연시간, 토큰 사용량)을 추적 가능</li></ul><hr><h2 id="📝-요약"><a href="#📝-요약" class="headerlink" title="📝 요약"></a>📝 요약</h2><p>Amazon Bedrock은 단순히 <strong>질문에 답하는 AI</strong>가 아니라,<br>👉 <strong>지식베이스와 시스템(API, DB, Lambda 등)을 연동하여 실제 작업을 수행하는 AI 에이전트</strong>를 만들 수 있습니다.  </p><p>AI Stylist 데모는 이 개념을 보여주는 좋은 예시이며, 실제 현업에서는:  </p><ul><li>쇼핑몰 추천 서비스  </li><li>고객 지원 챗봇  </li><li>IT 운영 자동화  </li><li>맞춤형 교육&#x2F;헬스케어 코치</li></ul><p>등으로 확장될 수 있습니다.  </p><hr><p>👉 <strong>한 줄 정리:</strong><br>Amazon Bedrock을 활용하면, 단순한 AI 답변을 넘어서 **실제 업무를 자동화하는 AI 비서(Agent)**를 만들 수 있다.<br>이 과정에서 <strong>Knowledge Base, RAG, API 연동, IAM 권한, CloudWatch 모니터링</strong> 같은 AWS 핵심 서비스 개념이 함께 시험 포인트로 등장할 수 있다.  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;👗-Amazon-Bedrock-End-to-End-Use-Case-AI-Stylist-Demo&quot;&gt;&lt;a href=&quot;#👗-Amazon-Bedrock-End-to-End-Use-Case-AI-Stylist-Demo&quot; class=&quot;heade</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (11) - CloudWatch</title>
    <link href="https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-11/"/>
    <id>https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-11/</id>
    <published>2025-08-20T23:55:07.000Z</published>
    <updated>2025-08-21T04:38:32.185Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📊-Amazon-Bedrock-CloudWatch"><a href="#📊-Amazon-Bedrock-CloudWatch" class="headerlink" title="📊 Amazon Bedrock &amp; CloudWatch"></a>📊 Amazon Bedrock &amp; CloudWatch</h1><h2 id="📌-CloudWatch란"><a href="#📌-CloudWatch란" class="headerlink" title="📌 CloudWatch란?"></a>📌 CloudWatch란?</h2><p><strong>Amazon CloudWatch</strong>는 AWS 리소스와 애플리케이션을 모니터링하는 서비스입니다.<br>CloudWatch는 다음과 같은 기능을 제공합니다:</p><ul><li><strong>Logs (로그)</strong> → 이벤트나 요청 내역을 기록 (디버깅에 유용)  </li><li><strong>Metrics (지표)</strong> → 시스템 성능을 수치로 모니터링  </li><li><strong>Alarms (알람)</strong> → 특정 기준을 넘었을 때 알림 전송  </li><li><strong>Dashboards (대시보드)</strong> → 모니터링 정보를 시각화</li></ul><p>👉 시험에 자주 나오는 포인트:  </p><ul><li><strong>CloudWatch Logs</strong>: 이벤트·로그 기록  </li><li><strong>CloudWatch Metrics</strong>: CPU, 메모리, 지연 시간 같은 성능 수치  </li><li><strong>CloudWatch Alarms</strong>: 기준치 초과 시 알림  </li><li><strong>CloudWatch Dashboards</strong>: 모니터링 결과 시각화</li></ul><hr><h2 id="🔑-Bedrock-CloudWatch-연동"><a href="#🔑-Bedrock-CloudWatch-연동" class="headerlink" title="🔑 Bedrock + CloudWatch 연동"></a>🔑 Bedrock + CloudWatch 연동</h2><h3 id="1-모델-호출-Invocation-로깅"><a href="#1-모델-호출-Invocation-로깅" class="headerlink" title="1. 모델 호출(Invocation) 로깅"></a>1. 모델 호출(Invocation) 로깅</h3><ul><li>Bedrock이 실행될 때 <strong>입력과 출력 전부</strong>를 기록합니다.  </li><li>기록 가능한 데이터:  <ul><li>텍스트 입력&#x2F;출력  </li><li>이미지  </li><li>임베딩(Embedding) 데이터</li></ul></li><li>로그 저장 위치:  <ul><li><strong>CloudWatch Logs</strong> → 실시간 모니터링  </li><li><strong>Amazon S3</strong> → 장기 저장용</li></ul></li></ul><p><strong>장점</strong>  </p><ul><li>모든 모델 사용 내역 추적 가능  </li><li>오류나 지연 시간 문제 분석  </li><li><strong>CloudWatch Logs Insights</strong>로 실시간 쿼리 및 분석</li></ul><hr><h3 id="2-CloudWatch-Metrics-지표"><a href="#2-CloudWatch-Metrics-지표" class="headerlink" title="2. CloudWatch Metrics (지표)"></a>2. CloudWatch Metrics (지표)</h3><ul><li>Bedrock은 성능 관련 지표를 CloudWatch에 보냅니다.  </li><li>주요 지표 예시:<ul><li><strong>Invocation Count</strong>: 호출 횟수  </li><li><strong>Invocation Latency</strong>: 응답 지연 시간  </li><li><strong>Token Usage</strong>: 토큰 사용량  </li><li><strong>ContentFilteredCount</strong>: Guardrails(안전장치)가 콘텐츠를 차단한 횟수</li></ul></li></ul><p><strong>장점</strong>  </p><ul><li>모델 성능을 시간별로 추적 가능  </li><li>지연 시간 스파이크(급증) 파악  </li><li>Guardrails 동작 여부 확인  </li><li><strong>CloudWatch Alarms</strong>을 통해 SLA(서비스 수준 계약) 보장</li></ul><p align="center">  <img src="/images/aws_basic_65.png" width="80%"></p><hr><h2 id="⚙️-실제-동작-흐름-Workflow"><a href="#⚙️-실제-동작-흐름-Workflow" class="headerlink" title="⚙️ 실제 동작 흐름 (Workflow)"></a>⚙️ 실제 동작 흐름 (Workflow)</h2><ol><li><p><strong>Invocation Logging 활성화</strong>  </p><ul><li>Bedrock 콘솔에서 CloudWatch&#x2F;S3 대상 선택  </li><li>로그 그룹 생성 (예: <code>BedrockInvocationLogs</code>)  </li><li>IAM Role 연결</li></ul></li><li><p><strong>모델 호출 실행</strong>  </p><ul><li>예시: <code>Amazon.Titan-Text-Express-V1</code> 모델이 텍스트 처리  </li><li>로그에는 다음이 기록됨:  <ul><li>모델 ID  </li><li>리전(region)  </li><li>입력·출력 토큰 수  </li><li>응답 지연 시간 (예: 4,038ms)</li></ul></li></ul></li><li><p><strong>CloudWatch 모니터링</strong>  </p><ul><li><strong>Logs</strong>: 상세 호출 내역 디버깅  </li><li><strong>Metrics</strong>: 지연 시간 그래프 확인  </li><li><strong>Alarms</strong>: 지연 시간 5초 초과 시 알림 전송</li></ul></li></ol><hr><h2 id="📝-요약표"><a href="#📝-요약표" class="headerlink" title="📝 요약표"></a>📝 요약표</h2><table><thead><tr><th>기능</th><th>설명</th><th>예시</th></tr></thead><tbody><tr><td><strong>Invocation Logging</strong></td><td>모든 입력&#x2F;출력 기록</td><td>CloudWatch Logs, S3 저장</td></tr><tr><td><strong>지원 데이터</strong></td><td>텍스트, 이미지, 임베딩</td><td>사용자 요청 디버깅</td></tr><tr><td><strong>Logs Insights</strong></td><td>실시간 로그 분석</td><td>지연 시간 급증 추적</td></tr><tr><td><strong>Metrics</strong></td><td>성능 지표 수집</td><td>호출 수, 토큰 수, 지연 시간</td></tr><tr><td><strong>ContentFilteredCount</strong></td><td>Guardrail 차단 횟수</td><td>위험 콘텐츠 차단 모니터링</td></tr><tr><td><strong>Alarms</strong></td><td>기준 초과 시 알림</td><td>지연 시간 5초 초과 시 경고</td></tr></tbody></table><hr><h2 id="✅-왜-중요한가"><a href="#✅-왜-중요한가" class="headerlink" title="✅ 왜 중요한가?"></a>✅ 왜 중요한가?</h2><ul><li><strong>투명성</strong> → 모델이 어떻게 사용되는지 추적 가능  </li><li><strong>신뢰성</strong> → 성능 문제를 조기 감지  </li><li><strong>보안·컴플라이언스</strong> → Guardrail 동작 확인 가능  </li><li><strong>최적화</strong> → 토큰&#x2F;호출 패턴 분석으로 비용 최적화 가능</li></ul><hr><p>👉 <strong>한 줄 정리:</strong><br><strong>Amazon Bedrock + CloudWatch</strong>를 연동하면 <strong>AI 모델 사용 현황을 실시간 추적하고, 성능 지표를 모니터링하며, 알람을 통해 안정적인 서비스 운영</strong>이 가능합니다.  </p><hr><p>📌 <strong>시험 대비 포인트</strong>  </p><ul><li>CloudWatch Logs vs S3 → Logs는 실시간 분석, S3는 장기 저장  </li><li>ContentFilteredCount → Bedrock Guardrails 관련 지표  </li><li>Alarms 설정 → 시험 문제에서 “지연 시간이 5초 초과하면 알림 받기” 같은 시나리오 자주 출제됨</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📊-Amazon-Bedrock-CloudWatch&quot;&gt;&lt;a href=&quot;#📊-Amazon-Bedrock-CloudWatch&quot; class=&quot;headerlink&quot; title=&quot;📊 Amazon Bedrock &amp;amp; CloudWatch&quot;&gt;</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (10) - Agents (에이전트)</title>
    <link href="https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-10/"/>
    <id>https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-10/</id>
    <published>2025-08-20T23:51:11.000Z</published>
    <updated>2025-08-21T04:38:32.185Z</updated>
    
    <content type="html"><![CDATA[<h1 id="🤖-Amazon-Bedrock-–-Agents-에이전트"><a href="#🤖-Amazon-Bedrock-–-Agents-에이전트" class="headerlink" title="🤖 Amazon Bedrock – Agents (에이전트)"></a>🤖 Amazon Bedrock – Agents (에이전트)</h1><h2 id="📌-에이전트란"><a href="#📌-에이전트란" class="headerlink" title="📌 에이전트란?"></a>📌 에이전트란?</h2><p>Amazon Bedrock의 <strong>에이전트(Agents)</strong> 는 단순히 질문에 답변하는 모델이 아니라, <strong>여러 단계를 계획하고 실행</strong>할 수 있는 고급 기능입니다.<br>즉, 사람이 “생각하고 → 계획하고 → 행동하는” 과정을 흉내 내서 <strong>실제 작업까지 자동으로 수행</strong>할 수 있습니다.  </p><p>에이전트는 단순 텍스트 생성 외에도 다음과 같은 일을 할 수 있습니다:</p><ul><li>AWS 인프라 생성 (서버, S3, Lambda 등)</li><li>애플리케이션 배포 자동화</li><li>데이터베이스&#x2F;시스템 작업 수행</li><li>외부 API 및 사내 시스템 연동</li></ul><hr><h2 id="🔑-Bedrock-Agents-주요-특징"><a href="#🔑-Bedrock-Agents-주요-특징" class="headerlink" title="🔑 Bedrock Agents 주요 특징"></a>🔑 Bedrock Agents 주요 특징</h2><ul><li><strong>멀티스텝 작업 실행</strong>: 단순 질의응답이 아니라, 여러 단계를 거쳐 복잡한 업무를 수행  </li><li><strong>작업 순서 제어</strong>: 각 단계가 올바른 순서로 실행되고, 데이터가 단계 간 잘 전달됨  </li><li><strong>액션 그룹(Action Groups)</strong>: API, Lambda 함수 등 미리 정의된 작업 단위를 사용  </li><li><strong>시스템 통합</strong>: DB, API, AWS Lambda와 연동하여 실제 비즈니스 작업 실행  </li><li><strong>지식베이스 연동</strong>: 기업 정책, FAQ 같은 내부 데이터 참조 가능  </li><li><strong>RAG (검색 증강 생성)</strong>: 필요시 외부 데이터 검색 후 답변 품질 향상  </li><li><strong>추적 및 디버깅</strong>: 실행된 단계를 하나하나 확인 가능 → 문제 해결 용이</li></ul><p align="center">  <img src="/images/aws_basic_64.png" width="80%"></p><hr><h2 id="⚙️-에이전트-동작-방식"><a href="#⚙️-에이전트-동작-방식" class="headerlink" title="⚙️ 에이전트 동작 방식"></a>⚙️ 에이전트 동작 방식</h2><ol><li><strong>사용자 요청 인식</strong> → 사용자의 질문&#x2F;명령을 분석  </li><li><strong>컨텍스트 평가</strong> → 사용할 수 있는 API, 지식베이스, 액션 그룹 확인  </li><li><strong>계획 수립 (Chain of Thought)</strong> → 단계별 실행 계획 생성  <ul><li>Step 1: API 호출 → 구매 내역 확인  </li><li>Step 2: 지식베이스 조회 → 반품 정책 확인  </li><li>Step 3: Lambda 실행 → 주문 처리</li></ul></li><li><strong>실행</strong> → 계획에 따라 API·Lambda·DB 등을 호출  </li><li><strong>최종 응답 생성</strong> → 실행 결과를 바탕으로 사용자에게 답변 제공  </li><li><strong>추적(Tracing)</strong> → 각 단계 기록을 확인해 디버깅 가능</li></ol><hr><h2 id="🛠️-예시-활용-시나리오"><a href="#🛠️-예시-활용-시나리오" class="headerlink" title="🛠️ 예시 활용 시나리오"></a>🛠️ 예시 활용 시나리오</h2><h3 id="1-전자상거래-고객-지원"><a href="#1-전자상거래-고객-지원" class="headerlink" title="1. 전자상거래 고객 지원"></a>1. 전자상거래 고객 지원</h3><ul><li><strong>사용자 질문</strong>: “지난달에 뭘 샀는지 알려주고, 비슷한 상품 추천해줘.”  </li><li><strong>에이전트 실행</strong>:<ul><li>구매 내역 API 호출</li><li>추천 시스템 조회</li><li>추천 상품 최종 제안</li></ul></li></ul><h3 id="2-인프라-자동화"><a href="#2-인프라-자동화" class="headerlink" title="2. 인프라 자동화"></a>2. 인프라 자동화</h3><ul><li><strong>사용자 명령</strong>: “새로운 애플리케이션 환경을 만들어줘.”  </li><li><strong>에이전트 실행</strong>:<ul><li>AWS 인프라 프로비저닝</li><li>Lambda 함수로 애플리케이션 배포</li><li>배포 상태 확인 후 결과 보고</li></ul></li></ul><hr><h2 id="📝-요약-표"><a href="#📝-요약-표" class="headerlink" title="📝 요약 표"></a>📝 요약 표</h2><table><thead><tr><th>카테고리</th><th>설명</th><th>예시</th></tr></thead><tbody><tr><td><strong>목적</strong></td><td>AI가 여러 단계를 자동 실행</td><td>서버 프로비저닝, 앱 배포</td></tr><tr><td><strong>작업 순서 제어</strong></td><td>단계별 순서와 데이터 전달 보장</td><td>Step1: DB 조회 → Step2: 배포</td></tr><tr><td><strong>액션 그룹</strong></td><td>API&#x2F;Lambda 등 미리 정의된 작업 집합</td><td>구매내역 조회, 주문 실행</td></tr><tr><td><strong>시스템 통합</strong></td><td>DB, API, 서비스와 연결</td><td>백엔드 API 호출, DB 업데이트</td></tr><tr><td><strong>지식베이스</strong></td><td>내부 정책·FAQ 참조</td><td>반품 규정 조회</td></tr><tr><td><strong>RAG</strong></td><td>외부 데이터 검색</td><td>배송 상태 실시간 확인</td></tr><tr><td><strong>추적</strong></td><td>단계별 실행 기록 제공</td><td>실패 단계 디버깅</td></tr></tbody></table><hr><h2 id="✅-Bedrock-Agents를-쓰는-이유"><a href="#✅-Bedrock-Agents를-쓰는-이유" class="headerlink" title="✅ Bedrock Agents를 쓰는 이유"></a>✅ Bedrock Agents를 쓰는 이유</h2><ul><li><strong>자동화</strong> → 인프라&#x2F;운영&#x2F;앱 배포 작업을 자동화해 인력 부담 감소  </li><li><strong>확장성</strong> → 복잡한 워크플로우도 최소한의 코드로 처리 가능  </li><li><strong>정확성</strong> → RAG+지식베이스로 맥락 있는 답변 제공  </li><li><strong>유연성</strong> → AWS 서비스·외부 시스템 연동 가능  </li><li><strong>투명성</strong> → Tracing으로 결과를 신뢰할 수 있음</li></ul><hr><h2 id="📌-시험-대비-포인트-AWS-자격증"><a href="#📌-시험-대비-포인트-AWS-자격증" class="headerlink" title="📌 시험 대비 포인트 (AWS 자격증)"></a>📌 시험 대비 포인트 (AWS 자격증)</h2><ul><li><strong>Bedrock Agents의 역할</strong>: 단순 답변 모델이 아닌, <strong>멀티스텝 자동화와 시스템 통합</strong> 가능  </li><li><strong>Action Group</strong>: API&#x2F;Lambda 같은 작업 단위 → 시험에 자주 나올 개념  </li><li><strong>지식베이스 + RAG 활용</strong>: 기업 데이터와 외부 데이터 결합  </li><li><strong>Tracing 기능</strong>: 디버깅과 신뢰성 확보에 중요한 포인트</li></ul><hr><p>👉 <strong>정리하면</strong><br>Amazon Bedrock Agents는 단순 대화형 AI가 아니라, <strong>실제 행동까지 수행하는 AI 비서</strong>입니다.<br>복잡한 업무를 계획하고 실행하면서, AWS 서비스와 외부 시스템까지 연동해 <strong>현실적인 자동화 솔루션</strong>을 제공합니다.  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;🤖-Amazon-Bedrock-–-Agents-에이전트&quot;&gt;&lt;a href=&quot;#🤖-Amazon-Bedrock-–-Agents-에이전트&quot; class=&quot;headerlink&quot; title=&quot;🤖 Amazon Bedrock – Agents (에이</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (9) - Guardrails (가드레일)</title>
    <link href="https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-9/"/>
    <id>https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-9/</id>
    <published>2025-08-20T23:47:31.000Z</published>
    <updated>2025-08-21T04:38:32.194Z</updated>
    
    <content type="html"><![CDATA[<h1 id="🛡️-Amazon-Bedrock-–-Guardrails-가드레일"><a href="#🛡️-Amazon-Bedrock-–-Guardrails-가드레일" class="headerlink" title="🛡️ Amazon Bedrock – Guardrails (가드레일)"></a>🛡️ Amazon Bedrock – Guardrails (가드레일)</h1><h2 id="📌-Guardrails란-무엇인가"><a href="#📌-Guardrails란-무엇인가" class="headerlink" title="📌 Guardrails란 무엇인가?"></a>📌 Guardrails란 무엇인가?</h2><p>Amazon Bedrock의 <strong>Guardrails(가드레일)</strong> 은 사용자가 입력한 내용과 모델이 생성하는 답변을 <strong>필터링하고 제어하는 안전장치</strong>입니다.<br>즉, AI가 잘못된 답변이나 위험한 내용을 내놓지 않도록 <strong>보호막 역할</strong>을 합니다.</p><p align="center">  <img src="/images/aws_basic_62.png" width="80%"></p><hr><h2 id="🔑-Guardrails-주요-기능"><a href="#🔑-Guardrails-주요-기능" class="headerlink" title="🔑 Guardrails 주요 기능"></a>🔑 Guardrails 주요 기능</h2><ul><li><strong>유해 콘텐츠 차단</strong><br>욕설, 혐오 표현, 성적인 내용, 폭력적인 내용 등을 자동으로 차단</li><li><strong>특정 주제 제한</strong><br>민감하거나 허용하지 않은 주제(예: 의료 조언, 법률 상담, 레시피 등)는 답변하지 않도록 설정</li><li><strong>개인정보 보호(PII)</strong><br>이메일, 전화번호, 주소 같은 개인정보를 자동 감지 후 마스킹 처리</li><li><strong>환각(Hallucination) 줄이기</strong><br>모델이 근거 없는 답변을 하지 않도록 맥락 기반 사실 확인(grounding) 적용</li><li><strong>금지어(Word Filter)</strong><br>직접 정의한 특정 단어·문구를 차단</li><li><strong>정규식(Regex) 필터</strong><br>예: 신용카드 번호, 주민번호 등 특정 패턴 데이터 차단 가능</li><li><strong>다중 가드레일</strong><br>상황별로 여러 가드레일을 동시에 적용 가능</li><li><strong>모니터링</strong><br>위반 로그를 저장해 추후 분석 및 정책 강화 가능</li></ul><hr><h2 id="⚙️-사용-사례-예시"><a href="#⚙️-사용-사례-예시" class="headerlink" title="⚙️ 사용 사례 예시"></a>⚙️ 사용 사례 예시</h2><h3 id="1-제한된-주제-차단"><a href="#1-제한된-주제-차단" class="headerlink" title="1. 제한된 주제 차단"></a>1. 제한된 주제 차단</h3><ul><li><strong>사용자 요청</strong>: “오늘 저녁에 먹을 요리 레시피 추천해줘.”</li><li><strong>Guardrail 동작</strong>: “죄송하지만, 이 주제는 답변할 수 없습니다.”</li></ul><h3 id="2-개인정보-마스킹"><a href="#2-개인정보-마스킹" class="headerlink" title="2. 개인정보 마스킹"></a>2. 개인정보 마스킹</h3><ul><li><strong>사용자 요청</strong>: “<a href="mailto:&#x64;&#97;&#110;&#x6e;&#121;&#x40;&#x65;&#x78;&#x61;&#109;&#x70;&#108;&#x65;&#46;&#99;&#x6f;&#109;">danny@example.com</a> 으로 메일을 보내줘.”</li><li><strong>Guardrail 동작</strong>: 이메일 주소를 <code>[PII 제거됨]</code> 으로 자동 변환</li></ul><hr><h2 id="🛠️-Guardrails-설정-방법"><a href="#🛠️-Guardrails-설정-방법" class="headerlink" title="🛠️ Guardrails 설정 방법"></a>🛠️ Guardrails 설정 방법</h2><ol><li><strong>가드레일 생성</strong> – 이름과 차단 메시지 설정<br>(예: <em>“죄송하지만, 해당 질문에는 답변할 수 없습니다.”</em>)</li><li><strong>필터 규칙 설정</strong>  <ul><li>콘텐츠 필터: 욕설, 성적, 폭력, 혐오 표현 등  </li><li>금지 주제: 의료, 법률, 요리 레시피 등  </li><li>금지 단어&#x2F;정규식: 특정 단어, 신용카드 번호 등  </li><li>PII 필터: 이메일, 전화번호 등 개인정보 마스킹  </li><li>Grounding: 모델 답변이 실제 문서와 일치하는지 검증</li></ul></li><li><strong>테스트</strong> – 입력 프롬프트로 가드레일이 제대로 작동하는지 확인</li><li><strong>모델에 적용</strong> – Anthropic, Claude, Sonnet 등 지원되는 FM(기초 모델)에 연결</li><li><strong>다중 적용 가능</strong> – 여러 가드레일을 동시에 사용해 강화된 제어 가능</li></ol><hr><h2 id="✅-Guardrails를-사용하는-이유"><a href="#✅-Guardrails를-사용하는-이유" class="headerlink" title="✅ Guardrails를 사용하는 이유"></a>✅ Guardrails를 사용하는 이유</h2><ul><li><strong>책임 있는 AI</strong>: 위험하거나 불필요한 답변을 차단  </li><li><strong>개인정보 보호</strong>: 민감한 사용자 정보 자동 제거  </li><li><strong>법적·윤리적 리스크 방지</strong>: 규제 준수 및 기업 신뢰 확보  </li><li><strong>출력 품질 개선</strong>: 더 정확하고 신뢰할 수 있는 응답 제공</li></ul><p>👉 한마디로, Guardrails는 <strong>AI 안전벨트</strong> 역할을 합니다.<br>사용자와 기업 모두를 보호하면서 <strong>안전하고 신뢰할 수 있는 AI 서비스</strong>를 운영할 수 있습니다.  </p><hr><h2 id="📝-Guardrails-요약표"><a href="#📝-Guardrails-요약표" class="headerlink" title="📝 Guardrails 요약표"></a>📝 Guardrails 요약표</h2><table><thead><tr><th>구분</th><th>설명</th><th>예시</th></tr></thead><tbody><tr><td><strong>목적</strong></td><td>모델과 사용자 간 상호작용 제어</td><td>잘못된 답변 방지</td></tr><tr><td><strong>콘텐츠 필터</strong></td><td>혐오, 욕설, 성적, 폭력 차단</td><td>“폭력적인 이야기” 요청 → 차단</td></tr><tr><td><strong>금지 주제</strong></td><td>특정 주제 제한</td><td>의료&#x2F;법률 상담, 레시피</td></tr><tr><td><strong>PII 보호</strong></td><td>개인정보 자동 마스킹</td><td>이메일, 전화번호 제거</td></tr><tr><td><strong>금지어 필터</strong></td><td>특정 단어&#x2F;문구 차단</td><td>비속어 차단</td></tr><tr><td><strong>정규식 필터</strong></td><td>패턴 기반 정보 차단</td><td>신용카드 번호</td></tr><tr><td><strong>Grounding</strong></td><td>답변의 사실성 확인</td><td>근거 없는 생성 방지</td></tr><tr><td><strong>다중 가드레일</strong></td><td>여러 규칙을 함께 적용</td><td>개인정보+유해콘텐츠 동시 필터링</td></tr><tr><td><strong>모니터링</strong></td><td>위반 로그 기록</td><td>보안 정책 강화</td></tr><tr><td><strong>차단 메시지</strong></td><td>사용자에게 보여줄 문구 설정</td><td>“답변할 수 없습니다.”</td></tr></tbody></table><hr><h2 id="✅-시험-대비-포인트-AWS-자격증"><a href="#✅-시험-대비-포인트-AWS-자격증" class="headerlink" title="✅ 시험 대비 포인트 (AWS 자격증)"></a>✅ 시험 대비 포인트 (AWS 자격증)</h2><ul><li><strong>Bedrock Guardrails 핵심</strong>:<br>콘텐츠 필터링 + 개인정보 보호(PII) + Grounding(환각 방지)  </li><li><strong>PII</strong> → 이메일, 전화번호, 주소, 신용카드 등 자동 마스킹  </li><li><strong>Grounding</strong> → “AI가 지어낸 답변(hallucination)을 줄이는 기능”  </li><li><strong>실무 적용</strong>: Guardrails는 <strong>다중 적용 가능</strong>하며 <strong>로그 모니터링</strong> 지원  </li><li><strong>시험 문제 유형 예시</strong>  <blockquote><p>“Bedrock 모델이 사용자의 이메일 주소를 그대로 출력하지 않게 하려면 어떤 기능을 사용해야 하는가?”<br>정답 → <strong>Guardrails의 PII Protection</strong></p></blockquote></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;🛡️-Amazon-Bedrock-–-Guardrails-가드레일&quot;&gt;&lt;a href=&quot;#🛡️-Amazon-Bedrock-–-Guardrails-가드레일&quot; class=&quot;headerlink&quot; title=&quot;🛡️ Amazon Bedrock –</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (8) - 토큰화, 컨텍스트 윈도우, 임베딩</title>
    <link href="https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-8/"/>
    <id>https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-8/</id>
    <published>2025-08-20T23:41:40.000Z</published>
    <updated>2025-08-21T04:38:32.185Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📚-생성형-AI-핵심-개념-–-토큰화-컨텍스트-윈도우-임베딩"><a href="#📚-생성형-AI-핵심-개념-–-토큰화-컨텍스트-윈도우-임베딩" class="headerlink" title="📚 생성형 AI 핵심 개념 – 토큰화, 컨텍스트 윈도우, 임베딩"></a>📚 생성형 AI 핵심 개념 – 토큰화, 컨텍스트 윈도우, 임베딩</h1><p>이 세 가지는 <strong>생성형 AI(GenAI)의 기본 개념</strong>으로, 시험 문제에도 자주 등장하고 LLM(대규모 언어 모델)을 이해하는 데 꼭 필요합니다.  </p><hr><h2 id="1-🔹-토큰화-Tokenization"><a href="#1-🔹-토큰화-Tokenization" class="headerlink" title="1. 🔹 토큰화(Tokenization)"></a>1. 🔹 토큰화(Tokenization)</h2><p><strong>정의</strong><br>텍스트를 모델이 이해할 수 있는 작은 단위인 <strong>토큰(token)</strong> 으로 쪼개는 과정입니다.<br>모델은 단어가 아니라 <strong>토큰 단위</strong>로 학습하고 추론합니다.  </p><p><strong>종류</strong></p><ol><li><strong>단어 단위 토큰화 (Word-based)</strong>  <ul><li>문장을 단어 단위로 분리  </li><li>예: <code>&quot;The cat sat&quot;</code> → <code>[&quot;The&quot;, &quot;cat&quot;, &quot;sat&quot;]</code></li></ul></li><li><strong>서브워드 단위 토큰화 (Subword-based)</strong>  <ul><li>긴 단어나 잘 안 쓰이는 단어를 더 작은 의미 단위로 분리  </li><li>예: <code>&quot;unacceptable&quot;</code> → <code>&quot;un&quot;</code> + <code>&quot;acceptable&quot;</code></li></ul></li></ol><p><strong>중요한 이유</strong></p><ul><li>모델은 <strong>텍스트가 아닌 숫자(토큰 ID)</strong> 로 동작합니다.  </li><li>토큰 개수 &#x3D; <strong>비용과 성능에 직접적인 영향</strong><br>→ 토큰이 많으면 <strong>컨텍스트 윈도우를 빨리 소모</strong>하고 비용도 올라갑니다.  </li><li>구두점, 공백, 심지어 이모지도 각각 토큰입니다.</li></ul><p><strong>예시</strong><br>문장 : <code>&quot;Danny, Good job!! Learning AI technology is incredibly difficult, but it&#39;s worth it.&quot;</code>  </p><ul><li><code>&quot;Danny&quot;</code> &#x3D; 토큰  </li><li><code>&quot;,&quot;</code> &#x3D; 토큰  </li><li><code>&quot;Good&quot;</code> &#x3D; 토큰</li></ul><p align="center">  <img src="/images/aws_basic_58.png" width="80%"></p><p>📌 <strong>시험 포인트</strong>  </p><ul><li>“LLM은 단어 단위가 아니라 토큰 단위로 처리한다” → 정답 키워드  </li><li>토큰 수 계산 연습: <a href="https://platform.openai.com/tokenizer">OpenAI Tokenizer</a></li></ul><hr><h2 id="2-🔹-컨텍스트-윈도우-Context-Window"><a href="#2-🔹-컨텍스트-윈도우-Context-Window" class="headerlink" title="2. 🔹 컨텍스트 윈도우(Context Window)"></a>2. 🔹 컨텍스트 윈도우(Context Window)</h2><p><strong>정의</strong><br>LLM이 한 번에 처리할 수 있는 <strong>최대 토큰 수(입력 + 출력)</strong> 를 의미합니다.  </p><p><strong>왜 중요한가?</strong></p><ul><li>컨텍스트 윈도우가 클수록 많은 정보를 넣을 수 있어 더 정확한 답변을 얻을 수 있습니다.  </li><li>하지만 클수록 <strong>메모리·비용 증가</strong> → 최적화 필요</li></ul><p><strong>대표 모델별 컨텍스트 윈도우</strong></p><table><thead><tr><th>모델</th><th>지원 토큰 수</th><th>대략적인 단어 수</th></tr></thead><tbody><tr><td>GPT-4 Turbo</td><td>128,000</td><td>약 96,000 단어</td></tr><tr><td>Claude 2.1</td><td>200,000</td><td>약 150,000 단어</td></tr><tr><td>Google Gemini 1.5 Pro</td><td>1,000,000</td><td>약 700,000 단어</td></tr></tbody></table><p><strong>체감 예시</strong>  </p><ul><li><strong>100만 토큰</strong> ≈ 책 3~4권, 코드 3만 줄, 오디오 11시간 분량</li></ul><p align="center">  <img src="/images/aws_basic_59.png" width="60%"></p><p>📌 <strong>시험 포인트</strong>  </p><ul><li>“모델을 선택할 때 가장 먼저 고려해야 하는 요소는?” → <strong>컨텍스트 윈도우 크기</strong></li></ul><hr><h2 id="3-🔹-임베딩-Embeddings"><a href="#3-🔹-임베딩-Embeddings" class="headerlink" title="3. 🔹 임베딩(Embeddings)"></a>3. 🔹 임베딩(Embeddings)</h2><p><strong>정의</strong><br>텍스트·이미지·오디오 같은 데이터를 <strong>수치 벡터(vector)</strong> 로 변환한 표현 방식입니다.  </p><p><strong>처리 과정</strong></p><ol><li>텍스트를 <strong>토큰화</strong>  </li><li>토큰에 <strong>ID 부여</strong>  </li><li>임베딩 모델이 각 토큰을 <strong>다차원 벡터</strong>로 변환</li></ol><p>예: <code>&quot;cat&quot;</code> → <code>[0.025, -0.12, 0.33, ...]</code> (보통 100차원 이상)  </p><p align="center">  <img src="/images/aws_basic_60.png" width="80%"></p><p><strong>왜 고차원 벡터?</strong>  </p><ul><li>단어의 여러 특징을 동시에 담을 수 있음  <ul><li>의미(semantic)  </li><li>문법적 역할(syntax)  </li><li>감정(sentiment)</li></ul></li><li>비슷한 단어일수록 벡터 공간에서 <strong>가까이 위치</strong></li></ul><p><strong>시각화 예시 (2D)</strong>  </p><ul><li><code>&quot;dog&quot;</code> ↔ <code>&quot;puppy&quot;</code> → 가까움  </li><li><code>&quot;dog&quot;</code> ↔ <code>&quot;cat&quot;</code> → 비슷한 범주  </li><li><code>&quot;dog&quot;</code> ↔ <code>&quot;house&quot;</code> → 멀리 떨어짐</li></ul><p align="center">  <img src="/images/aws_basic_61.png" width="80%"></p><hr><h3 id="3-1-RAG-검색에서의-임베딩-활용"><a href="#3-1-RAG-검색에서의-임베딩-활용" class="headerlink" title="3.1. RAG &amp; 검색에서의 임베딩 활용"></a>3.1. RAG &amp; 검색에서의 임베딩 활용</h3><ul><li>임베딩은 <strong>벡터 데이터베이스</strong>(예: OpenSearch, Pinecone, FAISS, Redis Vector)에 저장  </li><li>검색 시 쿼리도 벡터로 변환 → <strong>KNN(k-Nearest Neighbors) 검색</strong>으로 가장 가까운 의미를 가진 데이터 반환</li></ul><p>📌 <strong>시험 포인트</strong>  </p><ul><li>“벡터 유사도 검색(vector similarity search)” &#x3D; <strong>KNN 검색</strong>  </li><li>AWS에서는 <strong>OpenSearch Serverless</strong> + <strong>pgvector(Aurora)</strong> 자주 언급</li></ul><hr><h2 id="4-📌-요약-표"><a href="#4-📌-요약-표" class="headerlink" title="4. 📌 요약 표"></a>4. 📌 요약 표</h2><table><thead><tr><th>개념</th><th>설명</th><th>중요한 이유</th><th>예시</th></tr></thead><tbody><tr><td>토큰화</td><td>텍스트를 토큰으로 분리</td><td>모델은 토큰 단위로 처리, 비용·성능에 영향</td><td><code>&quot;unacceptable&quot;</code> → <code>&quot;un&quot;</code>, <code>&quot;acceptable&quot;</code></td></tr><tr><td>컨텍스트 윈도우</td><td>모델이 한 번에 처리 가능한 토큰 수</td><td>클수록 더 많은 문맥 가능, 하지만 비용↑</td><td>GPT-4 Turbo &#x3D; 128k 토큰</td></tr><tr><td>임베딩</td><td>데이터를 숫자 벡터로 변환</td><td>의미·문법·감정을 반영해 검색&#x2F;추천에 활용</td><td><code>&quot;dog&quot;</code> 벡터 ↔ <code>&quot;puppy&quot;</code> 벡터 가까움</td></tr></tbody></table><hr><p>✅ <strong>AWS 시험 핵심 포인트 정리</strong></p><ul><li>토큰 &#x3D; 모델의 최소 단위 (단어가 아님, 구두점도 포함됨).  </li><li>컨텍스트 윈도우 &#x3D; 입력+출력 전체 토큰 수.  </li><li>임베딩 &#x3D; 벡터 표현, <strong>RAG에서 필수</strong>.  </li><li>유사도 검색 &#x3D; <strong>KNN (코사인 유사도&#x2F;유클리드 거리)</strong>.  </li><li>AWS에서 벡터 검색 &#x3D; <strong>OpenSearch</strong> &#x2F; <strong>Aurora(pgvector)</strong> &#x2F; <strong>Neptune Analytics</strong> &#x2F; <strong>S3 Vectors</strong>.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📚-생성형-AI-핵심-개념-–-토큰화-컨텍스트-윈도우-임베딩&quot;&gt;&lt;a href=&quot;#📚-생성형-AI-핵심-개념-–-토큰화-컨텍스트-윈도우-임베딩&quot; class=&quot;headerlink&quot; title=&quot;📚 생성형 AI 핵심 개념 – 토큰화, 컨</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (7) - Amazon Bedrock RAG &amp; Knowledge Base 설정</title>
    <link href="https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-7/"/>
    <id>https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-7/</id>
    <published>2025-08-20T23:32:18.000Z</published>
    <updated>2025-08-21T04:38:32.209Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📚-Amazon-Bedrock-–-RAG-지식-베이스-설정"><a href="#📚-Amazon-Bedrock-–-RAG-지식-베이스-설정" class="headerlink" title="📚 Amazon Bedrock – RAG &amp; 지식 베이스 설정"></a>📚 Amazon Bedrock – RAG &amp; 지식 베이스 설정</h1><p>이 문서는 <strong>Amazon Bedrock</strong>에서 <strong>RAG(Retrieval-Augmented Generation)</strong><br>파이프라인과 **지식 베이스(Knowledge Base)**를 설정하는 방법을 단계별로<br>정리한 가이드입니다.<br>스토리지는 <strong>Amazon S3</strong>, 벡터 데이터베이스는 <strong>Amazon OpenSearch<br>Serverless</strong>를 사용합니다.</p><hr><h2 id="1-🔍-준비-사항"><a href="#1-🔍-준비-사항" class="headerlink" title="1. 🔍 준비 사항"></a>1. 🔍 준비 사항</h2><ul><li><strong>IAM 사용자</strong> (루트 계정 ❌, IAM 계정 ✅)</li><li>IAM 사용자에게 <strong>AdministratorAccess</strong> 정책 부여</li><li>필요한 AWS 서비스:<ul><li>Amazon Bedrock</li><li>Amazon S3</li><li>Amazon OpenSearch Serverless (또는 외부 벡터 DB)</li></ul></li><li>업로드할 문서 파일 (예: <code>evolution_of_the_internet.pdf</code>)</li></ul><hr><h2 id="2-🛠-단계별-설정"><a href="#2-🛠-단계별-설정" class="headerlink" title="2. 🛠 단계별 설정"></a>2. 🛠 단계별 설정</h2><h3 id="Step-1-–-IAM-사용자-만들기"><a href="#Step-1-–-IAM-사용자-만들기" class="headerlink" title="Step 1 – IAM 사용자 만들기"></a>Step 1 – IAM 사용자 만들기</h3><ol><li>IAM 콘솔 → <strong>사용자 생성</strong></li><li>사용자 이름 입력 (예: <code>danny</code>)</li><li><strong>AWS Management Console Access</strong> 활성화</li><li>비밀번호 설정</li><li><strong>AdministratorAccess 정책</strong> 연결</li><li>로그인 URL &#x2F; 계정 정보 저장 후 IAM 사용자로 로그인</li></ol><p align="center">  <img src="/images/aws_basic_31.png" width="80%"></p><hr><h3 id="Step-2-–-Bedrock에서-지식-베이스-생성"><a href="#Step-2-–-Bedrock에서-지식-베이스-생성" class="headerlink" title="Step 2 – Bedrock에서 지식 베이스 생성"></a>Step 2 – Bedrock에서 지식 베이스 생성</h3><ol><li>Bedrock 콘솔 → <strong>Knowledge Bases → Create</strong></li><li>지식 베이스 이름 입력</li></ol><p align="center">  <img src="/images/aws_basic_36.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_37.png" width="80%"></p><ol start="3"><li>IAM 권한 → <strong>새 서비스 역할 생성</strong></li><li><strong>데이터 소스 선택</strong> → Amazon S3</li><li>(선택) 다른 데이터 소스:<ul><li>웹 크롤러 (웹 페이지)</li><li>Confluence</li><li>Salesforce</li><li>SharePoint</li></ul></li></ol><p align="center">  <img src="/images/aws_basic_32.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_33.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_34.png" width="20%"></p><p align="center">  <img src="/images/aws_basic_35.png" width="20%"></p><hr><h3 id="Step-3-–-Amazon-S3-버킷-만들고-문서-업로드"><a href="#Step-3-–-Amazon-S3-버킷-만들고-문서-업로드" class="headerlink" title="Step 3 – Amazon S3 버킷 만들고 문서 업로드"></a>Step 3 – Amazon S3 버킷 만들고 문서 업로드</h3><ol><li>S3 콘솔 → <strong>버킷 생성</strong><ul><li>리전: <code>us-east-1</code></li><li>버킷 이름: 전 세계에서 유일해야 함 (예: <code>my-kb-bucket-danny</code>)</li></ul></li><li>문서 업로드</li><li>업로드 확인 (객체 리스트에서 보이는지 체크)</li></ol><p align="center">  <img src="/images/aws_basic_38.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_39.png" width="80%"></p><hr><h3 id="Step-4-–-S3와-Bedrock-지식-베이스-연결"><a href="#Step-4-–-S3와-Bedrock-지식-베이스-연결" class="headerlink" title="Step 4 – S3와 Bedrock 지식 베이스 연결"></a>Step 4 – S3와 Bedrock 지식 베이스 연결</h3><ol><li>Bedrock 지식 베이스 생성 중 → <strong>데이터 소스에 S3 버킷 선택</strong></li></ol><p align="center">  <img src="/images/aws_basic_40.png" width="80%"></p><ol start="2"><li>임베딩 모델 선택:<ul><li><strong>Amazon Titan Text Embeddings V2</strong> (기본)</li></ul></li><li>벡터 데이터베이스 선택:<ul><li><strong>시험 대비 포인트</strong> → Amazon OpenSearch Serverless (가장 자주 언급됨)</li><li>외부 DB → Pinecone(무료 티어 제공)</li></ul></li></ol><p>⚠️ 비용 주의: OpenSearch Serverless는 최소 약 <strong>$172&#x2F;월</strong> 발생 → 테스트 후 반드시 삭제 필요!</p><p align="center">  <img src="/images/aws_basic_41.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_42.png" width="80%"></p><hr><h3 id="Step-5-–-데이터-동기화"><a href="#Step-5-–-데이터-동기화" class="headerlink" title="Step 5 – 데이터 동기화"></a>Step 5 – 데이터 동기화</h3><ol><li>지식 베이스에서 <strong>Sync</strong> 실행<ul><li>PDF → 텍스트 청크 분할 → 임베딩 생성 → 벡터 DB 저장</li></ul></li><li>OpenSearch에서 컬렉션 &#x2F; 인덱스 확인 가능</li></ol><p align="center">  <img src="/images/aws_basic_43.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_44.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_45.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_46.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_47.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_48.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_49.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_50.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_51.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_52.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_53.png" width="80%"></p><hr><h3 id="Step-6-–-지식-베이스-테스트"><a href="#Step-6-–-지식-베이스-테스트" class="headerlink" title="Step 6 – 지식 베이스 테스트"></a>Step 6 – 지식 베이스 테스트</h3><ol><li>모델 선택 (예: <strong>Anthropic Claude Haiku</strong>)</li><li>질문 입력 (예: <code>&quot;World Wide Web을 만든 사람은 누구야?&quot;</code>)</li><li>Bedrock 내부 처리:<ul><li>벡터 DB에서 관련 청크 검색</li><li>질문 + 검색 결과를 합쳐서 프롬프트 생성</li><li>모델이 최종 답변 생성 (출처 포함)</li></ul></li><li>출처 링크 클릭 시 → S3 문서 열람 가능</li></ol><p align="center">  <img src="/images/aws_basic_54.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_55.png" width="80%"></p><hr><h2 id="3-🧠-내부-동작-원리-RAG"><a href="#3-🧠-내부-동작-원리-RAG" class="headerlink" title="3. 🧠 내부 동작 원리 (RAG)"></a>3. 🧠 내부 동작 원리 (RAG)</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">flowchart TD</span><br><span class="line">    A[📂 Amazon S3 문서] --&gt; B[✂️ 청크 분할 &amp; 임베딩 생성&lt;br/&gt;(Amazon Titan)]</span><br><span class="line">    B --&gt; C[🗄 벡터 DB&lt;br/&gt;OpenSearch Serverless]</span><br><span class="line">    C --&gt; D[🔍 KNN 검색]</span><br><span class="line">    D --&gt; E[📑 관련 청크 추출]</span><br><span class="line">    E --&gt; F[📝 쿼리와 합쳐서 프롬프트 생성]</span><br><span class="line">    F --&gt; G[🤖 모델이 답변 생성 + 출처 제공]</span><br></pre></td></tr></table></figure><ul><li><strong>Chunking (청크 분할)</strong>: 큰 문서를 작은 단위로 나눔\</li><li><strong>Embeddings (임베딩)</strong>: 텍스트를 숫자 벡터로 변환\</li><li><strong>KNN 검색</strong>: 가장 유사한 k개의 벡터를 찾아냄\</li><li><strong>Augmented Prompt</strong>: 원래 질문 + 검색된 내용 → 더 정확한 답변</li></ul><hr><h2 id="4-🛑-비용-절감-–-리소스-정리"><a href="#4-🛑-비용-절감-–-리소스-정리" class="headerlink" title="4. 🛑 비용 절감 – 리소스 정리"></a>4. 🛑 비용 절감 – 리소스 정리</h2><p>테스트 끝난 후: 1. Bedrock 지식 베이스 삭제 2. OpenSearch Serverless 컬렉션 삭제 3. (선택) S3 버킷 유지 또는 삭제 (S3는 저렴)</p><p align="center">  <img src="/images/aws_basic_56.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_57.png" width="80%"></p><hr><h2 id="5-📌-시험-대비-핵심-포인트"><a href="#5-📌-시험-대비-핵심-포인트" class="headerlink" title="5. 📌 시험 대비 핵심 포인트"></a>5. 📌 시험 대비 핵심 포인트</h2><ul><li><strong>루트 계정은 Bedrock 지식 베이스 생성 불가 → IAM 사용자 사용해야 함</strong></li><li><strong>벡터 DB 선택지 (시험에 자주 등장)</strong>:<ul><li>OpenSearch (KNN 검색)</li><li>Aurora PostgreSQL (pgvector 확장)</li><li>Neptune Analytics (그래프 기반 RAG)</li><li>S3 Vectors (저비용, 초저지연 검색)</li></ul></li><li><strong>외부 벡터 DB</strong>: Pinecone, Redis, MongoDB Atlas</li><li><strong>데이터 소스 확장성</strong>: S3, 웹 크롤러, Salesforce, Confluence,SharePoint 등</li><li><strong>RAG 핵심 정의</strong>: Retrieve → Augment → Generate</li></ul><hr><p>✅ <strong>정리</strong>:<br>Amazon Bedrock에서 <strong>S3 + OpenSearch</strong> 기반의 지식 베이스를 구축하고, <strong>Titan 임베딩 모델</strong>로 벡터를 생성한 뒤, <strong>KNN 검색 + LLM 응답</strong>까지 연결하는 과정을 마쳤습니다.<br>이 흐름은 <strong>AWS 자격증 시험</strong>에서도 자주 등장하는 주제이므로 꼭 이해하고 기억해두세요.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📚-Amazon-Bedrock-–-RAG-지식-베이스-설정&quot;&gt;&lt;a href=&quot;#📚-Amazon-Bedrock-–-RAG-지식-베이스-설정&quot; class=&quot;headerlink&quot; title=&quot;📚 Amazon Bedrock – RAG &amp;a</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (6) - Amazon Bedrock RAG &amp; Knowledge Base</title>
    <link href="https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-6/"/>
    <id>https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-6/</id>
    <published>2025-08-20T23:27:08.000Z</published>
    <updated>2025-08-21T04:38:32.213Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📚-Amazon-Bedrock-–-RAG-Knowledge-Base"><a href="#📚-Amazon-Bedrock-–-RAG-Knowledge-Base" class="headerlink" title="📚 Amazon Bedrock – RAG &amp; Knowledge Base"></a>📚 Amazon Bedrock – RAG &amp; Knowledge Base</h1><h2 id="1-🔍-RAG란-무엇일까"><a href="#1-🔍-RAG란-무엇일까" class="headerlink" title="1. 🔍 RAG란 무엇일까?"></a>1. 🔍 RAG란 무엇일까?</h2><p><strong>RAG (Retrieval-Augmented Generation)</strong> 은  </p><blockquote><p>외부 데이터에서 정보를 <strong>검색(Retrieve)</strong> 하고 → 이를 <strong>프롬프트에 추가(Augment)</strong> 하여 → 모델이 더 정확한 답변을 <strong>생성(Generate)</strong> 하는 방법이에요.</p></blockquote><ul><li><strong>검색(Retrieval)</strong>: 모델이 학습하지 못한 최신 데이터나 특정 도메인 데이터를 가져와요.  </li><li><strong>증강(Augmentation)</strong>: 검색한 데이터를 질문과 합쳐서 모델에 전달해요.  </li><li><strong>장점</strong>: 모델을 새로 학습(Fine-tuning)하지 않고도 최신 지식을 반영할 수 있어요.</li></ul><hr><h2 id="2-🏗-동작-방식-Step-by-Step"><a href="#2-🏗-동작-방식-Step-by-Step" class="headerlink" title="2. 🏗 동작 방식 (Step-by-Step)"></a>2. 🏗 동작 방식 (Step-by-Step)</h2><ol><li><strong>데이터 저장소</strong>  <ul><li>Amazon S3, Confluence, SharePoint, Salesforce, 웹사이트 등에 문서를 저장</li></ul></li><li><strong>벡터 임베딩 생성</strong>  <ul><li>Bedrock이 문서를 작은 조각으로 나누고  </li><li>Amazon Titan, Cohere 같은 임베딩 모델로 숫자 벡터로 변환</li></ul></li><li><strong>벡터 데이터베이스 저장</strong>  <ul><li>변환된 벡터를 OpenSearch, Aurora, Neptune, S3 Vectors 같은 벡터 DB에 저장</li></ul></li><li><strong>쿼리 처리</strong>  <ul><li>사용자가 질문하면 → 질문도 벡터로 변환 → DB에서 유사한 벡터 검색</li></ul></li><li><strong>프롬프트 증강</strong>  <ul><li>검색된 결과를 원래 질문과 합쳐서 모델에 전달</li></ul></li><li><strong>답변 생성</strong>  <ul><li>Claude, Titan Text, Llama 같은 모델이 맥락을 이해하고 답변 + 출처 제공</li></ul></li></ol>  <p align="center">  <img src="/images/aws_basic_27.png" width="100%">  </p><hr><h2 id="3-🛠-주요-구성-요소"><a href="#3-🛠-주요-구성-요소" class="headerlink" title="3. 🛠 주요 구성 요소"></a>3. 🛠 주요 구성 요소</h2><table><thead><tr><th>구성 요소</th><th>설명</th><th>AWS &#x2F; 외부 옵션</th></tr></thead><tbody><tr><td><strong>데이터 소스</strong></td><td>원본 데이터 저장 위치</td><td>Amazon S3, Confluence, SharePoint, Salesforce, 웹사이트</td></tr><tr><td><strong>임베딩 모델</strong></td><td>텍스트를 벡터로 변환</td><td>Amazon Titan, Cohere</td></tr><tr><td><strong>벡터 DB</strong></td><td>벡터 저장 및 검색</td><td>OpenSearch, Aurora, Neptune, S3 Vectors &#x2F; Pinecone, Redis, MongoDB</td></tr><tr><td><strong>기초 모델</strong></td><td>최종 답변 생성</td><td>Claude, Titan Text, Llama 등</td></tr></tbody></table><hr><h2 id="4-📊-AWS-벡터-DB-비교-시험-포인트"><a href="#4-📊-AWS-벡터-DB-비교-시험-포인트" class="headerlink" title="4. 📊 AWS 벡터 DB 비교 (시험 포인트!)"></a>4. 📊 AWS 벡터 DB 비교 (시험 포인트!)</h2><table><thead><tr><th>서비스</th><th>특징</th><th>활용 사례</th></tr></thead><tbody><tr><td><strong>OpenSearch</strong></td><td>실시간 검색, KNN 지원, 서버리스 모드 있음</td><td>대규모 실시간 검색 &amp; 분석</td></tr><tr><td><strong>Aurora PostgreSQL</strong></td><td>RDB에 벡터 검색 통합 (pgvector)</td><td>기존 SQL 시스템에 RAG 결합</td></tr><tr><td><strong>Neptune Analytics</strong></td><td>그래프 기반 검색 (GraphRAG)</td><td>관계 중심 데이터, 그래프 분석</td></tr><tr><td><strong>S3 Vectors</strong></td><td>저비용, 높은 내구성, 빠른 쿼리</td><td>장기 보관 및 비용 최적화</td></tr></tbody></table>  <p align="center">  <img src="/images/aws_basic_28.png" width="100%">  </p><p>✅ <strong>시험 꿀팁</strong>  </p><ul><li>“실시간 대규모 검색” → <strong>OpenSearch</strong>  </li><li>“그래프 관계 중심” → <strong>Neptune</strong>  </li><li>“저비용&#x2F;고내구성” → <strong>S3 Vectors</strong></li></ul><hr><h2 id="5-📌-왜-KNN-검색이-중요한가"><a href="#5-📌-왜-KNN-검색이-중요한가" class="headerlink" title="5. 📌 왜 KNN 검색이 중요한가?"></a>5. 📌 왜 KNN 검색이 중요한가?</h2><p>RAG에서 <strong>KNN (k-Nearest Neighbors)</strong> 검색은 가장 중요한 단계예요.  </p><ul><li>문서와 질문을 벡터로 변환 → 서로의 “거리”를 계산 → 가장 가까운 k개 문서 검색  </li><li>거리 계산 방법: <strong>코사인 유사도(Cosine Similarity)</strong>, <strong>유클리드 거리</strong> 등  </li><li><strong>AWS 시험에서는</strong> “semantic search”, “vector similarity search” &#x3D; <strong>KNN 검색</strong>을 의미한다고 보면 돼요.  </li><li>OpenSearch의 <strong>Approximate k-NN</strong> 은 <strong>대규모 실시간 검색</strong>에 자주 출제돼요.</li></ul><hr><h2 id="6-💡-대표적인-활용-사례"><a href="#6-💡-대표적인-활용-사례" class="headerlink" title="6. 💡 대표적인 활용 사례"></a>6. 💡 대표적인 활용 사례</h2><ol><li><strong>고객 서비스 챗봇</strong> → 제품 매뉴얼, FAQ, 트러블슈팅 문서 기반 답변  </li><li><strong>법률 리서치</strong> → 판례, 법령, 규제 문서를 검색해 정확한 출처와 함께 제공  </li><li><strong>헬스케어 Q&amp;A</strong> → 질병, 치료, 연구 논문 데이터를 기반으로 답변</li></ol><hr><h2 id="7-🧪-실습-예시-–-“내-문서와-대화하기”"><a href="#7-🧪-실습-예시-–-“내-문서와-대화하기”" class="headerlink" title="7. 🧪 실습 예시 – “내 문서와 대화하기”"></a>7. 🧪 실습 예시 – “내 문서와 대화하기”</h2><ul><li><p><strong>목표</strong>: 업로드한 문서를 기반으로 질문-답변 챗봇 만들기  </p></li><li><p><strong>절차</strong>  </p><ol><li>AWS Console → <strong>Knowledge Bases</strong> 이동  </li><li>“Chat with your document” 선택  </li><li>문서 업로드  </li><li>질문 입력 → <em>예: “WWW를 발명한 사람은 누구야?”</em>  </li><li>모델이 문서 검색 → 관련 문단 찾아서 답변 생성 (출처 포함)</li></ol><p align="center"><img src="/images/aws_basic_29.png" width="100%"></p>  <p align="center"><img src="/images/aws_basic_30.png" width="100%"></p></li><li><p><strong>시험 팁</strong>: 답변할 데이터가 없을 땐 “제공된 데이터에 해당 내용이 없습니다” 라고 응답해야 함</p></li></ul><hr><h2 id="8-📌-시험-대비-핵심-요약"><a href="#8-📌-시험-대비-핵심-요약" class="headerlink" title="8. 📌 시험 대비 핵심 요약"></a>8. 📌 시험 대비 핵심 요약</h2><ul><li><strong>RAG 정의</strong>: 외부 데이터 검색 + 프롬프트 증강 → 더 정확한 답변  </li><li><strong>Bedrock 장점</strong>: 임베딩 생성, KB 관리, FM 연결 자동화  </li><li><strong>벡터 DB 옵션</strong>: OpenSearch, Aurora, Neptune, S3 Vectors  </li><li><strong>데이터 소스</strong>: S3, Confluence, SharePoint, Salesforce, 웹페이지  </li><li><strong>사용 사례</strong>: 챗봇, 법률 검색, 의료 지식 Q&amp;A  </li><li><strong>시험 자주 나오는 키워드</strong>  <ul><li>“vector similarity search” &#x3D; <strong>k-NN</strong>  </li><li>“Provisioned Throughput” &#x3D; <strong>커스텀 모델 필수</strong>  </li><li>“Fine-tuning vs RAG” → Fine-tuning &#x3D; 모델 자체 수정, RAG &#x3D; 데이터 추가만</li></ul></li></ul><hr><p>✅ <strong>추가 시험 포인트</strong></p><ul><li><strong>Fine-tuning</strong> 은 모델 가중치 변경, 비용 ↑, 데이터 필요 ↑  </li><li><strong>RAG</strong> 는 가중치 변경 없음, 최신 데이터 반영, 비용 ↓  </li><li><strong>Bedrock KB</strong> 는 <strong>S3, Confluence, Salesforce</strong> 등 다양한 소스와 직접 연결 가능  </li><li><strong>Aurora (pgvector)</strong> 는 기존 SQL DB를 사용하는 기업에서 자주 언급됨</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📚-Amazon-Bedrock-–-RAG-Knowledge-Base&quot;&gt;&lt;a href=&quot;#📚-Amazon-Bedrock-–-RAG-Knowledge-Base&quot; class=&quot;headerlink&quot; title=&quot;📚 Amazon Bedroc</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (5) - Amazon Bedrock 모델 평가 가이드</title>
    <link href="https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-5/"/>
    <id>https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-5/</id>
    <published>2025-08-20T23:21:35.000Z</published>
    <updated>2025-08-21T04:38:32.213Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📊-Amazon-Bedrock-–-모델-평가-가이드"><a href="#📊-Amazon-Bedrock-–-모델-평가-가이드" class="headerlink" title="📊 Amazon Bedrock – 모델 평가 가이드"></a>📊 Amazon Bedrock – 모델 평가 가이드</h1><p>Amazon Bedrock에서 <strong>Foundation Model (FM)</strong> 을 평가하는 과정은 단순히 성능 확인을 넘어서,<br>👉 <strong>품질 관리</strong>, 👉 <strong>비즈니스 효과 측정</strong>, 👉 <strong>편향성(bias) 탐지</strong> 를 위해 꼭 필요합니다.  </p><p>Bedrock은 크게 <strong>자동 평가</strong>와 <strong>사람에 의한 평가</strong> 두 가지 방식을 제공하며,<br>평가 시에는 <strong>기술적인 지표(ROUGE, BLEU 등)</strong> 와 <strong>비즈니스 지표(만족도, 매출 등)</strong> 를 함께 고려해야 합니다.  </p><hr><h2 id="1-🔄-자동-평가-Automatic-Evaluation"><a href="#1-🔄-자동-평가-Automatic-Evaluation" class="headerlink" title="1. 🔄 자동 평가 (Automatic Evaluation)"></a>1. 🔄 자동 평가 (Automatic Evaluation)</h2><p>Bedrock이 직접 모델의 성능을 점수화해주는 방식입니다.  </p><p><strong>지원되는 기본 과제(Task)</strong></p><ul><li>텍스트 요약 (Summarization)  </li><li>질문–답변 (Q&amp;A)  </li><li>텍스트 분류 (Classification)  </li><li>자유 텍스트 생성 (Open-ended Generation)</li></ul><p><strong>작동 방식</strong></p><ol><li><strong>평가용 데이터셋 준비</strong>  <ul><li>AWS가 제공하는 벤치마크 데이터 또는 직접 만든 데이터.  </li><li>질문과 ‘정답’(이상적인 답변)을 포함.</li></ul></li><li><strong>모델 테스트</strong>  <ul><li>준비된 질문을 모델에 입력 → 모델이 답변 생성.</li></ul></li><li><strong>자동 비교</strong>  <ul><li>‘심판 모델’이 모델 답변을 정답과 비교 → 점수 산출.  </li><li>ROUGE, BLEU, BERTScore 같은 지표 활용.</li></ul></li></ol><p>✅ 장점: 빠르고 일관성 있음, 관리 부담 적음, 편향 탐지 가능.</p><p align="center">  <img src="/images/aws_basic_20.png" width="100%"></p><hr><h2 id="2-🧑-사람-평가-Human-Evaluation"><a href="#2-🧑-사람-평가-Human-Evaluation" class="headerlink" title="2. 🧑 사람 평가 (Human Evaluation)"></a>2. 🧑 사람 평가 (Human Evaluation)</h2><p>사람(내부 직원, 전문가)이 직접 모델의 답변을 보고 평가하는 방식입니다.  </p><p><strong>평가 방법</strong></p><ul><li>👍 &#x2F; 👎 (좋아요&#x2F;싫어요)  </li><li>여러 답변 순위 매기기  </li><li>별점이나 커스텀 점수 방식</li></ul><p>✅ 장점: 기계가 잡아내기 어려운 <strong>미묘한 품질 차이</strong>나 <strong>도메인 특화된 답변</strong> 평가에 유리.</p><p align="center">  <img src="/images/aws_basic_23.png" width="100%"></p><hr><h2 id="3-📏-주요-자동-평가-지표"><a href="#3-📏-주요-자동-평가-지표" class="headerlink" title="3. 📏 주요 자동 평가 지표"></a>3. 📏 주요 자동 평가 지표</h2><ul><li><strong>ROUGE</strong> → 생성된 답변과 기준 텍스트 간의 단어&#x2F;구문 겹치는 정도 (요약 평가에 적합)  </li><li><strong>BLEU</strong> → 번역 품질 평가 (짧은 답변에 불이익 주지 않음)  </li><li><strong>BERTScore</strong> → 단순 단어가 아니라 <strong>의미(semantic similarity)</strong> 기반 비교  </li><li><strong>Perplexity</strong> → 모델이 다음 단어를 얼마나 잘 예측하는지 (낮을수록 좋음)</li></ul><p align="center">  <img src="/images/aws_basic_21.png" width="100%"></p><p>📌 <strong>시험 포인트</strong>: 지표별 특징을 구분해서 외워두는 게 중요합니다.  </p><hr><h2 id="4-💼-비즈니스-지표-Business-Metrics"><a href="#4-💼-비즈니스-지표-Business-Metrics" class="headerlink" title="4. 💼 비즈니스 지표 (Business Metrics)"></a>4. 💼 비즈니스 지표 (Business Metrics)</h2><table><thead><tr><th>지표</th><th>의미</th><th>예시</th></tr></thead><tbody><tr><td><strong>사용자 만족도</strong></td><td>모델 결과에 대한 유저 반응</td><td>챗봇 설문조사 결과</td></tr><tr><td><strong>ARPU</strong></td><td>유저 1명당 평균 매출</td><td>추천 AI 도입 후 매출 증가</td></tr><tr><td><strong>전환율(Conversion)</strong></td><td>행동으로 이어진 비율</td><td>클릭 → 구매 비율</td></tr><tr><td><strong>효율성</strong></td><td>인프라 대비 성능</td><td>비용 줄이면서 정확도 유지</td></tr></tbody></table><p>시험에서는 <strong>기술 지표 + 비즈니스 지표 둘 다 묻는 문제</strong>가 자주 나옵니다.</p><hr><h2 id="5-📚-RAG-Retrieval-Augmented-Generation-Knowledge-Base"><a href="#5-📚-RAG-Retrieval-Augmented-Generation-Knowledge-Base" class="headerlink" title="5. 📚 RAG (Retrieval-Augmented Generation) &amp; Knowledge Base"></a>5. 📚 RAG (Retrieval-Augmented Generation) &amp; Knowledge Base</h2><ul><li><strong>RAG</strong>: 모델이 외부 DB(최신 문서, 데이터베이스 등)에서 필요한 정보를 가져와 답변에 반영하는 방식.  </li><li><strong>동작 흐름</strong>:  <ol><li>문서를 임베딩(벡터화)  </li><li>벡터 DB에 저장  </li><li>질문 시 관련 데이터 검색  </li><li>검색 결과를 프롬프트에 넣고 모델이 최종 답변 생성</li></ol></li></ul><p align="center">  <img src="/images/aws_basic_22.png" width="100%"></p><p>📌 시험에서 “실시간 최신 데이터 반영” → <strong>RAG</strong>가 정답일 확률 높음.</p><hr><h2 id="6-📝-AWS-자격증-시험에서-중요한-포인트"><a href="#6-📝-AWS-자격증-시험에서-중요한-포인트" class="headerlink" title="6. 📝 AWS 자격증 시험에서 중요한 포인트"></a>6. 📝 AWS 자격증 시험에서 중요한 포인트</h2><ul><li><strong>ROUGE ↔ Summarization</strong>, <strong>BLEU ↔ Translation</strong>, <strong>BERTScore ↔ 의미 비교</strong> 구분 필수  </li><li><strong>Perplexity 낮을수록 좋은 모델</strong>  </li><li><strong>Bias(편향) 검출도 평가 목적</strong> 중 하나  </li><li>Bedrock에서 <strong>평가(Evaluation) 기능</strong>은 콘솔 메뉴에 있음  </li><li><strong>Provisioned Throughput</strong> (전용 리소스 예약) 개념 자주 출제됨  </li><li><strong>RAG</strong> &#x3D; 실시간 데이터 반영 &#x2F; <strong>Fine-tuning</strong> &#x3D; 도메인 특화 학습</li></ul><hr><h2 id="7-🚀-AWS-Bedrock에서-실제-평가-방법"><a href="#7-🚀-AWS-Bedrock에서-실제-평가-방법" class="headerlink" title="7. 🚀 AWS Bedrock에서 실제 평가 방법"></a>7. 🚀 AWS Bedrock에서 실제 평가 방법</h2><ol><li><p>콘솔에서 <strong>Evaluations</strong> 메뉴 클릭  </p><p align="center"></li></ol>  <img src="/images/aws_basic_24.png" width="100%">  </p><ol start="2"><li><strong>Create Evaluation</strong> → 자동&#x2F;사람 평가 선택  </li><li>평가할 모델 선택 (여러 개 비교 가능)  </li><li>과제(Task) 유형 선택 (요약, 분류, Q&amp;A 등)  </li><li>데이터셋 선택 (AWS 제공 or 직접 업로드)  </li><li>평가 지표(ROUGE, BLEU, BERTScore, Perplexity) 선택</li></ol>  <p align="center">  <img src="/images/aws_basic_25.png" width="100%">  </p>  <p align="center">  <img src="/images/aws_basic_26.png" width="100%">  </p>  <ol start="7"><li>평가 실행 (Start Evaluation)  </li><li>결과 리포트 확인 (점수 + 예시 답변 + 편향 여부)</li></ol><p>📌 시험에서 “어떻게 평가하나요?” → 위 단계를 기억하면 답하기 쉽습니다.  </p><hr><h2 id="✅-정리"><a href="#✅-정리" class="headerlink" title="✅ 정리"></a>✅ 정리</h2><p>Amazon Bedrock의 모델 평가는 크게  </p><ul><li><strong>자동 평가 (지표 기반)</strong>  </li><li><strong>사람 평가 (주관적 판단)</strong><br>두 가지로 나뉘며, 실제 프로젝트에서는 <strong>비즈니스 지표</strong>와 함께 봐야 합니다.</li></ul><p>시험에서는 <strong>평가 지표의 특징</strong>과 <strong>RAG, Fine-Tuning, Provisioned Throughput 개념</strong>이 자주 출제됩니다.  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📊-Amazon-Bedrock-–-모델-평가-가이드&quot;&gt;&lt;a href=&quot;#📊-Amazon-Bedrock-–-모델-평가-가이드&quot; class=&quot;headerlink&quot; title=&quot;📊 Amazon Bedrock – 모델 평가 가이드&quot;&gt;&lt;/a</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (4) - Amazon Bedrock 파인튜닝 &amp; 모델 선택</title>
    <link href="https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-4/"/>
    <id>https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-4/</id>
    <published>2025-08-20T23:07:22.000Z</published>
    <updated>2025-08-21T04:38:32.216Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📚-Amazon-Bedrock-파인튜닝-모델-선택"><a href="#📚-Amazon-Bedrock-파인튜닝-모델-선택" class="headerlink" title="📚 Amazon Bedrock 파인튜닝 &amp; 모델 선택"></a>📚 Amazon Bedrock 파인튜닝 &amp; 모델 선택</h1><h2 id="1-다양한-제공자와-모델-특징"><a href="#1-다양한-제공자와-모델-특징" class="headerlink" title="1. 다양한 제공자와 모델 특징"></a>1. 다양한 제공자와 모델 특징</h2><ul><li>대표 제공자(Providers): Anthropic, Amazon, DeepSeek, Stability AI 등  </li><li>각 모델마다 잘하는 분야가 다름:  <ul><li><strong>Claude 3.5 Haiku</strong> → 텍스트 처리에 최적화  </li><li><strong>Amazon Nova Reel</strong> → 텍스트-영상, 이미지-영상 변환</li></ul></li><li>💡 <strong>시험 포인트</strong>: 시험에서 “어떤 모델이 제일 좋은가?”를 묻지 않음 → <strong>각 모델이 할 수 있는 것과 못 하는 것만 구분</strong></li></ul><hr><h2 id="2-모델-비교하기"><a href="#2-모델-비교하기" class="headerlink" title="2. 모델 비교하기"></a>2. 모델 비교하기</h2><ul><li>Bedrock Playground에서 여러 모델을 나란히 테스트 가능  </li><li>비교 기준:  <ul><li>✅ 지원 기능 (텍스트, 이미지, 비디오)  </li><li>✅ 출력 스타일&#x2F;형식  </li><li>✅ 속도(지연 시간)  </li><li>✅ 비용(토큰 사용량)</li></ul></li><li>예시:  <ul><li><strong>Nova Micro</strong> → 이미지 업로드 불가 ❌, 대신 빠르고 간단한 답변  </li><li><strong>Claude 3.5 Sonnet</strong> → 이미지 지원 가능 ✅, 길고 상세한 답변</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_11.png" width="100%"></p><hr><h2 id="3-파인튜닝-방법-비교-시험-자주-출제"><a href="#3-파인튜닝-방법-비교-시험-자주-출제" class="headerlink" title="3. 파인튜닝 방법 비교 (시험 자주 출제!)"></a>3. 파인튜닝 방법 비교 (시험 자주 출제!)</h2><table><thead><tr><th>구분</th><th>Instruction-Based Fine-Tuning</th><th>Continued Pre-Training</th><th>Transfer Learning</th></tr></thead><tbody><tr><td><strong>데이터 유형</strong></td><td>라벨링된 데이터 (프롬프트–응답 쌍)</td><td>라벨링 안 된 원본 텍스트</td><td>라벨링&#x2F;비라벨링 모두 가능</td></tr><tr><td><strong>목표</strong></td><td>특정 태스크&#x2F;톤&#x2F;스타일 맞춤</td><td>특정 도메인 전문화</td><td>다른 유사한 태스크로 전이</td></tr><tr><td><strong>예시</strong></td><td>특정 톤으로 대답하는 챗봇</td><td>AWS 문서 전체 학습 → AWS 전문가 모델</td><td>의료 분야 텍스트 분류</td></tr><tr><td><strong>모델 가중치 변경?</strong></td><td>✅ 변경됨</td><td>✅ 변경됨</td><td>✅ 변경됨</td></tr><tr><td><strong>복잡도</strong></td><td>중간</td><td>높음</td><td>다양</td></tr><tr><td><strong>비용</strong></td><td>상대적으로 저렴</td><td>매우 비쌈 (데이터 많음)</td><td>상황에 따라 다름</td></tr><tr><td><strong>시험 키워드</strong></td><td>“라벨링 데이터”, “프롬프트–응답”</td><td>“비라벨링 데이터”, “도메인 적응”</td><td>“새로운 유사 태스크 적응”</td></tr><tr><td><strong>Bedrock 지원</strong></td><td>일부 모델 지원</td><td>일부 모델 지원</td><td>일반 ML 개념 (Bedrock 전용 아님)</td></tr></tbody></table><blockquote><p>Instruction-based Fine Tuning</p></blockquote><p align="center">  <img src="/images/aws_basic_16.png" width="100%"></p><blockquote><p>Continued Pre-training</p></blockquote><p align="center">  <img src="/images/aws_basic_17.png" width="100%"></p><hr><h2 id="4-메시징-파인튜닝"><a href="#4-메시징-파인튜닝" class="headerlink" title="4. 메시징 파인튜닝"></a>4. 메시징 파인튜닝</h2><ul><li><strong>단일 턴(Single-Turn)</strong>: 질문 1개 → 답변 1개, 필요 시 <code>system</code> 컨텍스트 추가</li></ul><p align="center">  <img src="/images/aws_basic_18.png" width="100%"></p><ul><li><strong>다중 턴(Multi-Turn)</strong>: 대화처럼 <code>user</code>와 <code>assistant</code>가 번갈아 대화 → 챗봇 훈련에 활용</li></ul><p align="center">  <img src="/images/aws_basic_19.png" width="100%"></p><hr><h2 id="5-전이-학습-Transfer-Learning"><a href="#5-전이-학습-Transfer-Learning" class="headerlink" title="5. 전이 학습 (Transfer Learning)"></a>5. 전이 학습 (Transfer Learning)</h2><ul><li>정의: 이미 학습된 모델을 새로운 유사한 작업에 활용  </li><li>예시:  <ul><li>이미지 분류 (고양이 vs 강아지 → 꽃 분류)  </li><li>NLP 모델 (BERT, GPT) 재활용</li></ul></li><li>💡 <strong>시험 팁</strong>:  <ul><li>일반 ML 문제 → <strong>Transfer Learning</strong>  </li><li>Bedrock 관련 → <strong>Fine-Tuning</strong></li></ul></li></ul><hr><h2 id="6-Bedrock에서-파인튜닝-조건"><a href="#6-Bedrock에서-파인튜닝-조건" class="headerlink" title="6. Bedrock에서 파인튜닝 조건"></a>6. Bedrock에서 파인튜닝 조건</h2><ul><li>학습 데이터는 반드시:  <ul><li><strong>Amazon S3에 저장</strong>  </li><li>정해진 <strong>포맷</strong> 준수</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_15.png" width="100%"></p><ul><li><p><strong>Provisioned Throughput</strong> 필요:  </p><ul><li>커스텀 모델 생성 시  </li><li>커스텀 모델 사용 시</li></ul><p align="center"><img src="/images/aws_basic_12.png" width="100%"></li></ul></p><p align="center">  <img src="/images/aws_basic_13.png" width="100%"></p><p align="center">  <img src="/images/aws_basic_14.png" width="100%"></p><ul><li>모든 모델이 파인튜닝 가능한 건 아님 → 주로 오픈소스 모델 지원</li></ul><hr><h2 id="7-파인튜닝-활용-사례"><a href="#7-파인튜닝-활용-사례" class="headerlink" title="7. 파인튜닝 활용 사례"></a>7. 파인튜닝 활용 사례</h2><ul><li>특정 톤&#x2F;페르소나 챗봇 제작  </li><li>최신 지식 반영  </li><li>기업 내부 <strong>비공개 데이터</strong> 활용 (고객 로그, 내부 문서)  </li><li>분류 정확도 향상, 응답 스타일 조정</li></ul><hr><h2 id="8-시험-팁-정리"><a href="#8-시험-팁-정리" class="headerlink" title="8. 시험 팁 정리"></a>8. 시험 팁 정리</h2><ul><li>“라벨링 데이터” → Instruction-Based Fine-Tuning  </li><li>“비라벨링 데이터 &#x2F; 도메인 적응” → Continued Pre-Training  </li><li>“새로운 유사 작업 적응” → Transfer Learning  </li><li>Bedrock에서 커스텀 모델 &#x3D; <strong>Provisioned Throughput 필수</strong>  </li><li>파인튜닝 &#x3D; 모델 가중치 변경 → 내 전용 모델 생성  </li><li>모델 비교 시 → 품질뿐 아니라 <strong>속도와 비용</strong> 고려</li></ul><hr><h2 id="9-추가로-알아두면-좋은-점"><a href="#9-추가로-알아두면-좋은-점" class="headerlink" title="9. 추가로 알아두면 좋은 점"></a>9. 추가로 알아두면 좋은 점</h2><ul><li>FM 전체 재학습은 비용·시간 모두 매우 큼  </li><li>Instruction 기반 파인튜닝은 상대적으로 저렴 (적은 데이터, 적은 연산)  </li><li>하지만 <strong>전문 ML 엔지니어</strong> 필요  </li><li>과정: <strong>데이터 준비 → 파인튜닝 → 모델 평가 → 운영</strong>  </li><li>파인튜닝 모델 실행 시도 <strong>Provisioned Throughput 필요 → 비용 추가</strong></li></ul><hr><h2 id="10-Provisioned-Throughput-중요-시험-포인트"><a href="#10-Provisioned-Throughput-중요-시험-포인트" class="headerlink" title="10. Provisioned Throughput (중요 시험 포인트!)"></a>10. Provisioned Throughput (중요 시험 포인트!)</h2><ul><li><strong>정의</strong>: 커스텀 모델을 위한 전용 처리 용량 예약  </li><li><strong>필요 이유</strong>:  <ul><li>안정적 성능 보장  </li><li>트래픽 증가 시 성능 저하 방지  </li><li>예측 가능한 비용 관리</li></ul></li><li>💡 <strong>시험 팁</strong>: Bedrock에서 커스텀 모델 &#x3D; 무조건 <strong>Provisioned Throughput 필요</strong></li></ul><hr><h2 id="✅-시험-핵심-요약표"><a href="#✅-시험-핵심-요약표" class="headerlink" title="✅ 시험 핵심 요약표"></a>✅ 시험 핵심 요약표</h2><table><thead><tr><th>구분</th><th>핵심 포인트</th><th>시험 키워드</th></tr></thead><tbody><tr><td><strong>모델 제공자</strong></td><td>Anthropic, Amazon, DeepSeek, Stability AI 등</td><td>“어떤 모델이 제일 좋은가?” ❌, “할 수 있는 것&#x2F;못하는 것” ✅</td></tr><tr><td><strong>모델 비교 기준</strong></td><td>기능(텍스트&#x2F;이미지&#x2F;비디오), 출력 스타일, 속도, 비용</td><td>Compare Mode</td></tr><tr><td><strong>Instruction-Based Fine-Tuning</strong></td><td>라벨링 데이터 필요 (프롬프트–응답 쌍), 비용 낮음, 특정 톤&#x2F;스타일 맞춤</td><td><strong>Labeled data</strong>, Prompt–Response</td></tr><tr><td><strong>Continued Pre-Training</strong></td><td>비라벨링 데이터로 도메인 전문화, 데이터·비용 큼</td><td><strong>Unlabeled data</strong>, Domain Adaptation</td></tr><tr><td><strong>Transfer Learning</strong></td><td>기존 모델을 새로운 유사 작업에 적응</td><td>Adapt model to new task</td></tr><tr><td><strong>메시징 파인튜닝</strong></td><td>단일 턴(Single-Turn), 다중 턴(Multi-Turn) 지원</td><td>Chatbot Training</td></tr><tr><td><strong>Provisioned Throughput</strong></td><td>커스텀 모델 생성&#x2F;운영 시 필수, 전용 처리 용량 예약</td><td>Required for Bedrock Custom Models</td></tr><tr><td><strong>비용 절감</strong></td><td>Instruction-Based FT가 가장 저렴, Full FM 재학습은 비용 매우 큼</td><td>Cost Optimization</td></tr></tbody></table><hr><h2 id="📌-추가-시험-포인트"><a href="#📌-추가-시험-포인트" class="headerlink" title="📌 추가 시험 포인트"></a>📌 추가 시험 포인트</h2><ul><li>파인튜닝은 모델 <strong>가중치를 변경</strong>하여 <strong>내 전용 모델</strong>을 만드는 것  </li><li>Bedrock은 모든 모델이 파인튜닝 가능한 건 아님 → 주로 오픈소스 모델 지원  </li><li>커스텀 모델은 반드시 <strong>Provisioned Throughput 필요</strong>  </li><li>모델 비교 시 <strong>속도와 비용</strong>도 중요  </li><li>Fine-Tuning 단계: <strong>데이터 준비 → 학습 → 평가 → 운영</strong>  </li><li>실행 비용은 일반 모델보다 높음 (전용 리소스 사용)</li></ul><hr><p>👉 <strong>결론</strong>:<br>Amazon Bedrock 파인튜닝 &#x3D; 내 데이터로 맞춤형 모델을 만들 수 있는 기능<br>시험 핵심 &#x3D; <strong>키워드 매핑(라벨링 vs 비라벨링 vs 새로운 태스크) + Provisioned Throughput</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📚-Amazon-Bedrock-파인튜닝-모델-선택&quot;&gt;&lt;a href=&quot;#📚-Amazon-Bedrock-파인튜닝-모델-선택&quot; class=&quot;headerlink&quot; title=&quot;📚 Amazon Bedrock 파인튜닝 &amp;amp; 모델 선택&quot;&gt;</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (3) - 생성형 AI &amp; Amazon Bedrock</title>
    <link href="https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-3/"/>
    <id>https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-3/</id>
    <published>2025-08-20T23:02:20.000Z</published>
    <updated>2025-08-21T04:38:32.220Z</updated>
    
    <content type="html"><![CDATA[<h1 id="🧠-생성형-AI-Amazon-Bedrock"><a href="#🧠-생성형-AI-Amazon-Bedrock" class="headerlink" title="🧠 생성형 AI &amp; Amazon Bedrock"></a>🧠 생성형 AI &amp; Amazon Bedrock</h1><h2 id="1-생성형-AI란"><a href="#1-생성형-AI란" class="headerlink" title="1. 생성형 AI란?"></a>1. 생성형 AI란?</h2><ul><li><strong>Generative AI (생성형 AI)</strong>: 학습한 데이터를 바탕으로 <strong>새로운 데이터</strong>를 만들어내는 AI.  </li><li>만들 수 있는 것들: 텍스트, 이미지, 오디오, 코드, 비디오  </li><li>예시: ChatGPT가 사람처럼 대화 문장을 만들어내는 것.</li></ul><hr><h2 id="2-파운데이션-모델-Foundation-Models-FM"><a href="#2-파운데이션-모델-Foundation-Models-FM" class="headerlink" title="2. 파운데이션 모델(Foundation Models, FM)"></a>2. 파운데이션 모델(Foundation Models, FM)</h2><ul><li>대규모 데이터로 학습된 초거대 AI 모델.  </li><li>개발 비용이 매우 큼 (수백억~수천억 원).  </li><li>대표 모델:<ul><li>OpenAI → GPT 시리즈  </li><li>Meta → LLaMA  </li><li>Google → BERT, Gemini  </li><li>Amazon → Titan  </li><li>Anthropic → Claude</li></ul></li><li>오픈소스(무료)와 상용(유료) 모델이 있음.</li></ul><hr><h2 id="3-대규모-언어-모델-LLM"><a href="#3-대규모-언어-모델-LLM" class="headerlink" title="3. 대규모 언어 모델(LLM)"></a>3. 대규모 언어 모델(LLM)</h2><ul><li>텍스트 생성에 특화된 AI.  </li><li>수십억 개 이상의 파라미터.  </li><li>활용: 번역, 요약, Q&amp;A, 글쓰기</li></ul><hr><h2 id="4-언어-모델-동작-방식"><a href="#4-언어-모델-동작-방식" class="headerlink" title="4. 언어 모델 동작 방식"></a>4. 언어 모델 동작 방식</h2><ol><li>사용자가 <strong>프롬프트 입력</strong>  </li><li>모델이 확률적으로 <strong>다음 단어 예측</strong>  </li><li>문장 출력  </li><li>같은 입력이라도 답변이 달라질 수 있음 → <strong>비결정적 특성</strong></li></ol><p>💡 시험 포인트: LLM은 <strong>확률 기반 모델</strong>이라는 점!  </p><hr><h2 id="5-Amazon-Bedrock-개요"><a href="#5-Amazon-Bedrock-개요" class="headerlink" title="5. Amazon Bedrock 개요"></a>5. Amazon Bedrock 개요</h2><ul><li>AWS의 생성형 AI 서비스  </li><li><strong>완전 관리형</strong> → 서버 관리 불필요  </li><li><strong>사용량 기반 과금(On-Demand)</strong>  </li><li>하나의 API로 여러 파운데이션 모델 사용 가능  </li><li>제공 기능:<ul><li>RAG (검색 + 생성 결합)  </li><li>LLM Agents (자동화 지원)</li></ul></li><li>보안·프라이버시·책임 있는 AI 강조</li></ul><p align="center">  <img src="/images/aws_basic_5.png" width="100%"></p><hr><h2 id="6-Bedrock과-파운데이션-모델"><a href="#6-Bedrock과-파운데이션-모델" class="headerlink" title="6. Bedrock과 파운데이션 모델"></a>6. Bedrock과 파운데이션 모델</h2><ul><li>개인 전용 환경에서 모델 사용 → 데이터가 공유되지 않음  </li><li>내 데이터로 파인튜닝 가능  </li><li>내 데이터는 공용 모델 학습에 쓰이지 않음  </li><li><strong>Amazon Titan</strong>:<ul><li>텍스트, 이미지, 멀티모달 지원  </li><li>맞춤화 가능  </li><li>작은 모델 선택 시 비용 절감</li></ul></li></ul><hr><h2 id="7-Bedrock-사용-방법"><a href="#7-Bedrock-사용-방법" class="headerlink" title="7. Bedrock 사용 방법"></a>7. Bedrock 사용 방법</h2><ol><li>모델 접근 권한 신청</li></ol><p align="center">  <img src="/images/aws_basic_6.png" width="70%"></p><ol start="2"><li>프롬프트 테스트</li></ol><p align="center">  <img src="/images/aws_basic_7.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_8.png" width="70%"></p><ol start="3"><li>이미지 생성 플레이그라운드 활용</li></ol><p align="center">  <img src="/images/aws_basic_9.png" width="70%"></p><hr><h2 id="8-제공-모델-예시"><a href="#8-제공-모델-예시" class="headerlink" title="8. 제공 모델 예시"></a>8. 제공 모델 예시</h2><ul><li>Amazon Titan  </li><li>Meta LLaMA  </li><li>Anthropic Claude  </li><li>Stable Diffusion (이미지 생성)</li></ul><p align="center">  <img src="/images/aws_basic_10.png" width="70%"></p><hr><h2 id="✅-시험-대비-요약표"><a href="#✅-시험-대비-요약표" class="headerlink" title="✅ 시험 대비 요약표"></a>✅ 시험 대비 요약표</h2><table><thead><tr><th>구분</th><th>핵심 포인트</th></tr></thead><tbody><tr><td><strong>Gen AI</strong></td><td>데이터를 바탕으로 새 콘텐츠 생성 (텍스트, 이미지, 오디오 등)</td></tr><tr><td><strong>FM (Foundation Models)</strong></td><td>대규모 학습 모델, 오픈소스&#x2F;상용 모두 존재</td></tr><tr><td><strong>LLM</strong></td><td>텍스트 특화, 번역·요약·Q&amp;A 가능</td></tr><tr><td><strong>LLM 동작 원리</strong></td><td>확률 기반 예측 → 같은 입력도 다른 출력 가능</td></tr><tr><td><strong>Bedrock 특징</strong></td><td>완전 관리형, 서버리스, 여러 FM을 API로 통합 제공</td></tr><tr><td><strong>보안&#x2F;데이터</strong></td><td>내 데이터는 공용 학습에 사용되지 않음</td></tr><tr><td><strong>제공 기능</strong></td><td>RAG, LLM Agents</td></tr><tr><td><strong>비용 모델</strong></td><td>On-Demand (사용량 기반)</td></tr><tr><td><strong>Amazon Titan</strong></td><td>텍스트·이미지·멀티모달, 커스터마이징 가능</td></tr></tbody></table><hr><p>👉 결론: <strong>Amazon Bedrock &#x3D; 다양한 생성형 AI 모델을 보안적으로 안전하게, 서버 관리 없이, 비용 효율적으로 활용할 수 있는 서비스</strong>  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;🧠-생성형-AI-Amazon-Bedrock&quot;&gt;&lt;a href=&quot;#🧠-생성형-AI-Amazon-Bedrock&quot; class=&quot;headerlink&quot; title=&quot;🧠 생성형 AI &amp;amp; Amazon Bedrock&quot;&gt;&lt;/a&gt;🧠 생성형 A</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (2) - AWS 비용 &amp; 예산 관리</title>
    <link href="https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-2/"/>
    <id>https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-2/</id>
    <published>2025-08-20T23:00:05.000Z</published>
    <updated>2025-08-21T04:38:32.220Z</updated>
    
    <content type="html"><![CDATA[<h1 id="💰-AWS-비용-예산-관리"><a href="#💰-AWS-비용-예산-관리" class="headerlink" title="💰 AWS 비용 &amp; 예산 관리"></a>💰 AWS 비용 &amp; 예산 관리</h1><h2 id="1-IAM-사용자-접근-설정"><a href="#1-IAM-사용자-접근-설정" class="headerlink" title="1. IAM 사용자 접근 설정"></a>1. IAM 사용자 접근 설정</h2><ul><li>AWS에서 <strong>비용과 결제(Billing &amp; Cost Management)</strong> 화면을 보려면,<br>단순히 계정만 있다고 바로 볼 수 있는 게 아니에요.  </li><li><strong>관리자(Admin)</strong> 가 먼저 설정에서<br>👉 <strong>“IAM 사용자 및 역할이 Billing 정보에 접근할 수 있도록 허용”</strong> 옵션을 켜줘야 합니다.  </li><li>이렇게 해야 IAM 사용자도 비용 내역을 확인할 수 있습니다.</li></ul><p align="center">  <img src="/images/aws_basic_3.png" width="100%"></p><hr><h2 id="2-주요-비용-관리-도구"><a href="#2-주요-비용-관리-도구" class="headerlink" title="2. 주요 비용 관리 도구"></a>2. 주요 비용 관리 도구</h2><ul><li><p><strong>Bills (청구서)</strong><br>→ 매달 AWS가 어떤 서비스에서 얼마를 썼는지 <strong>상세 내역</strong>을 보여줍니다.  </p></li><li><p><strong>Free Tier (프리 티어)</strong><br>→ 신규 계정에 제공되는 <strong>무료 사용량</strong>이 얼마나 남았는지 확인할 수 있습니다.<br>💡 <em>예: EC2 750시간 무료, S3 5GB 저장 무료 등</em>  </p></li><li><p><strong>Budgets (예산 관리)</strong><br>→ 내가 설정한 금액을 초과하면 <strong>이메일로 알림</strong>을 줍니다.<br>💡 <em>예: 한 달 예산을 10달러로 정해두고, 예상 사용량이 10달러를 넘으면 경고 메일 받기</em></p></li></ul><p align="center">  <img src="/images/aws_basic_4.png" width="100%"></p><hr><h2 id="✅-추가로-알아두면-좋은-점"><a href="#✅-추가로-알아두면-좋은-점" class="headerlink" title="✅ 추가로 알아두면 좋은 점"></a>✅ 추가로 알아두면 좋은 점</h2><ul><li><strong>Cost Explorer</strong>: 서비스별, 날짜별로 얼마나 썼는지 그래프로 확인 가능 → 비용 추세 파악에 유용.  </li><li><strong>알림 설정</strong>: Budgets와 SNS(알림 서비스)를 연동하면 <strong>문자·푸시 알림</strong>도 받을 수 있음.  </li><li><strong>Tip</strong>: AWS 비용은 <strong>끄지 않은 리소스(EC2, RDS 등)</strong> 때문에 많이 새어나가는 경우가 많아요. 사용하지 않으면 꼭 꺼두는 습관이 필요합니다.</li></ul><hr><p>👉 정리하면,<br>AWS 비용 관리의 핵심은 <strong>“청구서 확인(Bills) → 무료 혜택 확인(Free Tier) → 예산 알림 설정(Budgets)”</strong> 순서로 관리하는 것입니다.  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;💰-AWS-비용-예산-관리&quot;&gt;&lt;a href=&quot;#💰-AWS-비용-예산-관리&quot; class=&quot;headerlink&quot; title=&quot;💰 AWS 비용 &amp;amp; 예산 관리&quot;&gt;&lt;/a&gt;💰 AWS 비용 &amp;amp; 예산 관리&lt;/h1&gt;&lt;h2 id=&quot;1</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (1) - IT &amp; AWS 기초</title>
    <link href="https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-1/"/>
    <id>https://kish191919.github.io/2025/08/20/KO-AWS-Certified-AI-Practitioner-1/</id>
    <published>2025-08-20T22:54:12.000Z</published>
    <updated>2025-08-21T04:38:32.220Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📚-IT-AWS-기초-요약"><a href="#📚-IT-AWS-기초-요약" class="headerlink" title="📚 IT &amp; AWS 기초 요약"></a>📚 IT &amp; AWS 기초 요약</h1><h2 id="1-기본-IT-용어"><a href="#1-기본-IT-용어" class="headerlink" title="1. 기본 IT 용어"></a>1. 기본 IT 용어</h2><ul><li><strong>네트워크(Network)</strong>: 케이블, 라우터, 서버 등이 연결되어 데이터가 오가는 길.  </li><li><strong>라우터(Router)</strong>: 인터넷에서 데이터를 어디로 보낼지 길잡이 역할을 하는 장치.  </li><li><strong>스위치(Switch)</strong>: 네트워크 안에서 데이터가 정확한 서버나 컴퓨터로 가도록 도와주는 장치.</li></ul><p align="center">  <img src="/images/aws_basic_1.png" width="60%"></p><hr><h2 id="2-클라우드-컴퓨팅의-5가지-핵심-특징"><a href="#2-클라우드-컴퓨팅의-5가지-핵심-특징" class="headerlink" title="2. 클라우드 컴퓨팅의 5가지 핵심 특징"></a>2. 클라우드 컴퓨팅의 5가지 핵심 특징</h2><ol><li><strong>즉시 자원 사용(On-demand self service)</strong> → 필요한 자원을 바로 얻을 수 있음.  </li><li><strong>넓은 네트워크 접근(Broad network access)</strong> → 인터넷만 있으면 여러 기기에서 접근 가능.  </li><li><strong>자원 공유(Multi-tenancy &amp; Resource pooling)</strong> → 여러 사용자가 안전하게 같은 자원 공유.  </li><li><strong>빠른 확장성(Rapid elasticity &amp; Scalability)</strong> → 필요에 따라 서버나 자원을 늘리거나 줄일 수 있음.  </li><li><strong>사용량 기반 과금(Measured service)</strong> → 쓴 만큼만 비용 지불.</li></ol><hr><h2 id="3-클라우드의-6가지-장점"><a href="#3-클라우드의-6가지-장점" class="headerlink" title="3. 클라우드의 6가지 장점"></a>3. 클라우드의 6가지 장점</h2><ul><li>하드웨어 구매 필요 없음 → 사용한 만큼만 지불.  </li><li>대규모 운영으로 비용 절감.  </li><li>실제 사용량에 따라 자동 확장 가능.  </li><li>개발과 배포가 훨씬 빨라짐.  </li><li>직접 데이터 센터를 운영·관리할 필요 없음.  </li><li>전 세계 어디든 빠르게 서비스 제공 가능.</li></ul><hr><h2 id="4-클라우드가-해결하는-문제들"><a href="#4-클라우드가-해결하는-문제들" class="headerlink" title="4. 클라우드가 해결하는 문제들"></a>4. 클라우드가 해결하는 문제들</h2><ul><li><strong>유연성</strong>: 자원의 종류나 크기를 쉽게 변경 가능.  </li><li><strong>비용 효율성</strong>: 사용량 기반 결제 (Pay-as-you-go).  </li><li><strong>확장성(Scalability)</strong>: 트래픽이 늘어나면 서버&#x2F;하드웨어 추가 가능.  </li><li><strong>탄력성(Elasticity)</strong>: 필요할 때 늘리고 줄이는 자동 조정.  </li><li><strong>고가용성 &amp; 장애 대응</strong>: 여러 데이터 센터에 분산되어 있어 안정적.  </li><li><strong>민첩성(Agility)</strong>: 빠른 개발과 서비스 출시 가능.</li></ul><hr><h2 id="5-클라우드-서비스-종류와-예시"><a href="#5-클라우드-서비스-종류와-예시" class="headerlink" title="5. 클라우드 서비스 종류와 예시"></a>5. 클라우드 서비스 종류와 예시</h2><ul><li><strong>IaaS (Infrastructure as a Service)</strong>: 기본 인프라 제공 → AWS EC2, GCP, Azure  </li><li><strong>PaaS (Platform as a Service)</strong>: 개발 환경 제공 → AWS Elastic Beanstalk, Heroku  </li><li><strong>SaaS (Software as a Service)</strong>: 소프트웨어 자체 제공 → Gmail, Dropbox, Zoom</li></ul><p align="center">  <img src="/images/aws_basic_2.png" width="60%"></p><hr><h2 id="6-AWS-요금-기본-개념"><a href="#6-AWS-요금-기본-개념" class="headerlink" title="6. AWS 요금 기본 개념"></a>6. AWS 요금 기본 개념</h2><ul><li><strong>컴퓨팅(Compute)</strong>: 서버를 사용한 시간만큼 비용 지불.  </li><li><strong>스토리지(Storage)</strong>: 클라우드에 저장된 데이터 용량에 따라 과금.  </li><li><strong>데이터 전송(Data Transfer)</strong>: 클라우드 <strong>밖으로 나가는 데이터</strong>만 비용 발생 (들어오는 건 무료).</li></ul><p>💡 <strong>Tip</strong>: AWS 요금은 주로 <em>사용한 만큼만 내는 구조</em>라서 불필요한 리소스를 꺼두는 습관이 중요합니다.  </p><hr><h2 id="7-AWS-리전-Region"><a href="#7-AWS-리전-Region" class="headerlink" title="7. AWS 리전(Region)"></a>7. AWS 리전(Region)</h2><ul><li><strong>리전(Region)</strong> &#x3D; 전 세계에 있는 데이터 센터 묶음.  </li><li>선택 기준:<ul><li>법적·규제 준수  </li><li>고객과의 거리 (지연 시간 ↓)  </li><li>리전마다 제공되는 서비스 여부  </li><li>가격 차이</li></ul></li></ul><hr><h2 id="8-AWS-가용-영역-Availability-Zone-AZ"><a href="#8-AWS-가용-영역-Availability-Zone-AZ" class="headerlink" title="8. AWS 가용 영역(Availability Zone, AZ)"></a>8. AWS 가용 영역(Availability Zone, AZ)</h2><ul><li>한 리전 안에는 보통 3~6개의 독립된 데이터 센터가 존재.  </li><li>각각 전력, 네트워크가 중복 구성되어 있어 장애에 강함.  </li><li>서로 떨어져 있지만 고속 네트워크로 연결되어 있음.</li></ul><hr><h2 id="9-AWS-엣지-로케이션-Edge-Locations"><a href="#9-AWS-엣지-로케이션-Edge-Locations" class="headerlink" title="9. AWS 엣지 로케이션(Edge Locations)"></a>9. AWS 엣지 로케이션(Edge Locations)</h2><ul><li>전 세계 40여 개국, 90여 도시, 400개 이상의 엣지 위치 운영.  </li><li>주로 <strong>콘텐츠 전송(CDN, CloudFront)</strong> 에 사용 → 사용자에게 더 빠르게 서비스 제공.</li></ul><hr><h2 id="10-AWS-서비스-범위"><a href="#10-AWS-서비스-범위" class="headerlink" title="10. AWS 서비스 범위"></a>10. AWS 서비스 범위</h2><ul><li><strong>전 세계(Global) 서비스</strong>: IAM, Route 53, CloudFront, WAF  </li><li><strong>리전별 서비스(Region-specific)</strong>: EC2, Elastic Beanstalk, Lambda, Rekognition</li></ul><hr><h3 id="✅-추가로-알아두면-좋은-점"><a href="#✅-추가로-알아두면-좋은-점" class="headerlink" title="✅ 추가로 알아두면 좋은 점"></a>✅ 추가로 알아두면 좋은 점</h3><ul><li><strong>Cloud vs On-Premise 차이</strong>: 클라우드는 필요할 때만 자원 쓰고 꺼둘 수 있지만, 온프레미스는 서버를 직접 사고 관리해야 함.  </li><li><strong>Cloud 비용 관리 팁</strong>: CloudWatch, Budgets 같은 AWS 도구를 활용해 실시간으로 비용을 추적하고 경고 설정 가능.</li></ul><hr><p>👉 이렇게 보면 클라우드는 “필요할 때 쓰고, 쓰는 만큼만 내고, 어디서든 빠르게 확장할 수 있는 IT 인프라” 라고 이해하면 됩니다.  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📚-IT-AWS-기초-요약&quot;&gt;&lt;a href=&quot;#📚-IT-AWS-기초-요약&quot; class=&quot;headerlink&quot; title=&quot;📚 IT &amp;amp; AWS 기초 요약&quot;&gt;&lt;/a&gt;📚 IT &amp;amp; AWS 기초 요약&lt;/h1&gt;&lt;h2 id=&quot;1</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(12) - Pricing &amp; Model Improvement</title>
    <link href="https://kish191919.github.io/2025/08/20/AWS-Certified-AI-Practitioner-12/"/>
    <id>https://kish191919.github.io/2025/08/20/AWS-Certified-AI-Practitioner-12/</id>
    <published>2025-08-20T22:46:03.000Z</published>
    <updated>2025-08-21T04:38:32.220Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📘-Amazon-Bedrock-–-Pricing-Model-Improvement"><a href="#📘-Amazon-Bedrock-–-Pricing-Model-Improvement" class="headerlink" title="📘 Amazon Bedrock – Pricing &amp; Model Improvement"></a>📘 Amazon Bedrock – Pricing &amp; Model Improvement</h1><h2 id="1️⃣-Pricing-Options"><a href="#1️⃣-Pricing-Options" class="headerlink" title="1️⃣ Pricing Options"></a>1️⃣ Pricing Options</h2><h3 id="🔹-On-Demand-Pay-as-you-go"><a href="#🔹-On-Demand-Pay-as-you-go" class="headerlink" title="🔹 On-Demand (Pay-as-you-go)"></a>🔹 On-Demand (Pay-as-you-go)</h3><ul><li><strong>How it works</strong>: Pay only for what you use, like an electricity bill.  </li><li><strong>Pricing basis</strong>  <ul><li>Text Models → Input&#x2F;Output token count  </li><li>Embedding Models → Input token count  </li><li>Image Models → Number of images generated</li></ul></li><li><strong>Available Models</strong>: Base Models only  </li><li>✅ <strong>Pros</strong>: Flexible, good for unpredictable workloads  </li><li>❌ <strong>Cons</strong>: Can become expensive if used continuously over time</li></ul><hr><h3 id="🔹-Batch-Mode-Bulk-processing-up-to-50-discount"><a href="#🔹-Batch-Mode-Bulk-processing-up-to-50-discount" class="headerlink" title="🔹 Batch Mode (Bulk processing, up to 50% discount)"></a>🔹 Batch Mode (Bulk processing, up to 50% discount)</h3><ul><li><strong>How it works</strong>: Group multiple requests together → results stored as a single file in Amazon S3  </li><li><strong>Discount</strong>: Up to 50% cheaper  </li><li>✅ <strong>Pros</strong>: Great for large-scale processing, strong cost savings  </li><li>❌ <strong>Cons</strong>: No real-time response, results are delayed  </li><li><strong>Best use case</strong>: Large batch jobs where immediate results are not required</li></ul><hr><h3 id="🔹-Provisioned-Throughput-Reserved-capacity-guaranteed-performance"><a href="#🔹-Provisioned-Throughput-Reserved-capacity-guaranteed-performance" class="headerlink" title="🔹 Provisioned Throughput (Reserved capacity, guaranteed performance)"></a>🔹 Provisioned Throughput (Reserved capacity, guaranteed performance)</h3><ul><li><strong>How it works</strong>: Like a gym membership — reserve processing capacity for a set period (e.g., 1–6 months)  </li><li><strong>Guaranteed performance</strong>: Ensures a maximum number of input&#x2F;output tokens per minute  </li><li><strong>Available Models</strong>: Base, Fine-tuned, and Custom Models  </li><li>✅ <strong>Pros</strong>: Stable performance and capacity, supports custom models  </li><li>❌ <strong>Cons</strong>: Not a cost-saving option, purpose is <strong>performance guarantee</strong></li></ul><hr><h2 id="📊-Pricing-Options-Comparison-Table"><a href="#📊-Pricing-Options-Comparison-Table" class="headerlink" title="📊 Pricing Options Comparison Table"></a>📊 Pricing Options Comparison Table</h2><table><thead><tr><th>Option</th><th>Billing Method</th><th>Pricing Basis</th><th>Available Models</th><th>Pros</th><th>Cons</th><th>Best Use Case</th></tr></thead><tbody><tr><td><strong>On-Demand</strong></td><td>Pay-as-you-go</td><td>- Text: Input&#x2F;Output tokens<br>- Embedding: Input tokens<br>- Image: Generated images</td><td>Base Models only</td><td>High flexibility<br>Great for unpredictable workloads</td><td>Expensive for long-term use</td><td>Occasional use &#x2F; Unpredictable demand</td></tr><tr><td><strong>Batch Mode</strong></td><td>Bulk processing</td><td>Results stored in Amazon S3</td><td>Base Models only</td><td>Up to 50% discount<br>Efficient for large-scale jobs</td><td>No real-time response<br>Delayed results</td><td>Large requests &#x2F; No need for instant results</td></tr><tr><td><strong>Provisioned Throughput</strong></td><td>Reserved capacity (1–6 months)</td><td>Guaranteed tokens per minute</td><td>Base, Fine-tuned, Custom Models</td><td>Guaranteed stable performance<br>Supports custom models</td><td>Almost no cost savings</td><td>When using custom models &#x2F; Need guaranteed performance</td></tr></tbody></table><hr><h2 id="2️⃣-Model-Improvement-Techniques-Low-→-High-Cost"><a href="#2️⃣-Model-Improvement-Techniques-Low-→-High-Cost" class="headerlink" title="2️⃣ Model Improvement Techniques (Low → High Cost)"></a>2️⃣ Model Improvement Techniques (Low → High Cost)</h2><h3 id="1-Prompt-Engineering"><a href="#1-Prompt-Engineering" class="headerlink" title="1. Prompt Engineering"></a>1. Prompt Engineering</h3><ul><li>Improve results simply by optimizing prompts  </li><li>No extra computation → <strong>Lowest cost</strong></li></ul><h3 id="2-Retrieval-Augmented-Generation-RAG"><a href="#2-Retrieval-Augmented-Generation-RAG" class="headerlink" title="2. Retrieval Augmented Generation (RAG)"></a>2. Retrieval Augmented Generation (RAG)</h3><ul><li>Uses an external knowledge database (Vector DB)  </li><li>No model retraining → relatively low cost  </li><li>Additional cost for building and maintaining the database</li></ul><blockquote><p>RAG &#x3D; “Model + Search function” → lets the model find external knowledge it doesn’t already know.</p></blockquote><h3 id="3-Instruction-based-Fine-tuning"><a href="#3-Instruction-based-Fine-tuning" class="headerlink" title="3. Instruction-based Fine-tuning"></a>3. Instruction-based Fine-tuning</h3><ul><li>Fine-tune the model with labeled data and specific instructions  </li><li>Requires extra computation → Higher cost</li></ul><h3 id="4-Domain-Adaptation-Fine-tuning"><a href="#4-Domain-Adaptation-Fine-tuning" class="headerlink" title="4. Domain Adaptation Fine-tuning"></a>4. Domain Adaptation Fine-tuning</h3><ul><li>Retrain the model with a large domain-specific dataset  </li><li>Requires extensive data preparation + heavy computation → <strong>Highest cost</strong></li></ul><hr><h2 id="3️⃣-Cost-Optimization-Tips"><a href="#3️⃣-Cost-Optimization-Tips" class="headerlink" title="3️⃣ Cost Optimization Tips"></a>3️⃣ Cost Optimization Tips</h2><ul><li><strong>Token management</strong> → main driver of cost savings  <ul><li>Keep prompts concise  </li><li>Limit output length to what’s necessary</li></ul></li><li><strong>Use Batch Mode</strong> → up to 50% cheaper  </li><li><strong>Choose smaller models</strong> → generally cheaper  </li><li><strong>Adjust hyperparameters (Temperature, Top-K, Top-P)</strong>  <ul><li>Affects model behavior but <strong>not pricing</strong></li></ul></li></ul><hr><h2 id="📝-Final-Summary-Exam-Practical-Points"><a href="#📝-Final-Summary-Exam-Practical-Points" class="headerlink" title="📝 Final Summary (Exam&#x2F;Practical Points)"></a>📝 Final Summary (Exam&#x2F;Practical Points)</h2><ul><li><strong>On-Demand</strong> &#x3D; Flexibility &#x2F; <strong>Batch</strong> &#x3D; Bulk &amp; Discounts &#x2F; <strong>Provisioned</strong> &#x3D; Guaranteed Performance  </li><li><strong>Cost order</strong>: Prompt Engineering &lt; RAG &lt; Instruction Fine-tuning &lt; Domain Adaptation  </li><li><strong>Cost-saving keys</strong>: Token management + Batch Mode</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📘-Amazon-Bedrock-–-Pricing-Model-Improvement&quot;&gt;&lt;a href=&quot;#📘-Amazon-Bedrock-–-Pricing-Model-Improvement&quot; class=&quot;headerlink&quot; title=&quot;📘</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
</feed>
