<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Danny&#39;s Blog</title>
  
  <subtitle>Data, AI, and Tech Insight</subtitle>
  <link href="https://kish191919.github.io/atom.xml" rel="self"/>
  
  <link href="https://kish191919.github.io/"/>
  <updated>2025-08-27T02:57:51.733Z</updated>
  <id>https://kish191919.github.io/</id>
  
  <author>
    <name>Danny Ki</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (31) - AWS AI 관리형 서비스</title>
    <link href="https://kish191919.github.io/2025/08/26/KO-AWS-Certified-AI-Practitioner-31/"/>
    <id>https://kish191919.github.io/2025/08/26/KO-AWS-Certified-AI-Practitioner-31/</id>
    <published>2025-08-26T19:37:13.000Z</published>
    <updated>2025-08-27T02:57:51.733Z</updated>
    
    <content type="html"><![CDATA[<h1 id="AWS-AI-관리형-서비스-AWS-AI-Managed-Services"><a href="#AWS-AI-관리형-서비스-AWS-AI-Managed-Services" class="headerlink" title="AWS AI 관리형 서비스 (AWS AI Managed Services)"></a>AWS AI 관리형 서비스 (AWS AI Managed Services)</h1><h2 id="1-왜-AWS-AI-관리형-서비스인가"><a href="#1-왜-AWS-AI-관리형-서비스인가" class="headerlink" title="1. 왜 AWS AI 관리형 서비스인가?"></a>1. 왜 AWS AI 관리형 서비스인가?</h2><ul><li><strong>사전 학습된 ML 모델 제공</strong> → 별도의 훈련 필요 없음</li><li><strong>고가용성 &amp; 빠른 응답성</strong></li><li><strong>중복성 &amp; 리전 배포</strong>: 여러 AZ&#x2F;Region 배포로 장애에도 안정적</li><li><strong>최적화된 성능</strong>: 특수 CPU&#x2F;GPU 사용으로 비용 절감</li><li><strong>토큰 기반 과금</strong>: 사용한 만큼만 지불 (Pay-as-you-go)</li><li><strong>Provisioned Throughput</strong>: 예측 가능한 워크로드에 대해 안정적 성능 제공</li></ul><p>👉 <strong>시험 포인트</strong>: AWS AI 서비스는 <strong>Fully Managed, Serverless, Pay-per-use</strong> 구조임</p><p align="center">  <img src="/images/aws_basic_144.png" width="80%"></p> <hr><h1 id="Amazon-Comprehend-자연어-처리-NLP"><a href="#Amazon-Comprehend-자연어-처리-NLP" class="headerlink" title="Amazon Comprehend (자연어 처리, NLP)"></a>Amazon Comprehend (자연어 처리, NLP)</h1><ul><li><strong>완전 관리형(Serverless) NLP 서비스</strong></li><li><strong>주요 기능</strong>:<ul><li>언어 식별(Language Detection)</li><li>키 구문, 인물, 장소, 조직, 브랜드, 이벤트 추출</li><li>감정 분석(Sentiment Analysis)</li><li>품사 태깅(Part-of-Speech)</li><li>토픽 모델링(Topic Modeling)</li></ul></li></ul><h3 id="활용-사례"><a href="#활용-사례" class="headerlink" title="활용 사례"></a>활용 사례</h3><ul><li>고객 이메일 분석 → 긍정&#x2F;부정 경험 요인 파악</li><li>기사&#x2F;문서 자동 분류</li></ul><hr><h2 id="1-Custom-Classification"><a href="#1-Custom-Classification" class="headerlink" title="1. Custom Classification"></a>1. Custom Classification</h2><ul><li>사용자가 정의한 카테고리로 문서 자동 분류</li><li>예: 고객 이메일을 “결제&#x2F;기술 지원&#x2F;불만”으로 분류</li><li>지원 포맷: Text, PDF, Word, 이미지 등</li><li>분석 모드: <strong>실시간(Sync)</strong>, <strong>비동기(Async)</strong></li></ul><p align="center">  <img src="/images/aws_basic_145.png" width="80%"></p> <hr><h2 id="2-Named-Entity-Recognition-NER"><a href="#2-Named-Entity-Recognition-NER" class="headerlink" title="2. Named Entity Recognition (NER)"></a>2. Named Entity Recognition (NER)</h2><ul><li>텍스트에서 <strong>사람, 조직, 장소, 날짜</strong> 등 추출</li></ul><p align="center">  <img src="/images/aws_basic_146.png" width="80%"></p> ------------------------------------------------------------------------<h2 id="3-Custom-Entity-Recognition"><a href="#3-Custom-Entity-Recognition" class="headerlink" title="3. Custom Entity Recognition"></a>3. Custom Entity Recognition</h2><ul><li>비즈니스 맞춤 엔터티 추출 (예: 보험번호, 특정 제품 코드)</li><li>사용자 데이터로 훈련 → 실시간&#x2F;비동기 분석 가능</li></ul><p>👉 <strong>시험 포인트</strong>:</p><ul><li>Comprehend &#x3D; <strong>NLP 서비스</strong></li><li>핵심 기능: 언어 식별, 감정 분석, NER</li><li>고급 기능: <strong>Custom Classification, Custom Entity Recognition</strong></li></ul><p align="center">  <img src="/images/aws_basic_147.png" width="80%"></p> <hr><h1 id="Amazon-Translate-자동-번역"><a href="#Amazon-Translate-자동-번역" class="headerlink" title="Amazon Translate (자동 번역)"></a>Amazon Translate (자동 번역)</h1><ul><li><strong>신경망 기반(NMT)</strong> 번역 서비스</li><li>웹&#x2F;앱 현지화(Localization), 대규모 문서 번역 지원</li><li><strong>Custom Terminology</strong>: 브랜드명, 도메인 용어 번역 일관성 유지</li><li><strong>Parallel Data</strong>: 번역 스타일 지정 (격식체 vs 비격식체)</li></ul><p>👉 <strong>시험 포인트</strong>: Translate는 <strong>Custom Terminology &amp; Parallel Data</strong> 기능으로 차별화됨</p><p align="center">  <img src="/images/aws_basic_148.png" width="80%"></p> ------------------------------------------------------------------------<h1 id="Amazon-Transcribe-음성-→-텍스트"><a href="#Amazon-Transcribe-음성-→-텍스트" class="headerlink" title="Amazon Transcribe (음성 → 텍스트)"></a>Amazon Transcribe (음성 → 텍스트)</h1><ul><li><strong>자동 음성 인식(ASR)</strong> 기반</li><li>음성을 빠르고 정확하게 텍스트로 변환</li><li><strong>PII Redaction</strong>: 개인정보 자동 제거</li><li><strong>자동 언어 감지</strong>: 다국어 오디오 지원</li></ul><h3 id="활용-사례-1"><a href="#활용-사례-1" class="headerlink" title="활용 사례"></a>활용 사례</h3><ul><li>고객센터 통화 기록 자동 변환</li><li>자막&#x2F;캡션 자동 생성</li><li>미디어 검색용 메타데이터 생성</li></ul><p align="center">  <img src="/images/aws_basic_149.png" width="80%"></p> ------------------------------------------------------------------------<h2 id="1-Accuracy-향상-기능"><a href="#1-Accuracy-향상-기능" class="headerlink" title="1. Accuracy 향상 기능"></a>1. Accuracy 향상 기능</h2><ul><li><strong>Custom Vocabularies (단어 단위)</strong><ul><li>브랜드명, 전문 용어, 약어 인식률 향상</li></ul></li><li><strong>Custom Language Models (문맥 단위)</strong><ul><li>도메인 텍스트 학습 → 정확도 향상</li></ul></li><li>두 기능을 함께 사용 → 최고 정확도 제공</li></ul><p align="center">  <img src="/images/aws_basic_151.png" width="80%"></p> <hr><h2 id="2-Toxicity-Detection"><a href="#2-Toxicity-Detection" class="headerlink" title="2. Toxicity Detection"></a>2. Toxicity Detection</h2><ul><li>음성과 텍스트 분석 → <strong>혐오 발언, 욕설, 성희롱, 협박 등 탐지</strong></li><li>카테고리: 성적 괴롭힘, 증오 발언, 위협, 욕설, 모욕 등</li></ul><p>👉 <strong>시험 포인트</strong>:</p><ul><li>Transcribe &#x3D; <strong>Speech-to-Text 서비스</strong></li><li>자주 나오는 기능: <strong>PII Redaction, Custom Vocabulary, Toxicity Detection</strong></li></ul><p align="center">  <img src="/images/aws_basic_150.png" width="80%"></p> ------------------------------------------------------------------------<h1 id="시험-대비-핵심-정리"><a href="#시험-대비-핵심-정리" class="headerlink" title="시험 대비 핵심 정리"></a>시험 대비 핵심 정리</h1><ol><li><strong>Comprehend</strong> → NLP (언어 식별, 감정 분석, NER, Custom 기능)</li><li><strong>Translate</strong> → 번역 서비스 (Custom Terminology, Parallel Data)</li><li><strong>Transcribe</strong> → 음성 인식 (PII Redaction, Custom Vocabulary,<br>Toxicity Detection)</li><li>공통 특징: <strong>Fully Managed, Serverless, Pay-as-you-go</strong></li><li><strong>시험에서 강조되는 포인트</strong>:<ul><li>Comprehend: NLP 서비스, Custom 기능</li><li>Translate: Terminology &amp; Parallel Data</li><li>Transcribe: PII Redaction, Custom Language Model, Toxicity<br>Detection</li></ul></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;AWS-AI-관리형-서비스-AWS-AI-Managed-Services&quot;&gt;&lt;a href=&quot;#AWS-AI-관리형-서비스-AWS-AI-Managed-Services&quot; class=&quot;headerlink&quot; title=&quot;AWS AI 관리형 서비스 (</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(31) - AWS AI Managed Services</title>
    <link href="https://kish191919.github.io/2025/08/26/AWS-Certified-AI-Practitioner-31/"/>
    <id>https://kish191919.github.io/2025/08/26/AWS-Certified-AI-Practitioner-31/</id>
    <published>2025-08-26T19:37:08.000Z</published>
    <updated>2025-08-26T19:47:39.483Z</updated>
    
    <content type="html"><![CDATA[<h1 id="AWS-AI-Managed-Services"><a href="#AWS-AI-Managed-Services" class="headerlink" title="AWS AI Managed Services"></a>AWS AI Managed Services</h1><h2 id="Why-AWS-AI-Managed-Services"><a href="#Why-AWS-AI-Managed-Services" class="headerlink" title="Why AWS AI Managed Services?"></a>Why AWS AI Managed Services?</h2><p>AWS AI Managed Services provide <strong>pre-trained ML models</strong> designed for specific use cases, without requiring you to build or train models from scratch.</p><h3 id="Key-Benefits"><a href="#Key-Benefits" class="headerlink" title="Key Benefits:"></a>Key Benefits:</h3><ul><li><strong>Responsiveness and Availability</strong>: Always accessible, deployed across multiple Availability Zones and AWS Regions.</li><li><strong>Redundancy and Reliability</strong>: Services remain available even if one AZ experiences downtime.</li><li><strong>Performance</strong>: Use of specialized CPUs and GPUs optimized for ML workloads → cost efficiency.</li><li><strong>Token-based Pricing</strong>: Pay only for what you use (no need to over-provision).</li><li><strong>Provisioned Throughput</strong>: Option for predictable workloads to guarantee performance and optimize costs.</li></ul><p>👉 <strong>Exam Tip</strong>: AWS will test your understanding that these services are <strong>Fully Managed, Serverless, Pay-as-you-go, and globally scalable</strong>.</p><p align="center">  <img src="/images/aws_basic_144.png" width="80%"></p> <hr><h1 id="Amazon-Comprehend-Natural-Language-Processing-–-NLP"><a href="#Amazon-Comprehend-Natural-Language-Processing-–-NLP" class="headerlink" title="Amazon Comprehend (Natural Language Processing – NLP)"></a>Amazon Comprehend (Natural Language Processing – NLP)</h1><p>Amazon Comprehend is a <strong>fully managed, serverless NLP service</strong>. It uses ML to extract insights and relationships from text.</p><h3 id="Core-Capabilities"><a href="#Core-Capabilities" class="headerlink" title="Core Capabilities:"></a>Core Capabilities:</h3><ul><li>Detects text language</li><li>Extracts key phrases, people, places, brands, and events</li><li>Sentiment analysis → positive, negative, neutral, or mixed</li><li>Tokenization and Part-of-Speech tagging</li><li>Automatically organizes text files by topic</li></ul><h3 id="Common-Use-Cases"><a href="#Common-Use-Cases" class="headerlink" title="Common Use Cases:"></a>Common Use Cases:</h3><ul><li>Analyze customer support emails to identify what leads to positive&#x2F;negative experiences</li><li>Group large document collections (e.g., news articles) by topic</li></ul><hr><h2 id="Custom-Classification"><a href="#Custom-Classification" class="headerlink" title="Custom Classification"></a>Custom Classification</h2><ul><li>Organize documents into <strong>categories you define</strong>.</li><li>Example: Categorize emails into <em>billing, technical support, complaints</em>.</li><li>Supports formats: text, PDF, Word, images.</li><li><strong>Real-time (synchronous)</strong> for single documents, or <strong>batch&#x2F;asynchronous</strong> for larger workloads.</li></ul><p align="center">  <img src="/images/aws_basic_145.png" width="80%"></p> <hr><h2 id="Named-Entity-Recognition-NER"><a href="#Named-Entity-Recognition-NER" class="headerlink" title="Named Entity Recognition (NER)"></a>Named Entity Recognition (NER)</h2><ul><li>Extracts <strong>predefined general entities</strong>: people, organizations, places, dates, etc.</li><li>Example: From “John works at AnyCompany on July 31st,” Comprehend identifies John (Person), AnyCompany (Organization), and July 31st (Date).</li></ul><p align="center">  <img src="/images/aws_basic_146.png" width="80%"></p> ------------------------------------------------------------------------<h2 id="Custom-Entity-Recognition"><a href="#Custom-Entity-Recognition" class="headerlink" title="Custom Entity Recognition"></a>Custom Entity Recognition</h2><ul><li>Allows detection of <strong>business-specific terms</strong>.</li><li>Example: Policy numbers, escalation phrases, custom product codes.</li><li>Requires <strong>training data</strong> (entity list + documents) stored in S3 → Comprehend builds a custom recognizer.</li><li>Works in <strong>real-time</strong> or <strong>batch</strong>.</li></ul><p>👉 <strong>Exam Tip</strong>:</p><ul><li><strong>NER &#x3D; predefined entities</strong>.</li><li><strong>Custom Entity Recognition &#x3D; business-specific entities trained with your data</strong>.</li></ul><p align="center">  <img src="/images/aws_basic_147.png" width="80%"></p> <hr><h1 id="Amazon-Translate"><a href="#Amazon-Translate" class="headerlink" title="Amazon Translate"></a>Amazon Translate</h1><p>A <strong>neural machine translation (NMT) service</strong> that provides natural and<br>accurate translations.</p><h3 id="Features"><a href="#Features" class="headerlink" title="Features:"></a>Features:</h3><ul><li>Translate text and entire documents (txt, HTML, docx).</li><li><strong>Batch Translation</strong>: Translate large volumes via S3 jobs.</li><li><strong>Custom Terminology</strong>: Maintain brand names or domain-specific terms across translations.</li><li><strong>Parallel Data</strong>: Control translation style (formal vs informal).</li></ul><p>👉 <strong>Exam Tip</strong>: Custom Terminology and Parallel Data are key differentiators.</p><p align="center">  <img src="/images/aws_basic_148.png" width="80%"></p> <hr><h1 id="Amazon-Transcribe-Speech-to-Text"><a href="#Amazon-Transcribe-Speech-to-Text" class="headerlink" title="Amazon Transcribe (Speech-to-Text)"></a>Amazon Transcribe (Speech-to-Text)</h1><p>A fully managed <strong>Automatic Speech Recognition (ASR)</strong> service that converts speech to text.</p><h3 id="Features-1"><a href="#Features-1" class="headerlink" title="Features:"></a>Features:</h3><ul><li>Converts audio to text quickly and accurately</li><li><strong>PII Redaction</strong>: Removes personally identifiable information (name, SSN, phone number, etc.)</li><li><strong>Automatic Language Identification</strong>: Handles multilingual audio streams</li></ul><h3 id="Use-Cases"><a href="#Use-Cases" class="headerlink" title="Use Cases:"></a>Use Cases:</h3><ul><li>Transcribe customer service calls</li><li>Generate subtitles and closed captions</li><li>Create searchable metadata for media archives</li></ul><p align="center">  <img src="/images/aws_basic_149.png" width="80%"></p> <hr><h2 id="Improving-Accuracy"><a href="#Improving-Accuracy" class="headerlink" title="Improving Accuracy"></a>Improving Accuracy</h2><ul><li><strong>Custom Vocabularies</strong>: Add words, acronyms, brand names → improve recognition.</li><li><strong>Custom Language Models</strong>: Train on domain-specific text to provide context (e.g., distinguishing <em>“microservice”</em> vs <em>“my crow service”</em>).</li><li>Best accuracy is achieved when <strong>both are used together</strong>.</li></ul><p align="center">  <img src="/images/aws_basic_151.png" width="80%"></p> <hr><h2 id="Toxicity-Detection"><a href="#Toxicity-Detection" class="headerlink" title="Toxicity Detection"></a>Toxicity Detection</h2><ul><li>Detects <strong>toxic speech content</strong> using both voice cues (tone, pitch) and text cues.</li><li>Categories: sexual harassment, hate speech, threats, abuse, profanity, insults, graphic content.</li></ul><p>👉 <strong>Exam Tip</strong>:</p><ul><li>Know that Transcribe supports <strong>PII Redaction, Custom Vocabulary, Custom Language Models, and Toxicity Detection</strong>.</li><li>Expect scenario-based exam questions about improving transcription accuracy.</li></ul><p align="center">  <img src="/images/aws_basic_150.png" width="80%"></p> <hr><h1 id="Exam-Focused-Summary"><a href="#Exam-Focused-Summary" class="headerlink" title="Exam-Focused Summary"></a>Exam-Focused Summary</h1><ol><li><strong>Comprehend</strong> → NLP (Sentiment, NER, Custom Classification, Custom Entities).</li><li><strong>Translate</strong> → Language translation (Custom Terminology, Parallel Data).</li><li><strong>Transcribe</strong> → Speech-to-Text (PII Redaction, Custom Vocabulary, Toxicity Detection).</li><li><strong>Shared Traits</strong>: Fully Managed, Serverless, Pay-as-you-go, scalable across regions.</li><li><strong>AWS Exam Hotspots</strong>:<ul><li>When to use Custom Terminology vs Parallel Data in Translate.</li><li>How Comprehend Custom Classification differs from Custom Entity Recognition.</li><li>Improving Transcribe accuracy (Custom Vocabulary + Custom Language Models).</li><li>Toxicity Detection categories in Transcribe.</li></ul></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;AWS-AI-Managed-Services&quot;&gt;&lt;a href=&quot;#AWS-AI-Managed-Services&quot; class=&quot;headerlink&quot; title=&quot;AWS AI Managed Services&quot;&gt;&lt;/a&gt;AWS AI Managed Se</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(30) - Hyperparameter Tuning</title>
    <link href="https://kish191919.github.io/2025/08/26/AWS-Certified-AI-Practitioner-30/"/>
    <id>https://kish191919.github.io/2025/08/26/AWS-Certified-AI-Practitioner-30/</id>
    <published>2025-08-26T19:20:21.000Z</published>
    <updated>2025-08-26T19:27:31.165Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Hyperparameter-Tuning"><a href="#Hyperparameter-Tuning" class="headerlink" title="Hyperparameter Tuning"></a>Hyperparameter Tuning</h1><h2 id="1-What-is-a-Hyperparameter"><a href="#1-What-is-a-Hyperparameter" class="headerlink" title="1. What is a Hyperparameter?"></a>1. What is a Hyperparameter?</h2><ul><li><strong>Definition</strong>: Settings that define how the model is structured and how the learning algorithm works.</li><li><strong>Set before training begins</strong> (they are not learned from the data).</li><li><strong>Examples</strong>:<ul><li><strong>Learning rate</strong></li><li><strong>Batch size</strong></li><li><strong>Number of epochs</strong></li><li><strong>Regularization</strong></li></ul></li></ul><p>👉 <strong>Exam Tip</strong>: Hyperparameters are <strong>not learned</strong> during training. They are chosen before training and tuned for best performance.</p><hr><h2 id="2-Why-Hyperparameter-Tuning-Matters"><a href="#2-Why-Hyperparameter-Tuning-Matters" class="headerlink" title="2. Why Hyperparameter Tuning Matters"></a>2. Why Hyperparameter Tuning Matters</h2><ul><li><strong>Goal</strong>: Find the best combination of hyperparameters to optimize model performance.</li><li><strong>Benefits</strong>:<ul><li>Improves accuracy</li><li>Reduces overfitting</li><li>Enhances generalization to new data</li></ul></li><li><strong>Methods</strong>:<ul><li><strong>Grid Search</strong>: Tries all possible parameter combinations.</li><li><strong>Random Search</strong>: Tests random parameter values.</li><li><strong>Automated Services</strong>:<ul><li><strong>Amazon SageMaker Automatic Model Tuning (AMT)</strong> runs multiple training jobs and finds the best settings.</li></ul></li></ul></li></ul><hr><h2 id="3-Key-Hyperparameters"><a href="#3-Key-Hyperparameters" class="headerlink" title="3. Key Hyperparameters"></a>3. Key Hyperparameters</h2><h3 id="1-Learning-Rate"><a href="#1-Learning-Rate" class="headerlink" title="(1) Learning Rate"></a>(1) Learning Rate</h3><ul><li>Controls <strong>how big the steps are</strong> when updating model weights.</li><li><strong>High learning rate</strong>: Faster training, but may overshoot the optimal solution.</li><li><strong>Low learning rate</strong>: More stable and precise, but much slower.</li></ul><hr><h3 id="2-Batch-Size"><a href="#2-Batch-Size" class="headerlink" title="(2) Batch Size"></a>(2) Batch Size</h3><ul><li>Number of training examples processed in one iteration.</li><li><strong>Small batches</strong>: More stable, but slower.</li><li><strong>Large batches</strong>: Faster, but may cause less stable updates.</li></ul><hr><h3 id="3-Number-of-Epochs"><a href="#3-Number-of-Epochs" class="headerlink" title="(3) Number of Epochs"></a>(3) Number of Epochs</h3><ul><li>How many times the model goes through the <strong>entire training dataset</strong>.</li><li><strong>Too few</strong>: Underfitting (model doesn’t learn enough).</li><li><strong>Too many</strong>: Overfitting (model memorizes the data, performs poorly on new data).</li></ul><hr><h3 id="4-Regularization"><a href="#4-Regularization" class="headerlink" title="(4) Regularization"></a>(4) Regularization</h3><ul><li>Controls the <strong>balance between a simple and complex model</strong>.</li><li>More regularization → less overfitting.</li></ul><p>👉 <strong>Exam Tip</strong>: If asked how to reduce overfitting, <strong>increasing regularization</strong> is often the correct answer.</p><hr><h2 id="4-Overfitting"><a href="#4-Overfitting" class="headerlink" title="4. Overfitting"></a>4. Overfitting</h2><h3 id="What-is-it"><a href="#What-is-it" class="headerlink" title="What is it?"></a>What is it?</h3><ul><li>The model performs very well on training data but poorly on new, unseen data.</li></ul><h3 id="Causes"><a href="#Causes" class="headerlink" title="Causes"></a>Causes</h3><ul><li>Too little training data → not representative.</li><li>Training for too many epochs.</li><li>Model too complex → learns noise instead of patterns.</li></ul><h3 id="Solutions"><a href="#Solutions" class="headerlink" title="Solutions"></a>Solutions</h3><ul><li>Increase training data size (best option).</li><li>Use <strong>early stopping</strong> (stop training before overfitting).</li><li>Apply <strong>data augmentation</strong> (add diversity to training data).</li><li>Adjust hyperparameters (e.g., increase regularization, change batch size).</li></ul><p>👉 <strong>Exam Tip</strong>: If the question is <strong>“best way to prevent overfitting”</strong>, the answer is usually <strong>increase training data</strong>.</p><hr><h2 id="5-When-NOT-to-Use-Machine-Learning"><a href="#5-When-NOT-to-Use-Machine-Learning" class="headerlink" title="5. When NOT to Use Machine Learning"></a>5. When NOT to Use Machine Learning</h2><ul><li><strong>Example</strong>:<br>You have a deck of 10 cards (5 red, 3 blue, 2 yellow).<br>Q: What is the probability of drawing a blue card?<br>A: 3&#x2F;10 &#x3D; 0.3</li></ul>   <p align="center">  <img src="/images/aws_basic_143.png" width="80%"></p> <ul><li><p>This is a <strong>deterministic problem</strong>:</p><ul><li>The exact answer can be computed mathematically.</li><li>Writing simple code is the best solution.</li></ul></li><li><p>If we used ML (supervised, unsupervised, or reinforcement learning), we’d only get an <strong>approximation</strong>, not an exact result.</p></li></ul><p>👉 <strong>Exam Tip</strong>:<br>Machine Learning is <strong>not appropriate</strong> for problems that have a <strong>clear, deterministic answer</strong>. It is designed for problems where patterns must be learned from data.</p><hr><h2 id="6-AWS-Specific-Notes-for-Exams"><a href="#6-AWS-Specific-Notes-for-Exams" class="headerlink" title="6. AWS-Specific Notes for Exams"></a>6. AWS-Specific Notes for Exams</h2><ul><li><strong>Amazon SageMaker Automatic Model Tuning (AMT)</strong>: Automates hyperparameter tuning by running multiple jobs in parallel.</li><li><strong>Common Exam Questions</strong>:<ul><li>How to fix overfitting → Increase data &#x2F; regularization.</li><li>What hyperparameter affects convergence speed → Learning rate.</li><li>Which AWS service automates tuning → SageMaker AMT.</li><li>When NOT to use ML → Deterministic problem with exact answers.</li></ul></li></ul><hr><p>✅ <strong>Summary</strong> - <strong>Hyperparameters</strong> (learning rate, batch size, epochs regularization) must be tuned for best performance.</p><ul><li><strong>Tuning</strong> improves accuracy, reduces overfitting, and enhances generalization.</li><li><strong>Overfitting</strong> occurs when the model memorizes training data → fix by more data, regularization, early stopping.</li><li><strong>ML is not appropriate</strong> for deterministic problems.</li><li>On AWS, <strong>SageMaker AMT</strong> is the go-to tool for automated hyperparameter tuning.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Hyperparameter-Tuning&quot;&gt;&lt;a href=&quot;#Hyperparameter-Tuning&quot; class=&quot;headerlink&quot; title=&quot;Hyperparameter Tuning&quot;&gt;&lt;/a&gt;Hyperparameter Tuning&lt;/</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (30) - 하이퍼파라미터 튜닝</title>
    <link href="https://kish191919.github.io/2025/08/26/KO-AWS-Certified-AI-Practitioner-30/"/>
    <id>https://kish191919.github.io/2025/08/26/KO-AWS-Certified-AI-Practitioner-30/</id>
    <published>2025-08-26T19:20:12.000Z</published>
    <updated>2025-08-27T02:57:51.733Z</updated>
    
    <content type="html"><![CDATA[<h1 id="하이퍼파라미터-튜닝-Hyperparameter-Tuning"><a href="#하이퍼파라미터-튜닝-Hyperparameter-Tuning" class="headerlink" title="하이퍼파라미터 튜닝 (Hyperparameter Tuning)"></a>하이퍼파라미터 튜닝 (Hyperparameter Tuning)</h1><h2 id="1-하이퍼파라미터란"><a href="#1-하이퍼파라미터란" class="headerlink" title="1. 하이퍼파라미터란?"></a>1. 하이퍼파라미터란?</h2><ul><li><strong>정의</strong>: 모델 구조와 학습 방식을 결정하는 설정값</li><li><strong>특징</strong>:<ul><li>학습이 시작되기 전에 정해짐</li><li>데이터 자체가 아니라, <strong>학습 알고리즘의 동작 방식</strong>에 영향을 줌</li></ul></li><li><strong>대표 예시</strong>:<ul><li>학습률(Learning rate)</li><li>배치 크기(Batch size)</li><li>에포크 수(Number of epochs)</li><li>정규화(Regularization)</li></ul></li></ul><p>👉 <strong>시험 포인트</strong>:<br>하이퍼파라미터는 모델 학습 과정에서 자동으로 학습되는 값이 아니라, <strong>사전에 설정하는 값</strong>이다.</p><hr><h2 id="2-하이퍼파라미터-튜닝-Hyperparameter-Tuning"><a href="#2-하이퍼파라미터-튜닝-Hyperparameter-Tuning" class="headerlink" title="2. 하이퍼파라미터 튜닝(Hyperparameter Tuning)"></a>2. 하이퍼파라미터 튜닝(Hyperparameter Tuning)</h2><ul><li><strong>목적</strong>: 최적의 하이퍼파라미터 값을 찾아 모델 성능을 극대화\</li><li><strong>효과</strong>:<ul><li>정확도 향상</li><li>과적합(Overfitting) 감소</li><li>일반화 성능 강화</li></ul></li><li><strong>방법</strong>:<ul><li><strong>Grid Search</strong>: 가능한 모든 조합 탐색</li><li><strong>Random Search</strong>: 임의의 조합을 탐색</li><li><strong>자동화 서비스</strong>:<ul><li><strong>Amazon SageMaker Automatic Model Tuning (AMT)</strong> 활용</li></ul></li></ul></li></ul><hr><h2 id="3-주요-하이퍼파라미터"><a href="#3-주요-하이퍼파라미터" class="headerlink" title="3. 주요 하이퍼파라미터"></a>3. 주요 하이퍼파라미터</h2><h3 id="1-학습률-Learning-Rate"><a href="#1-학습률-Learning-Rate" class="headerlink" title="(1) 학습률 (Learning Rate)"></a>(1) 학습률 (Learning Rate)</h3><ul><li>모델 가중치를 얼마나 크게&#x2F;작게 업데이트할지 결정</li><li><strong>높은 학습률</strong>: 빠른 수렴 가능, 하지만 최적값을 지나칠 위험</li><li><strong>낮은 학습률</strong>: 더 정밀한 수렴 가능, 하지만 속도가 느림</li></ul><hr><h3 id="2-배치-크기-Batch-Size"><a href="#2-배치-크기-Batch-Size" class="headerlink" title="(2) 배치 크기 (Batch Size)"></a>(2) 배치 크기 (Batch Size)</h3><ul><li>한 번의 가중치 업데이트에 사용되는 데이터 샘플 개수</li><li><strong>작은 배치</strong>: 안정적인 학습, 하지만 연산 시간이 오래 걸림</li><li><strong>큰 배치</strong>: 빠른 학습, 하지만 불안정한 업데이트 가능</li></ul><hr><h3 id="3-에포크-수-Number-of-Epochs"><a href="#3-에포크-수-Number-of-Epochs" class="headerlink" title="(3) 에포크 수 (Number of Epochs)"></a>(3) 에포크 수 (Number of Epochs)</h3><ul><li>전체 학습 데이터를 몇 번 반복해서 학습할지 결정</li><li><strong>너무 적으면</strong>: 학습 부족(Underfitting)</li><li><strong>너무 많으면</strong>: 과적합(Overfitting)</li></ul><hr><h3 id="4-정규화-Regularization"><a href="#4-정규화-Regularization" class="headerlink" title="(4) 정규화 (Regularization)"></a>(4) 정규화 (Regularization)</h3><ul><li>모델이 너무 복잡해져 과적합되지 않도록 제어</li><li>정규화를 높이면 단순해지고, 과적합 방지 효과</li></ul><p>👉 <strong>시험 포인트</strong>:<br>“과적합을 줄이고 싶다”라는 질문 → <strong>정규화 강화를 정답으로 선택</strong>하는 경우가 많음.</p><hr><h2 id="4-과적합-Overfitting-과-해결-방법"><a href="#4-과적합-Overfitting-과-해결-방법" class="headerlink" title="4. 과적합(Overfitting)과 해결 방법"></a>4. 과적합(Overfitting)과 해결 방법</h2><ul><li><strong>정의</strong>: 학습 데이터에서는 높은 정확도를 보이지만, 새로운 데이터에서는 성능이 급격히 떨어지는 현상</li></ul><h3 id="원인"><a href="#원인" class="headerlink" title="원인"></a>원인</h3><ul><li>학습 데이터가 너무 적음 → 대표성이 부족</li><li>너무 많은 에포크 학습 → 특정 데이터에만 맞춰짐</li><li>모델이 지나치게 복잡 → 데이터의 <strong>노이즈까지 학습</strong></li></ul><h3 id="방지-방법"><a href="#방지-방법" class="headerlink" title="방지 방법"></a>방지 방법</h3><ul><li><strong>데이터 양 늘리기</strong> (가장 효과적)</li><li><strong>Early Stopping</strong> (학습 조기 종료)</li><li><strong>데이터 증강(Data Augmentation)</strong> (다양성 확보)</li><li><strong>하이퍼파라미터 조정</strong> (학습률, 배치 크기, 정규화 등)</li></ul><p>👉 <strong>시험 포인트</strong>:<br>과적합 방지의 <strong>가장 좋은 답</strong>은 보통 <strong>데이터 양 늘리기</strong></p><hr><h2 id="5-머신러닝이-적합하지-않은-경우"><a href="#5-머신러닝이-적합하지-않은-경우" class="headerlink" title="5. 머신러닝이 적합하지 않은 경우"></a>5. 머신러닝이 적합하지 않은 경우</h2><ul><li><strong>예시 문제</strong>:<br>“카드 10장 중 빨강 5장, 파랑 3장, 노랑 2장 → 파랑 카드를 뽑을 확률은?”<ul><li>답: <strong>3&#x2F;10 &#x3D; 0.3</strong></li><li>단순 수학적 계산으로 정확히 해결 가능</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_143.png" width="80%"></p> <p>👉 <strong>결론</strong>:</p><ul><li><strong>결정론적(Deterministic) 문제</strong>: 코드로 수학적으로 풀 수 있음 → 머신러닝 불필요</li><li>머신러닝은 항상 **근사값(Approximation)**을 내므로, 이런 문제에서는 <strong>적절하지 않음</strong></li></ul><hr><h2 id="6-시험-대비-핵심-요약"><a href="#6-시험-대비-핵심-요약" class="headerlink" title="6. 시험 대비 핵심 요약"></a>6. 시험 대비 핵심 요약</h2><ol><li><strong>하이퍼파라미터</strong> &#x3D; 학습 전 설정 (학습률, 배치 크기, 에포크 수, 정규화)</li><li><strong>튜닝 목적</strong> &#x3D; 성능 향상, 과적합 방지</li><li><strong>과적합 방지 방법</strong> &#x3D; 데이터 늘리기, Early Stopping, 데이터 증강, 정규화</li><li><strong>AWS 서비스</strong> &#x3D; <strong>SageMaker Automatic Model Tuning</strong></li><li><strong>머신러닝이 필요 없는 경우</strong> &#x3D; 답을 명확히 계산할 수 있는 결정론적 문제</li></ol><hr><p>👉 요약하면, <strong>시험에서 하이퍼파라미터와 과적합 방지 방법은 반드시 나오는 단골 주제</strong>입니다.<br>특히 <strong>SageMaker AMT</strong>와 <strong>정규화&#x2F;데이터 증강</strong> 관련 문항이 자주 출제됩니다.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;하이퍼파라미터-튜닝-Hyperparameter-Tuning&quot;&gt;&lt;a href=&quot;#하이퍼파라미터-튜닝-Hyperparameter-Tuning&quot; class=&quot;headerlink&quot; title=&quot;하이퍼파라미터 튜닝 (Hyperparameter T</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (29) - 머신러닝 프로젝트 단계</title>
    <link href="https://kish191919.github.io/2025/08/25/KO-AWS-Certified-AI-Practitioner-29/"/>
    <id>https://kish191919.github.io/2025/08/25/KO-AWS-Certified-AI-Practitioner-29/</id>
    <published>2025-08-25T17:33:46.000Z</published>
    <updated>2025-08-25T17:44:54.806Z</updated>
    
    <content type="html"><![CDATA[<h1 id="머신러닝-프로젝트-단계-Phases-of-Machine-Learning-Project"><a href="#머신러닝-프로젝트-단계-Phases-of-Machine-Learning-Project" class="headerlink" title="머신러닝 프로젝트 단계 (Phases of Machine Learning Project)"></a>머신러닝 프로젝트 단계 (Phases of Machine Learning Project)</h1><h2 id="1-비즈니스-목표-정의"><a href="#1-비즈니스-목표-정의" class="headerlink" title="1. 비즈니스 목표 정의"></a>1. 비즈니스 목표 정의</h2><ul><li><strong>목표</strong>: 어떤 문제를 해결할지 명확히 정의</li><li><strong>이해관계자(Stakeholders)</strong>: 프로젝트의 <strong>가치, 예산, 성공 기준</strong>을 설정</li><li><strong>KPI(핵심 성과 지표)</strong>: 반드시 정의해야 함 → 모델이 실제로 비즈니스 목표에 기여하는지 판단하는 기준</li></ul><p>👉 시험 포인트:<br>머신러닝 프로젝트의 첫 단계는 항상 <strong>비즈니스 문제를 정의</strong>하는 것. <strong>KPI 설정</strong>은 AWS 시험에서 자주 강조됨.</p><hr><h2 id="2-문제-정의와-ML-문제로-전환-ML-Problem-Framing"><a href="#2-문제-정의와-ML-문제로-전환-ML-Problem-Framing" class="headerlink" title="2. 문제 정의와 ML 문제로 전환 (ML Problem Framing)"></a>2. 문제 정의와 ML 문제로 전환 (ML Problem Framing)</h2><ul><li><strong>비즈니스 문제 → ML 문제로 변환</strong></li><li>머신러닝이 정말 필요한지, 다른 해결책(예: 단순 규칙 기반)이 더 나은지 판단</li><li>데이터 과학자, 데이터 엔지니어, ML 아키텍트, 도메인 전문가가 함께 협업</li></ul><hr><h2 id="3-데이터-처리-Data-Processing"><a href="#3-데이터-처리-Data-Processing" class="headerlink" title="3. 데이터 처리 (Data Processing)"></a>3. 데이터 처리 (Data Processing)</h2><ul><li><strong>데이터 수집 및 통합</strong>: 중앙에서 접근 가능하도록 정리</li><li><strong>전처리 및 시각화</strong>: 데이터 품질 확인, 이상치 제거, 결측값 처리</li><li><strong>피처 엔지니어링</strong>: 새로운 변수를 생성, 변환, 추출하여 모델이 학습할 수 있도록 가공</li></ul><p>👉 시험 포인트:<br>AWS 서비스 연결</p><ul><li><strong>AWS Glue</strong>: 데이터 수집&#x2F;정리</li><li><strong>Amazon S3</strong>: 중앙 저장소</li><li><strong>Amazon QuickSight</strong>: 데이터 시각화</li></ul><hr><h2 id="4-탐색적-데이터-분석-EDA-Exploratory-Data-Analysis"><a href="#4-탐색적-데이터-분석-EDA-Exploratory-Data-Analysis" class="headerlink" title="4. 탐색적 데이터 분석 (EDA, Exploratory Data Analysis)"></a>4. 탐색적 데이터 분석 (EDA, Exploratory Data Analysis)</h2><ul><li><strong>그래프 시각화</strong>로 데이터 분포와 특성 이해</li><li><strong>상관행렬(Correlation Matrix)</strong>: 피처들 간의 연관성 파악<ul><li>예: 공부 시간 ↔ 시험 점수 (0.85 상관관계 → 강한 양의 상관관계)</li></ul></li><li>어떤 피처가 모델에 중요한지 판단</li></ul><p align="center">  <img src="/images/aws_basic_142.png" width="80%"></p><hr><h2 id="5-모델-개발-Model-Development"><a href="#5-모델-개발-Model-Development" class="headerlink" title="5. 모델 개발 (Model Development)"></a>5. 모델 개발 (Model Development)</h2><ul><li><strong>모델 학습(Training), 튜닝(Tuning), 평가(Evaluation)</strong></li><li><strong>하이퍼파라미터(Hyperparameters)</strong>: 알고리즘 동작 방식을 조정하는 값 (예: 학습률, 트리 개수 등)</li><li>반복적인 과정 (Iterative Process)<ul><li>추가적인 피처 엔지니어링</li><li>하이퍼파라미터 튜닝</li></ul></li></ul><p>👉 시험 포인트:</p><ul><li><strong>Amazon SageMaker</strong>는 학습, 튜닝, 평가까지 전체 파이프라인을 지원하는 대표 서비스.</li><li>SageMaker <strong>Automatic Model Tuning</strong> 기능도 시험에 자주 나옴.</li></ul><hr><h2 id="6-재학습-Retraining"><a href="#6-재학습-Retraining" class="headerlink" title="6. 재학습 (Retraining)"></a>6. 재학습 (Retraining)</h2><ul><li>새로운 데이터가 들어올 때 모델을 재학습</li><li>피처와 하이퍼파라미터를 조정하여 성능 개선</li></ul><hr><h2 id="7-배포-Deployment"><a href="#7-배포-Deployment" class="headerlink" title="7. 배포 (Deployment)"></a>7. 배포 (Deployment)</h2><ul><li>모델을 실제 환경에 배포하여 <strong>추론(Inferencing)</strong> 시작</li><li><strong>배포 옵션</strong>:<ul><li><strong>실시간 추론 (Real-Time)</strong></li><li><strong>비동기 추론 (Asynchronous)</strong></li><li><strong>배치 추론 (Batch)</strong></li><li><strong>서버리스 (Serverless)</strong></li><li><strong>온프레미스(On-Premises)</strong></li></ul></li></ul><p>👉 시험 포인트:</p><ul><li>SageMaker는 <strong>실시간 엔드포인트</strong>, <strong>배치 변환(Batch Transform)</strong>, <strong>Serverless Inference</strong> 모두 지원</li></ul><hr><h2 id="8-모니터링-Monitoring"><a href="#8-모니터링-Monitoring" class="headerlink" title="8. 모니터링 (Monitoring)"></a>8. 모니터링 (Monitoring)</h2><ul><li>모델이 원하는 성능을 유지하는지 지속적으로 확인</li><li><strong>문제 조기 감지 및 대응(Early Detection &amp; Mitigation)</strong></li><li><strong>모델 드리프트(Model Drift)</strong>: 시간이 지남에 따라 데이터 패턴이 변하면서 모델 성능이 저하되는 현상</li></ul><p>👉 시험 포인트:</p><ul><li><strong>Amazon SageMaker Model Monitor</strong> → 모델 성능 모니터링 자동화</li></ul><hr><h2 id="9-반복-Iteration-과-유지보수"><a href="#9-반복-Iteration-과-유지보수" class="headerlink" title="9. 반복(Iteration)과 유지보수"></a>9. 반복(Iteration)과 유지보수</h2><ul><li><strong>모델 성능 개선 사이클</strong>:<ul><li>새로운 데이터 → 재학습 → 배포 → 모니터링</li></ul></li><li>요구사항과 환경은 시간이 지나면서 변함 → 지속적 개선 필요</li><li>예시: 의류 추천 모델은 <strong>10년 후 패션 트렌드 변화</strong>에 따라 새롭게 학습해야 함</li></ul><hr><h2 id="전체-워크플로우-요약"><a href="#전체-워크플로우-요약" class="headerlink" title="전체 워크플로우 요약"></a>전체 워크플로우 요약</h2><ol><li><strong>비즈니스 목표 정의 &amp; KPI 설정</strong></li><li><strong>ML 문제로 전환</strong></li><li><strong>데이터 수집, 전처리, 피처 엔지니어링</strong></li><li><strong>탐색적 데이터 분석(EDA)</strong></li><li><strong>모델 학습, 튜닝, 평가</strong></li><li><strong>재학습 및 반복 개선</strong></li><li><strong>배포(실시간, 배치, 서버리스 등)</strong></li><li><strong>모니터링 및 디버깅</strong></li><li><strong>지속적 개선 &amp; 요구사항 반영</strong></li></ol><p align="center">  <img src="/images/aws_basic_141.png" width="80%"></p><hr><p>✅ <strong>시험 대비 핵심 포인트</strong>: - KPI 정의가 가장 첫 단계</p><ul><li>EDA(탐색적 데이터 분석)과 상관행렬의 역할</li><li>SageMaker 주요 기능: Training, Tuning, Deployment, Monitoring</li><li>모델 배포 방식: Real-time, Batch, Serverless, On-premises</li><li><strong>모델 드리프트 감지 &amp; 재학습</strong> 중요성</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;머신러닝-프로젝트-단계-Phases-of-Machine-Learning-Project&quot;&gt;&lt;a href=&quot;#머신러닝-프로젝트-단계-Phases-of-Machine-Learning-Project&quot; class=&quot;headerlink&quot; title</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(29) - Phases of a Machine Learning Project</title>
    <link href="https://kish191919.github.io/2025/08/25/AWS-Certified-AI-Practitioner-29/"/>
    <id>https://kish191919.github.io/2025/08/25/AWS-Certified-AI-Practitioner-29/</id>
    <published>2025-08-25T17:33:41.000Z</published>
    <updated>2025-08-25T17:44:54.806Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Phases-of-a-Machine-Learning-Project"><a href="#Phases-of-a-Machine-Learning-Project" class="headerlink" title="Phases of a Machine Learning Project"></a>Phases of a Machine Learning Project</h1><h2 id="1-Define-Business-Goals"><a href="#1-Define-Business-Goals" class="headerlink" title="1. Define Business Goals"></a>1. Define Business Goals</h2><ul><li>Every ML project starts with defining the <strong>business objective</strong>.</li><li><strong>Stakeholders</strong> must agree on:<ul><li>The <strong>value</strong> the project will provide</li><li>The <strong>budget</strong></li><li>The <strong>success criteria</strong></li></ul></li><li><strong>KPI (Key Performance Indicators)</strong> are critical to measure whether<br>the ML model actually achieves business goals.</li></ul><p>👉 <strong>Exam Tip</strong>: AWS often asks about the importance of KPIs in framing an ML project. The first step is always <strong>business problem definition</strong>, not jumping into training a model.</p><hr><h2 id="2-Frame-the-Problem-as-an-ML-Problem"><a href="#2-Frame-the-Problem-as-an-ML-Problem" class="headerlink" title="2. Frame the Problem as an ML Problem"></a>2. Frame the Problem as an ML Problem</h2><ul><li>Convert the <strong>business problem</strong> into a <strong>machine learning problem</strong>.</li><li>Ask: Is machine learning the right tool? Sometimes rules-based systems are more appropriate.</li><li>Collaboration is key: <strong>data scientists, data engineers, ML architects, and subject matter experts (SMEs)</strong> must all contribute.</li></ul><p>👉 <strong>Example</strong>:</p><ul><li>Business problem: “How can we reduce customer churn?”</li><li>ML problem: “Predict whether a customer will leave in the next 30 days.”</li></ul><hr><h2 id="3-Data-Processing"><a href="#3-Data-Processing" class="headerlink" title="3. Data Processing"></a>3. Data Processing</h2><ul><li><strong>Data collection and integration</strong>: Centralize data into a usable location (e.g., Amazon S3).</li><li><strong>Data preprocessing</strong>: Clean, normalize, handle missing values.</li><li><strong>Data visualization</strong>: Understand data patterns and spot anomalies.</li><li><strong>Feature engineering</strong>: Create or transform variables that help the model learn.</li></ul><p>👉 <strong>AWS Services</strong>:</p><ul><li><strong>AWS Glue</strong> for ETL (extract, transform, load)</li><li><strong>Amazon QuickSight</strong> for visualization</li><li><strong>Amazon S3</strong> for data storage</li></ul><hr><h2 id="4-Exploratory-Data-Analysis-EDA"><a href="#4-Exploratory-Data-Analysis-EDA" class="headerlink" title="4. Exploratory Data Analysis (EDA)"></a>4. Exploratory Data Analysis (EDA)</h2><ul><li><strong>Visualize</strong> data distributions and trends using charts.</li><li><strong>Correlation Matrix</strong>: Measures how strongly variables are related.<ul><li>Example: Study hours ↔ Test score correlation of 0.85 shows a strong positive relationship.</li></ul></li><li>Helps you decide which features are most valuable for your model.</li></ul><p align="center">  <img src="/images/aws_basic_142.png" width="80%"></p><p>👉 <strong>Exam Tip</strong>: Feature selection and correlation analysis often appear in ML exam scenarios.</p><hr><h2 id="5-Model-Development"><a href="#5-Model-Development" class="headerlink" title="5. Model Development"></a>5. Model Development</h2><ul><li><strong>Model training</strong>: Fit the model with training data.</li><li><strong>Model tuning</strong>: Adjust <strong>hyperparameters</strong> (e.g., learning rate, number of trees).</li><li><strong>Model evaluation</strong>: Test against validation or test datasets.</li><li>This process is <strong>iterative</strong>:<ul><li>Go back and improve features.</li><li>Try different algorithms.</li><li>Tune hyperparameters repeatedly.</li></ul></li></ul><p>👉 <strong>AWS Services</strong>:</p><ul><li><strong>Amazon SageMaker</strong> provides: - Model training</li><li>Automatic hyperparameter tuning</li><li>Built-in evaluation metrics</li></ul><hr><h2 id="6-Retraining"><a href="#6-Retraining" class="headerlink" title="6. Retraining"></a>6. Retraining</h2><ul><li>As new data arrives, retrain the model to keep it relevant.</li><li>Adjust features and hyperparameters based on performance.</li></ul><hr><h2 id="7-Deployment"><a href="#7-Deployment" class="headerlink" title="7. Deployment"></a>7. Deployment</h2><ul><li>Once the model meets goals, it is deployed for predictions (inference).</li><li><strong>Deployment options</strong>:<ul><li><strong>Real-time</strong> (low-latency APIs)</li><li><strong>Batch</strong> (large-scale predictions at once)</li><li><strong>Serverless</strong> (cost-efficient, scalable)</li><li><strong>On-premises</strong> (for compliance or offline needs)</li></ul></li></ul><p>👉 <strong>AWS Services</strong>:</p><ul><li><strong>SageMaker Endpoints</strong>: real-time inference</li><li><strong>Batch Transform</strong>: batch inference</li><li><strong>Serverless Inference</strong>: scalable, cost-optimized</li></ul><hr><h2 id="8-Monitoring"><a href="#8-Monitoring" class="headerlink" title="8. Monitoring"></a>8. Monitoring</h2><ul><li>Ensure the model maintains expected performance.</li><li><strong>Early detection</strong> of problems such as <strong>model drift</strong> (when new data no longer matches training patterns).</li><li><strong>Debugging</strong> and understanding behavior in production.</li></ul><p>👉 <strong>AWS Service</strong>:</p><ul><li><strong>SageMaker Model Monitor</strong> automatically detects drift, anomalies, and performance degradation.</li></ul><hr><h2 id="9-Iterations-and-Continuous-Improvement"><a href="#9-Iterations-and-Continuous-Improvement" class="headerlink" title="9. Iterations and Continuous Improvement"></a>9. Iterations and Continuous Improvement</h2><ul><li>ML projects are never “one-and-done.”</li><li>As new data becomes available:<ul><li>Retrain</li><li>Deploy again</li><li>Monitor results</li></ul></li><li>Requirements may change over time.</li><li>Example: A clothing recommendation model must be retrained regularly as fashion trends evolve.</li></ul><p>👉 <strong>Exam Tip</strong>: AWS emphasizes <strong>continuous retraining and monitoring</strong> to keep ML models accurate and relevant.</p><hr><h2 id="Workflow-Summary"><a href="#Workflow-Summary" class="headerlink" title="Workflow Summary"></a>Workflow Summary</h2><ol><li>Define <strong>business goals</strong> &amp; KPIs</li><li>Frame as an <strong>ML problem</strong></li><li>Collect &amp; process data</li><li>Perform <strong>EDA</strong> and <strong>feature engineering</strong></li><li>Train, tune, and evaluate the model</li><li>Retrain when needed</li><li>Deploy (real-time, batch, serverless, on-prem)</li><li>Monitor performance &amp; drift</li><li>Iterate for continuous improvement</li></ol><p align="center">  <img src="/images/aws_basic_141.png" width="80%"></p><hr><p>✅ <strong>Key Takeaways for Exams</strong>: - The first step &#x3D; <strong>business goals + KPI definition</strong>.</p><ul><li>EDA and correlation matrices help identify key features.</li><li><strong>SageMaker</strong> supports training, tuning, deployment, and monitoring.</li><li>Know the differences between <strong>real-time vs batch vs serverless</strong> inference.</li><li>Monitoring and retraining are critical due to <strong>model drift</strong>.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Phases-of-a-Machine-Learning-Project&quot;&gt;&lt;a href=&quot;#Phases-of-a-Machine-Learning-Project&quot; class=&quot;headerlink&quot; title=&quot;Phases of a Machine </summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (28) - 머신러닝 추론</title>
    <link href="https://kish191919.github.io/2025/08/25/KO-AWS-Certified-AI-Practitioner-28/"/>
    <id>https://kish191919.github.io/2025/08/25/KO-AWS-Certified-AI-Practitioner-28/</id>
    <published>2025-08-25T17:11:46.000Z</published>
    <updated>2025-08-25T17:29:46.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="머신러닝-–-추론-Inferencing"><a href="#머신러닝-–-추론-Inferencing" class="headerlink" title="머신러닝 – 추론(Inferencing)"></a>머신러닝 – 추론(Inferencing)</h1><h2 id="1-추론이란"><a href="#1-추론이란" class="headerlink" title="1. 추론이란?"></a>1. 추론이란?</h2><ul><li><strong>추론(Inferencing)</strong>: 이미 학습된 모델이 새로운 데이터에 대해<br>예측을 내리는 과정\</li><li>**학습(Training)**은 모델이 패턴을 배우는 과정이고,<br>**추론(Inferencing)**은 학습된 지식을 활용하는 단계</li></ul><hr><h2 id="2-추론의-두-가지-방식"><a href="#2-추론의-두-가지-방식" class="headerlink" title="2. 추론의 두 가지 방식"></a>2. 추론의 두 가지 방식</h2><h3 id="1-실시간-추론-Real-Time-Inference"><a href="#1-실시간-추론-Real-Time-Inference" class="headerlink" title="(1) 실시간 추론 (Real-Time Inference)"></a>(1) 실시간 추론 (Real-Time Inference)</h3><ul><li>데이터가 들어오는 즉시 예측을 내려야 하는 경우</li><li><strong>특징</strong>:<ul><li>빠른 속도가 중요 (정확도보다는 속도 우선)</li><li>결과를 즉각적으로 제공해야 함</li></ul></li><li><strong>예시</strong>: 챗봇, 음성 비서(Alexa, Siri), 온라인 추천 시스템</li></ul><p>👉 AWS 자격증에서 자주 나오는 포인트:<br>실시간 추론은 <strong>지연(latency) 최소화</strong>가 핵심. 모델 정확도가 조금<br>낮더라도 <strong>즉각적인 응답</strong>이 필요한 경우 사용됨.</p><hr><h3 id="2-배치-추론-Batch-Inference"><a href="#2-배치-추론-Batch-Inference" class="headerlink" title="(2) 배치 추론 (Batch Inference)"></a>(2) 배치 추론 (Batch Inference)</h3><ul><li>대량의 데이터를 모아서 한 번에 처리하는 방식</li><li><strong>특징</strong>:<ul><li>속도보다는 정확성이 중요</li><li>분석용으로 주로 사용</li><li>결과를 받기까지 시간이 오래 걸려도 문제 없음 (분 → 시 → 일 단위 가능)</li></ul></li><li><strong>예시</strong>: 대규모 고객 데이터 분석, 리스크 평가 모델</li></ul><p>👉 시험에서 자주 묻는 포인트:</p><ul><li>실시간 vs 배치 추론의 차이점</li><li><strong>실시간 &#x3D; 속도 중시, 배치 &#x3D; 정확성 중시</strong></li></ul><p align="center">  <img src="/images/aws_basic_139.png" width="80%"></p><hr><h2 id="3-엣지-Edge-에서의-추론"><a href="#3-엣지-Edge-에서의-추론" class="headerlink" title="3. 엣지(Edge)에서의 추론"></a>3. 엣지(Edge)에서의 추론</h2><h3 id="1-엣지-디바이스란"><a href="#1-엣지-디바이스란" class="headerlink" title="(1) 엣지 디바이스란?"></a>(1) 엣지 디바이스란?</h3><ul><li>데이터가 생성되는 가까운 위치에 있는 장치들\</li><li>일반적으로 <strong>컴퓨팅 파워가 제한적</strong>이고, <strong>인터넷 연결이 불안정</strong>할<br>수 있음\</li><li>예시: IoT 센서, CCTV, 라즈베리 파이, 스마트폰</li></ul><hr><h3 id="2-소형-언어-모델-SLM-Small-Language-Model"><a href="#2-소형-언어-모델-SLM-Small-Language-Model" class="headerlink" title="(2) 소형 언어 모델 (SLM, Small Language Model)"></a>(2) 소형 언어 모델 (SLM, Small Language Model)</h3><ul><li><strong>엣지 디바이스에서 직접 실행 가능</strong>\</li><li><strong>특징</strong>:<ul><li><strong>지연 시간이 매우 낮음</strong> (인터넷 통신 불필요, 로컬 실행)\</li><li><strong>컴퓨팅 자원 소모 적음</strong>\</li><li><strong>오프라인 상태에서도 추론 가능</strong>\</li></ul></li><li><strong>예시</strong>: 스마트폰 번역 앱, 오프라인 이미지 인식</li></ul><hr><h3 id="3-대형-언어-모델-LLM-Large-Language-Model"><a href="#3-대형-언어-모델-LLM-Large-Language-Model" class="headerlink" title="(3) 대형 언어 모델 (LLM, Large Language Model)"></a>(3) 대형 언어 모델 (LLM, Large Language Model)</h3><ul><li><strong>원격 서버에서 실행</strong>\</li><li><strong>특징</strong>:<ul><li>더 강력한 모델 사용 가능\</li><li>다만, <strong>인터넷 연결 필요</strong>\</li><li><strong>지연 시간(네트워크 왕복)</strong> 발생\</li></ul></li><li><strong>예시</strong>: ChatGPT, Amazon Bedrock 같은 클라우드 기반 AI</li></ul><p>👉 시험 포인트:\</p><ul><li><strong>엣지에서의 추론</strong>은 <strong>SLM → 속도, 오프라인 가능</strong>\</li><li><strong>클라우드 LLM → 성능 우수하지만 지연과 인터넷 의존도 있음</strong>\</li><li>문제에서 “인터넷 연결 불안정, 오프라인 환경”이 나오면 <strong>SLM</strong> 정답!\</li><li>“고성능 모델, 복잡한 연산 필요”가 나오면 <strong>LLM</strong> 선택</li></ul><p align="center">  <img src="/images/aws_basic_140.png" width="80%"></p><hr><h2 id="4-시험-대비-정리-Trade-off-비교"><a href="#4-시험-대비-정리-Trade-off-비교" class="headerlink" title="4. 시험 대비 정리 (Trade-off 비교)"></a>4. 시험 대비 정리 (Trade-off 비교)</h2><hr><p>  구분     실시간 추론       배치 추론      SLM(엣지)       LLM(서버)</p><hr><p>  속도     매우 빠름         느려도 OK      매우 빠름       인터넷 지연<br>                                            (로컬)          발생</p><p>  정확도   다소 낮을 수 있음 최대한 높음    모델 크기       높음<br>                                            제한으로 낮음   </p><p>  환경     챗봇, 음성비서    데이터 분석,   오프라인 IoT,   클라우드 AI<br>                             리스크 모델    스마트폰        서비스</p><h2 id="인터넷-O-O-X-O-필요"><a href="#인터넷-O-O-X-O-필요" class="headerlink" title="  인터넷   O                 O              X               O  필요                                                      "></a>  인터넷   O                 O              X               O<br>  필요                                                      </h2><hr><h2 id="5-추가로-알아두면-좋은-시험-포인트"><a href="#5-추가로-알아두면-좋은-시험-포인트" class="headerlink" title="5. 추가로 알아두면 좋은 시험 포인트"></a>5. 추가로 알아두면 좋은 시험 포인트</h2><ul><li><strong>AWS 관련 서비스와 연결</strong>:<ul><li><strong>Amazon SageMaker</strong>: 실시간&#x2F;배치 추론 모두 지원</li><li><strong>Amazon Bedrock</strong>: 서버 기반 LLM 실행</li><li><strong>AWS IoT Greengrass</strong>: 엣지 디바이스에서 모델 실행 가능</li></ul></li><li><strong>시험 문제 예시</strong>:<ul><li>“한 공장에서 인터넷 연결이 자주 끊기는데, 장치에서 데이터를<br>분석해야 한다. 어떤 추론 방식을 선택할까?” → <strong>엣지 추론, SLM</strong>\</li><li>“수백만 건의 고객 로그를 기반으로 분석을 진행하고, 결과는 하루<br>뒤에 받아도 괜찮다.” → <strong>배치 추론</strong>\</li><li>“고객이 입력한 질문에 즉각 답변해야 한다.” → <strong>실시간 추론</strong>\</li><li>“더 정확한 결과가 필요하고, 인터넷 연결이 안정적이다.” → <strong>LLM<br>원격 서버</strong></li></ul></li></ul><hr><p>👉 요약:\</p><ul><li><strong>실시간 추론 &#x3D; 속도 우선, 챗봇</strong>\</li><li><strong>배치 추론 &#x3D; 정확도 우선, 대규모 분석</strong>\</li><li><strong>SLM(엣지) &#x3D; 빠름 + 오프라인 가능</strong>\</li><li><strong>LLM(서버) &#x3D; 강력하지만 인터넷 필요, 지연 존재</strong></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;머신러닝-–-추론-Inferencing&quot;&gt;&lt;a href=&quot;#머신러닝-–-추론-Inferencing&quot; class=&quot;headerlink&quot; title=&quot;머신러닝 – 추론(Inferencing)&quot;&gt;&lt;/a&gt;머신러닝 – 추론(Inferencing)</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(28) - Machine Learning Inferencing</title>
    <link href="https://kish191919.github.io/2025/08/25/AWS-Certified-AI-Practitioner-28/"/>
    <id>https://kish191919.github.io/2025/08/25/AWS-Certified-AI-Practitioner-28/</id>
    <published>2025-08-25T17:10:35.000Z</published>
    <updated>2025-08-25T17:29:46.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Machine-Learning-–-Inferencing"><a href="#Machine-Learning-–-Inferencing" class="headerlink" title="Machine Learning – Inferencing"></a>Machine Learning – Inferencing</h1><h2 id="1-What-is-Inferencing"><a href="#1-What-is-Inferencing" class="headerlink" title="1. What is Inferencing?"></a>1. What is Inferencing?</h2><ul><li><strong>Inferencing</strong> is when a trained model makes predictions on <strong>new unseen data</strong>.</li><li>Training &#x3D; teaching the model.</li><li>Inferencing &#x3D; applying what the model has learned to make<br>predictions.</li></ul><hr><h2 id="2-Two-Types-of-Inferencing"><a href="#2-Two-Types-of-Inferencing" class="headerlink" title="2. Two Types of Inferencing"></a>2. Two Types of Inferencing</h2><h3 id="1-Real-Time-Inference"><a href="#1-Real-Time-Inference" class="headerlink" title="(1) Real-Time Inference"></a>(1) Real-Time Inference</h3><ul><li>Predictions are made <strong>instantly</strong> as new data arrives.</li><li><strong>Key Points</strong>:<ul><li><strong>Speed is more important than perfect accuracy</strong>.</li><li>Users expect immediate responses.</li></ul></li><li><strong>Examples</strong>:<ul><li>Chatbots (customer service bots, Alexa, Siri)</li><li>Fraud detection while processing a payment</li></ul></li></ul><p>👉 <strong>Exam Tip</strong>: Real-time inference is required when <strong>low latency (fast response)</strong> is critical. Accuracy may be slightly lower, but immediate results are necessary.</p><hr><h3 id="2-Batch-Inference"><a href="#2-Batch-Inference" class="headerlink" title="(2) Batch Inference"></a>(2) Batch Inference</h3><ul><li>Predictions are made on <strong>large datasets all at once</strong>.</li><li><strong>Key Points</strong>:<ul><li>Processing can take <strong>minutes, hours, or days</strong>.</li><li><strong>Accuracy is more important than speed</strong>.</li><li>Often used for large-scale analysis.</li></ul></li><li><strong>Examples</strong>:<ul><li>Analyzing millions of customer transactions overnight</li><li>Generating product recommendations for all users at once</li></ul></li></ul><p>👉 <strong>Exam Tip</strong>: Batch inference is chosen when <strong>speed is not critical</strong>, but <strong>accuracy and completeness</strong> are more important.</p><p align="center">  <img src="/images/aws_basic_139.png" width="80%"></p><hr><h2 id="3-Inferencing-at-the-Edge"><a href="#3-Inferencing-at-the-Edge" class="headerlink" title="3. Inferencing at the Edge"></a>3. Inferencing at the Edge</h2><h3 id="1-What-is-the-Edge"><a href="#1-What-is-the-Edge" class="headerlink" title="(1) What is the Edge?"></a>(1) What is the Edge?</h3><ul><li><strong>Edge devices</strong> are close to where the data is generated.</li><li>Usually have <strong>limited computing power</strong> and may operate with<br><strong>unreliable internet</strong>.</li><li>Examples: IoT sensors, Raspberry Pi, mobile devices, smart cameras.</li></ul><hr><h3 id="2-Small-Language-Models-SLM-on-Edge-Devices"><a href="#2-Small-Language-Models-SLM-on-Edge-Devices" class="headerlink" title="(2) Small Language Models (SLM) on Edge Devices"></a>(2) Small Language Models (SLM) on Edge Devices</h3><ul><li><strong>Run locally on small devices</strong>.</li><li><strong>Key Points</strong>:<ul><li>Very low latency (no internet call required).</li><li>Low compute footprint (uses fewer resources).</li><li>Can work <strong>offline</strong>.</li></ul></li><li><strong>Example</strong>:<ul><li>A smartphone running an offline translation app.</li></ul></li></ul><hr><h3 id="3-Large-Language-Models-LLM-on-Remote-Servers"><a href="#3-Large-Language-Models-LLM-on-Remote-Servers" class="headerlink" title="(3) Large Language Models (LLM) on Remote Servers"></a>(3) Large Language Models (LLM) on Remote Servers</h3><ul><li><strong>Run on powerful cloud servers (not on the device itself)</strong>.</li><li><strong>Key Points</strong>:<ul><li>Can handle <strong>complex tasks</strong> and provide <strong>better accuracy</strong>.</li><li>Requires internet connection.</li><li>Has higher latency (waiting for API response).</li></ul></li><li><strong>Example</strong>:<ul><li>Amazon Bedrock hosting a large model, with the edge device sending API requests.</li></ul></li></ul><p>👉 <strong>Exam Tip</strong>:\</p><ul><li>Use <strong>SLM on edge</strong> if: - Low latency and offline capability are required.</li><li>The device has limited internet connectivity.</li><li>Use <strong>LLM on the cloud</strong> if: - You need higher accuracy and more powerful computation.</li><li>Internet connectivity is reliable.</li></ul><p align="center">  <img src="/images/aws_basic_140.png" width="80%"></p><hr><h2 id="4-Trade-Off-Comparison"><a href="#4-Trade-Off-Comparison" class="headerlink" title="4. Trade-Off Comparison"></a>4. Trade-Off Comparison</h2><hr><p>  Type           Real-Time Inference    Batch Inference   SLM (Edge)   LLM (Cloud)</p><hr><p>  <strong>Speed</strong>      Instant                Slow              Instant      Slower<br>                                        (minutes–days)   (local)      (network<br>                                                                       latency)</p><p>  <strong>Accuracy</strong>   May be lower           High accuracy     Limited by   High<br>                                                          model size   </p><p>  <strong>Use Case</strong>   Chatbots, fraud        Data analytics,   IoT, mobile  Cloud AI<br>                 detection              reporting         apps         services</p><h2 id="Internet-Yes-Yes-No-Yes-Needed"><a href="#Internet-Yes-Yes-No-Yes-Needed" class="headerlink" title="  Internet     Yes                    Yes               No           Yes  Needed                                                             "></a>  <strong>Internet     Yes                    Yes               No           Yes<br>  Needed</strong>                                                             </h2><hr><h2 id="5-AWS-Services-for-Inferencing"><a href="#5-AWS-Services-for-Inferencing" class="headerlink" title="5. AWS Services for Inferencing"></a>5. AWS Services for Inferencing</h2><ul><li><strong>Amazon SageMaker</strong>:<ul><li>Supports <strong>real-time endpoints</strong> and <strong>batch transform jobs</strong>.</li></ul></li><li><strong>Amazon Bedrock</strong>:<ul><li>Provides <strong>LLMs as a managed service</strong> for inference.</li></ul></li><li><strong>AWS IoT Greengrass</strong>:<ul><li>Runs <strong>models locally</strong> on IoT edge devices.</li></ul></li></ul><p>👉 <strong>Common Exam Questions</strong>: 1. <em>A factory with unreliable internet wants to analyze data on-site.</em> → <strong>Edge + SLM</strong><br>2. <em>You need to process millions of records overnight for an analytics report.</em> → <strong>Batch inference</strong><br>3. <em>A chatbot must respond instantly to user queries.</em> → <strong>Real-time inference</strong><br>4. <em>You want maximum accuracy and can rely on cloud connectivity.</em> → <strong>LLM on a remote server</strong></p><hr><p>✅ <strong>Summary</strong>:</p><ul><li><strong>Real-time inference</strong> &#x3D; speed matters (chatbots, fraud detection).</li><li><strong>Batch inference</strong> &#x3D; accuracy matters (large-scale analytics).</li><li><strong>SLM on edge</strong> &#x3D; fast, offline, resource-efficient.</li><li><strong>LLM in cloud</strong> &#x3D; powerful, but requires internet and higher latency.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Machine-Learning-–-Inferencing&quot;&gt;&lt;a href=&quot;#Machine-Learning-–-Inferencing&quot; class=&quot;headerlink&quot; title=&quot;Machine Learning – Inferencing&quot;&gt;</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(27) - Model Evaluation - Classification &amp; Regression</title>
    <link href="https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-27/"/>
    <id>https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-27/</id>
    <published>2025-08-24T00:55:13.000Z</published>
    <updated>2025-08-24T01:05:14.597Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📊-Model-Evaluation-–-Classification-Regression"><a href="#📊-Model-Evaluation-–-Classification-Regression" class="headerlink" title="📊 Model Evaluation – Classification &amp; Regression"></a>📊 Model Evaluation – Classification &amp; Regression</h1><p>When building ML models, it’s not enough to just train them—you also<br>need to evaluate how good they are. Different problems (classification<br>vs regression) use different metrics. Let’s break it down.</p><hr><h2 id="🔹-Binary-Classification-Example-–-Confusion-Matrix"><a href="#🔹-Binary-Classification-Example-–-Confusion-Matrix" class="headerlink" title="🔹 Binary Classification Example – Confusion Matrix"></a>🔹 Binary Classification Example – Confusion Matrix</h2><p>A <strong>confusion matrix</strong> compares actual labels (truth) with the model’s<br>predictions.</p><ul><li><strong>True Positive (TP):</strong> predicted positive, actually positive\</li><li><strong>False Positive (FP):</strong> predicted positive, actually negative\</li><li><strong>True Negative (TN):</strong> predicted negative, actually negative\</li><li><strong>False Negative (FN):</strong> predicted negative, actually positive</li></ul><p>👉 Goal: maximize TP and TN, minimize FP and FN.</p><p align="center">  <img src="/images/aws_basic_135.png" width="80%"></p><h3 id="Key-Metrics"><a href="#Key-Metrics" class="headerlink" title="Key Metrics"></a>Key Metrics</h3><ul><li><p><strong>Precision &#x3D; TP &#x2F; (TP + FP)</strong><br><em>“Of all predicted positives, how many were actually positive?”</em><br>Best when <strong>false positives are costly</strong> (e.g., diagnosing a healthy<br>person as sick).</p></li><li><p><strong>Recall &#x3D; TP &#x2F; (TP + FN)</strong><br><em>“Of all actual positives, how many did we correctly identify?”</em><br>Best when <strong>false negatives are costly</strong> (e.g., missing a cancer<br>diagnosis).</p></li><li><p><strong>F1 Score &#x3D; 2 × (Precision × Recall) &#x2F; (Precision + Recall)</strong><br>Harmonic mean of precision and recall.<br>Best for <strong>imbalanced datasets</strong> where accuracy alone is misleading.</p></li><li><p><strong>Accuracy &#x3D; (TP + TN) &#x2F; (All predictions)</strong><br>Useful only for <strong>balanced datasets</strong>.<br>Example: If 95% of emails are “not spam,” a model that always<br>predicts “not spam” has 95% accuracy but is useless.</p></li></ul><p align="center">  <img src="/images/aws_basic_136.png" width="80%"></p><hr><h2 id="🔹-AUC-ROC-Area-Under-the-Curve-–-Receiver-Operator-Curve"><a href="#🔹-AUC-ROC-Area-Under-the-Curve-–-Receiver-Operator-Curve" class="headerlink" title="🔹 AUC-ROC (Area Under the Curve – Receiver Operator Curve)"></a>🔹 AUC-ROC (Area Under the Curve – Receiver Operator Curve)</h2><ul><li>Plots <strong>True Positive Rate (Sensitivity&#x2F;Recall)</strong> vs <strong>False<br>Positive Rate (1 - Specificity)</strong> at various thresholds.\</li><li><strong>AUC value ranges from 0 to 1.</strong><ul><li><strong>1.0 &#x3D; perfect model</strong>\</li><li><strong>0.5 &#x3D; random guessing</strong></li></ul></li></ul><p>👉 Business use case: choose a threshold that balances precision and<br>recall for your needs (fraud detection, medical tests, etc.).<br>📌 <strong>Exam Tip:</strong> Remember AUC-ROC helps compare multiple models and find<br>the best threshold.</p><p align="center">  <img src="/images/aws_basic_137.png" width="80%"></p><hr><h2 id="🔹-Regression-Model-Metrics"><a href="#🔹-Regression-Model-Metrics" class="headerlink" title="🔹 Regression Model Metrics"></a>🔹 Regression Model Metrics</h2><p>For regression (continuous predictions, e.g., house prices, stock<br>values), we measure <strong>errors</strong>:</p><ul><li><p><strong>MAE (Mean Absolute Error):</strong> average absolute difference between<br>prediction and truth.<br>→ Easy to interpret: “On average, the model is off by X units.”</p></li><li><p><strong>MAPE (Mean Absolute Percentage Error):</strong> average error as a<br>percentage.<br>→ Useful when scale of values matters (e.g., sales forecasts).</p></li><li><p><strong>RMSE (Root Mean Squared Error):</strong> penalizes large errors more<br>heavily than MAE.<br>→ Common when big mistakes are unacceptable.</p></li><li><p><strong>R² (Coefficient of Determination):</strong> measures how much variance in<br>the target is explained by the model.</p><ul><li>R² &#x3D; 0.8 → 80% of variation is explained by features, 20% by<br>noise&#x2F;other factors.\</li><li>R² close to 1 &#x3D; strong model.</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_138.png" width="80%"></p><hr><h2 id="🔹-Example-Regression-Metrics-in-Action"><a href="#🔹-Example-Regression-Metrics-in-Action" class="headerlink" title="🔹 Example (Regression Metrics in Action)"></a>🔹 Example (Regression Metrics in Action)</h2><p>You predict student test scores based on study hours:</p><ul><li><strong>RMSE &#x3D; 5</strong> → model predictions are ~5 points off on average.\</li><li><strong>R² &#x3D; 0.8</strong> → 80% of score differences explained by study hours,<br>20% due to natural ability or luck.</li></ul><hr><h2 id="✅-Key-Takeaways-Exam-Perspective"><a href="#✅-Key-Takeaways-Exam-Perspective" class="headerlink" title="✅ Key Takeaways (Exam Perspective)"></a>✅ Key Takeaways (Exam Perspective)</h2><ul><li><strong>Classification models → Confusion Matrix, Precision, Recall, F1,<br>Accuracy, AUC-ROC</strong>\</li><li><strong>Regression models → MAE, MAPE, RMSE, R²</strong>\</li><li><strong>Choose metrics based on business need:</strong><ul><li>Precision for costly false positives\</li><li>Recall for costly false negatives\</li><li>F1 for imbalanced data\</li><li>Accuracy only for balanced datasets</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📊-Model-Evaluation-–-Classification-Regression&quot;&gt;&lt;a href=&quot;#📊-Model-Evaluation-–-Classification-Regression&quot; class=&quot;headerlink&quot; title</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (27) - 이진 분류와 혼동 행렬 (Confusion Matrix)</title>
    <link href="https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-27/"/>
    <id>https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-27/</id>
    <published>2025-08-24T00:55:08.000Z</published>
    <updated>2025-08-25T17:10:15.641Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📊-Model-Evaluation-in-Machine-Learning"><a href="#📊-Model-Evaluation-in-Machine-Learning" class="headerlink" title="📊 Model Evaluation in Machine Learning"></a>📊 Model Evaluation in Machine Learning</h1><p>머신러닝 모델을 만들었을 때, <strong>성능이 잘 나오는지</strong>를 확인하는 과정이 필요합니다.<br>이때 <strong>분류(Classification)</strong> 모델과 <strong>회귀(Regression)</strong> 모델의 평가 방식이 다르므로 구분해서 알아두어야 합니다.</p><hr><h2 id="🔹-이진-분류-Binary-Classification-와-혼동-행렬-Confusion-Matrix"><a href="#🔹-이진-분류-Binary-Classification-와-혼동-행렬-Confusion-Matrix" class="headerlink" title="🔹 이진 분류 (Binary Classification)와 혼동 행렬 (Confusion Matrix)"></a>🔹 이진 분류 (Binary Classification)와 혼동 행렬 (Confusion Matrix)</h2><h3 id="Confusion-Matrix란"><a href="#Confusion-Matrix란" class="headerlink" title="Confusion Matrix란?"></a>Confusion Matrix란?</h3><ul><li>실제 정답(라벨)과 모델 예측값을 비교해서 성능을 평가하는 도구  </li><li>네 가지 값으로 나뉩니다:</li></ul><table><thead><tr><th>구분</th><th>예측 Positive</th><th>예측 Negative</th></tr></thead><tbody><tr><td>실제 Positive</td><td><strong>True Positive (TP)</strong></td><td><strong>False Negative (FN)</strong></td></tr><tr><td>실제 Negative</td><td><strong>False Positive (FP)</strong></td><td><strong>True Negative (TN)</strong></td></tr></tbody></table><p>👉 목표: <strong>TP와 TN을 최대화</strong>하고, <strong>FP와 FN을 최소화</strong>하는 것.</p><p align="center">  <img src="/images/aws_basic_135.png" width="80%"></p><hr><h3 id="주요-평가-지표-Classification-Metrics"><a href="#주요-평가-지표-Classification-Metrics" class="headerlink" title="주요 평가 지표 (Classification Metrics)"></a>주요 평가 지표 (Classification Metrics)</h3><ul><li><p><strong>Precision (정밀도)</strong>  </p><ul><li>공식: TP &#x2F; (TP + FP)  </li><li>“Positive라고 예측한 것 중에서, 실제로 Positive인 비율”  </li><li>**False Positive(잘못된 양성 예측)**이 치명적인 경우 중요  </li><li>예: 스팸 필터에서 정상 메일을 스팸으로 잘못 분류하면 안 됨</li></ul></li><li><p><strong>Recall (재현율, 민감도)</strong>  </p><ul><li>공식: TP &#x2F; (TP + FN)  </li><li>“실제 Positive 중에서, 제대로 맞춘 비율”  </li><li>**False Negative(놓친 케이스)**가 치명적인 경우 중요  </li><li>예: 암 진단 모델에서 환자를 “정상”으로 잘못 분류하면 안 됨</li></ul></li><li><p><strong>F1 Score</strong>  </p><ul><li>공식: 2 × (Precision × Recall) &#x2F; (Precision + Recall)  </li><li>Precision과 Recall의 <strong>균형을 평가</strong>  </li><li>특히 **데이터가 불균형(imbalanced dataset)**할 때 유용</li></ul></li><li><p><strong>Accuracy (정확도)</strong>  </p><ul><li>공식: (TP + TN) &#x2F; 전체 데이터  </li><li>단순히 “얼마나 맞췄는가”  </li><li>데이터가 <strong>균형 잡힌 경우</strong>에만 의미 있음  </li><li>예: 95%가 Negative인 데이터에서 Accuracy 95% → 쓸모없는 지표</li></ul></li></ul><p>📌 <strong>시험 팁</strong>:  </p><ul><li><strong>Precision → FP가 비쌀 때</strong>  </li><li><strong>Recall → FN이 비쌀 때</strong>  </li><li><strong>F1 → 불균형 데이터셋에서 균형 평가</strong>  </li><li><strong>Accuracy → 데이터가 균형일 때만</strong></li></ul><p align="center">  <img src="/images/aws_basic_136.png" width="80%"></p><hr><h2 id="🔹-AUC-ROC-Area-Under-the-Curve-Receiver-Operating-Characteristic"><a href="#🔹-AUC-ROC-Area-Under-the-Curve-Receiver-Operating-Characteristic" class="headerlink" title="🔹 AUC-ROC (Area Under the Curve - Receiver Operating Characteristic)"></a>🔹 AUC-ROC (Area Under the Curve - Receiver Operating Characteristic)</h2><ul><li><strong>0 ~ 1 사이 값</strong>, 1에 가까울수록 완벽한 모델  </li><li>축:  <ul><li>X축 → False Positive Rate (1 - Specificity)  </li><li>Y축 → True Positive Rate (Sensitivity, Recall)</li></ul></li><li>여러 Threshold(임계값)를 기준으로 Confusion Matrix를 만들고 곡선을 그림  </li><li>AUC &#x3D; ROC Curve 아래 면적</li></ul><p>👉 <strong>시험 포인트</strong>:  </p><ul><li>AUC가 클수록 모델이 좋은 것  </li><li>다양한 임계값을 비교할 때 활용</li></ul><p align="center">  <img src="/images/aws_basic_137.png" width="80%"></p><hr><h2 id="🔹-회귀-모델-평가-지표-Regression-Metrics"><a href="#🔹-회귀-모델-평가-지표-Regression-Metrics" class="headerlink" title="🔹 회귀 모델 평가 지표 (Regression Metrics)"></a>🔹 회귀 모델 평가 지표 (Regression Metrics)</h2><p>회귀 모델은 <strong>연속적인 값</strong>을 예측하기 때문에 평가 방식이 다릅니다.</p><ul><li><p><strong>MAE (Mean Absolute Error)</strong>  </p><ul><li>예측값과 실제값 차이의 절댓값 평균  </li><li>직관적이고 해석하기 쉬움  </li><li>예: MAE &#x3D; 5 → 평균적으로 5점 차이 발생</li></ul></li><li><p><strong>MAPE (Mean Absolute Percentage Error)</strong>  </p><ul><li>퍼센트 기준 오차율  </li><li>값의 크기가 다양할 때 상대적 오류를 보려면 사용</li></ul></li><li><p><strong>RMSE (Root Mean Squared Error)</strong>  </p><ul><li>오차를 제곱 후 평균 내고 제곱근을 취함  </li><li>큰 오차에 더 민감 → 모델 안정성 평가에 유용</li></ul></li><li><p><strong>R² (R-Squared, 결정계수)</strong>  </p><ul><li>모델이 데이터를 얼마나 설명할 수 있는지를 나타냄  </li><li>값이 1에 가까울수록 좋은 모델  </li><li>예: R² &#x3D; 0.8 → 모델이 80%를 설명, 나머지 20%는 다른 요인</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_138.png" width="80%"></p><p>📌 <strong>시험 팁</strong>:  </p><ul><li>분류(Classification) → Precision, Recall, F1, Accuracy, AUC-ROC  </li><li>회귀(Regression) → MAE, MAPE, RMSE, R²</li></ul><hr><h1 id="✅-정리-시험-대비-핵심"><a href="#✅-정리-시험-대비-핵심" class="headerlink" title="✅ 정리 (시험 대비 핵심)"></a>✅ 정리 (시험 대비 핵심)</h1><ul><li><strong>Classification 평가 지표</strong>: Confusion Matrix, Precision, Recall, F1, Accuracy, AUC-ROC  </li><li><strong>Regression 평가 지표</strong>: MAE, MAPE, RMSE, R²  </li><li><strong>Precision ↔ Recall Trade-off</strong> 기억하기 (특히 시험에 자주 출제)</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📊-Model-Evaluation-in-Machine-Learning&quot;&gt;&lt;a href=&quot;#📊-Model-Evaluation-in-Machine-Learning&quot; class=&quot;headerlink&quot; title=&quot;📊 Model Evalu</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (26) - 모델 적합도와 편향 &amp; 분산</title>
    <link href="https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-26/"/>
    <id>https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-26/</id>
    <published>2025-08-24T00:39:04.000Z</published>
    <updated>2025-08-24T01:05:14.598Z</updated>
    
    <content type="html"><![CDATA[<h1 id="🤖-모델-적합도-Model-Fit-와-편향-Bias-·-분산-Variance"><a href="#🤖-모델-적합도-Model-Fit-와-편향-Bias-·-분산-Variance" class="headerlink" title="🤖 모델 적합도(Model Fit)와 편향(Bias) · 분산(Variance)"></a>🤖 모델 적합도(Model Fit)와 편향(Bias) · 분산(Variance)</h1><h2 id="1-모델-적합도-Model-Fit"><a href="#1-모델-적합도-Model-Fit" class="headerlink" title="1. 모델 적합도(Model Fit)"></a>1. 모델 적합도(Model Fit)</h2><p>머신러닝 모델이 제대로 동작하지 않을 때는 <strong>모델의 적합도(Fit)</strong> 를 살펴봐야 합니다.<br>모델이 데이터를 얼마나 잘 설명하는지가 핵심입니다.  </p><ul><li><p><strong>과적합(Overfitting)</strong>  </p><ul><li>훈련 데이터에서는 성능이 매우 좋음  </li><li>새로운 데이터(검증&#x2F;테스트 데이터)에서는 성능이 나쁨  </li><li>원인: 모델이 데이터의 <strong>노이즈까지 학습</strong>해서 일반화가 안 됨  </li><li>📌 예시: 훈련 데이터 점 하나하나에 맞게 선을 구부려 만든 복잡한 곡선</li></ul></li><li><p><strong>과소적합(Underfitting)</strong>  </p><ul><li>훈련 데이터에서도 성능이 나쁨  </li><li>원인: 모델이 너무 단순하거나, 특징(Feature)이 부족함  </li><li>📌 예시: 복잡한 곡선 데이터에 단순 직선을 억지로 적용</li></ul></li><li><p><strong>균형(Balanced)</strong>  </p><ul><li>과적합도, 과소적합도 아닌 상태  </li><li>어느 정도 오차는 있지만, 데이터의 전체적인 패턴을 잘 따름  </li><li>📌 가장 이상적인 상황</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_129.png" width="80%"></p><hr><h2 id="2-편향-Bias-과-분산-Variance"><a href="#2-편향-Bias-과-분산-Variance" class="headerlink" title="2. 편향(Bias)과 분산(Variance)"></a>2. 편향(Bias)과 분산(Variance)</h2><h3 id="📌-Bias-편향"><a href="#📌-Bias-편향" class="headerlink" title="📌 Bias (편향)"></a>📌 Bias (편향)</h3><ul><li><strong>정의</strong>: 실제 값과 예측 값의 차이  </li><li><strong>High Bias (편향 높음)</strong>  <ul><li>모델이 데이터 패턴을 잘 잡지 못함 → 과소적합  </li><li>예시: 곡선 패턴 데이터를 직선으로 예측</li></ul></li><li><strong>줄이는 방법</strong>  <ul><li>더 복잡한 모델 사용 (예: 선형 → 비선형 모델)  </li><li>더 많은 특징(Feature) 추가</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_130.png" width="80%"></p><hr><h3 id="📌-Variance-분산"><a href="#📌-Variance-분산" class="headerlink" title="📌 Variance (분산)"></a>📌 Variance (분산)</h3><ul><li><strong>정의</strong>: 훈련 데이터를 조금만 바꿔도 모델 성능이 크게 달라지는 정도  </li><li><strong>High Variance (분산 높음)</strong>  <ul><li>훈련 데이터에서는 성능이 매우 좋지만, 새로운 데이터에서는 성능이 급격히 떨어짐  </li><li>즉, 과적합 상황</li></ul></li><li><strong>줄이는 방법</strong>  <ul><li>불필요한 특징 제거 (Feature Selection)  </li><li>데이터셋을 여러 번 나눠서 교차검증(Cross Validation) 수행  </li><li>정규화(Regularization, 예: L1&#x2F;L2) 적용</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_131.png" width="80%"></p><hr><h2 id="3-Bias-Variance-Tradeoff-편향-분산-트레이드오프"><a href="#3-Bias-Variance-Tradeoff-편향-분산-트레이드오프" class="headerlink" title="3. Bias-Variance Tradeoff (편향-분산 트레이드오프)"></a>3. Bias-Variance Tradeoff (편향-분산 트레이드오프)</h2><p>머신러닝에서는 <strong>Bias(편향)</strong> 과 <strong>Variance(분산)</strong> 사이에서 균형을 맞추는 것이 중요합니다.</p><ul><li><strong>High Bias + Low Variance → 과소적합</strong></li><li><strong>Low Bias + High Variance → 과적합</strong></li><li><strong>Low Bias + Low Variance → 이상적인 모델</strong></li><li><strong>High Bias + High Variance → 최악의 경우 (피해야 함)</strong></li></ul><p>📌 시험 포인트:  </p><ul><li>과적합 ↔ 분산 높음 (Variance High)  </li><li>과소적합 ↔ 편향 높음 (Bias High)  </li><li>균형 잡힌 모델이 가장 좋은 상태</li></ul><p align="center">  <img src="/images/aws_basic_132.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_133.png" width="80%"></p><hr><h2 id="4-시각적-이해-다트판-예시-🎯"><a href="#4-시각적-이해-다트판-예시-🎯" class="headerlink" title="4. 시각적 이해 (다트판 예시 🎯)"></a>4. 시각적 이해 (다트판 예시 🎯)</h2><ul><li><strong>편향(Bias)</strong>: 다트가 과녁의 중심에서 얼마나 떨어져 있는지  </li><li><strong>분산(Variance)</strong>: 다트가 흩어져 있는 정도</li></ul><table><thead><tr><th>구분</th><th>설명</th><th>결과</th></tr></thead><tbody><tr><td>High Bias + Low Variance</td><td>계속 같은 위치에 맞추지만 중심에서 멂</td><td>Underfitting</td></tr><tr><td>Low Bias + High Variance</td><td>중심 근처에 맞추지만 흩어져 있음</td><td>Overfitting</td></tr><tr><td>Low Bias + Low Variance</td><td>중심에 가깝고 모여 있음</td><td>Best Model</td></tr><tr><td>High Bias + High Variance</td><td>멀리 있고 흩어져 있음</td><td>Worst Model</td></tr></tbody></table><hr><h2 id="✅-시험-대비-Key-Takeaways"><a href="#✅-시험-대비-Key-Takeaways" class="headerlink" title="✅ 시험 대비 Key Takeaways"></a>✅ 시험 대비 Key Takeaways</h2><ol><li><strong>Overfitting</strong> → 훈련 데이터 잘 맞춤, 테스트 데이터 성능 나쁨 → Variance ↑  </li><li><strong>Underfitting</strong> → 훈련 데이터조차 성능 나쁨 → Bias ↑  </li><li><strong>Balanced Fit</strong> → Bias와 Variance 모두 낮아야 함  </li><li><strong>Bias-Variance Tradeoff</strong> 개념 숙지 필수  </li><li>AWS 자격증 시험에서는 <strong>과적합 &#x2F; 과소적합을 어떻게 해결할지</strong>를 물을 수 있음  <ul><li>과적합 해결: Regularization, Feature Selection, Cross Validation  </li><li>과소적합 해결: 더 복잡한 모델, Feature 추가</li></ul></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;🤖-모델-적합도-Model-Fit-와-편향-Bias-·-분산-Variance&quot;&gt;&lt;a href=&quot;#🤖-모델-적합도-Model-Fit-와-편향-Bias-·-분산-Variance&quot; class=&quot;headerlink&quot; title=&quot;🤖 모델 </summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(26) - Model Fit, Bias, and Variance</title>
    <link href="https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-26/"/>
    <id>https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-26/</id>
    <published>2025-08-24T00:39:00.000Z</published>
    <updated>2025-08-24T01:02:42.203Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📊-Model-Fit-Bias-and-Variance"><a href="#📊-Model-Fit-Bias-and-Variance" class="headerlink" title="📊 Model Fit, Bias, and Variance"></a>📊 Model Fit, Bias, and Variance</h1><p>When a machine learning model performs poorly, one of the first things<br>to check is whether it’s a <strong>good fit</strong> for the data. This is often<br>discussed in terms of <strong>overfitting</strong>, <strong>underfitting</strong>, and<br><strong>balance</strong>.</p><hr><h2 id="✅-Model-Fit"><a href="#✅-Model-Fit" class="headerlink" title="✅ Model Fit"></a>✅ Model Fit</h2><h3 id="🔹-Overfitting"><a href="#🔹-Overfitting" class="headerlink" title="🔹 Overfitting"></a>🔹 Overfitting</h3><ul><li>The model performs <strong>very well</strong> on training data.\</li><li>But performs <strong>poorly</strong> on evaluation or unseen test data.\</li><li>Example: A line that connects every single training point perfectly<br>— great for training, useless for new data.\</li><li>Common when the model is <strong>too complex</strong> and “memorizes” instead of<br>generalizing.</li></ul><h3 id="🔹-Underfitting"><a href="#🔹-Underfitting" class="headerlink" title="🔹 Underfitting"></a>🔹 Underfitting</h3><ul><li>The model performs poorly even on training data.\</li><li>Often happens when the model is <strong>too simple</strong> (e.g., a straight<br>line for data that is clearly non-linear).\</li><li>Can also be caused by <strong>poor features</strong>.</li></ul><h3 id="🔹-Balanced-Fit"><a href="#🔹-Balanced-Fit" class="headerlink" title="🔹 Balanced Fit"></a>🔹 Balanced Fit</h3><ul><li>Neither overfitting nor underfitting.\</li><li>The model generalizes well: some error is expected, but predictions<br>follow the data trend.\</li><li><strong>Goal: Low training error + low test error.</strong></li></ul><p>👉 <strong>AWS Exam Tip</strong>: You might get questions asking which situation<br>describes <em>overfitting vs. underfitting</em>. Remember:\</p><ul><li><strong>Overfitting → High variance problem.</strong>\</li><li><strong>Underfitting → High bias problem.</strong></li></ul><p align="center">  <img src="/images/aws_basic_129.png" width="80%"></p><hr><h2 id="⚖️-Bias-and-Variance"><a href="#⚖️-Bias-and-Variance" class="headerlink" title="⚖️ Bias and Variance"></a>⚖️ Bias and Variance</h2><p>Bias and variance help explain why models underfit or overfit.</p><h3 id="🔹-Bias"><a href="#🔹-Bias" class="headerlink" title="🔹 Bias"></a>🔹 Bias</h3><ul><li>Difference between <strong>predicted values</strong> and <strong>actual values</strong>.\</li><li>High Bias &#x3D; model is too simple → can’t capture the pattern.\</li><li>Example: Using linear regression on a clearly curved dataset.\</li><li>Considered <strong>underfitting</strong>.</li></ul><p><strong>How to reduce bias:</strong> - Use a <strong>more complex model</strong> (e.g., move from<br>linear regression to decision trees or neural networks).\</p><ul><li>Add more <strong>features</strong> (better input data).</li></ul><p align="center">  <img src="/images/aws_basic_130.png" width="80%"></p><hr><h3 id="🔹-Variance"><a href="#🔹-Variance" class="headerlink" title="🔹 Variance"></a>🔹 Variance</h3><ul><li>Describes how much the model’s predictions change if trained on<br>different (but similar) datasets.\</li><li>High Variance &#x3D; model is <strong>too sensitive</strong> to training data<br>changes.\</li><li>Typical in <strong>overfitting</strong> cases.</li></ul><p><strong>How to reduce variance:</strong> - Feature selection (keep fewer, more<br>important features).\</p><ul><li>Use <strong>cross-validation</strong> (split data into train&#x2F;test multiple times).\</li><li>Regularization techniques (e.g., L1&#x2F;L2 penalties).</li></ul><p align="center">  <img src="/images/aws_basic_131.png" width="80%"></p><hr><h2 id="🎯-Putting-It-All-Together"><a href="#🎯-Putting-It-All-Together" class="headerlink" title="🎯 Putting It All Together"></a>🎯 Putting It All Together</h2><ul><li><strong>High Bias, Low Variance</strong> → Underfitting (too simple).\</li><li><strong>Low Bias, High Variance</strong> → Overfitting (too complex).\</li><li><strong>High Bias, High Variance</strong> → Bad model (don’t use it).\</li><li><strong>Low Bias, Low Variance</strong> → Balanced (ideal).</li></ul><h3 id="🎯-Visual-Analogy-–-Dartboard-🎯"><a href="#🎯-Visual-Analogy-–-Dartboard-🎯" class="headerlink" title="🎯 Visual Analogy – Dartboard 🎯"></a>🎯 Visual Analogy – Dartboard 🎯</h3><ul><li><strong>High Bias</strong>: All darts clustered far from the bullseye<br>(consistently wrong).\</li><li><strong>High Variance</strong>: Darts scattered everywhere (inconsistent).\</li><li><strong>Balanced</strong>: Darts tightly grouped near the bullseye.</li></ul><p align="center">  <img src="/images/aws_basic_132.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_133.png" width="80%"></p><hr><h2 id="🔑-Key-Takeaways-Exam-Focused"><a href="#🔑-Key-Takeaways-Exam-Focused" class="headerlink" title="🔑 Key Takeaways (Exam-Focused)"></a>🔑 Key Takeaways (Exam-Focused)</h2><ul><li><strong>Overfitting</strong> &#x3D; High variance problem → fix with simpler models or<br>regularization.\</li><li><strong>Underfitting</strong> &#x3D; High bias problem → fix with more complex models<br>or better features.\</li><li><strong>Balanced models</strong> generalize well.\</li><li>AWS exams often test your understanding of these tradeoffs when<br>evaluating ML models.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📊-Model-Fit-Bias-and-Variance&quot;&gt;&lt;a href=&quot;#📊-Model-Fit-Bias-and-Variance&quot; class=&quot;headerlink&quot; title=&quot;📊 Model Fit, Bias, and Variance</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(25) - Reinforcement Learning</title>
    <link href="https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-25/"/>
    <id>https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-25/</id>
    <published>2025-08-24T00:17:27.000Z</published>
    <updated>2025-08-24T00:33:26.299Z</updated>
    
    <content type="html"><![CDATA[<h1 id="🧠-Reinforcement-Learning-RL-RLHF"><a href="#🧠-Reinforcement-Learning-RL-RLHF" class="headerlink" title="🧠 Reinforcement Learning (RL) &amp; RLHF"></a>🧠 Reinforcement Learning (RL) &amp; RLHF</h1><h2 id="1-What-is-Reinforcement-Learning-RL"><a href="#1-What-is-Reinforcement-Learning-RL" class="headerlink" title="1. What is Reinforcement Learning (RL)?"></a>1. What is Reinforcement Learning (RL)?</h2><p>Reinforcement Learning is a type of machine learning where an <strong>agent</strong><br>learns to make decisions by interacting with an <strong>environment</strong> and<br>maximizing rewards.</p><ul><li><strong>Agent</strong> → the learner or decision-maker (e.g., a robot, software<br>bot).\</li><li><strong>Environment</strong> → the external system the agent interacts with<br>(e.g., a maze, stock market).\</li><li><strong>State</strong> → the current situation of the environment.\</li><li><strong>Action</strong> → the choice the agent makes.\</li><li><strong>Reward</strong> → feedback (positive or negative) from the environment.\</li><li><strong>Policy</strong> → the strategy the agent follows to decide its next<br>action.</li></ul><p>👉 <strong>Exam Tip:</strong> RL is less common in AWS certification questions, but<br>you may see it in contexts like <strong>robotics, gaming, or reinforcement<br>learning from human feedback (RLHF)</strong> in generative AI.</p><p align="center">  <img src="/images/aws_basic_123.png" width="80%"></p><hr><h2 id="2-How-Does-RL-Work"><a href="#2-How-Does-RL-Work" class="headerlink" title="2. How Does RL Work?"></a>2. How Does RL Work?</h2><ol><li>The agent observes the <strong>current state</strong>.\</li><li>It selects an <strong>action</strong> based on its <strong>policy</strong>.\</li><li>The environment transitions to a <strong>new state</strong> and gives a<br><strong>reward</strong>.\</li><li>The agent updates its <strong>policy</strong> to improve future actions.</li></ol><p>🎯 Goal: <strong>Maximize cumulative rewards over time.</strong></p><p align="center">  <img src="/images/aws_basic_124.png" width="80%"></p><hr><h2 id="3-Example-Robot-in-a-Maze"><a href="#3-Example-Robot-in-a-Maze" class="headerlink" title="3. Example: Robot in a Maze"></a>3. Example: Robot in a Maze</h2><ul><li><strong>Agent:</strong> Robot\</li><li><strong>Environment:</strong> Maze\</li><li><strong>Actions:</strong> Move up, down, left, right\</li><li><strong>Rewards:</strong><ul><li><code>-1</code> for taking a step\</li><li><code>-10</code> for hitting a wall\</li><li><code>+100</code> for reaching the exit</li></ul></li></ul><p>👉 Over time, the robot learns the best path to the exit by trial and<br>error.</p><p align="center">  <img src="/images/aws_basic_125.png" width="80%"></p><p>👉 Click the image or link to watch the video: <a href="https://youtu.be/2tamH76Tjvw">AI Learns to Escape</a></p><hr><h2 id="4-Applications-of-Reinforcement-Learning"><a href="#4-Applications-of-Reinforcement-Learning" class="headerlink" title="4. Applications of Reinforcement Learning"></a>4. Applications of Reinforcement Learning</h2><ul><li><strong>Gaming</strong> → Chess, Go, StarCraft\</li><li><strong>Robotics</strong> → navigation, object manipulation\</li><li><strong>Finance</strong> → portfolio management, trading strategies\</li><li><strong>Healthcare</strong> → personalized treatment recommendations\</li><li><strong>Autonomous Vehicles</strong> → path planning and decision-making</li></ul><p>👉 <strong>Exam Tip:</strong> AWS exams might frame RL in <strong>autonomous systems</strong> or<br><strong>AI training optimization</strong> contexts.</p><hr><h2 id="5-What-is-RLHF-Reinforcement-Learning-from-Human-Feedback"><a href="#5-What-is-RLHF-Reinforcement-Learning-from-Human-Feedback" class="headerlink" title="5. What is RLHF? (Reinforcement Learning from Human Feedback)"></a>5. What is RLHF? (Reinforcement Learning from Human Feedback)</h2><p>RLHF is widely used in <strong>Generative AI</strong> (like GPT models).<br>It combines <strong>reinforcement learning</strong> with <strong>human feedback</strong> to better<br>align AI with human goals.</p><ul><li>In standard RL, rewards are fixed (e.g., +100 for reaching the<br>exit).\</li><li>In RLHF, <strong>humans help define the reward function</strong> by ranking<br>outputs.</li></ul><p>Example:\</p><ul><li>Machine translation → “technically correct” vs. “natural-sounding”<br>translation.\</li><li>Humans score the responses → model learns to prefer human-preferred<br>outputs.</li></ul><hr><h2 id="6-How-Does-RLHF-Work"><a href="#6-How-Does-RLHF-Work" class="headerlink" title="6. How Does RLHF Work?"></a>6. How Does RLHF Work?</h2><ol><li><strong>Data Collection</strong> → Create human prompts + responses.<ul><li>Example: “Where is the HR department in Boston?”\</li></ul></li><li><strong>Supervised Fine-Tuning</strong> → Train a base model with labeled<br>responses.\</li><li><strong>Reward Model Creation</strong> → Humans rank multiple responses → AI<br>learns a <strong>reward model</strong>.\</li><li><strong>Optimization</strong> → Use the reward model to further train the base<br>model with reinforcement learning.</li></ol><p>🔄 This process can be repeated and eventually <strong>automated</strong>.</p><p align="center">  <img src="/images/aws_basic_128.png" width="80%"></p><hr><h2 id="7-Why-is-RLHF-Important"><a href="#7-Why-is-RLHF-Important" class="headerlink" title="7. Why is RLHF Important?"></a>7. Why is RLHF Important?</h2><ul><li>Aligns AI systems with <strong>human preferences</strong>.\</li><li>Used in <strong>LLMs (Large Language Models)</strong> like ChatGPT, Anthropic<br>Claude, and others.\</li><li>Improves quality, safety, and usefulness of responses.</li></ul><p>👉 <strong>Exam Tip:</strong><br>If you see <strong>“human feedback”</strong> or <strong>“reward model”</strong>, the answer is<br>likely <strong>RLHF</strong>.</p><hr><h2 id="✅-Key-Takeaways"><a href="#✅-Key-Takeaways" class="headerlink" title="✅ Key Takeaways"></a>✅ Key Takeaways</h2><ul><li><strong>Reinforcement Learning (RL):</strong> Agent learns via trial and error to<br>maximize cumulative reward.\</li><li><strong>Applications:</strong> Games, robotics, finance, healthcare, autonomous<br>vehicles.\</li><li><strong>RLHF:</strong> Human feedback is added to the reward function → critical<br>in modern LLMs.\</li><li><strong>Exam Strategy:</strong> Focus less on math and more on <strong>concepts +<br>applications</strong>.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;🧠-Reinforcement-Learning-RL-RLHF&quot;&gt;&lt;a href=&quot;#🧠-Reinforcement-Learning-RL-RLHF&quot; class=&quot;headerlink&quot; title=&quot;🧠 Reinforcement Learning </summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (25) - 강화학습</title>
    <link href="https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-25/"/>
    <id>https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-25/</id>
    <published>2025-08-24T00:17:22.000Z</published>
    <updated>2025-08-25T15:50:22.993Z</updated>
    
    <content type="html"><![CDATA[<h1 id="🧠-강화학습-Reinforcement-Learning-RL-과-RLHF-쉽게-이해하기"><a href="#🧠-강화학습-Reinforcement-Learning-RL-과-RLHF-쉽게-이해하기" class="headerlink" title="🧠 강화학습(Reinforcement Learning, RL)과 RLHF 쉽게 이해하기"></a>🧠 강화학습(Reinforcement Learning, RL)과 RLHF 쉽게 이해하기</h1><h2 id="1-강화학습이란"><a href="#1-강화학습이란" class="headerlink" title="1. 강화학습이란?"></a>1. 강화학습이란?</h2><p>강화학습(RL)은 <strong>환경(Environment)</strong> 속에서 **에이전트(Agent)**가<br>행동(Action)을 수행하면서 보상(Reward)을 얻고, 장기적으로 누적 보상을<br>극대화하는 방식으로 학습하는 머신러닝 기법입니다.</p><ul><li><strong>핵심 개념</strong><ul><li><strong>Agent</strong>: 학습자 또는 의사결정자 (예: 로봇)</li><li><strong>Environment</strong>: 에이전트가 상호작용하는 외부 시스템 (예: 미로)</li><li><strong>Action</strong>: 에이전트가 선택할 수 있는 행동 (예: 위, 아래, 왼쪽,오른쪽 이동)</li><li><strong>Reward</strong>: 행동의 결과에 따른 피드백 (예: +100 점 &#x3D; 성공, -10점 &#x3D; 벽 충돌)</li><li><strong>State</strong>: 환경의 현재 상태 (예: 로봇의 위치)\</li><li><strong>Policy</strong>: 상태에 따라 어떤 행동을 할지 정하는 전략</li></ul></li></ul><p>👉 <strong>시험 포인트</strong>: RL은 <strong>보상(Reward) 기반 학습</strong>이라는 점이 중요합니다.</p><p align="center">  <img src="/images/aws_basic_123.png" width="80%"></p><hr><h2 id="2-강화학습-동작-방식"><a href="#2-강화학습-동작-방식" class="headerlink" title="2. 강화학습 동작 방식"></a>2. 강화학습 동작 방식</h2><ol><li>에이전트가 환경의 현재 <strong>State</strong>를 관찰</li><li><strong>Policy</strong>에 따라 <strong>Action</strong> 선택</li><li>환경이 새로운 <strong>State</strong>로 전환되고 <strong>Reward</strong> 제공</li><li>에이전트는 보상 피드백을 반영하여 <strong>Policy</strong>를 업데이트</li><li>반복을 통해 최적의 전략 학습 → <strong>누적 보상 최대화</strong></li></ol><p align="center">  <img src="/images/aws_basic_124.png" width="80%"></p><hr><h2 id="3-예시-–-로봇-미로-탐색"><a href="#3-예시-–-로봇-미로-탐색" class="headerlink" title="3. 예시 – 로봇 미로 탐색"></a>3. 예시 – 로봇 미로 탐색</h2><ul><li><strong>시나리오</strong>: 로봇이 미로를 탈출하도록 학습</li><li><strong>보상 설계</strong>:<ul><li>한 걸음 이동: -1</li><li>벽 충돌: -10</li><li>출구 도착: +100</li></ul></li></ul><p>📌 결과: 처음에는 랜덤하게 움직이지만, 수많은 시뮬레이션을 반복하면서 <strong>짧고 효율적인 경로</strong>를 스스로 학습하게 됩니다.</p><p align="center">  <img src="/images/aws_basic_125.png" width="80%"></p><p>Here’s a great visual demonstration of <strong>Reinforcement Learning in action</strong>:</p><p>👉 Click the image or link to watch the video: <a href="https://youtu.be/2tamH76Tjvw">AI Learns to Escape</a></p><hr><h2 id="4-RL-활용-사례"><a href="#4-RL-활용-사례" class="headerlink" title="4. RL 활용 사례"></a>4. RL 활용 사례</h2><ul><li><strong>게임</strong>: 체스, 바둑 같은 복잡한 게임 학습</li><li><strong>로보틱스</strong>: 물체 조작, 경로 탐색</li><li><strong>금융</strong>: 포트폴리오 최적화, 자동 매매 전략</li><li><strong>헬스케어</strong>: 치료 계획 최적화</li><li><strong>자율주행차</strong>: 경로 계획 및 실시간 의사결정</li></ul><p>👉 <strong>시험 대비</strong>: RL은 <strong>시뮬레이션 환경</strong>에서 많이 활용된다는 점을<br>기억하세요.</p><hr><h2 id="5-RLHF-Reinforcement-Learning-from-Human-Feedback"><a href="#5-RLHF-Reinforcement-Learning-from-Human-Feedback" class="headerlink" title="5. RLHF (Reinforcement Learning from Human Feedback)"></a>5. RLHF (Reinforcement Learning from Human Feedback)</h2><p>RLHF는 <strong>강화학습에 인간의 피드백을 보상 함수에 통합</strong>하여 모델을 사람이<br>원하는 방향으로 학습시키는 방법입니다.</p><ul><li><strong>과정</strong><ol><li><strong>데이터 수집</strong>: 사람이 만든 질문 &amp; 답변 세트 준비</li><li><strong>Supervised Fine-Tuning</strong>: 기존 언어모델을 내부 지식에 맞게 미세조정</li><li><strong>Reward Model 구축</strong>: 같은 질문에 대해 여러 답변을 제시 → 사람이 더 선호하는 답변을 선택</li><li><strong>최적화</strong>: Reward Model을 RL 보상 함수로 활용하여 모델 개선</li></ol></li><li><strong>예시</strong><ul><li>기계 번역 모델이 “기술적으로 맞는 번역”을 하더라도 <strong>사람이 읽기에 어색하다면 낮은 점수</strong>를 주고, <strong>자연스러운 번역</strong>에는 높은 점수를 줌</li><li>이런 피드백을 통해 모델은 더 인간적인 답변을 학습</li></ul></li></ul><p>📌 <strong>시험 포인트</strong>: RLHF는 <strong>ChatGPT, Bard, Claude</strong> 같은 최신 LLM에 반드시 등장하는 개념이므로, <strong>데이터 수집 → 파인튜닝 → 보상모델 → 최적화</strong> 단계를 기억하세요.</p><p align="center">  <img src="/images/aws_basic_128.png" width="80%"></p><hr><h2 id="6-Key-Takeaways"><a href="#6-Key-Takeaways" class="headerlink" title="6. Key Takeaways"></a>6. Key Takeaways</h2><ul><li><strong>Reinforcement Learning (RL)</strong>: 보상 기반 학습, 시뮬레이션 환경에서 최적의 정책을 학습</li><li><strong>활용 분야</strong>: 게임, 로보틱스, 금융, 헬스케어, 자율주행</li><li><strong>RLHF</strong>: 인간의 피드백을 보상 함수에 통합하여 <strong>사람 친화적 모델</strong>을 학습</li><li><strong>시험 대비 핵심</strong>:<ul><li>RL은 <strong>보상 최대화 학습</strong></li><li>RLHF는 <strong>Human-in-the-loop</strong> 방식</li><li>RLHF &#x3D; LLM 성능 향상의 핵심 기법</li></ul></li></ul><hr><p>✍️ 참고: 실제 시험에서는 RL 자체의 수학적 세부사항보다는, <strong>개념과 활용사례, RLHF의 단계</strong>를 묻는 경우가 많습니다.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;🧠-강화학습-Reinforcement-Learning-RL-과-RLHF-쉽게-이해하기&quot;&gt;&lt;a href=&quot;#🧠-강화학습-Reinforcement-Learning-RL-과-RLHF-쉽게-이해하기&quot; class=&quot;headerlink&quot; tit</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (24) - 비지도 학습 &amp; 자기 지도 학습</title>
    <link href="https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-24/"/>
    <id>https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-24/</id>
    <published>2025-08-23T22:19:50.000Z</published>
    <updated>2025-08-24T00:33:26.299Z</updated>
    
    <content type="html"><![CDATA[<h1 id="🤖-머신러닝-알고리즘-–-비지도-학습-Unsupervised-Learning-자기-지도-학습-Self-Supervised-Learning"><a href="#🤖-머신러닝-알고리즘-–-비지도-학습-Unsupervised-Learning-자기-지도-학습-Self-Supervised-Learning" class="headerlink" title="🤖 머신러닝 알고리즘 – 비지도 학습(Unsupervised Learning) &amp; 자기 지도 학습(Self-Supervised Learning)"></a>🤖 머신러닝 알고리즘 – 비지도 학습(Unsupervised Learning) &amp; 자기 지도 학습(Self-Supervised Learning)</h1><h2 id="1-비지도-학습-Unsupervised-Learning"><a href="#1-비지도-학습-Unsupervised-Learning" class="headerlink" title="1. 비지도 학습 (Unsupervised Learning)"></a>1. 비지도 학습 (Unsupervised Learning)</h2><ul><li><strong>라벨(정답)이 없는 데이터</strong>에서 패턴, 구조, 관계를 스스로 발견하는 학습 방식  </li><li>머신러닝 모델이 데이터 그룹을 만들고, <strong>사람이 그 결과에 의미(라벨)를 부여</strong>  </li><li>대표 기법:<ul><li><strong>클러스터링(Clustering)</strong></li><li><strong>연관 규칙 학습(Association Rule Learning)</strong></li><li><strong>이상치 탐지(Anomaly Detection)</strong></li></ul></li><li><strong>활용 사례</strong><ul><li>고객 세분화 (마케팅)</li><li>추천 시스템</li><li>사기 탐지</li></ul></li><li>👉 <strong>시험 포인트</strong>: 비지도 학습은 <strong>라벨이 없는 데이터</strong>를 활용한다는 점 기억하기</li></ul><p align="center">  <img src="/images/aws_basic_116.png" width="80%"></p><hr><h2 id="2-클러스터링-Clustering"><a href="#2-클러스터링-Clustering" class="headerlink" title="2. 클러스터링 (Clustering)"></a>2. 클러스터링 (Clustering)</h2><ul><li><strong>정의</strong>: 유사한 특징을 가진 데이터를 묶어 그룹(cluster)으로 나눔  </li><li><strong>사례: 고객 세분화(Customer Segmentation)</strong>  <ul><li>상황: e-commerce 기업이 고객을 구매 패턴에 따라 구분  </li><li>데이터: 구매 빈도, 평균 주문 금액 등  </li><li>알고리즘: <strong>K-means Clustering</strong>  </li><li>결과:  <ul><li>그룹 1 → 학생층 (피자, 과자, 맥주 구매)  </li><li>그룹 2 → 신생아 부모 (기저귀, 베이비 제품 구매)  </li><li>그룹 3 → 건강 관심층 (과일, 채소 구매)</li></ul></li><li>활용: 그룹별 <strong>맞춤형 마케팅 전략</strong> 가능</li></ul></li></ul><p>👉 <strong>시험 포인트</strong>: K-means는 비지도 학습 대표 알고리즘, 고객 세분화 사례로 자주 출제됨.  </p><p align="center">  <img src="/images/aws_basic_117.png" width="80%"></p><hr><h2 id="3-연관-규칙-학습-Association-Rule-Learning"><a href="#3-연관-규칙-학습-Association-Rule-Learning" class="headerlink" title="3. 연관 규칙 학습 (Association Rule Learning)"></a>3. 연관 규칙 학습 (Association Rule Learning)</h2><ul><li><strong>정의</strong>: 어떤 상품이 <strong>자주 함께 구매되는지</strong>를 찾아내는 방법  </li><li><strong>사례: 장바구니 분석(Market Basket Analysis)</strong>  <ul><li>상황: 슈퍼마켓이 상품 진열 최적화  </li><li>데이터: 고객 구매 이력  </li><li>알고리즘: <strong>Apriori 알고리즘</strong>  </li><li>결과:  <ul><li>“빵을 사면 버터도 함께 구매” → 빵과 버터를 가까이 진열 → 매출 증가</li></ul></li></ul></li></ul><p align="center">  <img src="/images/aws_basic_118.png" width="60%"></p><p>👉 <strong>시험 포인트</strong>: Apriori &#x3D; 대표적인 연관 규칙 알고리즘  </p><hr><h2 id="4-이상치-탐지-Anomaly-Detection"><a href="#4-이상치-탐지-Anomaly-Detection" class="headerlink" title="4. 이상치 탐지 (Anomaly Detection)"></a>4. 이상치 탐지 (Anomaly Detection)</h2><ul><li><strong>정의</strong>: 정상 패턴과 다른 <strong>이상한 데이터(Outlier)</strong> 탐지  </li><li><strong>사례: 신용카드 사기 탐지(Fraud Detection)</strong>  <ul><li>데이터: 결제 금액, 시간, 위치  </li><li>알고리즘: <strong>Isolation Forest</strong>  </li><li>결과: 정상 거래 패턴과 크게 다른 트랜잭션을 <strong>사기 의심 거래로 표시</strong></li></ul></li></ul><p>👉 <strong>시험 포인트</strong>: 비지도 학습의 대표적인 실제 활용 &#x3D; <strong>사기 탐지</strong>  </p><p align="center">  <img src="/images/aws_basic_119.png" width="80%"></p><hr><h2 id="5-준지도-학습-Semi-Supervised-Learning"><a href="#5-준지도-학습-Semi-Supervised-Learning" class="headerlink" title="5. 준지도 학습 (Semi-Supervised Learning)"></a>5. 준지도 학습 (Semi-Supervised Learning)</h2><ul><li><strong>정의</strong>: 소량의 라벨 데이터 + 대량의 비라벨 데이터를 함께 학습  </li><li><strong>방법</strong>:<ol><li>라벨 데이터로 초기 학습  </li><li>학습된 모델이 비라벨 데이터에 <strong>가짜 라벨(Pseudo-label)</strong> 생성  </li><li>전체 데이터(라벨 + 가짜 라벨)로 재학습</li></ol></li><li>👉 데이터 라벨링 비용이 높을 때 효과적</li></ul><p>👉 <strong>시험 포인트</strong>: Semi-supervised learning &#x3D; <strong>pseudo-labeling</strong> 핵심 키워드  </p><p align="center">  <img src="/images/aws_basic_120.png" width="80%"></p><hr><h2 id="6-자기-지도-학습-Self-Supervised-Learning"><a href="#6-자기-지도-학습-Self-Supervised-Learning" class="headerlink" title="6. 자기 지도 학습 (Self-Supervised Learning)"></a>6. 자기 지도 학습 (Self-Supervised Learning)</h2><ul><li><strong>정의</strong>: 사람이 직접 라벨링하지 않고, <strong>모델이 스스로 가짜 라벨(pseudo-labels)을 생성</strong>하여 학습  </li><li><strong>활용 사례</strong>:<ul><li>NLP → BERT, GPT 같은 대규모 언어 모델  </li><li>이미지 인식 → 마스킹된 부분 예측 등</li></ul></li><li><strong>방법: Pre-text Task 활용</strong><ul><li>문장에서 다음 단어 맞추기  </li><li>문장의 일부를 가려놓고 채우기 (Masked Language Modeling)  </li><li>이미지에서 가려진 부분 예측하기</li></ul></li></ul><p>👉 이렇게 학습된 모델은 이후 <strong>요약, 번역, 분류</strong> 같은 <strong>다운스트림(실제) 과제</strong>에 활용 가능  </p><p align="center">  <img src="/images/aws_basic_121.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_122.png" width="80%"></p><hr><h1 id="📌-최종-요약"><a href="#📌-최종-요약" class="headerlink" title="📌 최종 요약"></a>📌 최종 요약</h1><ul><li><strong>비지도 학습</strong>: 라벨 없음 → 패턴&#x2F;그룹 찾기  <ul><li>K-means (클러스터링) → 고객 세분화  </li><li>Apriori (연관 규칙) → 장바구니 분석  </li><li>Isolation Forest (이상치 탐지) → 사기 탐지</li></ul></li><li><strong>준지도 학습</strong>: 소량 라벨 + 대량 비라벨 → Pseudo-labeling  </li><li><strong>자기 지도 학습</strong>: 모델이 자체적으로 라벨 생성 (GPT, BERT 기반)</li></ul><p>👉 <strong>시험 대비 키워드</strong>  </p><ul><li>비지도 학습 &#x3D; 라벨 없음  </li><li>K-means &#x3D; 고객 세분화  </li><li>Apriori &#x3D; 장바구니 분석  </li><li>이상치 탐지 &#x3D; 사기 탐지  </li><li>Semi-supervised &#x3D; Pseudo-labeling  </li><li>Self-supervised &#x3D; GPT&#x2F;BERT 기반 학습</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;🤖-머신러닝-알고리즘-–-비지도-학습-Unsupervised-Learning-자기-지도-학습-Self-Supervised-Learning&quot;&gt;&lt;a href=&quot;#🤖-머신러닝-알고리즘-–-비지도-학습-Unsupervised-Learning</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(24) - Unsupervised &amp; Semi/Self-Supervised Learning</title>
    <link href="https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-24/"/>
    <id>https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-24/</id>
    <published>2025-08-23T22:19:44.000Z</published>
    <updated>2025-08-24T00:31:01.851Z</updated>
    
    <content type="html"><![CDATA[<h1 id="🧠-Machine-Learning-Algorithms-–-Unsupervised-Semi-Self-Supervised-Learning"><a href="#🧠-Machine-Learning-Algorithms-–-Unsupervised-Semi-Self-Supervised-Learning" class="headerlink" title="🧠 Machine Learning Algorithms – Unsupervised &amp; Semi&#x2F;Self-Supervised Learning"></a>🧠 Machine Learning Algorithms – Unsupervised &amp; Semi&#x2F;Self-Supervised Learning</h1><h2 id="1-What-is-Unsupervised-Learning"><a href="#1-What-is-Unsupervised-Learning" class="headerlink" title="1. What is Unsupervised Learning?"></a>1. What is Unsupervised Learning?</h2><ul><li><strong>Definition</strong>: Machine learning on unlabeled data (no predefined outputs).  </li><li><strong>Goal</strong>: Discover hidden patterns, structures, or relationships in the data.  </li><li><strong>Key point</strong>: The algorithm finds groups or rules by itself, while humans later assign meaning (labels) to those groups.</li></ul><p><strong>Common techniques</strong>:</p><ul><li><strong>Clustering</strong> → finding groups of similar data (e.g., customer segmentation)  </li><li><strong>Association Rule Learning</strong> → discovering relationships between items (e.g., “bread + butter”)  </li><li><strong>Anomaly Detection</strong> → spotting unusual behaviors (e.g., fraud detection)</li></ul><p>👉 <strong>Exam Tip</strong>: You don’t need deep math for the exam, but know what each technique is used for.  </p><p align="center">  <img src="/images/aws_basic_116.png" width="80%"></p><hr><h2 id="2-Clustering-Example-–-Customer-Segmentation"><a href="#2-Clustering-Example-–-Customer-Segmentation" class="headerlink" title="2. Clustering Example – Customer Segmentation"></a>2. Clustering Example – Customer Segmentation</h2><ul><li><strong>Scenario</strong>: An e-commerce company wants to understand customer purchase behavior.  </li><li><strong>Data</strong>: Purchase history (e.g., average order size, purchase frequency).  </li><li><strong>Technique</strong>: <strong>K-Means Clustering</strong>  </li><li><strong>Goal</strong>: Group customers into segments based on behavior.</li></ul><p><strong>Outcome</strong>:</p><ul><li>Segment A: Students (buy pizza, chips, beer)  </li><li>Segment B: New parents (buy baby shampoo, wipes)  </li><li>Segment C: Health-conscious customers (buy fruits, vegetables)</li></ul><p>💡 The company can now target each group with tailored marketing campaigns.  </p><p align="center">  <img src="/images/aws_basic_117.png" width="80%"></p><hr><h2 id="3-Association-Rule-Learning-–-Market-Basket-Analysis"><a href="#3-Association-Rule-Learning-–-Market-Basket-Analysis" class="headerlink" title="3. Association Rule Learning – Market Basket Analysis"></a>3. Association Rule Learning – Market Basket Analysis</h2><ul><li><strong>Scenario</strong>: A supermarket wants to know which products are often bought together.  </li><li><strong>Data</strong>: Transaction histories.  </li><li><strong>Technique</strong>: <strong>Apriori Algorithm</strong>  </li><li><strong>Goal</strong>: Find product associations.</li></ul><p><strong>Outcome</strong>:</p><ul><li>“Bread → Butter”  </li><li>“Chips → Soda”</li></ul><p>📌 <strong>Business Value</strong>: Place associated items together on shelves or bundle promotions to increase sales.  </p><p align="center">  <img src="/images/aws_basic_118.png" width="60%"></p><hr><h2 id="4-Anomaly-Detection-–-Fraud-Detection"><a href="#4-Anomaly-Detection-–-Fraud-Detection" class="headerlink" title="4. Anomaly Detection – Fraud Detection"></a>4. Anomaly Detection – Fraud Detection</h2><ul><li><strong>Scenario</strong>: Detect fraudulent credit card transactions.  </li><li><strong>Data</strong>: Amount, time, location of transactions.  </li><li><strong>Technique</strong>: <strong>Isolation Forest</strong> (or other anomaly detection methods).  </li><li><strong>Goal</strong>: Identify transactions that deviate significantly from normal behavior.</li></ul><p><strong>Outcome</strong>: The system flags suspicious transactions for manual review.  </p><p>👉 <strong>Exam Insight</strong>: Anomaly detection is commonly tied to fraud detection, intrusion detection, or system monitoring.  </p><p align="center">  <img src="/images/aws_basic_119.png" width="80%"></p><hr><h2 id="5-Semi-Supervised-Learning"><a href="#5-Semi-Supervised-Learning" class="headerlink" title="5. Semi-Supervised Learning"></a>5. Semi-Supervised Learning</h2><ul><li><p><strong>Definition</strong>: Uses a small amount of labeled data + a large amount of unlabeled data.  </p></li><li><p><strong>Process</strong>:</p><ol><li>Train model on labeled data.  </li><li>Model assigns labels to unlabeled data (<strong>pseudo-labeling</strong>).  </li><li>Retrain model on the now-larger dataset.</li></ol></li><li><p><strong>Use case</strong>: Medical imaging (expensive to label every scan).</p></li></ul><p>📌 <strong>Exam Tip</strong>: Remember <strong>semi-supervised &#x3D; mix of supervised + unsupervised.</strong>  </p><p align="center">  <img src="/images/aws_basic_120.png" width="80%"></p><hr><h2 id="6-Self-Supervised-Learning"><a href="#6-Self-Supervised-Learning" class="headerlink" title="6. Self-Supervised Learning"></a>6. Self-Supervised Learning</h2><ul><li><strong>Definition</strong>: Model creates its own pseudo-labels without human labeling.</li></ul><p><strong>How it works</strong>:</p><ul><li>Use “pretext tasks” → simple prediction challenges that force the model to learn patterns.  </li><li>Examples:  <ul><li>Predict the next word in a sentence (language models).  </li><li>Predict a missing part of an image (vision tasks).</li></ul></li></ul><p><strong>Outcome</strong>: Model builds internal representations of data, which can then be used for downstream tasks like translation, summarization, or classification.  </p><p>💡 <strong>Real-world use</strong>:  </p><ul><li><strong>NLP</strong>: Training BERT and GPT models.  </li><li><strong>Computer Vision</strong>: Pretraining models for image recognition.</li></ul><p>👉 <strong>Exam Tip</strong>: If you see <strong>BERT, GPT, or modern NLP models</strong>, think <strong>Self-Supervised Learning.</strong>  </p><p align="center">  <img src="/images/aws_basic_121.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_122.png" width="80%"></p><hr><h2 id="✅-Key-Takeaways-for-Exams"><a href="#✅-Key-Takeaways-for-Exams" class="headerlink" title="✅ Key Takeaways for Exams"></a>✅ Key Takeaways for Exams</h2><ul><li><strong>Unsupervised Learning</strong> &#x3D; find hidden patterns in unlabeled data.  <ul><li>Clustering → segmentation  </li><li>Association Rule → product relationships  </li><li>Anomaly Detection → fraud &#x2F; unusual behavior</li></ul></li><li><strong>Semi-Supervised Learning</strong> &#x3D; small labeled + large unlabeled (pseudo-labeling).  </li><li><strong>Self-Supervised Learning</strong> &#x3D; model labels itself using pretext tasks (foundation for GPT&#x2F;BERT).  </li><li><strong>Feature Engineering</strong> still helps improve results in all cases.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;🧠-Machine-Learning-Algorithms-–-Unsupervised-Semi-Self-Supervised-Learning&quot;&gt;&lt;a href=&quot;#🧠-Machine-Learning-Algorithms-–-Unsupervised</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(23) - Training Data &amp; Feature Engineering</title>
    <link href="https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-23/"/>
    <id>https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-23/</id>
    <published>2025-08-23T13:50:14.000Z</published>
    <updated>2025-08-23T14:08:31.634Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📘-Training-Data-Feature-Engineering"><a href="#📘-Training-Data-Feature-Engineering" class="headerlink" title="📘 Training Data &amp; Feature Engineering"></a>📘 Training Data &amp; Feature Engineering</h1><h2 id="Why-Training-Data-Matters"><a href="#Why-Training-Data-Matters" class="headerlink" title="Why Training Data Matters"></a>Why Training Data Matters</h2><ul><li>To build a reliable ML model, you need <strong>good quality data</strong>.\</li><li>Principle: <strong>Garbage In → Garbage Out</strong>. If your input data is messy<br>or incorrect, your model will produce poor predictions.\</li><li>Data preparation is the <strong>most critical stage</strong> of ML.\</li><li>The way you model your data (e.g., labeled&#x2F;unlabeled,<br>structured&#x2F;unstructured) directly impacts which algorithms you can<br>use.</li></ul><p>👉 <strong>Exam Tip</strong>: Expect questions about <em>labeled vs. unlabeled</em> and<br><em>structured vs. unstructured data</em>.</p><hr><h2 id="Labeled-vs-Unlabeled-Data"><a href="#Labeled-vs-Unlabeled-Data" class="headerlink" title="Labeled vs. Unlabeled Data"></a>Labeled vs. Unlabeled Data</h2><h3 id="🔹-Labeled-Data"><a href="#🔹-Labeled-Data" class="headerlink" title="🔹 Labeled Data"></a>🔹 Labeled Data</h3><ul><li>Contains <strong>both input features</strong> and <strong>output labels</strong>.\</li><li>Example: Animal images labeled as “cat” or “dog.”\</li><li>Used in <strong>Supervised Learning</strong> → the model learns to map inputs to<br>outputs.\</li><li>Strong but expensive → requires manual labeling.</li></ul><p align="center">  <img src="/images/aws_basic_107.png" width="80%"></p><h3 id="🔹-Unlabeled-Data"><a href="#🔹-Unlabeled-Data" class="headerlink" title="🔹 Unlabeled Data"></a>🔹 Unlabeled Data</h3><ul><li>Contains <strong>only input features</strong>, with no labels.\</li><li>Example: A folder of animal pictures with no tags.\</li><li>Used in <strong>Unsupervised Learning</strong> → the model finds hidden patterns<br>or clusters.\</li><li>Cheaper and more abundant, but harder to interpret.</li></ul><p align="center">  <img src="/images/aws_basic_108.png" width="80%"></p><hr><h2 id="Structured-vs-Unstructured-Data"><a href="#Structured-vs-Unstructured-Data" class="headerlink" title="Structured vs. Unstructured Data"></a>Structured vs. Unstructured Data</h2><h3 id="🔹-Structured-Data"><a href="#🔹-Structured-Data" class="headerlink" title="🔹 Structured Data"></a>🔹 Structured Data</h3><p>Organized into rows&#x2F;columns (like Excel or databases).\</p><ul><li><strong>Tabular Data</strong>: Customer DB (Name, Age, Purchase Amount).\</li></ul><p align="center">  <img src="/images/aws_basic_109.png" width="80%"></p><ul><li><strong>Time Series Data</strong>: Stock prices collected daily.</li></ul><p align="center">  <img src="/images/aws_basic_110.png" width="80%"></p><h3 id="🔹-Unstructured-Data"><a href="#🔹-Unstructured-Data" class="headerlink" title="🔹 Unstructured Data"></a>🔹 Unstructured Data</h3><p>Doesn’t follow a set format, often text-heavy or media-rich.\</p><ul><li><strong>Text Data</strong>: Articles, social posts, product reviews.\</li><li><strong>Image Data</strong>: Photos, medical scans, etc.</li></ul><p>👉 <strong>Exam Tip</strong>: AWS might test you on which algorithm handles<br><strong>structured (tabular, time-series)</strong> vs. <strong>unstructured (text, image)</strong><br>data.</p><hr><h2 id="Supervised-Learning"><a href="#Supervised-Learning" class="headerlink" title="Supervised Learning"></a>Supervised Learning</h2><ul><li>Learns a <strong>mapping function</strong>: predicts output for unseen inputs.\</li><li>Requires <strong>labeled data</strong>.\</li><li>Types: <strong>Regression</strong> (continuous values) and <strong>Classification</strong><br>(categories).</li></ul><h3 id="🔹-Regression"><a href="#🔹-Regression" class="headerlink" title="🔹 Regression"></a>🔹 Regression</h3><ul><li>Predicts numeric values.\</li><li>Examples:<ul><li>House prices (based on size, location).\</li><li>Stock price forecasting.\</li><li>Weather prediction (temperature).\</li></ul></li><li>Output &#x3D; continuous (any real value).</li></ul><p align="center">  <img src="/images/aws_basic_112.png" width="80%"></p><h3 id="🔹-Classification"><a href="#🔹-Classification" class="headerlink" title="🔹 Classification"></a>🔹 Classification</h3><ul><li>Predicts discrete categories.\</li><li>Examples:<ul><li>Binary: Spam vs. Not Spam.\</li><li>Multi-class: Mammal, Bird, Reptile.\</li><li>Multi-label: A movie labeled as <em>Action + Comedy</em>.\</li></ul></li><li>Common Algorithm: <strong>k-NN (k-Nearest Neighbors)</strong>.</li></ul><p align="center">  <img src="/images/aws_basic_113.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_111.png" width="80%"></p>------------------------------------------------------------------------<h2 id="Splitting-the-Dataset"><a href="#Splitting-the-Dataset" class="headerlink" title="Splitting the Dataset"></a>Splitting the Dataset</h2><ul><li><strong>Training Set</strong>: 60–80% (used to train).\</li><li><strong>Validation Set</strong>: 10–20% (used to tune hyperparameters).\</li><li><strong>Test Set</strong>: 10–20% (used to evaluate final performance).</li></ul><p>👉 <strong>Exam Tip</strong>:\</p><ul><li>Training &#x3D; learning.\</li><li>Validation &#x3D; tuning.\</li><li>Test &#x3D; evaluation.</li></ul><p align="center">  <img src="/images/aws_basic_114.png" width="80%"></p><hr><h2 id="Feature-Engineering"><a href="#Feature-Engineering" class="headerlink" title="Feature Engineering"></a>Feature Engineering</h2><p>Transforming raw data into useful features → improves model accuracy.</p><h3 id="Techniques"><a href="#Techniques" class="headerlink" title="Techniques"></a>Techniques</h3><ul><li><strong>Feature Extraction</strong>: Convert raw values into meaningful ones.<ul><li>Example: From birth date → calculate age.\</li></ul></li><li><strong>Feature Selection</strong>: Keep only the most relevant features.<ul><li>Example: House price prediction → keep location &amp; size, drop<br>irrelevant columns.\</li></ul></li><li><strong>Feature Transformation</strong>: Normalize or scale data to improve<br>convergence.</li></ul><p align="center">  <img src="/images/aws_basic_115.png" width="80%"></p><hr><h2 id="Feature-Engineering-Examples"><a href="#Feature-Engineering-Examples" class="headerlink" title="Feature Engineering Examples"></a>Feature Engineering Examples</h2><h3 id="🔹-On-Structured-Data"><a href="#🔹-On-Structured-Data" class="headerlink" title="🔹 On Structured Data"></a>🔹 On Structured Data</h3><ul><li>Predicting house prices:<ul><li>Create <em>price per square foot</em>.\</li><li>Normalize features like size and income.</li></ul></li></ul><h3 id="🔹-On-Unstructured-Data"><a href="#🔹-On-Unstructured-Data" class="headerlink" title="🔹 On Unstructured Data"></a>🔹 On Unstructured Data</h3><ul><li><strong>Text</strong>: Convert reviews into numbers using TF-IDF or word<br>embeddings.\</li><li><strong>Images</strong>: Use CNNs to extract edges, shapes, or textures.</li></ul><p>👉 <strong>Exam Tip</strong>: Know that <strong>feature engineering &#x3D; boosting model<br>performance by transforming data.</strong></p><hr><h1 id="✅-Quick-Recap-for-Exam"><a href="#✅-Quick-Recap-for-Exam" class="headerlink" title="✅ Quick Recap for Exam"></a>✅ Quick Recap for Exam</h1><ol><li><strong>Good data is critical</strong> – Garbage In, Garbage Out.\</li><li><strong>Labeled → Supervised | Unlabeled → Unsupervised.</strong>\</li><li><strong>Structured vs. Unstructured</strong>: Tables vs. Text&#x2F;Images.\</li><li><strong>Regression</strong> &#x3D; numeric predictions, <strong>Classification</strong> &#x3D;<br>categories.\</li><li><strong>Data split</strong>: Train (learn), Validate (tune), Test (evaluate).\</li><li><strong>Feature Engineering</strong> improves accuracy through extraction,<br>selection, transformation.</li></ol><hr><p>👉 <strong>One-Liner Exam Tip</strong>:<br>Most AWS exam questions on ML basics test whether you can correctly<br><strong>match the data type with the ML method</strong> (e.g., <em>time-series →<br>supervised regression</em>, <em>unlabeled images → unsupervised clustering</em>).</p><h2 id="Additional-📌-What-is-TF-IDF"><a href="#Additional-📌-What-is-TF-IDF" class="headerlink" title="(Additional) 📌 What is TF-IDF?"></a>(Additional) 📌 What is TF-IDF?</h2><p>TF-IDF is a statistical method used in <strong>Natural Language Processing (NLP)</strong> to evaluate how important a word is within a document relative to a collection of documents (called a corpus).<br>It is widely used in <strong>search engines, information retrieval, and text mining</strong>.</p><hr><h2 id="Additional-⚡-How-It-Works"><a href="#Additional-⚡-How-It-Works" class="headerlink" title="(Additional)  ⚡ How It Works"></a>(Additional)  ⚡ How It Works</h2><h3 id="1-Term-Frequency-TF"><a href="#1-Term-Frequency-TF" class="headerlink" title="1. Term Frequency (TF)"></a>1. Term Frequency (TF)</h3><ul><li>Measures how often a word appears in a document.</li><li>Formula:<br>( TF(t, d) &#x3D; \frac{\text{Number of times term t appears in document d}}{\text{Total terms in document d}} )</li></ul><p>👉 Example: If the word <strong>“AI”</strong> appears 5 times in a 100-word document,<br>( TF(AI) &#x3D; 5 &#x2F; 100 &#x3D; 0.05 ).</p><hr><h3 id="2-Inverse-Document-Frequency-IDF"><a href="#2-Inverse-Document-Frequency-IDF" class="headerlink" title="2. Inverse Document Frequency (IDF)"></a>2. Inverse Document Frequency (IDF)</h3><ul><li>Measures how important a word is across all documents in the corpus.</li><li>Common words (like “the”, “is”, “and”) get lower scores, while rare words get higher scores.</li><li>Formula:<br>( IDF(t) &#x3D; \log\frac{N}{1 + df(t)} )<br>where:  <ul><li>(N) &#x3D; total number of documents  </li><li>(df(t)) &#x3D; number of documents containing the term t</li></ul></li></ul><p>👉 Example: If the word <strong>“AI”</strong> appears in 2 out of 10 documents,<br>( IDF(AI) &#x3D; \log(10 &#x2F; (1+2)) ≈ 1.20 ).</p><hr><h3 id="3-TF-IDF-Score"><a href="#3-TF-IDF-Score" class="headerlink" title="3. TF-IDF Score"></a>3. TF-IDF Score</h3><ul><li>Combines TF and IDF to measure the importance of a term in a document relative to the whole corpus.</li><li>Formula:<br>( TF\text{-}IDF(t, d) &#x3D; TF(t, d) \times IDF(t) )</li></ul><p>👉 Example:<br>Using the previous numbers, ( TF(AI) &#x3D; 0.05 ) and ( IDF(AI) &#x3D; 1.20 ).<br>So, ( TF\text{-}IDF(AI) &#x3D; 0.05 \times 1.20 &#x3D; 0.06 ).</p><hr><h2 id="🎯-Why-Is-TF-IDF-Useful"><a href="#🎯-Why-Is-TF-IDF-Useful" class="headerlink" title="🎯 Why Is TF-IDF Useful?"></a>🎯 Why Is TF-IDF Useful?</h2><ul><li><strong>Search Engines</strong>: Helps rank documents by relevance to a query.  </li><li><strong>Text Mining</strong>: Identifies key terms in large text datasets.  </li><li><strong>Spam Filtering</strong>: Detects suspicious terms often used in spam messages.  </li><li><strong>Recommendation Systems</strong>: Finds similarities between documents or user profiles.</li></ul><hr><h2 id="📝-Summary"><a href="#📝-Summary" class="headerlink" title="📝 Summary"></a>📝 Summary</h2><ul><li><strong>TF</strong> → Frequency of a word in a document.  </li><li><strong>IDF</strong> → Importance of a word across all documents.  </li><li><strong>TF-IDF</strong> → Highlights words that are frequent in one document but rare across the corpus.</li></ul><p>👉 In AWS or AI-related exams, TF-IDF often comes up as a <strong>classic feature extraction technique</strong> for text data before applying ML algorithms.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📘-Training-Data-Feature-Engineering&quot;&gt;&lt;a href=&quot;#📘-Training-Data-Feature-Engineering&quot; class=&quot;headerlink&quot; title=&quot;📘 Training Data &amp;am</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (23) - 머신러닝 학습 데이터 정리</title>
    <link href="https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-23/"/>
    <id>https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-23/</id>
    <published>2025-08-23T13:50:09.000Z</published>
    <updated>2025-08-23T22:13:40.546Z</updated>
    
    <content type="html"><![CDATA[<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id="MathJax-script" async  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><h1 id="📊-머신러닝-학습-데이터-정리"><a href="#📊-머신러닝-학습-데이터-정리" class="headerlink" title="📊 머신러닝 학습 데이터 정리"></a>📊 머신러닝 학습 데이터 정리</h1><h2 id="1-학습-데이터-Training-Data-의-중요성"><a href="#1-학습-데이터-Training-Data-의-중요성" class="headerlink" title="1. 학습 데이터(Training Data)의 중요성"></a>1. 학습 데이터(Training Data)의 중요성</h2><ul><li>좋은 데이터를 가져야 좋은 모델을 만들 수 있음  </li><li><strong>Garbage In → Garbage Out</strong> : 잘못된 데이터를 넣으면 결과도 잘못됨  </li><li>가장 중요한 단계 &#x3D; 데이터를 깨끗하게 준비하는 것  </li><li>데이터의 종류에 따라 사용할 수 있는 알고리즘도 달라짐</li></ul><hr><h2 id="2-라벨링-데이터-vs-비라벨링-데이터"><a href="#2-라벨링-데이터-vs-비라벨링-데이터" class="headerlink" title="2. 라벨링 데이터 vs 비라벨링 데이터"></a>2. 라벨링 데이터 vs 비라벨링 데이터</h2><h3 id="🔹-라벨링-데이터-Labeled-Data"><a href="#🔹-라벨링-데이터-Labeled-Data" class="headerlink" title="🔹 라벨링 데이터 (Labeled Data)"></a>🔹 라벨링 데이터 (Labeled Data)</h3><ul><li>입력값(Input) + 정답(Output Label)이 함께 있는 데이터  </li><li>예: 고양이, 강아지 이미지와 각각의 라벨이 함께 있음  </li><li><strong>사용 사례</strong>: 지도학습(Supervised Learning)</li></ul><p align="center">  <img src="/images/aws_basic_107.png" width="80%"></p><h3 id="🔹-비라벨링-데이터-Unlabeled-Data"><a href="#🔹-비라벨링-데이터-Unlabeled-Data" class="headerlink" title="🔹 비라벨링 데이터 (Unlabeled Data)"></a>🔹 비라벨링 데이터 (Unlabeled Data)</h3><ul><li>입력값만 있고 정답 라벨이 없음  </li><li>예: 고양이&#x2F;강아지 사진만 있고 라벨이 없는 경우  </li><li><strong>사용 사례</strong>: 비지도학습(Unsupervised Learning) → 패턴이나 군집 찾기</li></ul><p>👉 시험 포인트: <strong>라벨링 데이터 → 지도학습 &#x2F; 비라벨링 데이터 → 비지도학습</strong></p><p align="center">  <img src="/images/aws_basic_108.png" width="80%"></p>---<h2 id="3-구조화-데이터-vs-비구조화-데이터"><a href="#3-구조화-데이터-vs-비구조화-데이터" class="headerlink" title="3. 구조화 데이터 vs 비구조화 데이터"></a>3. 구조화 데이터 vs 비구조화 데이터</h2><h3 id="🔹-구조화-데이터-Structured-Data"><a href="#🔹-구조화-데이터-Structured-Data" class="headerlink" title="🔹 구조화 데이터 (Structured Data)"></a>🔹 구조화 데이터 (Structured Data)</h3><ul><li>행(Row)과 열(Column)로 정리된 데이터 (예: 엑셀, DB)</li><li><strong>예시</strong><ul><li>표 형태(Tabular): 고객 ID, 이름, 나이, 구매 금액</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_109.png" width="80%"></p><ul><li>시계열 데이터(Time Series): 주식 가격, 센서 데이터</li></ul><p align="center">  <img src="/images/aws_basic_110.png" width="80%"></p><h3 id="🔹-비구조화-데이터-Unstructured-Data"><a href="#🔹-비구조화-데이터-Unstructured-Data" class="headerlink" title="🔹 비구조화 데이터 (Unstructured Data)"></a>🔹 비구조화 데이터 (Unstructured Data)</h3><ul><li>일정한 형식이 없는 데이터 (텍스트, 이미지, 오디오 등)</li><li><strong>예시</strong><ul><li>텍스트 데이터: 리뷰, SNS 글</li><li>이미지 데이터: 객체 인식용 이미지</li></ul></li></ul><hr><h2 id="4-지도학습-Supervised-Learning"><a href="#4-지도학습-Supervised-Learning" class="headerlink" title="4. 지도학습 (Supervised Learning)"></a>4. 지도학습 (Supervised Learning)</h2><ul><li>정답(라벨)이 있는 데이터를 기반으로 학습  </li><li><strong>목표</strong>: 입력값 → 출력값 예측</li></ul><h3 id="📈-회귀-Regression"><a href="#📈-회귀-Regression" class="headerlink" title="📈 회귀(Regression)"></a>📈 회귀(Regression)</h3><ul><li>연속적인 숫자 값 예측  </li><li>예시:<ul><li>집값 예측 (면적, 위치, 방 개수 기반)</li><li>주식 가격 예측</li><li>날씨(온도) 예측</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_112.png" width="80%"></p><h3 id="🏷️-분류-Classification"><a href="#🏷️-분류-Classification" class="headerlink" title="🏷️ 분류(Classification)"></a>🏷️ 분류(Classification)</h3><ul><li>카테고리 예측 (이산형 데이터)  </li><li>예시:<ul><li>이진 분류(Binary): 스팸메일 &#x2F; 정상메일</li><li>다중 분류(Multi-class): 동물 → 포유류, 조류, 파충류</li><li>다중 라벨(Multi-label): 영화 → 액션 + 코미디</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_113.png" width="80%"></p><p>👉 시험 포인트: <strong>Regression &#x3D; 숫자 예측 &#x2F; Classification &#x3D; 카테고리 예측</strong></p><p align="center">  <img src="/images/aws_basic_111.png" width="80%"></p><hr><h2 id="5-데이터셋-분리"><a href="#5-데이터셋-분리" class="headerlink" title="5. 데이터셋 분리"></a>5. 데이터셋 분리</h2><ul><li>학습 데이터셋(Training), 검증 데이터셋(Validation), 테스트 데이터셋(Test)으로 나눔</li></ul><table><thead><tr><th>데이터셋</th><th>비율</th><th>역할</th></tr></thead><tbody><tr><td>Training</td><td>60~80%</td><td>모델 학습</td></tr><tr><td>Validation</td><td>10~20%</td><td>하이퍼파라미터 튜닝</td></tr><tr><td>Test</td><td>10~20%</td><td>최종 성능 평가</td></tr></tbody></table><p>👉 시험 포인트: <strong>Validation은 모델 조정용, Test는 최종 성능 확인용</strong></p><p align="center">  <img src="/images/aws_basic_114.png" width="80%"></p><hr><h2 id="6-특징-공학-Feature-Engineering"><a href="#6-특징-공학-Feature-Engineering" class="headerlink" title="6. 특징 공학 (Feature Engineering)"></a>6. 특징 공학 (Feature Engineering)</h2><ul><li>원시(raw) 데이터를 유용한 특징(Feature)으로 가공하는 과정  </li><li>성능 향상에 매우 중요한 단계</li></ul><h3 id="🔹-주요-기법"><a href="#🔹-주요-기법" class="headerlink" title="🔹 주요 기법"></a>🔹 주요 기법</h3><ol><li><strong>특징 추출 (Feature Extraction)</strong>  <ul><li>예: 생년월일 → 나이(age) 계산</li></ul></li></ol><p align="center">  <img src="/images/aws_basic_115.png" width="80%"></p><ol start="2"><li><strong>특징 선택 (Feature Selection)</strong>  <ul><li>중요한 특징만 선택 (예: 집값 예측에서 위치, 평수만 선택)</li></ul></li><li><strong>특징 변환 (Feature Transformation)</strong>  <ul><li>데이터 정규화(Normalization) 등으로 모델 학습을 빠르고 안정적으로 수행</li></ul></li></ol><h3 id="🔹-구조화-데이터에서의-특징-공학"><a href="#🔹-구조화-데이터에서의-특징-공학" class="headerlink" title="🔹 구조화 데이터에서의 특징 공학"></a>🔹 구조화 데이터에서의 특징 공학</h3><ul><li>예: 집값 예측<ul><li>새로운 특징 생성: “평당 가격”</li><li>중요 특징 선택: 위치, 방 개수</li><li>정규화: 모든 수치를 비슷한 스케일로 변환</li></ul></li></ul><h3 id="🔹-비구조화-데이터에서의-특징-공학"><a href="#🔹-비구조화-데이터에서의-특징-공학" class="headerlink" title="🔹 비구조화 데이터에서의 특징 공학"></a>🔹 비구조화 데이터에서의 특징 공학</h3><ul><li><strong>텍스트 데이터</strong>: TF-IDF, 워드 임베딩  </li><li><strong>이미지 데이터</strong>: CNN으로 엣지, 패턴, 색상 특징 추출</li></ul><p>👉 시험 포인트: <strong>Feature Engineering은 모델 성능 최적화의 핵심 과정</strong></p><hr><h2 id="✅-요약"><a href="#✅-요약" class="headerlink" title="✅ 요약"></a>✅ 요약</h2><ul><li><strong>좋은 데이터 확보</strong>가 가장 중요 (Garbage In → Garbage Out)  </li><li><strong>라벨링 여부</strong> → 지도학습 vs 비지도학습  </li><li><strong>데이터 구조</strong> → 구조화 vs 비구조화  </li><li><strong>지도학습 유형</strong> → 회귀(숫자 예측), 분류(카테고리 예측)  </li><li><strong>데이터셋 분리</strong> → Training &#x2F; Validation &#x2F; Test  </li><li><strong>특징 공학</strong> → 성능 최적화를 위한 데이터 가공</li></ul><p>👉 AWS 자격증 시험 대비:</p><ul><li>지도&#x2F;비지도 학습 개념</li><li>데이터셋 분리 비율</li><li>Feature Engineering 기법<br>을 확실히 기억해 두면 시험에 유용함 🚀</li></ul><h2 id="추가내용-1-TF-IDF란"><a href="#추가내용-1-TF-IDF란" class="headerlink" title="(추가내용) 1. TF-IDF란?"></a>(추가내용) 1. TF-IDF란?</h2><p>TF-IDF는 <strong>문서(Text)</strong> 안에서 단어의 중요도를 수치로 나타내는 방법이에요.<br>검색 엔진, 문서 분류, 자연어 처리(NLP)에서 자주 사용됩니다.  </p><p>👉 핵심 아이디어:  </p><ul><li>특정 문서에서 <strong>많이 등장하는 단어</strong>일수록 중요하다 (<strong>TF</strong>)  </li><li>하지만 <strong>모든 문서에 흔히 등장하는 단어</strong>는 중요하지 않다 (<strong>IDF</strong>)</li></ul><hr><h2 id="추가내용-2-TF-Term-Frequency-단어-빈도"><a href="#추가내용-2-TF-Term-Frequency-단어-빈도" class="headerlink" title="(추가내용) 2. TF (Term Frequency, 단어 빈도)"></a>(추가내용) 2. TF (Term Frequency, 단어 빈도)</h2><ul><li>어떤 문서 안에서 특정 단어가 얼마나 자주 등장했는지를 측정합니다.  </li><li>계산식:</li></ul><p>$$<br>TF(t, d) &#x3D; \frac{\text{단어 t의 등장 횟수}}{\text{문서 d의 전체 단어 수}}<br>$$</p><p>📌 예시:<br>문서에 단어가 100개 있고, 그 중 <strong>“dog”</strong> 가 5번 나왔다면:  </p><p>$$<br>TF(dog) &#x3D; \frac{5}{100} &#x3D; 0.05<br>$$</p><hr><h2 id="추가내용-3-IDF-Inverse-Document-Frequency-역문서-빈도"><a href="#추가내용-3-IDF-Inverse-Document-Frequency-역문서-빈도" class="headerlink" title="(추가내용) 3. IDF (Inverse Document Frequency, 역문서 빈도)"></a>(추가내용) 3. IDF (Inverse Document Frequency, 역문서 빈도)</h2><ul><li>흔한 단어(예: “the”, “and”)는 중요하지 않다고 보고, 드물게 등장하는 단어에 가중치를 더 줍니다.  </li><li>계산식:</li></ul><p>$$<br>IDF(t) &#x3D; \log \frac{\text{전체 문서 수}}{\text{단어 t가 등장한 문서 수}}<br>$$</p><p>📌 예시:  </p><ul><li>문서 1000개 중 “dog”이 10개 문서에만 등장 →</li></ul><p>$$<br>IDF(dog) &#x3D; \log \frac{1000}{10} &#x3D; \log(100) \approx 2<br>$$  </p><ul><li>“the”가 1000개 문서 모두에 등장 →</li></ul><p>$$<br>IDF(the) &#x3D; \log \frac{1000}{1000} &#x3D; \log(1) &#x3D; 0<br>$$  </p><p>즉, 흔한 단어는 중요도가 거의 0이 됩니다.</p><hr><h2 id="추가내용-4-TF-IDF-최종-계산"><a href="#추가내용-4-TF-IDF-최종-계산" class="headerlink" title="(추가내용) 4. TF-IDF 최종 계산"></a>(추가내용) 4. TF-IDF 최종 계산</h2><p>$$<br>TF\text{-}IDF(t, d) &#x3D; TF(t, d) \times IDF(t)<br>$$</p><p>👉 단어가 <strong>특정 문서에서 자주 나오고</strong>, 다른 문서에서는 잘 안 나오면 → <strong>중요 단어!</strong></p><hr><h2 id="추가내용-5-예시로-이해하기"><a href="#추가내용-5-예시로-이해하기" class="headerlink" title="(추가내용) 5. 예시로 이해하기"></a>(추가내용) 5. 예시로 이해하기</h2><p>문서 3개가 있다고 가정해 봅시다.</p><ul><li>문서1: “dog likes playing”  </li><li>문서2: “dog and cat are friends”  </li><li>문서3: “dog runs fast”</li></ul><p>📌 “dog”은 모든 문서에 등장 → IDF 값이 낮음 (중요도 ↓)<br>📌 “playing”은 문서1에만 등장 → IDF 값이 높음 (중요도 ↑)  </p><p>따라서 문서1에서 “playing”의 TF-IDF 점수는 높게 나오고, 검색 엔진은 이 단어를 문서1의 <strong>핵심 키워드</strong>로 인식합니다.</p><hr><h2 id="추가내용-6-시험-대비-핵심-포인트"><a href="#추가내용-6-시험-대비-핵심-포인트" class="headerlink" title="(추가내용) 6. 시험 대비 핵심 포인트"></a>(추가내용) 6. 시험 대비 핵심 포인트</h2><ul><li>TF &#x3D; 특정 문서 내 단어 빈도  </li><li>IDF &#x3D; 전체 문서에서 얼마나 드문 단어인지  </li><li>TF-IDF &#x3D; <strong>특정 문서에서 중요한 단어를 찾는 점수</strong>  </li><li>자주 나오는 흔한 단어는 무시, 드물게 나오지만 특정 문서에 집중된 단어는 강조</li></ul><hr><p>👉 한 줄 요약:<br><strong>TF-IDF는 문서에서 핵심 키워드를 뽑아내는 가장 기본적이고 중요한 방법이다.</strong><br>AWS 자격증 시험에서도 <strong>텍스트 처리나 NLP 관련 문제</strong>에서 등장할 수 있으니 꼭 기억하세요 ✅  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;script src=&quot;https://polyfill.io/v3/polyfill.min.js?features=es6&quot;&gt;&lt;/script&gt;
&lt;script id=&quot;MathJax-script&quot; async
  src=&quot;https://cdn.jsdelivr.ne</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (22) - 공지능(AI), 머신러닝(ML), 딥러닝(DL), 생성형 AI (GenAI) 정리</title>
    <link href="https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-22/"/>
    <id>https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-22/</id>
    <published>2025-08-23T13:01:55.000Z</published>
    <updated>2025-08-23T22:13:40.551Z</updated>
    
    <content type="html"><![CDATA[<h1 id="🤖-인공지능-AI-머신러닝-ML-딥러닝-DL-생성형-AI-GenAI-정리"><a href="#🤖-인공지능-AI-머신러닝-ML-딥러닝-DL-생성형-AI-GenAI-정리" class="headerlink" title="🤖 인공지능(AI), 머신러닝(ML), 딥러닝(DL), 생성형 AI (GenAI) 정리"></a>🤖 인공지능(AI), 머신러닝(ML), 딥러닝(DL), 생성형 AI (GenAI) 정리</h1><h2 id="1-인공지능-AI-란"><a href="#1-인공지능-AI-란" class="headerlink" title="1. 인공지능(AI)란?"></a>1. 인공지능(AI)란?</h2><ul><li>AI는 <strong>인간의 지능이 필요한 일을 대신 수행할 수 있는 시스템</strong>을 만드는 광범위한 기술 분야입니다.  </li><li>주요 기능:<ul><li>인식(Perception)</li><li>추론(Reasoning)</li><li>학습(Learning)</li><li>문제 해결(Problem Solving)</li><li>의사결정(Decision Making)</li></ul></li></ul><p>👉 <strong>시험 포인트</strong>: AI는 큰 개념(우산)이고, 그 안에 <strong>ML → DL → GenAI</strong> 순서로 세부 기술이 포함됩니다.  </p><p align="center">  <img src="/images/aws_basic_96.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_97.png" width="80%"></p>---<h2 id="2-AI의-구성-요소"><a href="#2-AI의-구성-요소" class="headerlink" title="2. AI의 구성 요소"></a>2. AI의 구성 요소</h2><ul><li><strong>데이터 계층</strong>: 대량의 데이터를 수집  </li><li><strong>ML 프레임워크 및 알고리즘 계층</strong>: 데이터 과학자와 엔지니어가 요구사항에 맞는 알고리즘 설계  </li><li><strong>모델 계층</strong>: 모델 구조 설계, 파라미터 및 최적화 함수 적용 → 학습 수행  </li><li><strong>애플리케이션 계층</strong>: 학습된 모델을 실제 사용자에게 서비스</li></ul><p align="center">  <img src="/images/aws_basic_98.png" width="80%"></p><hr><h2 id="3-머신러닝-ML-란"><a href="#3-머신러닝-ML-란" class="headerlink" title="3. 머신러닝(ML)란?"></a>3. 머신러닝(ML)란?</h2><ul><li>AI의 한 분야로, 데이터를 이용해 <strong>기계가 학습</strong>할 수 있도록 하는 기술  </li><li>규칙을 직접 프로그래밍하지 않고, 데이터를 통해 <strong>예측 모델</strong>을 만듦  </li><li>예시:<ul><li><strong>회귀(Regression)</strong>: 연속적인 값 예측 (예: 집값 예측)  </li><li><strong>분류(Classification)</strong>: 그룹 구분 (예: 고양이 vs 개 이미지 분류)</li></ul></li></ul><p>👉 <strong>시험 포인트</strong>: ML은 데이터를 통해 학습하지만, <strong>명시적 규칙(If&#x2F;Then)을 직접 작성하지 않는다</strong>.  </p><p align="center">  <img src="/images/aws_basic_99.png" width="80%"></p><hr><h2 id="4-AI-≠-ML-고전-AI-예시"><a href="#4-AI-≠-ML-고전-AI-예시" class="headerlink" title="4. AI ≠ ML (고전 AI 예시)"></a>4. AI ≠ ML (고전 AI 예시)</h2><ul><li><strong>MYCIN 전문가 시스템 (1970년대)</strong>  <ul><li>증상&#x2F;검사 결과를 기반으로 환자 진단  </li><li>500개 이상의 규칙(If-Then Rule)로 작동  </li><li>확률 기반으로 원인균 추정 및 치료 제안  </li><li>당시에는 개인용 컴퓨터가 없어 실제 도입은 제한적</li></ul></li></ul><p>👉 <strong>시험 포인트</strong>: 옛날 AI는 규칙 기반(Expert System)이었지만, 현대 AI는 ML을 중심으로 발전.  </p><p align="center">  <img src="/images/aws_basic_100.png" width="80%"></p><hr><h2 id="5-딥러닝-Deep-Learning-DL"><a href="#5-딥러닝-Deep-Learning-DL" class="headerlink" title="5. 딥러닝(Deep Learning, DL)"></a>5. 딥러닝(Deep Learning, DL)</h2><ul><li><p>ML의 하위 분야  </p></li><li><p>뇌의 <strong>뉴런(Neuron)과 시냅스(Synapse)</strong> 구조를 모방한 <strong>신경망(Neural Network)</strong> 기반  </p></li><li><p>특징:</p><ul><li>다층(hidden layers)을 활용 → 더 복잡한 패턴 학습  </li><li><strong>대량의 데이터</strong> 필요  </li><li><strong>GPU</strong> 필요 (병렬 연산을 빠르게 처리)</li></ul></li><li><p>주요 활용:</p><ul><li><strong>컴퓨터 비전</strong>: 이미지 분류, 객체 탐지, 영상 인식  </li><li><strong>자연어 처리(NLP)</strong>: 번역, 감정 분석, 텍스트 요약</li></ul></li></ul><p>👉 <strong>시험 포인트</strong>: DL &#x3D; ML보다 복잡한 문제 해결 가능, <strong>GPU 활용</strong>이 자주 언급됨.  </p><p align="center">  <img src="/images/aws_basic_101.png" width="80%"></p><hr><h2 id="6-신경망-Neural-Networks-동작-방식"><a href="#6-신경망-Neural-Networks-동작-방식" class="headerlink" title="6. 신경망(Neural Networks) 동작 방식"></a>6. 신경망(Neural Networks) 동작 방식</h2><ul><li>입력 데이터가 <strong>노드(Node)</strong> 를 통해 여러 층을 거치며 전달  </li><li>각 층에서 패턴을 학습 → 새로운 연결 생성 또는 불필요한 연결 제거  </li><li>수십억 개의 노드와 수백~수천 개의 층으로 구성 가능</li></ul><p>예: <strong>손글씨 숫자 인식</strong>  </p><ul><li>한 층은 “세로 선”을 감지 (1, 4, 7)  </li><li>또 다른 층은 “곡선”을 감지 (6, 8, 0)  </li><li>여러 층이 결합되면서 숫자 인식 가능</li></ul><p align="center">  <img src="/images/aws_basic_102.png" width="80%"></p>---<h2 id="7-생성형-AI-Generative-AI-GenAI"><a href="#7-생성형-AI-Generative-AI-GenAI" class="headerlink" title="7. 생성형 AI (Generative AI, GenAI)"></a>7. 생성형 AI (Generative AI, GenAI)</h2><ul><li>딥러닝의 하위 분야  </li><li>**사전 학습된 대규모 모델(Foundation Model)**을 활용  </li><li>새로운 텍스트, 이미지, 음성, 영상 등을 생성 가능  </li><li>필요하면 **파인튜닝(Fine-tuning)**으로 기업 맞춤형 모델 제작</li></ul><p align="center">  <img src="/images/aws_basic_103.png" width="80%"></p><hr><h2 id="8-트랜스포머-모델-Transformer-LLM"><a href="#8-트랜스포머-모델-Transformer-LLM" class="headerlink" title="8. 트랜스포머 모델(Transformer, LLM)"></a>8. 트랜스포머 모델(Transformer, LLM)</h2><ul><li>기존 RNN&#x2F;LSTM과 달리, 문장을 단어 단위가 아닌 <strong>전체 문맥</strong>으로 처리  </li><li><strong>Self-Attention 메커니즘</strong>으로 단어 간 중요도를 계산 → 더 일관성 있고 빠른 학습 가능  </li><li>대표 사례:<ul><li><strong>Google BERT</strong></li><li><strong>OpenAI ChatGPT</strong> (<em>Chat Generative Pre-trained Transformer</em>)</li></ul></li></ul><p>👉 <strong>시험 포인트</strong>:  </p><ul><li>트랜스포머는 <strong>LLM(대규모 언어 모델)의 핵심 아키텍처</strong>  </li><li><strong>ChatGPT &#x3D; 트랜스포머 기반 모델</strong></li></ul><p align="center">  <img src="/images/aws_basic_104.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_105.png" width="80%"></p><hr><h2 id="9-멀티모달-Multimodal-모델"><a href="#9-멀티모달-Multimodal-모델" class="headerlink" title="9. 멀티모달(Multimodal) 모델"></a>9. 멀티모달(Multimodal) 모델</h2><ul><li>텍스트, 이미지, 오디오 등 <strong>다양한 입력</strong>을 동시에 받아서, 복합적인 출력 생성 가능  </li><li>예: 고양이 사진 + 음성 입력 → 고양이가 말하는 영상 생성</li></ul><p>👉 <strong>시험 포인트</strong>: 멀티모달 모델 &#x3D; <strong>여러 형식의 입력과 출력 처리 가능</strong>  </p><p align="center">  <img src="/images/aws_basic_106.png" width="80%"></p><hr><h2 id="🔑-인간과-AI의-비교"><a href="#🔑-인간과-AI의-비교" class="headerlink" title="🔑 인간과 AI의 비교"></a>🔑 인간과 AI의 비교</h2><ul><li><strong>AI(규칙 기반)</strong>: “만약 불이 나면 물을 뿌려라” → 명시적 규칙  </li><li><strong>ML</strong>: 많이 본 데이터 기반으로 분류 (“이건 강아지일 확률이 높다”)  </li><li><strong>DL</strong>: 본 적 없는 새로운 데이터도 유사 패턴 학습으로 인식 (“처음 본 동물도 ‘동물’임을 알 수 있음”)  </li><li><strong>GenAI</strong>: 학습한 내용을 기반으로 새로운 창작 (“새로운 시나 그림을 만들어냄”)</li></ul><hr><h2 id="📝-시험-대비-요약"><a href="#📝-시험-대비-요약" class="headerlink" title="📝 시험 대비 요약"></a>📝 시험 대비 요약</h2><ul><li><strong>AI</strong>: 큰 개념 (지능적 시스템 전반)  </li><li><strong>ML</strong>: 데이터를 이용한 학습 (규칙 직접 코딩 X)  </li><li><strong>DL</strong>: 다층 신경망 + GPU 필요 → 이미지&#x2F;텍스트 처리 강력  </li><li><strong>GenAI</strong>: 사전학습된 모델로 새로운 콘텐츠 생성  </li><li><strong>Transformer</strong>: LLM의 핵심 구조, ChatGPT 기반  </li><li><strong>Multimodal</strong>: 텍스트+이미지+음성 등 다양한 입력&#x2F;출력 가능</li></ul><p>👉 <strong>한 줄 정리</strong>:<br>AWS 시험에서는 <strong>AI → ML → DL → GenAI → Transformer(LLM)</strong> 순서와 각각의 특징, GPU 필요 여부, 트랜스포머 기반 LLM(예: ChatGPT)이 자주 출제됩니다.  </p><h2 id="📌-주요-용어-정리"><a href="#📌-주요-용어-정리" class="headerlink" title="📌 주요 용어 정리"></a>📌 주요 용어 정리</h2><h3 id="1-GPT-Generative-Pre-trained-Transformer"><a href="#1-GPT-Generative-Pre-trained-Transformer" class="headerlink" title="1. GPT (Generative Pre-trained Transformer)"></a>1. GPT (Generative Pre-trained Transformer)</h3><ul><li>입력 프롬프트(문장)에 따라 <strong>사람 같은 텍스트나 코드</strong>를 생성하는 모델  </li><li>대표 예: ChatGPT  </li><li>👉 시험 포인트: 텍스트 생성, 코드 생성 &#x3D; GPT</li></ul><hr><h3 id="2-BERT-Bidirectional-Encoder-Representations-from-Transformers"><a href="#2-BERT-Bidirectional-Encoder-Representations-from-Transformers" class="headerlink" title="2. BERT (Bidirectional Encoder Representations from Transformers)"></a>2. BERT (Bidirectional Encoder Representations from Transformers)</h3><ul><li>텍스트를 <strong>양방향(앞뒤 모두)</strong> 으로 읽는 언어 모델  </li><li>문맥 이해에 강함 → 번역, 문서 요약 등에 많이 사용  </li><li>👉 시험 포인트: <strong>문맥 기반 이해 &#x3D; BERT</strong></li></ul><hr><h3 id="3-RNN-Recurrent-Neural-Network"><a href="#3-RNN-Recurrent-Neural-Network" class="headerlink" title="3. RNN (Recurrent Neural Network)"></a>3. RNN (Recurrent Neural Network)</h3><ul><li><strong>순차적 데이터(Sequential Data)</strong> 를 다루는 신경망  </li><li>예시: 시계열 데이터, 텍스트, 음성  </li><li>사용처: 음성 인식, 시계열 예측  </li><li>👉 시험 포인트: <strong>순서가 중요한 데이터 처리 &#x3D; RNN</strong></li></ul><hr><h3 id="4-ResNet-Residual-Network"><a href="#4-ResNet-Residual-Network" class="headerlink" title="4. ResNet (Residual Network)"></a>4. ResNet (Residual Network)</h3><ul><li>이미지 처리용 <strong>딥러닝 CNN(Convolutional Neural Network)</strong>  </li><li>이미지 인식, 객체 탐지, 얼굴 인식 등에 사용  </li><li>👉 시험 포인트: <strong>이미지 처리 &#x3D; ResNet</strong></li></ul><hr><h3 id="5-SVM-Support-Vector-Machine"><a href="#5-SVM-Support-Vector-Machine" class="headerlink" title="5. SVM (Support Vector Machine)"></a>5. SVM (Support Vector Machine)</h3><ul><li>분류(Classification)와 회귀(Regression)에 모두 사용되는 ML 알고리즘  </li><li>👉 시험 포인트: 전통적 ML 알고리즘 (비신경망 기반)</li></ul><hr><h3 id="6-WaveNet"><a href="#6-WaveNet" class="headerlink" title="6. WaveNet"></a>6. WaveNet</h3><ul><li><strong>원시 오디오 파형(raw audio waveform)</strong> 을 생성하는 모델  </li><li>음성 합성(Text-to-Speech, TTS)에 활용 (예: Google Assistant 음성)  </li><li>👉 시험 포인트: <strong>음성 합성 &#x3D; WaveNet</strong></li></ul><hr><h3 id="7-GAN-Generative-Adversarial-Network"><a href="#7-GAN-Generative-Adversarial-Network" class="headerlink" title="7. GAN (Generative Adversarial Network)"></a>7. GAN (Generative Adversarial Network)</h3><ul><li>두 개의 네트워크(생성자 vs 판별자)가 경쟁하며 학습  </li><li><strong>가짜 데이터(이미지, 영상, 음성 등)</strong> 를 진짜처럼 생성  </li><li>데이터 증강(Data Augmentation)에 활용  </li><li>👉 시험 포인트: <strong>합성 데이터 생성, 데이터 부족 보완 &#x3D; GAN</strong></li></ul><hr><h3 id="8-XGBoost-Extreme-Gradient-Boosting"><a href="#8-XGBoost-Extreme-Gradient-Boosting" class="headerlink" title="8. XGBoost (Extreme Gradient Boosting)"></a>8. XGBoost (Extreme Gradient Boosting)</h3><ul><li><strong>Gradient Boosting 알고리즘의 고성능 구현체</strong>  </li><li>분류(Classification)와 회귀(Regression) 문제에서 뛰어난 성능  </li><li>Kaggle 등 데이터 경진대회에서 자주 사용  </li><li>👉 시험 포인트: <strong>트리 기반, 고성능 ML &#x3D; XGBoost</strong></li></ul><hr><h2 id="✅-시험-대비-핵심-요약"><a href="#✅-시험-대비-핵심-요약" class="headerlink" title="✅ 시험 대비 핵심 요약"></a>✅ 시험 대비 핵심 요약</h2><ul><li><strong>GPT, BERT</strong> → 자연어 처리 (언어 모델)  </li><li><strong>RNN</strong> → 순차적 데이터 (시계열, 음성)  </li><li><strong>ResNet</strong> → 이미지 처리  </li><li><strong>WaveNet</strong> → 음성 합성  </li><li><strong>GAN</strong> → 합성 데이터 생성 &#x2F; 데이터 증강  </li><li><strong>XGBoost, SVM</strong> → 전통 ML 알고리즘</li></ul><p>👉 실제 시험에서는 용어의 상세 동작보다는 <strong>무엇을 위한 모델인지, 어떤 데이터 유형에 쓰이는지</strong> 정도만 구분할 수 있으면 충분합니다.</p><hr><p>📌 <strong>추가 시험 포인트</strong></p><ul><li>AWS 자격증에서는 <strong>GenAI, LLM(대규모 언어 모델), Transformer</strong> 와의 연계성을 강조할 수 있음  </li><li>“어떤 모델이 이미지에 쓰이는가?” → ResNet  </li><li>“언어 모델 관련 용어는?” → GPT, BERT  </li><li>“합성 데이터 생성?” → GAN</li></ul><h2 id="추가정보-🧠-Self-Attention이란"><a href="#추가정보-🧠-Self-Attention이란" class="headerlink" title="(추가정보) 🧠 Self-Attention이란?"></a>(추가정보) 🧠 Self-Attention이란?</h2><p>Self-Attention은 문장 안의 <strong>모든 단어가 서로를 바라보며 중요도를 계산</strong>하는 메커니즘이에요.<br>이를 통해 GPT, BERT 같은 대규모 언어 모델(LLM)은 문맥적 관계를 더 잘 파악할 수 있습니다.</p><hr><h2 id="⚙️-동작-방식-간단히"><a href="#⚙️-동작-방식-간단히" class="headerlink" title="⚙️ 동작 방식 (간단히)"></a>⚙️ 동작 방식 (간단히)</h2><p>각 단어는 세 가지 벡터로 변환됩니다: </p><ol><li><strong>Query (Q)</strong> – “내가 다른 단어들과 얼마나 관련이 있는지 알고 싶어.” </li><li><strong>Key (K)</strong> – “나는 이런 의미를 가지고 있어.” </li><li><strong>Value (V)</strong> – “내 정보는 이거야.”</li></ol><p>작동 단계: </p><ol><li>Query(Q)와 다른 모든 Key(K)의 내적 → <strong>유사도 점수 계산</strong></li><li>Softmax 적용 → **가중치(Attention Score)**로 변환 </li><li>각 Value(V)에 가중치를 곱하고 합산 → 문맥이 반영된 새로운 단어 표현 생성</li></ol><hr><h2 id="✨-Self-Attention의-장점"><a href="#✨-Self-Attention의-장점" class="headerlink" title="✨ Self-Attention의 장점"></a>✨ Self-Attention의 장점</h2><ol><li><strong>문맥 이해 강화</strong> – 멀리 떨어진 단어도 관계를 연결<br>(예: <em>“공은 빨갰다. 그것은 굴러갔다.”</em> → “그것” &#x3D; “공”)</li><li><strong>병렬 처리 가능</strong> – RNN처럼 순차적이 아니라, 모든 단어를 동시에 처리 → 학습 속도 빠름</li><li><strong>장거리 의존성 해결</strong> – 문장이 길어도 앞뒤 문맥을 잘 연결 가능</li></ol><hr><h2 id="📌-요약"><a href="#📌-요약" class="headerlink" title="📌 요약"></a>📌 요약</h2><p>Self-Attention &#x3D; <strong>“문장 안의 모든 단어가 서로를 바라보며 중요도를 계산하고, 그 정보를 합쳐 새로운 의미 있는 표현을 만드는 방법”</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;🤖-인공지능-AI-머신러닝-ML-딥러닝-DL-생성형-AI-GenAI-정리&quot;&gt;&lt;a href=&quot;#🤖-인공지능-AI-머신러닝-ML-딥러닝-DL-생성형-AI-GenAI-정리&quot; class=&quot;headerlink&quot; title=&quot;🤖 인공지능(AI</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(22) - Understanding AI, ML, DL, and GenAI</title>
    <link href="https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-22/"/>
    <id>https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-22/</id>
    <published>2025-08-23T13:01:51.000Z</published>
    <updated>2025-08-23T22:13:40.551Z</updated>
    
    <content type="html"><![CDATA[<h1 id="🤖-Understanding-AI-ML-DL-and-GenAI"><a href="#🤖-Understanding-AI-ML-DL-and-GenAI" class="headerlink" title="🤖 Understanding AI, ML, DL, and GenAI"></a>🤖 Understanding AI, ML, DL, and GenAI</h1><h2 id="1-What-is-Artificial-Intelligence-AI"><a href="#1-What-is-Artificial-Intelligence-AI" class="headerlink" title="1. What is Artificial Intelligence (AI)?"></a>1. What is Artificial Intelligence (AI)?</h2><p>Artificial Intelligence (AI) is a broad field focused on building intelligent systems capable of tasks that usually require human intelligence, such as:</p><ul><li>Perception  </li><li>Reasoning  </li><li>Learning  </li><li>Problem solving  </li><li>Decision making</li></ul><p>👉 AI is an <strong>umbrella term</strong> covering multiple techniques.</p><p align="center">  <img src="/images/aws_basic_96.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_97.png" width="80%"></p><hr><h2 id="2-AI-Components"><a href="#2-AI-Components" class="headerlink" title="2. AI Components"></a>2. AI Components</h2><ul><li><strong>Data Layer</strong>: Collects large amounts of data.  </li><li><strong>ML Framework &amp; Algorithm Layer</strong>: Data scientists and engineers design use cases and frameworks to solve them.  </li><li><strong>Model Layer</strong>: Implements and trains models (structure, parameters, optimizer functions).  </li><li><strong>Application Layer</strong>: How the model is served to users.</li></ul><p align="center">  <img src="/images/aws_basic_98.png" width="80%"></p><hr><h2 id="3-What-is-Machine-Learning-ML"><a href="#3-What-is-Machine-Learning-ML" class="headerlink" title="3. What is Machine Learning (ML)?"></a>3. What is Machine Learning (ML)?</h2><ul><li>ML is a <strong>subset of AI</strong> focused on building methods that allow machines to <strong>learn from data</strong>.  </li><li>Improves performance by finding patterns and making predictions.  </li><li>No need for explicitly programmed rules.</li></ul><p><strong>Examples of ML tasks</strong>:  </p><ul><li>Regression (predicting trends).  </li><li>Classification (distinguishing categories).</li></ul><p align="center">  <img src="/images/aws_basic_99.png" width="80%"></p><hr><h2 id="4-AI-≠-ML-Historical-Example"><a href="#4-AI-≠-ML-Historical-Example" class="headerlink" title="4. AI ≠ ML (Historical Example)"></a>4. AI ≠ ML (Historical Example)</h2><p><strong>MYCIN Expert System (1970s)</strong>  </p><ul><li>Used 500+ rules to diagnose patients.  </li><li>Asked yes&#x2F;no questions and suggested possible bacteria and treatments.  </li><li>Never widely used (computing power was too limited).</li></ul><p>👉 Shows that AI existed before ML became mainstream.</p><p align="center">  <img src="/images/aws_basic_100.png" width="80%"></p><hr><h2 id="5-What-is-Deep-Learning-DL"><a href="#5-What-is-Deep-Learning-DL" class="headerlink" title="5. What is Deep Learning (DL)?"></a>5. What is Deep Learning (DL)?</h2><ul><li>Subset of ML that uses <strong>artificial neural networks</strong> inspired by the human brain.  </li><li>Handles complex patterns using multiple hidden layers.  </li><li>Requires <strong>large datasets</strong> and <strong>GPUs</strong> for processing.</li></ul><p><strong>Examples</strong>:  </p><ul><li><strong>Computer Vision</strong>: Image classification, object detection, segmentation.  </li><li><strong>NLP (Natural Language Processing)</strong>: Text classification, sentiment analysis, machine translation, language generation.</li></ul><p align="center">  <img src="/images/aws_basic_101.png" width="80%"></p><hr><h2 id="6-Neural-Networks-–-How-They-Work"><a href="#6-Neural-Networks-–-How-They-Work" class="headerlink" title="6. Neural Networks – How They Work"></a>6. Neural Networks – How They Work</h2><ul><li>Nodes (neurons) are connected in layers.  </li><li>Input data flows through layers, adjusting connections (weights).  </li><li>Networks may contain <strong>billions of nodes</strong> and many hidden layers.  </li><li>The system “learns” patterns automatically — not manually programmed.</li></ul><p><strong>Example</strong>: Handwritten digit recognition  </p><ul><li>Early layers detect <strong>lines&#x2F;curves</strong>.  </li><li>Deeper layers combine these to recognize complete numbers.</li></ul><p align="center">  <img src="/images/aws_basic_102.png" width="80%"></p><hr><h2 id="7-What-is-Generative-AI-GenAI"><a href="#7-What-is-Generative-AI-GenAI" class="headerlink" title="7. What is Generative AI (GenAI)?"></a>7. What is Generative AI (GenAI)?</h2><ul><li>Subset of Deep Learning.  </li><li>Uses <strong>foundation models</strong> (trained on massive datasets) that can generate text, images, audio, or code.  </li><li>Can be <strong>fine-tuned</strong> with your own data for specific use cases.</li></ul><p align="center">  <img src="/images/aws_basic_103.png" width="80%"></p><hr><h2 id="8-What-is-the-Transformer-Model-LLM"><a href="#8-What-is-the-Transformer-Model-LLM" class="headerlink" title="8. What is the Transformer Model? (LLM)"></a>8. What is the Transformer Model? (LLM)</h2><ul><li>Processes entire sentences at once (not word by word).  </li><li>Assigns <strong>relative importance</strong> to words (attention mechanism).  </li><li>More efficient and coherent than older models.</li></ul><p><strong>Transformer-based LLMs</strong>:  </p><ul><li>Trained on vast amounts of internet, books, and documents.  </li><li>Examples: <strong>Google BERT</strong>, <strong>OpenAI ChatGPT</strong> (Chat Generative Pre-trained Transformer).</li></ul><p>👉 Key foundation of modern GenAI.</p><p align="center">  <img src="/images/aws_basic_104.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_105.png" width="80%"></p><hr><h2 id="9-Humans-as-a-Mix-of-AI"><a href="#9-Humans-as-a-Mix-of-AI" class="headerlink" title="9. Humans as a Mix of AI"></a>9. Humans as a Mix of AI</h2><ul><li><strong>AI (Rules-based)</strong>: “If this happens, then do that.”  </li><li><strong>ML</strong>: Learn patterns from past examples.  </li><li><strong>DL</strong>: Generalize from similar concepts (recognize new things by analogy).  </li><li><strong>GenAI</strong>: Go beyond recognition → generate creative, new content.</li></ul><p align="center">  <img src="/images/aws_basic_106.png" width="80%"></p><hr><h2 id="✅-Exam-Tips"><a href="#✅-Exam-Tips" class="headerlink" title="✅ Exam Tips"></a>✅ Exam Tips</h2><ul><li>AI &#x3D; umbrella field, ML &#x3D; subset, DL &#x3D; deeper subset, GenAI &#x3D; specialized subset of DL.  </li><li>ML does <strong>not require explicit rules</strong> (learns from data).  </li><li>DL requires <strong>big data + GPUs</strong>.  </li><li>Transformer &#x3D; key architecture behind LLMs like ChatGPT.  </li><li>Remember the order: <strong>AI → ML → DL → GenAI (→ Transformers&#x2F;LLMs)</strong>.</li></ul><h2 id="🧠-Key-Terms"><a href="#🧠-Key-Terms" class="headerlink" title="🧠 Key Terms"></a>🧠 Key Terms</h2><ul><li><p><strong>GPT (Generative Pre-trained Transformer)</strong>  </p><ul><li>Foundation model that generates human-like text or computer code from prompts.  </li><li><strong>Exam Tip:</strong> Remember it’s focused on <strong>text&#x2F;code generation</strong>.</li></ul></li><li><p><strong>BERT (Bidirectional Encoder Representations from Transformers)</strong>  </p><ul><li>Reads text <strong>both left-to-right and right-to-left</strong> to understand context.  </li><li>Very strong for <strong>language understanding and translation</strong>.  </li><li><strong>Exam Tip:</strong> GPT &#x3D; generation, BERT &#x3D; understanding.</li></ul></li><li><p><strong>RNN (Recurrent Neural Network)</strong>  </p><ul><li>Designed for <strong>sequential data</strong> (time-series, text, speech).  </li><li>Commonly used in <strong>speech recognition</strong> and <strong>time-series forecasting</strong>.  </li><li><strong>Exam Tip:</strong> Think <strong>R &#x3D; Recurrent &#x3D; Sequence</strong>.</li></ul></li><li><p><strong>ResNet (Residual Network)</strong>  </p><ul><li>A type of <strong>Deep Convolutional Neural Network (CNN)</strong>.  </li><li>Used for <strong>image recognition, object detection, and facial recognition</strong>.  </li><li><strong>Exam Tip:</strong> If it’s <strong>image-related</strong>, ResNet is a strong candidate.</li></ul></li><li><p><strong>SVM (Support Vector Machine)</strong>  </p><ul><li>Traditional ML algorithm for <strong>classification and regression</strong>.  </li><li>Finds a boundary (hyperplane) between categories.  </li><li><strong>Exam Tip:</strong> If you see “classification with small datasets,” think SVM.</li></ul></li><li><p><strong>WaveNet</strong>  </p><ul><li>Model that generates <strong>raw audio waveforms</strong>.  </li><li>Used in <strong>speech synthesis (text-to-speech)</strong>.  </li><li><strong>Exam Tip:</strong> “Wave” &#x3D; audio.</li></ul></li><li><p><strong>GAN (Generative Adversarial Network)</strong>  </p><ul><li>Two models compete (generator vs discriminator) to create <strong>synthetic data</strong>.  </li><li>Generates images, videos, or sounds that look real.  </li><li>Helpful for <strong>data augmentation</strong> when training data is limited.  </li><li><strong>Exam Tip:</strong> GAN &#x3D; “Fake but realistic data.”</li></ul></li><li><p><strong>XGBoost (Extreme Gradient Boosting)</strong>  </p><ul><li>Optimized implementation of gradient boosting.  </li><li>Commonly used in <strong>classification and regression</strong> tasks.  </li><li>Frequently wins Kaggle competitions due to efficiency.  </li><li><strong>Exam Tip:</strong> If you see “gradient boosting” in the exam, XGBoost is likely the answer.</li></ul></li></ul><hr><h2 id="✅-Quick-Exam-Memory-Aid"><a href="#✅-Quick-Exam-Memory-Aid" class="headerlink" title="✅ Quick Exam Memory Aid"></a>✅ Quick Exam Memory Aid</h2><ul><li><strong>GPT &amp; BERT</strong> → Language (Generation vs Understanding)  </li><li><strong>RNN</strong> → Sequences (speech, time-series)  </li><li><strong>ResNet</strong> → Images (recognition&#x2F;detection)  </li><li><strong>SVM</strong> → Classification (small datasets, traditional ML)  </li><li><strong>WaveNet</strong> → Audio (speech synthesis)  </li><li><strong>GAN</strong> → Synthetic data (augmentation, fake-but-realistic images&#x2F;videos)  </li><li><strong>XGBoost</strong> → Gradient boosting (fast, efficient, tabular data)</li></ul><hr><p>👉 <strong>Bottom line for the exam:</strong><br>Know which domain each term belongs to (text, image, audio, data augmentation, etc.) and you can eliminate wrong answers quickly. </p><h2 id="Additional-🧠-What-is-Self-Attention"><a href="#Additional-🧠-What-is-Self-Attention" class="headerlink" title="(Additional) 🧠 What is Self-Attention?"></a>(Additional) 🧠 What is Self-Attention?</h2><p>Self-Attention is a mechanism that allows <strong>each word in a sentence to<br>look at every other word</strong> and determine how much attention it should<br>pay to them.<br>It helps LLMs (Large Language Models) like GPT or BERT capture<br><strong>contextual relationships</strong> within a sentence.</p><hr><h2 id="⚙️-How-it-Works"><a href="#⚙️-How-it-Works" class="headerlink" title="⚙️ How it Works"></a>⚙️ How it Works</h2><p>Each token (word) is transformed into three vectors: 1. <strong>Query (Q)</strong> –<br>“I want to know how related I am to others.” 2. <strong>Key (K)</strong> – “This is<br>what I represent.” 3. <strong>Value (V)</strong> – “This is my actual information.”</p><p>Steps: 1. Compute the dot product of Query (Q) and Key (K) of all words<br>→ <strong>similarity score</strong> 2. Apply <strong>Softmax</strong> → turns similarity into<br>attention weights 3. Multiply each Value (V) by its weight and sum them<br>→ new context-aware representation of the word</p><hr><h2 id="✨-Why-it-Matters"><a href="#✨-Why-it-Matters" class="headerlink" title="✨ Why it Matters"></a>✨ Why it Matters</h2><ol><li><strong>Captures context</strong> – Even long-distance dependencies are<br>recognized<br>(e.g., <em>“The ball was red. It rolled away.”</em> → “It” refers to<br>“ball”)\</li><li><strong>Parallel computation</strong> – Unlike RNNs, attention processes all<br>words at once, making training faster\</li><li><strong>Handles long sequences</strong> – No degradation like RNN&#x2F;LSTM with long<br>sentences</li></ol><hr><h2 id="📌-Summary"><a href="#📌-Summary" class="headerlink" title="📌 Summary"></a>📌 Summary</h2><p>Self-Attention &#x3D;<br><em>“Every word looks at every other word, assigns importance, and builds a<br>new meaning-aware representation.”</em></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;🤖-Understanding-AI-ML-DL-and-GenAI&quot;&gt;&lt;a href=&quot;#🤖-Understanding-AI-ML-DL-and-GenAI&quot; class=&quot;headerlink&quot; title=&quot;🤖 Understanding AI, M</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
</feed>
