<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Danny&#39;s Blog</title>
  
  <subtitle>Data, AI, and Tech Insight</subtitle>
  <link href="https://kish191919.github.io/atom.xml" rel="self"/>
  
  <link href="https://kish191919.github.io/"/>
  <updated>2025-12-03T17:17:58.173Z</updated>
  <id>https://kish191919.github.io/</id>
  
  <author>
    <name>Danny Ki</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>TERADATA(3)-History View</title>
    <link href="https://kish191919.github.io/2025/12/03/TERADATA-3-History-View/"/>
    <id>https://kish191919.github.io/2025/12/03/TERADATA-3-History-View/</id>
    <published>2025-12-03T17:12:57.000Z</published>
    <updated>2025-12-03T17:17:58.173Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ“˜-Teradata-Studio-â€“-SQL-History-ì°½-ì™„ì „-ì •ë¦¬"><a href="#ğŸ“˜-Teradata-Studio-â€“-SQL-History-ì°½-ì™„ì „-ì •ë¦¬" class="headerlink" title="ğŸ“˜ Teradata Studio â€“ SQL History ì°½ ì™„ì „ ì •ë¦¬"></a>ğŸ“˜ Teradata Studio â€“ SQL History ì°½ ì™„ì „ ì •ë¦¬</h1><p><em>Teradata SQL History ì°½ ì„¤ì •, ì»¬ëŸ¼ ì„ íƒ, ë…¸íŠ¸ ê¸°ëŠ¥, ë³µì› ë°©ë²•</em></p><hr><h2 id="ğŸ“-1-SQL-History-ì°½-ë³µì›í•˜ê¸°"><a href="#ğŸ“-1-SQL-History-ì°½-ë³µì›í•˜ê¸°" class="headerlink" title="ğŸ“ 1. SQL History ì°½ ë³µì›í•˜ê¸°"></a>ğŸ“ 1. SQL History ì°½ ë³µì›í•˜ê¸°</h2><p>SQL History ì°½ì„ ì‹¤ìˆ˜ë¡œ ë‹«ì•˜ê±°ë‚˜ ì‚¬ë¼ì¡Œë‹¤ë©´:</p><p><strong>Window â†’ Reset Perspective</strong></p><p>ë¥¼ ëˆŒëŸ¬ì£¼ë©´ ê¸°ë³¸ ë ˆì´ì•„ì›ƒìœ¼ë¡œ ë³µì›ë©ë‹ˆë‹¤.<br>â†’ History ì°½, Result Viewer ë“± ëª¨ë“  íŒ¨ë„ì´ ì›ë˜ ìœ„ì¹˜ë¡œ ëŒì•„ì˜µë‹ˆë‹¤.</p><hr><h2 id="ğŸ“-2-SQL-History-ì°½-ì»¬ëŸ¼-Columns-ì»¤ìŠ¤í„°ë§ˆì´ì§•"><a href="#ğŸ“-2-SQL-History-ì°½-ì»¬ëŸ¼-Columns-ì»¤ìŠ¤í„°ë§ˆì´ì§•" class="headerlink" title="ğŸ“ 2. SQL History ì°½ ì»¬ëŸ¼(Columns) ì»¤ìŠ¤í„°ë§ˆì´ì§•"></a>ğŸ“ 2. SQL History ì°½ ì»¬ëŸ¼(Columns) ì»¤ìŠ¤í„°ë§ˆì´ì§•</h2><p>SQL HistoryëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë§¤ìš° ë§ì€ ì»¬ëŸ¼ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.<br>ì˜ˆ: Timestamp, Source, User, Destination, Row Count, Result, SQL Statement ë“±</p><p>í•„ìš” ì—†ëŠ” ì»¬ëŸ¼ì´ ë§ìœ¼ë©´ í™”ë©´ì´ ë³µì¡í•´ì§€ë¯€ë¡œ <strong>ì›í•˜ëŠ” í•­ëª©ë§Œ ì„ íƒ</strong>í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p><h3 id="ğŸ”§-ì„¤ì •-ê²½ë¡œ"><a href="#ğŸ”§-ì„¤ì •-ê²½ë¡œ" class="headerlink" title="ğŸ”§ ì„¤ì • ê²½ë¡œ"></a>ğŸ”§ ì„¤ì • ê²½ë¡œ</h3><p><strong>Window â†’ Preferences â†’ Teradata Datatools â†’ SQL History</strong></p><p>ì—¬ê¸°ì„œ ë‹¤ìŒì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:</p><h3 id="ğŸ”¹-1-í‘œì‹œí• -ì»¬ëŸ¼-ì„ íƒ"><a href="#ğŸ”¹-1-í‘œì‹œí• -ì»¬ëŸ¼-ì„ íƒ" class="headerlink" title="ğŸ”¹ 1) í‘œì‹œí•  ì»¬ëŸ¼ ì„ íƒ"></a>ğŸ”¹ 1) í‘œì‹œí•  ì»¬ëŸ¼ ì„ íƒ</h3><ul><li>Removed Columns â†’ í‘œì‹œ ì•ˆ í•¨</li><li>Displayed Columns â†’ í‘œì‹œë¨</li></ul><p>ì˜ˆì‹œ: ì•„ë˜ í•­ëª©ë§Œ ì„ íƒí•˜ì—¬ í•„ìš”í•œ ì •ë³´ë§Œ ë³´ì´ê²Œ í•  ìˆ˜ ìˆìŒ</p><ul><li>Timestamp</li><li>SQL Statement</li><li>Result (ì—ëŸ¬ ë©”ì‹œì§€ í¬í•¨)</li><li>Row Count</li><li>Elapsed Time</li></ul><p>ì ìš© í›„ History ì°½ì—ëŠ” ì„ íƒí•œ ì»¬ëŸ¼ë§Œ ê¹”ë”í•˜ê²Œ í‘œì‹œë©ë‹ˆë‹¤.</p><hr><h2 id="ğŸ“-3-ì„¤ì •-ì ìš©-í›„-ê²°ê³¼-í™•ì¸"><a href="#ğŸ“-3-ì„¤ì •-ì ìš©-í›„-ê²°ê³¼-í™•ì¸" class="headerlink" title="ğŸ“ 3. ì„¤ì • ì ìš© í›„ ê²°ê³¼ í™•ì¸"></a>ğŸ“ 3. ì„¤ì • ì ìš© í›„ ê²°ê³¼ í™•ì¸</h2><p>ì˜ˆì‹œ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•œ í›„ History ì°½ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:</p><ul><li><strong>Row Count</strong>: ì¡°íšŒëœ ë ˆì½”ë“œ ìˆ˜</li><li><strong>Result</strong>:<ul><li>ì„±ê³µ ì‹œ â€œExecuted as Single Statementâ€</li><li>2000ê°œ ë„˜ìœ¼ë©´ â€œCanceledâ€ (ì œí•œ ë•Œë¬¸ì— ì¼ë¶€ë§Œ ì¡°íšŒë¨)</li></ul></li><li><strong>Elapsed Time</strong>: ì‹¤í–‰ ì†Œìš” ì‹œê°„</li><li><strong>SQL Statement</strong>: ì‹¤í–‰í•œ SQL ì›ë¬¸</li><li><strong>Timestamp</strong>: ì‹¤í–‰í•œ ë‚ ì§œ&#x2F;ì‹œê°„</li></ul><p>ğŸ‘‰ ë¶ˆí•„ìš”í•œ ë°ì´í„° ì—†ì´ í•µì‹¬ ì •ë³´ë§Œ ë‚¨ì•„ì„œ í›¨ì”¬ ì½ê¸° ì‰¬ì›Œì§</p><hr><h2 id="ğŸ“-4-SQL-Notes-ê¸°ëŠ¥-ì‚¬ìš©í•˜ê¸°"><a href="#ğŸ“-4-SQL-Notes-ê¸°ëŠ¥-ì‚¬ìš©í•˜ê¸°" class="headerlink" title="ğŸ“ 4. SQL Notes ê¸°ëŠ¥ ì‚¬ìš©í•˜ê¸°"></a>ğŸ“ 4. SQL Notes ê¸°ëŠ¥ ì‚¬ìš©í•˜ê¸°</h2><p>SQL Editorì—ì„œ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•  ë•Œ <strong>ë…¸íŠ¸ ì…ë ¥ íŒì—…</strong>ì´ ëœ° ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p><p>ì˜ˆì‹œ íŒì—… ë‚´ìš©:</p><blockquote><p>â€œEnter a note for this queryâ€</p></blockquote><p>ì´ ê¸°ëŠ¥ì€ ì¿¼ë¦¬ ì‹¤í–‰ ì‹œ <strong>ê°œì¸ ë©”ëª¨</strong>ë¥¼ ê¸°ë¡í•´ë‘ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.</p><p>ì˜ˆ:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">My first query</span><br></pre></td></tr></table></figure><p>ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ê³  History ì°½ì— â€œNotesâ€ ì»¬ëŸ¼ì„ ì¶”ê°€í•˜ë©´ í•´ë‹¹ ë‚´ìš©ì´ í‘œì‹œë©ë‹ˆë‹¤.</p><hr><h2 id="ğŸ“-5-Notes-ì»¬ëŸ¼-ì¶”ê°€í•˜ëŠ”-ë°©ë²•"><a href="#ğŸ“-5-Notes-ì»¬ëŸ¼-ì¶”ê°€í•˜ëŠ”-ë°©ë²•" class="headerlink" title="ğŸ“ 5. Notes ì»¬ëŸ¼ ì¶”ê°€í•˜ëŠ” ë°©ë²•"></a>ğŸ“ 5. Notes ì»¬ëŸ¼ ì¶”ê°€í•˜ëŠ” ë°©ë²•</h2><p>ê²½ë¡œ:</p><p><strong>Window â†’ Preferences â†’ Teradata Datatools â†’ SQL History</strong></p><ol><li>Available Columns ëª©ë¡ì—ì„œ â€œNotesâ€ë¥¼ ì„ íƒ</li><li>Displayed Columnsë¡œ ì´ë™</li><li>í•„ìš”í•˜ë©´ <strong>ìˆœì„œ ì´ë™(Up&#x2F;Down)</strong> ê¸°ëŠ¥ìœ¼ë¡œ ì›í•˜ëŠ” ìœ„ì¹˜ ì¡°ì •</li><li>Apply and Close</li></ol><p>ì´ì œ History ì°½ì— Notesê°€ í‘œì‹œë©ë‹ˆë‹¤:</p><table><thead><tr><th>Timestamp</th><th>SQL Statement</th><th>Result</th><th>Notes</th></tr></thead><tbody><tr><td>2025-02-10</td><td>SELECT * FROM â€¦</td><td>OK</td><td>My first query</td></tr></tbody></table><p>ğŸ’¡ SQLì„ ë§ì´ ì‘ì„±í•˜ëŠ” ê²½ìš° ì¿¼ë¦¬ ëª©ì ì´ë‚˜ íŠ¹ì´ì‚¬í•­ì„ ê¸°ë¡í•´ë‘ë©´ ìœ ìš©í•¨.</p><hr><h2 id="ğŸ“-6-Notes-ê¸°ëŠ¥-ë¹„í™œì„±í™”"><a href="#ğŸ“-6-Notes-ê¸°ëŠ¥-ë¹„í™œì„±í™”" class="headerlink" title="ğŸ“ 6. Notes ê¸°ëŠ¥ ë¹„í™œì„±í™”"></a>ğŸ“ 6. Notes ê¸°ëŠ¥ ë¹„í™œì„±í™”</h2><p>Notes ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ë‹¤ìŒê³¼ ê°™ì´ ëŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p><p>ë°©ë²• â‘ </p><ul><li>SQL ì‹¤í–‰ í›„ ëœ¨ëŠ” ë…¸íŠ¸ íŒì—…ì„ â€œë¹„í™œì„±í™”â€ ì²´í¬</li></ul><p>ë°©ë²• â‘¡</p><ul><li>Notes ì»¬ëŸ¼ì„ ë‹¤ì‹œ Removed Columnsë¡œ ì´ë™<br>â†’ History ì°½ì—ì„œ ì œê±°ë¨</li></ul><hr><h2 id="ğŸ“-7-History-ì°½-ì¦‰ì‹œ-ì„¤ì •í•˜ëŠ”-ë¹ ë¥¸-ë°©ë²•"><a href="#ğŸ“-7-History-ì°½-ì¦‰ì‹œ-ì„¤ì •í•˜ëŠ”-ë¹ ë¥¸-ë°©ë²•" class="headerlink" title="ğŸ“ 7. History ì°½ ì¦‰ì‹œ ì„¤ì •í•˜ëŠ” ë¹ ë¥¸ ë°©ë²•"></a>ğŸ“ 7. History ì°½ ì¦‰ì‹œ ì„¤ì •í•˜ëŠ” ë¹ ë¥¸ ë°©ë²•</h2><p>History ì°½ ì˜¤ë¥¸ìª½ ìƒë‹¨ì˜ <strong>ğŸ”§ (Wrench) ì•„ì´ì½˜</strong>ì„ í´ë¦­í•˜ë©´<br>ë°”ë¡œ ê°™ì€ ì„¤ì • í™”ë©´ìœ¼ë¡œ ì´ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p><p><strong>Window â†’ Preferences</strong> ë©”ë‰´ë¥¼ íƒ€ê³  ê°ˆ í•„ìš” ì—†ìŒ.</p><hr><h2 id="ğŸ“-8-ì–¸ì œë“ -ê¸°ë³¸ê°’ìœ¼ë¡œ-ë³µì›-ê°€ëŠ¥"><a href="#ğŸ“-8-ì–¸ì œë“ -ê¸°ë³¸ê°’ìœ¼ë¡œ-ë³µì›-ê°€ëŠ¥" class="headerlink" title="ğŸ“ 8. ì–¸ì œë“  ê¸°ë³¸ê°’ìœ¼ë¡œ ë³µì› ê°€ëŠ¥"></a>ğŸ“ 8. ì–¸ì œë“  ê¸°ë³¸ê°’ìœ¼ë¡œ ë³µì› ê°€ëŠ¥</h2><p>History ì„¤ì •ì´ ê¼¬ì´ê±°ë‚˜ ë„ˆë¬´ ë³µì¡í•´ì¡Œë‹¤ë©´:</p><p><strong>Restore Defaults</strong> ë²„íŠ¼ í´ë¦­</p><p>â†’ Teradata Studioì˜ ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ê¹”ë”í•˜ê²Œ ë˜ëŒì•„ì˜µë‹ˆë‹¤.</p><hr><h2 id="ğŸ¯-ìµœì¢…-ìš”ì•½"><a href="#ğŸ¯-ìµœì¢…-ìš”ì•½" class="headerlink" title="ğŸ¯ ìµœì¢… ìš”ì•½"></a>ğŸ¯ ìµœì¢… ìš”ì•½</h2><p>ì´ë²ˆ ê°•ì˜ì—ì„œëŠ” SQL History ì°½ì„ ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤:</p><h3 id="âœ”-ì›í•˜ëŠ”-ì»¬ëŸ¼ë§Œ-í‘œì‹œí•˜ë„ë¡-ì»¤ìŠ¤í„°ë§ˆì´ì§•"><a href="#âœ”-ì›í•˜ëŠ”-ì»¬ëŸ¼ë§Œ-í‘œì‹œí•˜ë„ë¡-ì»¤ìŠ¤í„°ë§ˆì´ì§•" class="headerlink" title="âœ” ì›í•˜ëŠ” ì»¬ëŸ¼ë§Œ í‘œì‹œí•˜ë„ë¡ ì»¤ìŠ¤í„°ë§ˆì´ì§•"></a>âœ” ì›í•˜ëŠ” ì»¬ëŸ¼ë§Œ í‘œì‹œí•˜ë„ë¡ ì»¤ìŠ¤í„°ë§ˆì´ì§•</h3><ul><li>Timestamp</li><li>Row Count</li><li>Result</li><li>SQL Statement</li><li>Elapsed Time</li><li>Notes (í•„ìš” ì‹œ)</li></ul><h3 id="âœ”-Notes-ê¸°ëŠ¥"><a href="#âœ”-Notes-ê¸°ëŠ¥" class="headerlink" title="âœ” Notes ê¸°ëŠ¥"></a>âœ” Notes ê¸°ëŠ¥</h3><ul><li>ì¿¼ë¦¬ì— ê°œì¸ ë©”ëª¨ ì¶”ê°€ ê°€ëŠ¥</li><li>History ì°½ì— Notes ì»¬ëŸ¼ìœ¼ë¡œ í‘œì‹œë¨</li><li>ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë©´ ë¹„í™œì„±í™” ê°€ëŠ¥</li></ul><h3 id="âœ”-ë¹ ë¥¸-ì„¤ì •"><a href="#âœ”-ë¹ ë¥¸-ì„¤ì •" class="headerlink" title="âœ” ë¹ ë¥¸ ì„¤ì •"></a>âœ” ë¹ ë¥¸ ì„¤ì •</h3><ul><li>Historyì°½ì˜ ğŸ”§ ì•„ì´ì½˜ìœ¼ë¡œ ì¦‰ì‹œ ì´ë™</li></ul><h3 id="âœ”-ë ˆì´ì•„ì›ƒ-ë³µì›"><a href="#âœ”-ë ˆì´ì•„ì›ƒ-ë³µì›" class="headerlink" title="âœ” ë ˆì´ì•„ì›ƒ ë³µì›"></a>âœ” ë ˆì´ì•„ì›ƒ ë³µì›</h3><ul><li>Window â†’ Reset Perspective ë¡œ ì „ì²´ UI ì´ˆê¸°í™” ê°€ëŠ¥</li></ul><hr><p>í•„ìš”í•˜ì‹œë©´ ë‹¤ìŒ ê°•ì˜ë„ ì •ë¦¬í•´ì„œ ì—°ê²°ëœ md íŒŒì¼ë¡œ ë§Œë“¤ì–´ë“œë¦´ê²Œìš”!</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ“˜-Teradata-Studio-â€“-SQL-History-ì°½-ì™„ì „-ì •ë¦¬&quot;&gt;&lt;a href=&quot;#ğŸ“˜-Teradata-Studio-â€“-SQL-History-ì°½-ì™„ì „-ì •ë¦¬&quot; class=&quot;headerlink&quot; title=&quot;ğŸ“˜ Teradata </summary>
      
    
    
    
    <category term="TERADATA" scheme="https://kish191919.github.io/categories/TERADATA/"/>
    
    
    <category term="TERADATA" scheme="https://kish191919.github.io/tags/TERADATA/"/>
    
  </entry>
  
  <entry>
    <title>TERADATA(2)-Customizing the Interface and Result Set Viewer</title>
    <link href="https://kish191919.github.io/2025/12/03/TERADATA-2-Customizing-the-Interface-and-Result-Set-Viewer/"/>
    <id>https://kish191919.github.io/2025/12/03/TERADATA-2-Customizing-the-Interface-and-Result-Set-Viewer/</id>
    <published>2025-12-03T16:38:31.000Z</published>
    <updated>2025-12-03T16:43:04.692Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ“˜-Teradata-Studio-í™˜ê²½-ì„¤ì •-ë°-í™”ë©´-ì»¤ìŠ¤í„°ë§ˆì´ì§•"><a href="#ğŸ“˜-Teradata-Studio-í™˜ê²½-ì„¤ì •-ë°-í™”ë©´-ì»¤ìŠ¤í„°ë§ˆì´ì§•" class="headerlink" title="ğŸ“˜ Teradata Studio í™˜ê²½ ì„¤ì • ë° í™”ë©´ ì»¤ìŠ¤í„°ë§ˆì´ì§•"></a>ğŸ“˜ Teradata Studio í™˜ê²½ ì„¤ì • ë° í™”ë©´ ì»¤ìŠ¤í„°ë§ˆì´ì§•</h1><p><em>Teradata Studio ë·° ë³€ê²½ &#x2F; í°íŠ¸ ìˆ˜ì • &#x2F; Result Viewer ì„¤ì • &#x2F; í–‰ ìƒ‰ìƒ ë³€ê²½ ë“±</em></p><hr><h2 id="ğŸ“-1-í•˜ë‹¨-ì°½-History-ë“±-ìˆ¨ê¸°ê¸°-ë³´ì´ê¸°"><a href="#ğŸ“-1-í•˜ë‹¨-ì°½-History-ë“±-ìˆ¨ê¸°ê¸°-ë³´ì´ê¸°" class="headerlink" title="ğŸ“ 1. í•˜ë‹¨ ì°½(History ë“±) ìˆ¨ê¸°ê¸° &#x2F; ë³´ì´ê¸°"></a>ğŸ“ 1. í•˜ë‹¨ ì°½(History ë“±) ìˆ¨ê¸°ê¸° &#x2F; ë³´ì´ê¸°</h2><p>Teradata Studioì—ì„œ í•˜ë‹¨ì˜ <strong>SQL History</strong> ë˜ëŠ” ê¸°íƒ€ ì°½ì´ ê³µê°„ì„ ë§ì´ ì°¨ì§€í•  ë•Œ:</p><ul><li>ì°½ ìš°ì¸¡ ìƒë‹¨ì˜ <strong>minimize( â€” )</strong> ë²„íŠ¼ í´ë¦­ â†’ ì°½ì´ ì ‘í˜</li><li>ë‹¤ì‹œ ë³´ê³  ì‹¶ì„ ë•ŒëŠ” ì•„ë˜ ë„í‚¹ëœ íƒ­ì„ í´ë¦­í•˜ë©´ ë‹¤ì‹œ ë‚˜íƒ€ë‚¨</li></ul><p>âœ” í™”ë©´ì„ ë„“ê²Œ ì“°ê³  ì‹¶ì„ ë•Œ ë§¤ìš° ìœ ìš©í•œ ê¸°ëŠ¥</p><hr><h2 id="ğŸ“-2-í°íŠ¸-í¬ê¸°-ìŠ¤íƒ€ì¼-ë³€ê²½í•˜ê¸°"><a href="#ğŸ“-2-í°íŠ¸-í¬ê¸°-ìŠ¤íƒ€ì¼-ë³€ê²½í•˜ê¸°" class="headerlink" title="ğŸ“ 2. í°íŠ¸ í¬ê¸° &#x2F; ìŠ¤íƒ€ì¼ ë³€ê²½í•˜ê¸°"></a>ğŸ“ 2. í°íŠ¸ í¬ê¸° &#x2F; ìŠ¤íƒ€ì¼ ë³€ê²½í•˜ê¸°</h2><p>ê²½ë¡œ:<br><strong>Window â†’ Preferences â†’ General â†’ Appearance â†’ Colors and Fonts</strong></p><p>ì—¬ê¸°ì„œ ë‹¤ì–‘í•œ UI ìš”ì†Œì˜ í°íŠ¸ì™€ ìƒ‰ìƒì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p><h3 id="ğŸ”¸-í°íŠ¸-ì¢…ë¥˜-ì„¤ëª…"><a href="#ğŸ”¸-í°íŠ¸-ì¢…ë¥˜-ì„¤ëª…" class="headerlink" title="ğŸ”¸ í°íŠ¸ ì¢…ë¥˜ ì„¤ëª…"></a>ğŸ”¸ í°íŠ¸ ì¢…ë¥˜ ì„¤ëª…</h3><ul><li>ê¸€ì ì˜†ì— <strong>A ì•„ì´ì½˜</strong>ì´ ìˆìœ¼ë©´ â€œí°íŠ¸ ê´€ë ¨â€</li><li>Aê°€ ì—†ìœ¼ë©´ ë°°ê²½ìƒ‰&#x2F;ì „ê²½ìƒ‰ ê°™ì€ â€œìƒ‰ìƒ ê´€ë ¨â€</li></ul><h3 id="ğŸ”¸-Dialog-Font-ë³€ê²½í•˜ê¸°"><a href="#ğŸ”¸-Dialog-Font-ë³€ê²½í•˜ê¸°" class="headerlink" title="ğŸ”¸ Dialog Font ë³€ê²½í•˜ê¸°"></a>ğŸ”¸ Dialog Font ë³€ê²½í•˜ê¸°</h3><p>ê²½ë¡œ:<br><code>General â†’ Appearance â†’ Colors and Fonts â†’ Dialog Font</code></p><ol><li>ì›í•˜ëŠ” í°íŠ¸&#x2F;í¬ê¸° ì„ íƒ</li><li>Previewì—ì„œ í™•ì¸</li><li>Apply and Close</li></ol><p>ğŸ“Œ â€œDialog Fontâ€ëŠ” Studio ì „ë°˜ì˜ íŒì—…ì°½, ë²„íŠ¼, í‘œ(Row) ë“±ì˜ ê¸°ë³¸ í°íŠ¸ë¥¼ ì˜ë¯¸í•¨.</p><blockquote><p>ì¼ë¶€ ë³€ê²½ ì‚¬í•­ì€ ì°½ì„ <strong>ë‹«ì•˜ë‹¤ ë‹¤ì‹œ ì—´ì–´ì•¼ ë°˜ì˜ë¨</strong></p></blockquote><hr><h2 id="ğŸ“-3-í°íŠ¸-ë³€ê²½-í›„-ë§ˆìŒì—-ë“¤ì§€-ì•Šì„-ë•Œ"><a href="#ğŸ“-3-í°íŠ¸-ë³€ê²½-í›„-ë§ˆìŒì—-ë“¤ì§€-ì•Šì„-ë•Œ" class="headerlink" title="ğŸ“ 3. í°íŠ¸ ë³€ê²½ í›„ ë§ˆìŒì— ë“¤ì§€ ì•Šì„ ë•Œ"></a>ğŸ“ 3. í°íŠ¸ ë³€ê²½ í›„ ë§ˆìŒì— ë“¤ì§€ ì•Šì„ ë•Œ</h2><p>ì–¸ì œë“ ì§€ <strong>Restore Defaults(ê¸°ë³¸ê°’ìœ¼ë¡œ ë³µì›)</strong> â†’ Apply í•˜ë©´ ì´ˆê¸° ìƒíƒœë¡œ ëŒì•„ê°‘ë‹ˆë‹¤.</p><p>íŠ¹íˆ í°íŠ¸ë¥¼ ê³¼í•˜ê²Œ í¬ê²Œ&#x2F;ì‘ê²Œ ì„¤ì •í–ˆì„ ê²½ìš° ìœ ìš©í•©ë‹ˆë‹¤.</p><hr><h2 id="ğŸ“-4-SQL-Editor-í°íŠ¸-ë³€ê²½í•˜ê¸°"><a href="#ğŸ“-4-SQL-Editor-í°íŠ¸-ë³€ê²½í•˜ê¸°" class="headerlink" title="ğŸ“ 4. SQL Editor í°íŠ¸ ë³€ê²½í•˜ê¸°"></a>ğŸ“ 4. SQL Editor í°íŠ¸ ë³€ê²½í•˜ê¸°</h2><p>ê²½ë¡œ:<br><strong>Window â†’ Preferences â†’ General â†’ Appearance â†’ Colors and Fonts â†’ Text Font</strong></p><p>ì´ í°íŠ¸ëŠ” <strong>SQL Editor(ì¿¼ë¦¬ ì‘ì„± ì°½)</strong> ì— ì ìš©ë©ë‹ˆë‹¤.</p><p>ì˜ˆ:</p><ul><li>êµµê²Œ(Bold)</li><li>í°íŠ¸ ë³€ê²½</li><li>í¬ê¸° ë³€ê²½</li></ul><p>ì ìš© í›„ SQL ì°½ ê¸€ê¼´ì´ ì¦‰ì‹œ ë³€ê²½ë¨.</p><p>ë³µì›ì´ í•„ìš”í•˜ë©´ <strong>Restore Defaults</strong> ì‚¬ìš©.</p><hr><h2 id="ğŸ“-5-ìƒ‰ìƒ-Custom-Colors-ì»¤ìŠ¤í„°ë§ˆì´ì§•"><a href="#ğŸ“-5-ìƒ‰ìƒ-Custom-Colors-ì»¤ìŠ¤í„°ë§ˆì´ì§•" class="headerlink" title="ğŸ“ 5. ìƒ‰ìƒ(Custom Colors) ì»¤ìŠ¤í„°ë§ˆì´ì§•"></a>ğŸ“ 5. ìƒ‰ìƒ(Custom Colors) ì»¤ìŠ¤í„°ë§ˆì´ì§•</h2><p>Colors and Fonts ë©”ë‰´ì—ëŠ” ìˆ˜ì‹­ ê°€ì§€ ìƒ‰ìƒ ì˜µì…˜ì´ ì¡´ì¬í•©ë‹ˆë‹¤.</p><p>ì˜ˆ)</p><ul><li>Error Color (ì—ëŸ¬ ë©”ì‹œì§€ ìƒ‰)</li><li>View and Editor folders</li><li>Non-Focused Part Color<br>ë“±ë“±</li></ul><p>ì»¤ìŠ¤í„°ë§ˆì´ì§• ì‹œ ì‹¤ì‹œê°„ìœ¼ë¡œ UIì— ë°˜ì˜ë¨.</p><p>â†’ ì˜ëª» ë°”ê¿”ë„ <strong>Restore Defaults</strong>ë¡œ ì–¸ì œë“  ë³µêµ¬ ê°€ëŠ¥</p><hr><h2 id="ğŸ“-6-Result-Set-Viewer-ê²°ê³¼-ì°½-ì„¤ì •-ë³€ê²½"><a href="#ğŸ“-6-Result-Set-Viewer-ê²°ê³¼-ì°½-ì„¤ì •-ë³€ê²½" class="headerlink" title="ğŸ“ 6. Result Set Viewer(ê²°ê³¼ ì°½) ì„¤ì • ë³€ê²½"></a>ğŸ“ 6. Result Set Viewer(ê²°ê³¼ ì°½) ì„¤ì • ë³€ê²½</h2><p>ê²½ë¡œ:<br><strong>Window â†’ Preferences â†’ Teradata Datatools â†’ Result Set Viewer</strong></p><p>ì—¬ê¸°ì„œ ê²°ê³¼ì°½ì˜ ì—¬ëŸ¬ ì„¤ì •ì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p><h3 id="ğŸ”¸-1-êµì°¨-ìƒ‰ìƒ-Row-Alternate-Color-ì¼œê¸°"><a href="#ğŸ”¸-1-êµì°¨-ìƒ‰ìƒ-Row-Alternate-Color-ì¼œê¸°" class="headerlink" title="ğŸ”¸ 1) êµì°¨ ìƒ‰ìƒ(Row Alternate Color) ì¼œê¸°"></a>ğŸ”¸ 1) êµì°¨ ìƒ‰ìƒ(Row Alternate Color) ì¼œê¸°</h3><ul><li>â€˜Display alternate result set rows in a different colorâ€™ ì²´í¬<br>â†’ ì§ìˆ˜ í–‰&#x2F;í™€ìˆ˜ í–‰ì´ ë‹¤ë¥¸ ìƒ‰ìœ¼ë¡œ í‘œì‹œë˜ì–´ ê°€ë…ì„±ì´ ì¢‹ì•„ì§</li></ul><h3 id="ğŸ”¸-2-Column-Header-ìˆ¨ê¸°ê¸°-í‘œì‹œí•˜ê¸°"><a href="#ğŸ”¸-2-Column-Header-ìˆ¨ê¸°ê¸°-í‘œì‹œí•˜ê¸°" class="headerlink" title="ğŸ”¸ 2) Column Header ìˆ¨ê¸°ê¸° &#x2F; í‘œì‹œí•˜ê¸°"></a>ğŸ”¸ 2) Column Header ìˆ¨ê¸°ê¸° &#x2F; í‘œì‹œí•˜ê¸°</h3><ul><li>Column header ì˜µì…˜ OFF â†’ í—¤ë”(ì»¬ëŸ¼ëª…) ìˆ¨ê¸°ê¸°<br>â€» ë¹„ì¶”ì²œ (ì»¬ëŸ¼ì„ ì•Œì•„ë³´ê¸° ì–´ë ¤ì›Œì§)</li></ul><h3 id="ğŸ”¸-3-ê¸°ë³¸ìœ¼ë¡œ-ë¶ˆëŸ¬ì˜¤ëŠ”-ìµœëŒ€-Row-ìˆ˜-ë³€ê²½"><a href="#ğŸ”¸-3-ê¸°ë³¸ìœ¼ë¡œ-ë¶ˆëŸ¬ì˜¤ëŠ”-ìµœëŒ€-Row-ìˆ˜-ë³€ê²½" class="headerlink" title="ğŸ”¸ 3) ê¸°ë³¸ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ëŠ” ìµœëŒ€ Row ìˆ˜ ë³€ê²½"></a>ğŸ”¸ 3) ê¸°ë³¸ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ëŠ” ìµœëŒ€ Row ìˆ˜ ë³€ê²½</h3><p>ê¸°ë³¸ê°’: 2000<br>ì˜ˆ: 1000ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> DBC.TablesV;</span><br></pre></td></tr></table></figure><p>ì‹¤í–‰ ì‹œ:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2,000 rows exceed limit. Retrieve first 2,000?</span><br></pre></td></tr></table></figure><p>ì´ ë©”ì‹œì§€ì— ë‚˜ì˜¤ëŠ” ìˆ«ìê°€ í•´ë‹¹ ì„¤ì •ì— ì˜í•´ ì¡°ì •ë¨.</p><hr><h2 id="ğŸ“-7-Result-Viewer-ì˜µì…˜ì—-ë¹ ë¥´ê²Œ-ì ‘ê·¼í•˜ëŠ”-ë²•"><a href="#ğŸ“-7-Result-Viewer-ì˜µì…˜ì—-ë¹ ë¥´ê²Œ-ì ‘ê·¼í•˜ëŠ”-ë²•" class="headerlink" title="ğŸ“ 7. Result Viewer ì˜µì…˜ì— ë¹ ë¥´ê²Œ ì ‘ê·¼í•˜ëŠ” ë²•"></a>ğŸ“ 7. Result Viewer ì˜µì…˜ì— ë¹ ë¥´ê²Œ ì ‘ê·¼í•˜ëŠ” ë²•</h2><p>Result Viewer ìš°ì¸¡ ìƒë‹¨ì˜ <strong>wrench(ğŸ”§ ì•„ì´ì½˜)</strong> í´ë¦­í•˜ë©´<br>ë°”ë¡œ Preferencesì˜ ë™ì¼í•œ í™”ë©´ìœ¼ë¡œ ì´ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p><hr><h2 id="ğŸ“-8-ì„¸ë¯¸ì½œë¡ -ì‚¬ìš©-ìŠµê´€-ë“¤ì´ê¸°"><a href="#ğŸ“-8-ì„¸ë¯¸ì½œë¡ -ì‚¬ìš©-ìŠµê´€-ë“¤ì´ê¸°" class="headerlink" title="ğŸ“ 8. ì„¸ë¯¸ì½œë¡ (;) ì‚¬ìš© ìŠµê´€ ë“¤ì´ê¸°"></a>ğŸ“ 8. ì„¸ë¯¸ì½œë¡ (;) ì‚¬ìš© ìŠµê´€ ë“¤ì´ê¸°</h2><p>VTEQë‚˜ ì—¬ëŸ¬ SQL ì—ë””í„°ì—ì„œëŠ” <strong>ê° SQL ë¬¸ì¥ ë’¤ì— ë°˜ë“œì‹œ ì„¸ë¯¸ì½œë¡ ì´ í•„ìš”</strong>í•©ë‹ˆë‹¤.</p><p>ì˜ˆ:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> DBC.TablesV;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">CURRENT_DATE</span>;</span><br></pre></td></tr></table></figure><p>ì—¬ëŸ¬ SQLì„ í•œ ë²ˆì— ì‹¤í–‰í•  ë•Œ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´<br>í•­ìƒ ì„¸ë¯¸ì½œë¡ ì„ ë¶™ì´ëŠ” ê²ƒì´ ì¢‹ì€ ìŠµê´€ì…ë‹ˆë‹¤.</p><hr><h2 id="ğŸ“-9-ì„¤ì •-ì ìš©-í›„-í…ŒìŠ¤íŠ¸-ë°©ë²•"><a href="#ğŸ“-9-ì„¤ì •-ì ìš©-í›„-í…ŒìŠ¤íŠ¸-ë°©ë²•" class="headerlink" title="ğŸ“ 9. ì„¤ì • ì ìš© í›„ í…ŒìŠ¤íŠ¸ ë°©ë²•"></a>ğŸ“ 9. ì„¤ì • ì ìš© í›„ í…ŒìŠ¤íŠ¸ ë°©ë²•</h2><p>ì˜ˆë¥¼ ë“¤ì–´ Dialog Font í¬ê¸°ë¥¼ ì¡°ì •í•œ í›„ ê²°ê³¼ë¥¼ ë³´ê³  ì‹¶ë‹¤ë©´:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HELP SESSION;</span><br></pre></td></tr></table></figure><p>í˜¹ì€</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> DBC.TablesV;</span><br></pre></td></tr></table></figure><p>ì„ ì‹¤í–‰í•˜ë©´ Result Viewerì˜ í°íŠ¸&#x2F;ìƒ‰ìƒ ì ìš© ìƒíƒœë¥¼ ì‰½ê²Œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p><hr><h2 id="ğŸ¯-ìµœì¢…-ìš”ì•½"><a href="#ğŸ¯-ìµœì¢…-ìš”ì•½" class="headerlink" title="ğŸ¯ ìµœì¢… ìš”ì•½"></a>ğŸ¯ <strong>ìµœì¢… ìš”ì•½</strong></h2><p>ì´ë²ˆ ê°•ì˜ì—ì„œëŠ” ë‹¤ìŒì„ ë°°ì› ìŠµë‹ˆë‹¤:</p><h3 id="âœ”-í™”ë©´-ë ˆì´ì•„ì›ƒ-ì¡°ì ˆ"><a href="#âœ”-í™”ë©´-ë ˆì´ì•„ì›ƒ-ì¡°ì ˆ" class="headerlink" title="âœ” í™”ë©´ ë ˆì´ì•„ì›ƒ ì¡°ì ˆ"></a>âœ” í™”ë©´ ë ˆì´ì•„ì›ƒ ì¡°ì ˆ</h3><ul><li>í•˜ë‹¨ ì°½ ìˆ¨ê¸°ê¸°&#x2F;ë³´ì´ê¸°</li><li>Reset Perspectiveë¡œ ì´ˆê¸°í™” ê°€ëŠ¥</li></ul><h3 id="âœ”-UI-ì»¤ìŠ¤í„°ë§ˆì´ì§•"><a href="#âœ”-UI-ì»¤ìŠ¤í„°ë§ˆì´ì§•" class="headerlink" title="âœ” UI ì»¤ìŠ¤í„°ë§ˆì´ì§•"></a>âœ” UI ì»¤ìŠ¤í„°ë§ˆì´ì§•</h3><ul><li>Dialog Font</li><li>Text Font (SQL Editor)</li><li>ìƒ‰ìƒ(Color)</li><li>Row Alternate Color</li></ul><h3 id="âœ”-Result-Set-Viewer-ì„¤ì •"><a href="#âœ”-Result-Set-Viewer-ì„¤ì •" class="headerlink" title="âœ” Result Set Viewer ì„¤ì •"></a>âœ” Result Set Viewer ì„¤ì •</h3><ul><li>ìµœëŒ€ row ìˆ˜ ë³€ê²½</li><li>í—¤ë” í‘œì‹œ&#x2F;ìˆ¨ê¹€</li><li>í–‰ ìƒ‰ìƒ êµì°¨ í‘œì‹œ</li></ul><h3 id="âœ”-ì‹¤ìš©-íŒ"><a href="#âœ”-ì‹¤ìš©-íŒ" class="headerlink" title="âœ” ì‹¤ìš© íŒ"></a>âœ” ì‹¤ìš© íŒ</h3><ul><li>ğŸ”§ ì•„ì´ì½˜ìœ¼ë¡œ ë¹ ë¥´ê²Œ í™˜ê²½ì„¤ì • ì´ë™</li><li>ì„¸ë¯¸ì½œë¡ (;) ìŠµê´€í™”</li><li>HELP SESSIONìœ¼ë¡œ ì ìš© ê²°ê³¼ í™•ì¸</li></ul><hr><p>í•„ìš”í•˜ë‹¤ë©´:</p><ul><li>ë‹¤ìŒ ê°•ì˜ ë‚´ìš©ë„ md íŒŒì¼ë¡œ ìƒì„±</li><li>ì´ë¯¸ì§€ í¬í•¨ ë²„ì „</li><li>GitHub README ìŠ¤íƒ€ì¼</li><li>PDF ë³€í™˜</li></ul><p>ì–¸ì œë“  ìš”ì²­í•´ì£¼ì„¸ìš”!</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ“˜-Teradata-Studio-í™˜ê²½-ì„¤ì •-ë°-í™”ë©´-ì»¤ìŠ¤í„°ë§ˆì´ì§•&quot;&gt;&lt;a href=&quot;#ğŸ“˜-Teradata-Studio-í™˜ê²½-ì„¤ì •-ë°-í™”ë©´-ì»¤ìŠ¤í„°ë§ˆì´ì§•&quot; class=&quot;headerlink&quot; title=&quot;ğŸ“˜ Teradata Studio í™˜</summary>
      
    
    
    
    <category term="TERADATA" scheme="https://kish191919.github.io/categories/TERADATA/"/>
    
    
    <category term="TERADATA" scheme="https://kish191919.github.io/tags/TERADATA/"/>
    
  </entry>
  
  <entry>
    <title>TERADATA(1)-Overview of Teradata Studio Modules</title>
    <link href="https://kish191919.github.io/2025/12/03/TERADATA-1-Overview-of-Teradata-Studio-Modules/"/>
    <id>https://kish191919.github.io/2025/12/03/TERADATA-1-Overview-of-Teradata-Studio-Modules/</id>
    <published>2025-12-03T16:27:48.000Z</published>
    <updated>2025-12-03T16:36:04.790Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ“˜-Teradata-Studio-ê¸°ë³¸-í™”ë©´-ì´í•´í•˜ê¸°"><a href="#ğŸ“˜-Teradata-Studio-ê¸°ë³¸-í™”ë©´-ì´í•´í•˜ê¸°" class="headerlink" title="ğŸ“˜ Teradata Studio ê¸°ë³¸ í™”ë©´ ì´í•´í•˜ê¸°"></a>ğŸ“˜ Teradata Studio ê¸°ë³¸ í™”ë©´ ì´í•´í•˜ê¸°</h1><p><em>ê¸°ì´ˆ UI ì„¤ëª… + SQL ì‹¤í–‰ ë°©ë²• + íŠ¸ëœì­ì…˜ ëª¨ë“œ ê°œë…</em></p><h2 id="ğŸ“-1-Teradata-Studio-ì²«-í™”ë©´-êµ¬ì„±"><a href="#ğŸ“-1-Teradata-Studio-ì²«-í™”ë©´-êµ¬ì„±" class="headerlink" title="ğŸ“ 1. Teradata Studio ì²« í™”ë©´ êµ¬ì„±"></a>ğŸ“ 1. Teradata Studio ì²« í™”ë©´ êµ¬ì„±</h2><p>Teradata Studioë¥¼ ì‹¤í–‰í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì£¼ìš” ì˜ì—­ì„ ë³´ê²Œ ë©ë‹ˆë‹¤.</p><h3 id="ğŸ”¹-1-ìƒë‹¨-ë©”ë‰´-File-Edit-Window-ë“±"><a href="#ğŸ”¹-1-ìƒë‹¨-ë©”ë‰´-File-Edit-Window-ë“±" class="headerlink" title="ğŸ”¹ 1) ìƒë‹¨ ë©”ë‰´(File &#x2F; Edit &#x2F; Window ë“±)"></a>ğŸ”¹ 1) ìƒë‹¨ ë©”ë‰´(File &#x2F; Edit &#x2F; Window ë“±)</h3><p>ì¼ë°˜ì ì¸ íŒŒì¼ ê´€ë¦¬, ë³´ê¸° ì„¤ì •, í™˜ê²½ì„¤ì • ë³€ê²½ ë“±ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.</p><h3 id="ğŸ”¹-2-Studio-Toolbar"><a href="#ğŸ”¹-2-Studio-Toolbar" class="headerlink" title="ğŸ”¹ 2) Studio Toolbar"></a>ğŸ”¹ 2) Studio Toolbar</h3><p>ì¿¼ë¦¬ ì‹¤í–‰, ì €ì¥, ìƒˆ ì—°ê²° ìƒì„± ë“± ìì£¼ ì‚¬ìš©í•˜ëŠ” ê¸°ëŠ¥ ì•„ì´ì½˜ë“¤ì´ ìœ„ì¹˜í•©ë‹ˆë‹¤.</p><h3 id="ğŸ”¹-3-Data-Source-Explorer-ì¢Œì¸¡-ì˜ì—­"><a href="#ğŸ”¹-3-Data-Source-Explorer-ì¢Œì¸¡-ì˜ì—­" class="headerlink" title="ğŸ”¹ 3) Data Source Explorer (ì¢Œì¸¡ ì˜ì—­)"></a>ğŸ”¹ 3) Data Source Explorer (ì¢Œì¸¡ ì˜ì—­)</h3><p>Teradataì— ì—°ê²°ëœ <strong>ë°ì´í„°ë² ì´ìŠ¤ &#x2F; ìœ ì € &#x2F; í…Œì´ë¸” &#x2F; ë·°</strong> ë“±ì„ íƒìƒ‰í•  ìˆ˜ ìˆëŠ” ê°€ì¥ ì¤‘ìš”í•œ íŒ¨ë„ì…ë‹ˆë‹¤.</p><h3 id="ğŸ”¹-4-Project-Explorer"><a href="#ğŸ”¹-4-Project-Explorer" class="headerlink" title="ğŸ”¹ 4) Project Explorer"></a>ğŸ”¹ 4) Project Explorer</h3><p>SQL íŒŒì¼ì´ë‚˜ í”„ë¡œì íŠ¸ë¥¼ ë¡œì»¬ì— ì €ì¥í•˜ì—¬ ê´€ë¦¬í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.</p><h3 id="ğŸ”¹-5-SQL-Editor-ì¤‘ì•™-ìƒë‹¨"><a href="#ğŸ”¹-5-SQL-Editor-ì¤‘ì•™-ìƒë‹¨" class="headerlink" title="ğŸ”¹ 5) SQL Editor (ì¤‘ì•™ ìƒë‹¨)"></a>ğŸ”¹ 5) SQL Editor (ì¤‘ì•™ ìƒë‹¨)</h3><p>SQLì„ ì‘ì„±í•˜ëŠ” ê³µê°„ì…ë‹ˆë‹¤.<br>ì˜ˆ:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">CURRENT_TIME</span>;</span><br></pre></td></tr></table></figure><h3 id="ğŸ”¹-6-Result-Set-Viewer-ì¤‘ì•™-í•˜ë‹¨"><a href="#ğŸ”¹-6-Result-Set-Viewer-ì¤‘ì•™-í•˜ë‹¨" class="headerlink" title="ğŸ”¹ 6) Result Set Viewer (ì¤‘ì•™ &#x2F; í•˜ë‹¨)"></a>ğŸ”¹ 6) Result Set Viewer (ì¤‘ì•™ &#x2F; í•˜ë‹¨)</h3><p>ì¿¼ë¦¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.</p><h3 id="ğŸ”¹-7-SQL-History-í•˜ë‹¨"><a href="#ğŸ”¹-7-SQL-History-í•˜ë‹¨" class="headerlink" title="ğŸ”¹ 7) SQL History (í•˜ë‹¨)"></a>ğŸ”¹ 7) SQL History (í•˜ë‹¨)</h3><p>ì‹¤í–‰í•œ SQL ê¸°ë¡ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p><h3 id="ğŸ”¹-8-Perspective-ë©”ë‰´-ì˜¤ë¥¸ìª½-ìƒë‹¨"><a href="#ğŸ”¹-8-Perspective-ë©”ë‰´-ì˜¤ë¥¸ìª½-ìƒë‹¨" class="headerlink" title="ğŸ”¹ 8) Perspective ë©”ë‰´ (ì˜¤ë¥¸ìª½ ìƒë‹¨)"></a>ğŸ”¹ 8) Perspective ë©”ë‰´ (ì˜¤ë¥¸ìª½ ìƒë‹¨)</h3><ul><li>Administration</li><li>Query Development</li><li>Data Transfer</li></ul><hr><h2 id="ğŸ“-2-í™”ë©´ì´-ë§ê°€ì¡Œì„-ë•Œ-ë³µêµ¬-ë°©ë²•"><a href="#ğŸ“-2-í™”ë©´ì´-ë§ê°€ì¡Œì„-ë•Œ-ë³µêµ¬-ë°©ë²•" class="headerlink" title="ğŸ“ 2. í™”ë©´ì´ ë§ê°€ì¡Œì„ ë•Œ ë³µêµ¬ ë°©ë²•"></a>ğŸ“ 2. í™”ë©´ì´ ë§ê°€ì¡Œì„ ë•Œ ë³µêµ¬ ë°©ë²•</h2><p><strong>Window â†’ Reset Perspective</strong></p><hr><h2 id="ğŸ“-3-SQL-ì‹¤í–‰í•˜ëŠ”-ë°©ë²•"><a href="#ğŸ“-3-SQL-ì‹¤í–‰í•˜ëŠ”-ë°©ë²•" class="headerlink" title="ğŸ“ 3. SQL ì‹¤í–‰í•˜ëŠ” ë°©ë²•"></a>ğŸ“ 3. SQL ì‹¤í–‰í•˜ëŠ” ë°©ë²•</h2><h3 id="ğŸ”¸-ë°©ë²•-1-â€”-F5-ê°€ì¥-ë§ì´-ì‚¬ìš©"><a href="#ğŸ”¸-ë°©ë²•-1-â€”-F5-ê°€ì¥-ë§ì´-ì‚¬ìš©" class="headerlink" title="ğŸ”¸ ë°©ë²• 1 â€” F5 (ê°€ì¥ ë§ì´ ì‚¬ìš©)"></a>ğŸ”¸ ë°©ë²• 1 â€” <code>F5</code> (ê°€ì¥ ë§ì´ ì‚¬ìš©)</h3><ul><li>ì„ íƒí•œ SQLë§Œ ì‹¤í–‰</li><li>ì„ íƒí•˜ì§€ ì•Šìœ¼ë©´ ì „ì²´ ì‹¤í–‰</li></ul><h3 id="ğŸ”¸-ë°©ë²•-2-â€”-Ctrl-Alt-X"><a href="#ğŸ”¸-ë°©ë²•-2-â€”-Ctrl-Alt-X" class="headerlink" title="ğŸ”¸ ë°©ë²• 2 â€” Ctrl + Alt + X"></a>ğŸ”¸ ë°©ë²• 2 â€” <code>Ctrl + Alt + X</code></h3><p>ëª¨ë“  SQLì„ í•˜ë‚˜ì˜ íƒ­ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.</p><h3 id="ğŸ”¸-ë°©ë²•-3-â€”-ì‹¤í–‰-ë²„íŠ¼-í´ë¦­"><a href="#ğŸ”¸-ë°©ë²•-3-â€”-ì‹¤í–‰-ë²„íŠ¼-í´ë¦­" class="headerlink" title="ğŸ”¸ ë°©ë²• 3 â€” ì‹¤í–‰ ë²„íŠ¼ í´ë¦­"></a>ğŸ”¸ ë°©ë²• 3 â€” ì‹¤í–‰ ë²„íŠ¼ í´ë¦­</h3><p>ìƒë‹¨ì˜ â–¶ï¸ ì•„ì´ì½˜ í´ë¦­</p><hr><h2 id="ğŸ“-4-SQL-ì‹¤í–‰-í…ŒìŠ¤íŠ¸"><a href="#ğŸ“-4-SQL-ì‹¤í–‰-í…ŒìŠ¤íŠ¸" class="headerlink" title="ğŸ“ 4. SQL ì‹¤í–‰ í…ŒìŠ¤íŠ¸"></a>ğŸ“ 4. SQL ì‹¤í–‰ í…ŒìŠ¤íŠ¸</h2><h3 id="ğŸ”¸-í˜„ì¬-ì‹œê°„-í™•ì¸"><a href="#ğŸ”¸-í˜„ì¬-ì‹œê°„-í™•ì¸" class="headerlink" title="ğŸ”¸ í˜„ì¬ ì‹œê°„ í™•ì¸"></a>ğŸ”¸ í˜„ì¬ ì‹œê°„ í™•ì¸</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">CURRENT_TIME</span>;</span><br></pre></td></tr></table></figure><h3 id="ğŸ”¸-DBC-ë°ì´í„°ë² ì´ìŠ¤-ì¡°íšŒ"><a href="#ğŸ”¸-DBC-ë°ì´í„°ë² ì´ìŠ¤-ì¡°íšŒ" class="headerlink" title="ğŸ”¸ DBC ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ"></a>ğŸ”¸ DBC ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> DBC.DatabasesV;</span><br></pre></td></tr></table></figure><p>DBCëŠ” Teradataì˜ ë©”íƒ€ë°ì´í„°ë¥¼ ë³´ê´€í•˜ëŠ” í•µì‹¬ ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.</p><hr><h2 id="ğŸ“-5-ë‹¤ì¤‘-SQL-ì‹¤í–‰-ì‹œ-ì£¼ì˜ì "><a href="#ğŸ“-5-ë‹¤ì¤‘-SQL-ì‹¤í–‰-ì‹œ-ì£¼ì˜ì " class="headerlink" title="ğŸ“ 5. ë‹¤ì¤‘ SQL ì‹¤í–‰ ì‹œ ì£¼ì˜ì "></a>ğŸ“ 5. ë‹¤ì¤‘ SQL ì‹¤í–‰ ì‹œ ì£¼ì˜ì </h2><p>ê° SQL ë¬¸ ë’¤ì—ëŠ” ë°˜ë“œì‹œ **ì„¸ë¯¸ì½œë¡ (;)**ì´ í•„ìš”í•©ë‹ˆë‹¤.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> DBC.DatabasesV;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">CURRENT_DATE</span>;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">CURRENT_TIME</span>;</span><br></pre></td></tr></table></figure><hr><h2 id="ğŸ“-6-HELP-SESSION"><a href="#ğŸ“-6-HELP-SESSION" class="headerlink" title="ğŸ“ 6. HELP SESSION"></a>ğŸ“ 6. HELP SESSION</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HELP SESSION;</span><br></pre></td></tr></table></figure><p>ì„¸ì…˜ ì •ë³´(ì‚¬ìš©ì, ë¡œê·¸ì¸ ì‹œê°„, ëª¨ë“œ ë“±)ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p><hr><h2 id="ğŸ“-7-íŠ¸ëœì­ì…˜-ëª¨ë“œ-ANSI-vs-Teradata"><a href="#ğŸ“-7-íŠ¸ëœì­ì…˜-ëª¨ë“œ-ANSI-vs-Teradata" class="headerlink" title="ğŸ“ 7. íŠ¸ëœì­ì…˜ ëª¨ë“œ (ANSI vs Teradata)"></a>ğŸ“ 7. íŠ¸ëœì­ì…˜ ëª¨ë“œ (ANSI vs Teradata)</h2><h3 id="ğŸ”¸-Teradata-ëª¨ë“œ"><a href="#ğŸ”¸-Teradata-ëª¨ë“œ" class="headerlink" title="ğŸ”¸ Teradata ëª¨ë“œ"></a>ğŸ”¸ Teradata ëª¨ë“œ</h3><ul><li>ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì ìŒ</li><li>ê¸°ë³¸ ì¶”ì²œ ëª¨ë“œ</li></ul><h3 id="ğŸ”¸-ANSI-ëª¨ë“œ"><a href="#ğŸ”¸-ANSI-ëª¨ë“œ" class="headerlink" title="ğŸ”¸ ANSI ëª¨ë“œ"></a>ğŸ”¸ ANSI ëª¨ë“œ</h3><ul><li>í‘œì¤€ SQL ì¤€ìˆ˜</li><li>COMMIT í•„ìš”</li><li>ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—„ê²©</li></ul><hr><h2 id="ğŸ“-8-íŠ¸ëœì­ì…˜-UNIT-OF-WORK-ê°œë…"><a href="#ğŸ“-8-íŠ¸ëœì­ì…˜-UNIT-OF-WORK-ê°œë…" class="headerlink" title="ğŸ“ 8. íŠ¸ëœì­ì…˜(UNIT OF WORK) ê°œë…"></a>ğŸ“ 8. íŠ¸ëœì­ì…˜(UNIT OF WORK) ê°œë…</h2><p>íŠ¸ëœì­ì…˜ &#x3D; ì‘ì—… ë‹¨ìœ„<br>ì „ë¶€ ì„±ê³µí•˜ê±°ë‚˜, ì‹¤íŒ¨ ì‹œ ì „ì²´ ë¡¤ë°±ë˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.</p><p>ì˜ˆ: INSERT ì¤‘ ì •ì „ â†’ ì¼ë¶€ ì»¬ëŸ¼ë§Œ ì €ì¥ë˜ì§€ ì•Šê³  ì „ì²´ ì·¨ì†Œë¨</p><hr><h2 id="ğŸ¯-ìµœì¢…-ì •ë¦¬"><a href="#ğŸ¯-ìµœì¢…-ì •ë¦¬" class="headerlink" title="ğŸ¯ ìµœì¢… ì •ë¦¬"></a>ğŸ¯ ìµœì¢… ì •ë¦¬</h2><ul><li>UI êµ¬ì„± ì´í•´</li><li>SQL ì‹¤í–‰ ë‹¨ì¶•í‚¤(F5 &#x2F; Ctrl+Alt+X)</li><li>DBC ë°ì´í„° ì¡°íšŒ</li><li>íŠ¸ëœì­ì…˜ ëª¨ë“œ ì°¨ì´</li><li>HELP SESSION í™œìš©</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ“˜-Teradata-Studio-ê¸°ë³¸-í™”ë©´-ì´í•´í•˜ê¸°&quot;&gt;&lt;a href=&quot;#ğŸ“˜-Teradata-Studio-ê¸°ë³¸-í™”ë©´-ì´í•´í•˜ê¸°&quot; class=&quot;headerlink&quot; title=&quot;ğŸ“˜ Teradata Studio ê¸°ë³¸ í™”ë©´ ì´í•´í•˜ê¸°&quot;&gt;&lt;/a</summary>
      
    
    
    
    <category term="TERADATA" scheme="https://kish191919.github.io/categories/TERADATA/"/>
    
    
    <category term="TERADATA" scheme="https://kish191919.github.io/tags/TERADATA/"/>
    
  </entry>
  
  <entry>
    <title>Coding_Quiz_SQL_1</title>
    <link href="https://kish191919.github.io/2025/09/17/Coding-Quiz-SQL-1/"/>
    <id>https://kish191919.github.io/2025/09/17/Coding-Quiz-SQL-1/</id>
    <published>2025-09-18T02:07:37.000Z</published>
    <updated>2025-11-20T13:04:44.634Z</updated>
    
    
    
    
    <category term="DEV" scheme="https://kish191919.github.io/categories/DEV/"/>
    
    <category term="CODING_QUIZ_SQL" scheme="https://kish191919.github.io/categories/DEV/CODING-QUIZ-SQL/"/>
    
    
    <category term="LEETCODE" scheme="https://kish191919.github.io/tags/LEETCODE/"/>
    
    <category term="SQL" scheme="https://kish191919.github.io/tags/SQL/"/>
    
  </entry>
  
  <entry>
    <title>Coding_Quiz_Python_1</title>
    <link href="https://kish191919.github.io/2025/09/17/Coding-Quiz-Python-1/"/>
    <id>https://kish191919.github.io/2025/09/17/Coding-Quiz-Python-1/</id>
    <published>2025-09-17T20:29:17.000Z</published>
    <updated>2025-11-20T13:04:44.631Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Two-Sum"><a href="#1-Two-Sum" class="headerlink" title="1. Two Sum"></a>1. Two Sum</h1><p>Link : <a href="https://leetcode.com/problems/two-sum/description/?difficulty=EASY">https://leetcode.com/problems/two-sum/description/?difficulty=EASY</a></p><h2 id="Hash-Map-ë”•ì…”ë„ˆë¦¬-ì´ìš©"><a href="#Hash-Map-ë”•ì…”ë„ˆë¦¬-ì´ìš©" class="headerlink" title="Hash Map (ë”•ì…”ë„ˆë¦¬ ì´ìš©)"></a>Hash Map (ë”•ì…”ë„ˆë¦¬ ì´ìš©)</h2><p>ë³´ì¡° ê³µê°„ì„ ì´ìš©í•´ ë¹ ë¥´ê²Œ ì°¨ì´ë¥¼ ì°¾ëŠ” ë°©ì‹.</p><ul><li>ì‹œê°„ ë³µì¡ë„: <strong>O(n)</strong></li><li>ê³µê°„ ë³µì¡ë„: <strong>O(n)</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">twoSum</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        num_map = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> index, num <span class="keyword">in</span> <span class="built_in">enumerate</span>(nums):</span><br><span class="line">            diff = target - num</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> diff <span class="keyword">in</span> num_map:</span><br><span class="line">                <span class="keyword">return</span> [num_map[diff], index]</span><br><span class="line">            </span><br><span class="line">            num_map[num] = index</span><br></pre></td></tr></table></figure><h2 id="Sorting-Two-Pointers-ì •ë ¬-íˆ¬-í¬ì¸í„°"><a href="#Sorting-Two-Pointers-ì •ë ¬-íˆ¬-í¬ì¸í„°" class="headerlink" title="Sorting + Two Pointers (ì •ë ¬ + íˆ¬ í¬ì¸í„°)"></a>Sorting + Two Pointers (ì •ë ¬ + íˆ¬ í¬ì¸í„°)</h2><p>ì •ë ¬ í›„ ì–‘ ëì—ì„œ í•©ì„ ë¹„êµ.</p><ul><li>ì‹œê°„ ë³µì¡ë„: <strong>O(n log n)</strong></li><li>ê³µê°„ ë³µì¡ë„: <strong>O(n)</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">twoSum</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line"></span><br><span class="line">    arr = [(num, i) <span class="keyword">for</span> i, num <span class="keyword">in</span> <span class="built_in">enumerate</span>(nums)]</span><br><span class="line">    arr.sort()</span><br><span class="line"></span><br><span class="line">    left, right = <span class="number">0</span>, <span class="built_in">len</span>(arr) - <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> left &lt; right:</span><br><span class="line">        s = arr[left][<span class="number">0</span>] + arr[right][<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> s == target:</span><br><span class="line">            <span class="keyword">return</span> [arr[left][<span class="number">1</span>], arr[right][<span class="number">1</span>]]</span><br><span class="line">        <span class="keyword">elif</span> s &lt; target:</span><br><span class="line">            left +=<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            right -=<span class="number">1</span></span><br></pre></td></tr></table></figure><h1 id="2-Add-Two-Numbers"><a href="#2-Add-Two-Numbers" class="headerlink" title="2. Add Two Numbers"></a>2. Add Two Numbers</h1><p>Link : <a href="https://leetcode.com/problems/add-two-numbers/description/?difficulty=EASY">https://leetcode.com/problems/add-two-numbers/description/?difficulty=EASY</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">addTwoNumbers</span>(<span class="params">self, l1: <span class="type">Optional</span>[ListNode], l2: <span class="type">Optional</span>[ListNode], c=<span class="number">0</span></span>) -&gt; <span class="type">Optional</span>[ListNode]:</span><br><span class="line">    sum_ = l1.val + l2.val + c</span><br><span class="line">    remain = sum_ % <span class="number">10</span></span><br><span class="line">    carry = sum_ // <span class="number">10</span></span><br><span class="line"></span><br><span class="line">    new_node = ListNode(remain)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> l1.<span class="built_in">next</span> != <span class="literal">None</span> <span class="keyword">or</span> l2.<span class="built_in">next</span> !=<span class="literal">None</span> <span class="keyword">or</span> carry != <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">if</span> l1.<span class="built_in">next</span> == <span class="literal">None</span>:</span><br><span class="line">            l1.<span class="built_in">next</span> = ListNode(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">if</span> l2.<span class="built_in">next</span> == <span class="literal">None</span>:</span><br><span class="line">            l2.<span class="built_in">next</span> = ListNode(<span class="number">0</span>)</span><br><span class="line">        new_node.<span class="built_in">next</span> = <span class="variable language_">self</span>.addTwoNumbers(l1.<span class="built_in">next</span>, l2.<span class="built_in">next</span>, carry)</span><br><span class="line">    <span class="keyword">return</span> new_node</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">addTwoNumbers</span>(<span class="params">self, l1: <span class="type">Optional</span>[ListNode], l2: <span class="type">Optional</span>[ListNode]</span>) -&gt; <span class="type">Optional</span>[ListNode]:</span><br><span class="line">        dummy = ListNode(<span class="number">0</span>)</span><br><span class="line">        current = dummy</span><br><span class="line">        carry = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> l1 <span class="keyword">or</span> l2 <span class="keyword">or</span> carry:</span><br><span class="line">            val1 = l1.val <span class="keyword">if</span> l1 <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">            val2 = l2.val <span class="keyword">if</span> l2 <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            total = val1 + val2 + carry</span><br><span class="line">            remain = total % <span class="number">10</span></span><br><span class="line">            carry = total // <span class="number">10</span></span><br><span class="line"></span><br><span class="line">            current.<span class="built_in">next</span> = ListNode(remain)</span><br><span class="line">            current = current.<span class="built_in">next</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> l1: l1 = l1.<span class="built_in">next</span></span><br><span class="line">            <span class="keyword">if</span> l2: l2 = l2.<span class="built_in">next</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dummy.<span class="built_in">next</span></span><br></pre></td></tr></table></figure><h1 id="3-Longest-Substring-Without-Repeating-Characters"><a href="#3-Longest-Substring-Without-Repeating-Characters" class="headerlink" title="3. Longest Substring Without Repeating Characters"></a>3. Longest Substring Without Repeating Characters</h1><p>Link : <a href="https://leetcode.com/problems/longest-substring-without-repeating-characters/description/?difficulty=EASY">https://leetcode.com/problems/longest-substring-without-repeating-characters/description/?difficulty=EASY</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lengthOfLongestSubstring</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        max_num = <span class="number">0</span></span><br><span class="line">        temp = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)):</span><br><span class="line">            <span class="keyword">while</span> s[i] <span class="keyword">in</span> temp:</span><br><span class="line">                temp.pop(<span class="number">0</span>)</span><br><span class="line">            </span><br><span class="line">            temp.append(s[i])</span><br><span class="line">            max_num = <span class="built_in">max</span>(<span class="built_in">len</span>(temp), max_num)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> max_num</span><br></pre></td></tr></table></figure><h2 id="íˆ¬-í¬ì¸í„°-set"><a href="#íˆ¬-í¬ì¸í„°-set" class="headerlink" title="íˆ¬ í¬ì¸í„° + set"></a>íˆ¬ í¬ì¸í„° + set</h2><ul><li>ê°™ì€ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ì¸ë° setìœ¼ë¡œ í¬í•¨ ì—¬ë¶€ë¥¼ O(1)ì— ì²´í¬.</li><li>ì™¼ìª½ í¬ì¸í„°(left)ë¥¼ ì›€ì§ì´ë©° ì¤‘ë³µì„ ì œê±°.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lengthOfLongestSubstring</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        max_num = <span class="number">0</span></span><br><span class="line">        left = <span class="number">0</span></span><br><span class="line">        temp = <span class="built_in">set</span>()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> right, ch <span class="keyword">in</span> <span class="built_in">enumerate</span>(s):</span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span> ch <span class="keyword">in</span> temp:</span><br><span class="line">                temp.remove(s[left])</span><br><span class="line">                left += <span class="number">1</span></span><br><span class="line">            temp.add(ch)</span><br><span class="line"></span><br><span class="line">            max_num = <span class="built_in">max</span>(max_num, <span class="built_in">len</span>(temp))</span><br><span class="line">        <span class="keyword">return</span> max_num</span><br></pre></td></tr></table></figure><h1 id="5-Longest-Palindromic-Substring"><a href="#5-Longest-Palindromic-Substring" class="headerlink" title="5. Longest Palindromic Substring"></a>5. Longest Palindromic Substring</h1><p>Link : <a href="https://leetcode.com/problems/longest-palindromic-substring/?difficulty=EASY">https://leetcode.com/problems/longest-palindromic-substring/?difficulty=EASY</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestPalindrome</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(s) &lt;= <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> s</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">expand</span>(<span class="params">left, right</span>):</span><br><span class="line">            <span class="keyword">while</span> left &gt;= <span class="number">0</span> <span class="keyword">and</span> right &lt; <span class="built_in">len</span>(s) <span class="keyword">and</span> s[left] == s[right]:</span><br><span class="line">                left -= <span class="number">1</span></span><br><span class="line">                right +=<span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span> s[left+<span class="number">1</span> : right]</span><br><span class="line">        max_str = s[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)-<span class="number">1</span>):</span><br><span class="line">            odd = expand(i, i)</span><br><span class="line">            even = expand(i, i+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(odd) &gt; <span class="built_in">len</span>(max_str):</span><br><span class="line">                max_str = odd</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(even) &gt; <span class="built_in">len</span>(max_str):</span><br><span class="line">                max_str = even</span><br><span class="line">        <span class="keyword">return</span> max_str</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestPalindrome</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(s) &lt; <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">expand</span>(<span class="params">left, right</span>):</span><br><span class="line">            <span class="keyword">while</span> left &gt;= <span class="number">0</span> <span class="keyword">and</span> right &lt; <span class="built_in">len</span>(s) <span class="keyword">and</span> s[left] == s[right]:</span><br><span class="line">                left -= <span class="number">1</span></span><br><span class="line">                right += <span class="number">1</span></span><br><span class="line">            <span class="comment"># valid palindrome is s[left+1 : right] (right is exclusive)</span></span><br><span class="line">            <span class="keyword">return</span> left+<span class="number">1</span>, right</span><br><span class="line">        max_str = <span class="string">&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)):</span><br><span class="line">            l1, r1 = expand(i, i)</span><br><span class="line">            l2, r2 = expand(i, i+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            odd_str = s[l1:r1]</span><br><span class="line">            even_str = s[l2:r2]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(odd_str) &gt; <span class="built_in">len</span>(max_str):</span><br><span class="line">                max_str = odd_str</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(even_str) &gt; <span class="built_in">len</span>(max_str):</span><br><span class="line">                max_str = even_str</span><br><span class="line">        <span class="keyword">return</span> max_str</span><br></pre></td></tr></table></figure><h1 id="6-Zigzag-Conversion"><a href="#6-Zigzag-Conversion" class="headerlink" title="6. Zigzag Conversion"></a>6. Zigzag Conversion</h1><p>Link : <a href="https://leetcode.com/problems/zigzag-conversion/description/?difficulty=EASY">https://leetcode.com/problems/zigzag-conversion/description/?difficulty=EASY</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">convert</span>(<span class="params">self, s: <span class="built_in">str</span>, numRows: <span class="built_in">int</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> numRows == <span class="number">1</span> <span class="keyword">or</span> numRows &gt;= <span class="built_in">len</span>(s):</span><br><span class="line">            <span class="keyword">return</span> s</span><br><span class="line">        </span><br><span class="line">        rows = [[] <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(numRows)]</span><br><span class="line"></span><br><span class="line">        index = <span class="number">0</span></span><br><span class="line">        step = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> char <span class="keyword">in</span> s:</span><br><span class="line">            rows[index].append(char)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> index == <span class="number">0</span>:</span><br><span class="line">                step = <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> index == numRows-<span class="number">1</span>:</span><br><span class="line">                step = -<span class="number">1</span></span><br><span class="line">            </span><br><span class="line">            index += step</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(numRows):</span><br><span class="line">            rows[i] = <span class="string">&#x27;&#x27;</span>.join(rows[i])</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join(rows)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-Two-Sum&quot;&gt;&lt;a href=&quot;#1-Two-Sum&quot; class=&quot;headerlink&quot; title=&quot;1. Two Sum&quot;&gt;&lt;/a&gt;1. Two Sum&lt;/h1&gt;&lt;p&gt;Link : &lt;a href=&quot;https://leetcode.com/pro</summary>
      
    
    
    
    <category term="DEV" scheme="https://kish191919.github.io/categories/DEV/"/>
    
    <category term="CODING_QUIZ_PYTHON" scheme="https://kish191919.github.io/categories/DEV/CODING-QUIZ-PYTHON/"/>
    
    
    <category term="PYTHON" scheme="https://kish191919.github.io/tags/PYTHON/"/>
    
    <category term="LEETCODE" scheme="https://kish191919.github.io/tags/LEETCODE/"/>
    
  </entry>
  
  <entry>
    <title>Databricks CV Anomaly Detection</title>
    <link href="https://kish191919.github.io/2025/09/15/Databricks-CV-Anomaly-Detection/"/>
    <id>https://kish191919.github.io/2025/09/15/Databricks-CV-Anomaly-Detection/</id>
    <published>2025-09-15T20:40:23.000Z</published>
    <updated>2025-09-16T01:28:50.347Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ğŸ‘ï¸-Databricks-Computer-Vision-Anomaly-Detection-Model-Deployment"><a href="#ğŸ‘ï¸-Databricks-Computer-Vision-Anomaly-Detection-Model-Deployment" class="headerlink" title="ğŸ‘ï¸ Databricks + Computer Vision Anomaly Detection &amp; Model Deployment"></a>ğŸ‘ï¸ Databricks + Computer Vision Anomaly Detection &amp; Model Deployment</h2><p><em>A complete guide to anomaly detection with Databricks and Apache Spark</em>  </p><blockquote><p>â€œFrom data ingestion to real-time serving â€” build and deploy scalable computer vision anomaly detection models.â€</p></blockquote><p>ğŸ“ <strong>Full Project</strong>:<br><a href="https://github.com/kish191919/Databricks_CV_Anomaly_Detection">ğŸ‘‰ View Jupyter Notebooks on GitHub</a></p><p align="center">  <img src="/images/Anomaly.png" width="80%"></p><hr><h3 id="ğŸ“Œ-One-Line-Summary"><a href="#ğŸ“Œ-One-Line-Summary" class="headerlink" title="ğŸ“Œ One-Line Summary"></a>ğŸ“Œ One-Line Summary</h3><p>This project provides a full pipeline for <strong>computer visionâ€“based anomaly detection</strong>, covering <strong>data ingestion, preprocessing, model training, deployment, and REST API serving</strong> â€” all within <strong>Databricks</strong> and powered by <strong>Apache Spark</strong>.</p><hr><h2 id="1ï¸âƒ£-How-It-Was-Built"><a href="#1ï¸âƒ£-How-It-Was-Built" class="headerlink" title="1ï¸âƒ£ How It Was Built"></a>1ï¸âƒ£ How It Was Built</h2><h3 id="1-Utilities-00-utils-ipynb"><a href="#1-Utilities-00-utils-ipynb" class="headerlink" title="1. Utilities (00_utils.ipynb)"></a><strong>1. Utilities (<a href="https://github.com/kish191919/Databricks_CV_Anomaly_Detection/blob/master/Databricks_Code/00_utils.ipynb">00_utils.ipynb</a>)</strong></h3><ul><li>Common helper functions for preprocessing and visualization  </li><li>Reusable utilities to streamline workflows</li></ul><hr><h3 id="2-Data-Ingestion-ETL-01-Ingestion-ETL-ipynb"><a href="#2-Data-Ingestion-ETL-01-Ingestion-ETL-ipynb" class="headerlink" title="2. Data Ingestion &amp; ETL (01_Ingestion_ETL.ipynb)"></a><strong>2. Data Ingestion &amp; ETL (<a href="https://github.com/kish191919/Databricks_CV_Anomaly_Detection/blob/master/Databricks_Code/01_Ingestion_ETL.ipynb">01_Ingestion_ETL.ipynb</a>)</strong></h3><ul><li>Ingested large-scale image datasets into Databricks  </li><li>Implemented Spark-based ETL for scalability  </li><li>Optimized storage and partitioning for performance and cost efficiency </li><li>Image Processing Visualization</li></ul><p align="center">  <img src="/images/image_processing_visualization.png" width="80%"></p><hr><h3 id="3-Deep-Learning-Training-02-HF-Deep-Learning-ipynb"><a href="#3-Deep-Learning-Training-02-HF-Deep-Learning-ipynb" class="headerlink" title="3. Deep Learning Training (02_HF_Deep_Learning.ipynb)"></a><strong>3. Deep Learning Training (<a href="https://github.com/kish191919/Databricks_CV_Anomaly_Detection/blob/master/Databricks_Code/02_HF_Deep_Learning.ipynb">02_HF_Deep_Learning.ipynb</a>)</strong></h3><ul><li>Applied image preprocessing and augmentation  </li><li>Trained models using <strong>PyTorch + Hugging Face</strong>  </li><li>Evaluated performance with metrics like <strong>Accuracy</strong>, <strong>Loss</strong>, and <strong>PR-AUC</strong></li></ul><hr><h3 id="4-Model-Deployment-03-Model-Deployment-ipynb"><a href="#4-Model-Deployment-03-Model-Deployment-ipynb" class="headerlink" title="4. Model Deployment (03_Model_Deployment.ipynb)"></a><strong>4. Model Deployment (<a href="https://github.com/kish191919/Databricks_CV_Anomaly_Detection/blob/master/Databricks_Code/03_Model_Deployment.ipynb">03_Model_Deployment.ipynb</a>)</strong></h3><ul><li>Registered trained models in <strong>MLflow</strong>  </li><li>Managed versions for reproducibility  </li><li>Optimized inference pipelines for deployment</li></ul><hr><h3 id="5-Model-Serving-04-Model-Serving-ipynb"><a href="#5-Model-Serving-04-Model-Serving-ipynb" class="headerlink" title="5. Model Serving (04_Model_Serving.ipynb)"></a><strong>5. Model Serving (<a href="https://github.com/kish191919/Databricks_CV_Anomaly_Detection/blob/master/Databricks_Code/04_Model_Serving.ipynb">04_Model_Serving.ipynb</a>)</strong></h3><ul><li>Deployed models with <strong>Databricks Model Serving</strong>  </li><li>Exposed REST API endpoints for real-time predictions  </li><li>Integrated anomaly detection into external systems</li></ul><hr><h2 id="2ï¸âƒ£-Optimization-Best-Practices"><a href="#2ï¸âƒ£-Optimization-Best-Practices" class="headerlink" title="2ï¸âƒ£ Optimization &amp; Best Practices"></a>2ï¸âƒ£ Optimization &amp; Best Practices</h2><ul><li>Spark optimizations for large-scale image data  </li><li>Databricks cluster configuration for <strong>cost efficiency</strong>  </li><li>Strategies for balancing performance and resource usage</li></ul><hr><h2 id="ğŸ› -Technologies-Used"><a href="#ğŸ› -Technologies-Used" class="headerlink" title="ğŸ›  Technologies Used"></a>ğŸ›  Technologies Used</h2><table><thead><tr><th>Step</th><th>Technology</th></tr></thead><tbody><tr><td>Data Processing</td><td>Apache Spark, Databricks</td></tr><tr><td>Deep Learning</td><td>PyTorch, Hugging Face</td></tr><tr><td>Experiment Mgmt</td><td>MLflow</td></tr><tr><td>Deployment</td><td>Databricks Model Registry</td></tr><tr><td>Serving</td><td>REST API, Databricks Serving</td></tr></tbody></table><hr><h2 id="ğŸ’¡-Key-Learnings"><a href="#ğŸ’¡-Key-Learnings" class="headerlink" title="ğŸ’¡ Key Learnings"></a>ğŸ’¡ Key Learnings</h2><ul><li>Full lifecycle ML on Databricks: ingestion â†’ training â†’ deployment â†’ serving  </li><li>How to optimize Databricks for <strong>low-cost, high-performance workflows</strong>  </li><li>Practical experience with model versioning, reproducibility, and API integration</li></ul><hr><h2 id="ğŸ”—-GitHub-Repository"><a href="#ğŸ”—-GitHub-Repository" class="headerlink" title="ğŸ”— GitHub Repository"></a>ğŸ”— GitHub Repository</h2><p>ğŸ“‚ <a href="https://github.com/kish191919/Databricks_CV_Anomaly_Detection">View Project on GitHub</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;ğŸ‘ï¸-Databricks-Computer-Vision-Anomaly-Detection-Model-Deployment&quot;&gt;&lt;a href=&quot;#ğŸ‘ï¸-Databricks-Computer-Vision-Anomaly-Detection-Model-</summary>
      
    
    
    
    <category term="Showcase" scheme="https://kish191919.github.io/categories/Showcase/"/>
    
    
    <category term="Databricks" scheme="https://kish191919.github.io/tags/Databricks/"/>
    
    <category term="Apache Spark" scheme="https://kish191919.github.io/tags/Apache-Spark/"/>
    
    <category term="Computer Vision" scheme="https://kish191919.github.io/tags/Computer-Vision/"/>
    
    <category term="Deep Learning" scheme="https://kish191919.github.io/tags/Deep-Learning/"/>
    
    <category term="MLflow" scheme="https://kish191919.github.io/tags/MLflow/"/>
    
  </entry>
  
  <entry>
    <title>(í•œêµ­ì–´) AWS ML Associate (6) - Amazon S3 í•µì‹¬ ì •ë¦¬</title>
    <link href="https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-6/"/>
    <id>https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-6/</id>
    <published>2025-09-15T03:49:25.000Z</published>
    <updated>2025-09-15T04:13:20.934Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Amazon-S3-ë³´ì•ˆ-Amazon-S3-Security"><a href="#Amazon-S3-ë³´ì•ˆ-Amazon-S3-Security" class="headerlink" title="Amazon S3 ë³´ì•ˆ (Amazon S3 Security)"></a>Amazon S3 ë³´ì•ˆ (Amazon S3 Security)</h1><p>Amazon S3ëŠ” ë‹¨ìˆœí•œ ì €ì¥ì†Œ ì„œë¹„ìŠ¤ì§€ë§Œ, <strong>ë³´ì•ˆ(Security)</strong> ì„ ì œëŒ€ë¡œ ì„¤ì •í•˜ì§€ ì•Šìœ¼ë©´ ë°ì´í„° ìœ ì¶œ(Data Leak)ê³¼ ê°™ì€ ì‹¬ê°í•œ ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  AWS Certified Machine Learning Engineer â€“ Associate ì‹œí—˜ì—ì„œë„ ìì£¼ ì¶œì œë˜ëŠ” ì£¼ì œì´ë¯€ë¡œ ê¼­ ì´í•´í•´ì•¼ í•©ë‹ˆë‹¤.</p><hr><h2 id="1-S3-ë³´ì•ˆ-ìœ í˜•"><a href="#1-S3-ë³´ì•ˆ-ìœ í˜•" class="headerlink" title="1. S3 ë³´ì•ˆ ìœ í˜•"></a>1. S3 ë³´ì•ˆ ìœ í˜•</h2><h3 id="ğŸ”¹-User-Based-IAM-ê¸°ë°˜"><a href="#ğŸ”¹-User-Based-IAM-ê¸°ë°˜" class="headerlink" title="ğŸ”¹ User-Based (IAM ê¸°ë°˜)"></a>ğŸ”¹ User-Based (IAM ê¸°ë°˜)</h3><ul><li><strong>IAM Policies</strong><br>IAM(Identity and Access Management)ì—ì„œ íŠ¹ì • ì‚¬ìš©ì(User) ë˜ëŠ” ê·¸ë£¹(Group)ì— ëŒ€í•´ ì–´ë–¤ API í˜¸ì¶œ(API Calls)ì„ í—ˆìš©í• ì§€ ì •ì˜í•©ë‹ˆë‹¤.<br>â†’ ì˜ˆ: <code>s3:GetObject</code> ê¶Œí•œ ë¶€ì—¬.</li></ul><h3 id="ğŸ”¹-Resource-Based-ë¦¬ì†ŒìŠ¤-ê¸°ë°˜"><a href="#ğŸ”¹-Resource-Based-ë¦¬ì†ŒìŠ¤-ê¸°ë°˜" class="headerlink" title="ğŸ”¹ Resource-Based (ë¦¬ì†ŒìŠ¤ ê¸°ë°˜)"></a>ğŸ”¹ Resource-Based (ë¦¬ì†ŒìŠ¤ ê¸°ë°˜)</h3><ul><li><p><strong>Bucket Policies</strong>  </p><ul><li>JSON ê¸°ë°˜ ì •ì±…ìœ¼ë¡œ, ë²„í‚· ì „ì²´ì— ëŒ€í•œ ì ‘ê·¼ ê¶Œí•œì„ ì„¤ì •í•©ë‹ˆë‹¤.  </li><li><strong>Cross-Account Access</strong>(ê³„ì • ê°„ ì ‘ê·¼)ë„ í—ˆìš© ê°€ëŠ¥.  </li><li>ë²„í‚· ì •ì±…ì€ <strong>S3 ì½˜ì†”</strong>ì—ì„œ ì§ì ‘ ì‘ì„±&#x2F;ê´€ë¦¬.</li></ul></li><li><p><strong>Object ACL (Access Control List)</strong>  </p><ul><li>ê°ì²´ ë‹¨ìœ„ë¡œ ì„¸ë°€í•˜ê²Œ ì ‘ê·¼ ì œì–´.  </li><li>í•˜ì§€ë§Œ í˜„ì¬ëŠ” <strong>ë¹„ì¶”ì²œ(Deprecated)</strong> â†’ ëŒ€ë¶€ë¶„ <strong>ë²„í‚· ì •ì±…</strong>ìœ¼ë¡œ ëŒ€ì²´.</li></ul></li><li><p><strong>Bucket ACL</strong>  </p><ul><li>ë²„í‚· ë‹¨ìœ„ ACL. ê±°ì˜ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë©° ì—­ì‹œ ë¹„ì¶”ì²œ.</li></ul></li></ul><hr><h2 id="2-IAM-ê¶Œí•œ-í‰ê°€-ê·œì¹™"><a href="#2-IAM-ê¶Œí•œ-í‰ê°€-ê·œì¹™" class="headerlink" title="2. IAM ê¶Œí•œ í‰ê°€ ê·œì¹™"></a>2. IAM ê¶Œí•œ í‰ê°€ ê·œì¹™</h2><p>S3 ê°ì²´ì— ì ‘ê·¼í•˜ë ¤ë©´ ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•´ì•¼ í•©ë‹ˆë‹¤:</p><ul><li><strong>IAM ì •ì±…ì´ ALLOW</strong> ì´ê±°ë‚˜ <strong>ë¦¬ì†ŒìŠ¤ ì •ì±…ì´ ALLOW</strong>  </li><li>ê·¸ë¦¬ê³  <strong>ëª…ì‹œì  DENYê°€ ì—†ì–´ì•¼ í•¨</strong></li></ul><p>ğŸ‘‰ ì¦‰, <code>ALLOW OR ALLOW</code> ì´ë©´ì„œ ë™ì‹œì— <code>NO DENY</code> ì¡°ê±´ì´ì–´ì•¼ í•¨.</p><hr><h2 id="3-S3-ë²„í‚·-ì •ì±…-Bucket-Policies"><a href="#3-S3-ë²„í‚·-ì •ì±…-Bucket-Policies" class="headerlink" title="3. S3 ë²„í‚· ì •ì±… (Bucket Policies)"></a>3. S3 ë²„í‚· ì •ì±… (Bucket Policies)</h2><ul><li><strong>í˜•ì‹</strong>: JSON ê¸°ë°˜ ë¬¸ì„œ  </li><li><strong>êµ¬ì„± ìš”ì†Œ</strong><ul><li><strong>Resource</strong>: ì ìš© ëŒ€ìƒ (ë²„í‚·&#x2F;ê°ì²´ ARN)  </li><li><strong>Effect</strong>: <code>Allow</code> ë˜ëŠ” <code>Deny</code>  </li><li><strong>Action</strong>: í—ˆìš©&#x2F;ê±°ë¶€í•  API ëª©ë¡ (<code>s3:GetObject</code>, <code>s3:PutObject</code> ë“±)  </li><li><strong>Principal</strong>: ì •ì±… ì ìš© ëŒ€ìƒ (ê³„ì •, ì‚¬ìš©ì, ì—­í• , <code>*</code> &#x3D; ëª¨ë“  ì‚¬ìš©ì)</li></ul></li></ul><h3 id="ì˜ˆì‹œ-1-í¼ë¸”ë¦­-ì½ê¸°-Public-Access"><a href="#ì˜ˆì‹œ-1-í¼ë¸”ë¦­-ì½ê¸°-Public-Access" class="headerlink" title="ì˜ˆì‹œ 1: í¼ë¸”ë¦­ ì½ê¸° (Public Access)"></a>ì˜ˆì‹œ 1: í¼ë¸”ë¦­ ì½ê¸° (Public Access)</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;Version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2012-10-17&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;Statement&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;Effect&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Allow&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;Principal&quot;</span><span class="punctuation">:</span> <span class="string">&quot;*&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;Action&quot;</span><span class="punctuation">:</span> <span class="string">&quot;s3:GetObject&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;Resource&quot;</span><span class="punctuation">:</span> <span class="string">&quot;arn:aws:s3:::my-example-bucket/*&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><ul><li>ì´ ì •ì±…ì€ <code>my-example-bucket</code> ì•ˆì˜ ëª¨ë“  ê°ì²´(<code>*</code>)ë¥¼ <strong>ëˆ„êµ¬ë‚˜ ì½ê¸° ê°€ëŠ¥</strong>í•˜ë„ë¡ í—ˆìš©.</li></ul><hr><h2 id="4-ë³´ì•ˆ-ì‹œë‚˜ë¦¬ì˜¤ë³„-ì ‘ê·¼-ë°©ë²•"><a href="#4-ë³´ì•ˆ-ì‹œë‚˜ë¦¬ì˜¤ë³„-ì ‘ê·¼-ë°©ë²•" class="headerlink" title="4. ë³´ì•ˆ ì‹œë‚˜ë¦¬ì˜¤ë³„ ì ‘ê·¼ ë°©ë²•"></a>4. ë³´ì•ˆ ì‹œë‚˜ë¦¬ì˜¤ë³„ ì ‘ê·¼ ë°©ë²•</h2><ul><li><strong>í¼ë¸”ë¦­ ì ‘ê·¼ (Public Access)</strong>  <ul><li>ë²„í‚· ì •ì±…ìœ¼ë¡œ <code>GetObject</code> ê¶Œí•œì„ ì—´ì–´ì¤Œ.  </li><li>ë‹¨, <strong>Block Public Access ì„¤ì •</strong>ì„ í•´ì œí•´ì•¼ í•¨.</li></ul></li></ul><p align="center">  <img src="/images/aws-ml-02.png" width="80%"></p><ul><li><strong>ë‚´ë¶€ ì‚¬ìš©ì (IAM User)</strong>  <ul><li>IAM ì •ì±…ìœ¼ë¡œ ê¶Œí•œ ë¶€ì—¬ (<code>s3:ListBucket</code>, <code>s3:GetObject</code> ë“±).</li></ul></li></ul><p align="center">  <img src="/images/aws-ml-03.png" width="80%"></p><ul><li><strong>EC2 ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì ‘ê·¼</strong>  <ul><li>IAM User ì‚¬ìš© âŒ â†’ <strong>IAM Role</strong>ì„ EC2ì— ë¶€ì—¬í•´ì•¼ í•¨.</li></ul></li></ul><p align="center">  <img src="/images/aws-ml-04.png" width="80%"></p><ul><li><strong>Cross-Account Access (ê³„ì • ê°„ ì ‘ê·¼)</strong>  <ul><li>ë‹¤ë¥¸ AWS ê³„ì •ì˜ IAM Userê°€ ì ‘ê·¼í•˜ë ¤ë©´ â†’ <strong>ë²„í‚· ì •ì±…</strong>ìœ¼ë¡œ í—ˆìš©.</li></ul></li></ul><p align="center">  <img src="/images/aws-ml-05.png" width="80%"></p><hr><h2 id="5-Block-Public-Access-ì„¤ì •"><a href="#5-Block-Public-Access-ì„¤ì •" class="headerlink" title="5. Block Public Access ì„¤ì •"></a>5. Block Public Access ì„¤ì •</h2><ul><li>AWSê°€ <strong>ë°ì´í„° ìœ ì¶œ ë°©ì§€(Data Leak Prevention)</strong> ë¥¼ ìœ„í•´ ë„ì…í•œ ê¸°ëŠ¥.  </li><li>ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë“  í¼ë¸”ë¦­ ì ‘ê·¼ì„ ë§‰ìŒ.  </li><li>âœ… ì‹œí—˜ í¬ì¸íŠ¸:  <ul><li>ë²„í‚·ì„ ê³µê°œí•´ì•¼ í•œë‹¤ë©´ ë°˜ë“œì‹œ <strong>Block Public Accessë¥¼ í•´ì œ</strong>í•´ì•¼ í•¨.  </li><li>í•˜ì§€ë§Œ <strong>ê¸°ì—… í™˜ê²½ì—ì„œëŠ” ëŒ€ë¶€ë¶„ í•­ìƒ ì¼œë‘”ë‹¤</strong>.  </li><li>ê³„ì • ë ˆë²¨ì—ì„œë„ ì ìš© ê°€ëŠ¥ â†’ <strong>ëª¨ë“  ë²„í‚·ì´ í¼ë¸”ë¦­ ì°¨ë‹¨ë¨</strong>.</li></ul></li></ul><hr><h2 id="6-ì•”í˜¸í™”-Encryption"><a href="#6-ì•”í˜¸í™”-Encryption" class="headerlink" title="6. ì•”í˜¸í™” (Encryption)"></a>6. ì•”í˜¸í™” (Encryption)</h2><ul><li><strong>SSE-S3</strong>: S3ê°€ ìì²´ì ìœ¼ë¡œ í‚¤ ê´€ë¦¬ (ê°„ë‹¨, ê¸°ë³¸ ì˜µì…˜).  </li><li><strong>SSE-KMS</strong>: AWS KMS(Key Management Service)ë¥¼ ì‚¬ìš©í•´ í‚¤ ê´€ë¦¬ (ë” ì„¸ë°€í•œ ë³´ì•ˆ, ë¡œê¹… ê°€ëŠ¥).  </li><li>ì‹œí—˜ì—ì„œëŠ” <strong>SSE-S3ì™€ SSE-KMS ì°¨ì´ì </strong>ì„ ì˜ ë¬¼ì–´ë´„.</li></ul><hr><h1 id="âœ…-ì‹œí—˜-ëŒ€ë¹„-í•µì‹¬-ì •ë¦¬"><a href="#âœ…-ì‹œí—˜-ëŒ€ë¹„-í•µì‹¬-ì •ë¦¬" class="headerlink" title="âœ… ì‹œí—˜ ëŒ€ë¹„ í•µì‹¬ ì •ë¦¬"></a>âœ… ì‹œí—˜ ëŒ€ë¹„ í•µì‹¬ ì •ë¦¬</h1><ol><li><p><strong>IAM Policy vs Bucket Policy</strong>  </p><ul><li>IAM Policy: ì‚¬ìš©ì(User) ê´€ì ì—ì„œ ê¶Œí•œ ê´€ë¦¬.  </li><li>Bucket Policy: ë¦¬ì†ŒìŠ¤(Resource) ê´€ì ì—ì„œ ê¶Œí•œ ê´€ë¦¬.</li></ul></li><li><p><strong>ê°ì²´ ì ‘ê·¼ ì¡°ê±´</strong>  </p><ul><li>ALLOW(ì‚¬ìš©ì ì •ì±… OR ë¦¬ì†ŒìŠ¤ ì •ì±…) + NO DENY.</li></ul></li><li><p><strong>EC2ì—ì„œ S3 ì ‘ê·¼</strong> â†’ <strong>IAM Role ì‚¬ìš©</strong>.  </p></li><li><p><strong>Cross-Account Access</strong> â†’ <strong>ë²„í‚· ì •ì±… í•„ìš”</strong>.  </p></li><li><p><strong>Block Public Access</strong>  </p><ul><li>ê¸°ë³¸ ON (ë°ì´í„° ìœ ì¶œ ë°©ì§€).  </li><li>ì‹œí—˜ì—ì„œëŠ” â€œí¼ë¸”ë¦­ ë²„í‚·ì´ ë™ì‘í•˜ì§€ ì•ŠëŠ”ë‹¤ â†’ Block Public Access ë•Œë¬¸â€ ìì£¼ ì¶œì œ.</li></ul></li><li><p><strong>ì•”í˜¸í™” ì˜µì…˜</strong>  </p><ul><li>SSE-S3 (ìë™, ê°„ë‹¨) vs SSE-KMS (ë³´ì•ˆÂ·ê·œì œ ìš”êµ¬ì‚¬í•­ ëŒ€ì‘).</li></ul></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Amazon-S3-ë³´ì•ˆ-Amazon-S3-Security&quot;&gt;&lt;a href=&quot;#Amazon-S3-ë³´ì•ˆ-Amazon-S3-Security&quot; class=&quot;headerlink&quot; title=&quot;Amazon S3 ë³´ì•ˆ (Amazon S3 Securi</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_ML_ASSOCIATE_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-ML-ASSOCIATE-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
    <category term="AWS_ML_ASSOCIATE" scheme="https://kish191919.github.io/tags/AWS-ML-ASSOCIATE/"/>
    
  </entry>
  
  <entry>
    <title>(í•œêµ­ì–´) AWS ML Associate (5) - Amazon S3 í•µì‹¬ ì •ë¦¬</title>
    <link href="https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-5/"/>
    <id>https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-5/</id>
    <published>2025-09-15T02:33:24.000Z</published>
    <updated>2025-09-15T03:49:06.877Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Amazon-S3-í•µì‹¬-ì •ë¦¬"><a href="#Amazon-S3-í•µì‹¬-ì •ë¦¬" class="headerlink" title="Amazon S3 í•µì‹¬ ì •ë¦¬"></a>Amazon S3 í•µì‹¬ ì •ë¦¬</h1><blockquote><p><strong>ì™œ ì¤‘ìš”í•œê°€?</strong><br>Amazon S3(Simple Storage Service)ëŠ” AWSì˜ í•µì‹¬ ìŠ¤í† ë¦¬ì§€ ì„œë¹„ìŠ¤ë¡œ, â€œì‚¬ì‹¤ìƒ ë¬´í•œëŒ€(virtually unlimited)â€ í™•ì¥ì„±ì„ ì œê³µí•˜ëŠ” <strong>ê°ì²´ ìŠ¤í† ë¦¬ì§€(Object Storage)</strong> ì…ë‹ˆë‹¤. ëŒ€ë¶€ë¶„ì˜ ë°ì´í„°&#x2F;AI ì›Œí¬ë¡œë“œê°€ S3ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì—°ê²°ë˜ë©°, ë‹¤ë¥¸ AWS ì„œë¹„ìŠ¤ì™€ì˜ í†µí•©ì„±ì´ ë§¤ìš° ë›°ì–´ë‚©ë‹ˆë‹¤.</p></blockquote><hr><h2 id="1-S3ê°€-ì“°ì´ëŠ”-ê³³-Use-Cases"><a href="#1-S3ê°€-ì“°ì´ëŠ”-ê³³-Use-Cases" class="headerlink" title="1) S3ê°€ ì“°ì´ëŠ” ê³³ (Use Cases)"></a>1) S3ê°€ ì“°ì´ëŠ” ê³³ (Use Cases)</h2><ul><li><strong>ë°±ì—… &amp; ìŠ¤í† ë¦¬ì§€(Backup &amp; Storage)</strong>: ì¥ê¸° ë³´ê´€, ìŠ¤ëƒ…ìƒ· ì €ì¥.</li><li><strong>ì¬í•´ë³µêµ¬(Disaster Recovery, DR)</strong>: ë‹¤ë¥¸ <strong>ë¦¬ì „(Region)</strong> ìœ¼ë¡œ ë³µì œí•´ RTO&#x2F;RPO ê°œì„ .</li><li><strong>ì•„ì¹´ì´ë¸Œ(Archive)</strong>: ì €ë¹„ìš© ë³´ê´€(<strong>S3 Glacier</strong> ê³„ì—´) í›„ í•„ìš” ì‹œ ë³µì›.</li><li><strong>í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤í† ë¦¬ì§€(Hybrid Cloud Storage)</strong>: ì˜¨í”„ë ˆë¯¸ìŠ¤ + í´ë¼ìš°ë“œ ì—°ë™.</li><li><strong>ì• í”Œë¦¬ì¼€ì´ì…˜&#x2F;ë¯¸ë””ì–´ í˜¸ìŠ¤íŒ…(App&#x2F;Media Hosting)</strong>: ì´ë¯¸ì§€&#x2F;ë™ì˜ìƒ&#x2F;ì •ì  íŒŒì¼ ì œê³µ.</li><li><strong>ë°ì´í„° ë ˆì´í¬(Data Lake) &amp; ë¹…ë°ì´í„° ë¶„ì„(Big Data Analytics)</strong>: ì›ì²œ ë°ì´í„° ì €ì¥ í›„ <strong>Athena&#x2F;Glue&#x2F;Lake Formation</strong> ë“±ìœ¼ë¡œ ë¶„ì„.</li><li><strong>ì†Œí”„íŠ¸ì›¨ì–´ ë°°í¬(Software Delivery)</strong>: ì„¤ì¹˜ íŒŒì¼, ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ë°°í¬.</li><li><strong>ì •ì  ì›¹ì‚¬ì´íŠ¸(Static Website)</strong>: ì •ì  í˜¸ìŠ¤íŒ… + <strong>CloudFront(CDN)</strong> ë¡œ ê°€ì†.</li></ul><blockquote><p><strong>MLA-C01 í¬ì¸íŠ¸</strong>: S3ëŠ” <strong>SageMaker</strong>ì™€ í•¨ê»˜ ìì£¼ ì¶œì œë©ë‹ˆë‹¤. í•™ìŠµ&#x2F;ì¶”ë¡  ë°ì´í„° ì €ì¥, ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ì €ì¥, <strong>Athena&#x2F;Glue</strong>ì™€ ì—°ê³„í•œ í”¼ì²˜ ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ ë“±. S3 ê²½ë¡œ í‘œê¸°(<strong>S3 URI</strong>)ì™€ ê¶Œí•œ ëª¨ë¸ì„ ìµíˆì„¸ìš”.</p></blockquote><hr><h2 id="2-ë²„í‚·-Bucket-â€”-ìµœìƒìœ„-ë„¤ì„ìŠ¤í˜ì´ìŠ¤"><a href="#2-ë²„í‚·-Bucket-â€”-ìµœìƒìœ„-ë„¤ì„ìŠ¤í˜ì´ìŠ¤" class="headerlink" title="2) ë²„í‚·(Bucket) â€” ìµœìƒìœ„ ë„¤ì„ìŠ¤í˜ì´ìŠ¤"></a>2) ë²„í‚·(Bucket) â€” ìµœìƒìœ„ ë„¤ì„ìŠ¤í˜ì´ìŠ¤</h2><ul><li><strong>ì •ì˜</strong>: ê°ì²´(íŒŒì¼)ë¥¼ ë‹´ëŠ” <strong>ì»¨í…Œì´ë„ˆ</strong>. UIê°€ í´ë”ì²˜ëŸ¼ ë³´ì—¬ë„, ì‹¤ì œë¡œëŠ” <strong>ë²„í‚·&#x2F;í‚¤(key)</strong> ê¸°ë°˜ì˜ í‰ë©´ êµ¬ì¡°.</li><li><strong>ê¸€ë¡œë²Œ ìœ ë‹ˆí¬ ì´ë¦„(Global Unique Name)</strong>: <strong>ì „ ì„¸ê³„ ëª¨ë“  ê³„ì •&#x2F;ë¦¬ì „ì—ì„œ ìœ ì¼</strong>í•´ì•¼ í•¨.</li><li><strong>ë¦¬ì „ ë²”ìœ„(Region-scoped)</strong>: ë²„í‚·ì€ <strong>íŠ¹ì • ë¦¬ì „</strong>ì— ìƒì„±ë©ë‹ˆë‹¤. (S3ê°€ ê¸€ë¡œë²Œì²˜ëŸ¼ ë³´ì—¬ë„ ìƒì„± ìœ„ì¹˜ëŠ” ë¦¬ì „)</li><li><strong>ë„¤ì´ë° ê·œì¹™(Naming Rules)</strong> (ëŒ€í‘œ ê·œì¹™ë§Œ ë°œì·Œ)<ul><li>ì˜ë¬¸ ì†Œë¬¸ì&#x2F;ìˆ«ì&#x2F;í•˜ì´í”ˆë§Œ ì‚¬ìš©, <strong>ëŒ€ë¬¸ì&#x2F;ì–¸ë”ìŠ¤ì½”ì–´ ë¶ˆê°€</strong></li><li>ê¸¸ì´ 3~63ì</li><li>IP í˜•íƒœ ê¸ˆì§€(ì˜ˆ: <code>192.168.0.1</code>)</li><li><code>xn--</code> ë¡œ ì‹œì‘ ê¸ˆì§€, <code>-s3alias</code> ë¡œ ë ê¸ˆì§€</li></ul></li><li><strong>ê¶Œì¥ ì´ˆê¸° ì„¤ì •</strong><ul><li><strong>ACL ë¹„í™œì„±í™”(ACLs disabled, Bucket owner enforced)</strong>  </li><li><strong>í¼ë¸”ë¦­ ì ‘ê·¼ ì°¨ë‹¨(Block Public Access)</strong>: ê¸°ë³¸ on  </li><li><strong>ì„œë²„ì‚¬ì´ë“œ ì•”í˜¸í™”(Server-Side Encryption, SSE)</strong>: ê¸°ë³¸ <strong>SSE-S3</strong> ë˜ëŠ” <strong>SSE-KMS</strong></li></ul></li></ul><blockquote><p><strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>  </p><ul><li>â€œë²„í‚· ì´ë¦„ ê¸€ë¡œë²Œ ìœ ì¼â€ê³¼ â€œë²„í‚·ì€ ë¦¬ì „ì— ì¢…ì†â€ì„ êµ¬ë¶„í•˜ì„¸ìš”.  </li><li>ë³´ì•ˆ ê¸°ë³¸ê°’: <strong>Block Public Access &#x3D; ON</strong>, <strong>ACL ë¹„ê¶Œì¥</strong>, <strong>SSE ì ìš©</strong>.</li></ul></blockquote><hr><h2 id="3-ê°ì²´-Object-í‚¤-Key"><a href="#3-ê°ì²´-Object-í‚¤-Key" class="headerlink" title="3) ê°ì²´(Object) &amp; í‚¤(Key)"></a>3) ê°ì²´(Object) &amp; í‚¤(Key)</h2><ul><li><strong>í‚¤(Key) &#x3D; ì „ì²´ ê²½ë¡œ(Full Path)</strong>  <ul><li>ì˜ˆ: <code>s3://my-bucket/my_folder1/another_folder/my_file.txt</code>  </li><li><strong>Prefix + Object Name</strong> ì¡°í•© (ë””ë ‰í„°ë¦¬ ê°œë…ì€ UI í¸ì˜ì¼ ë¿, ì‹¤ì œë¡œëŠ” ê¸´ ë¬¸ìì—´ ê²½ë¡œ)</li></ul></li><li><strong>í¬ê¸° ì œí•œ(Size Limits)</strong><ul><li><strong>ìµœëŒ€ 5TB</strong></li><li><strong>5GB ì´ˆê³¼ ì—…ë¡œë“œëŠ” ë°˜ë“œì‹œ <em>ë©€í‹°íŒŒíŠ¸ ì—…ë¡œë“œ(Multi-part Upload)</em></strong> ì‚¬ìš©</li></ul></li><li><strong>ë©”íƒ€ë°ì´í„°(Metadata)</strong>: ì‹œìŠ¤í…œ&#x2F;ì‚¬ìš©ì ì •ì˜ Key-Value</li><li><strong>íƒœê·¸(Tags)</strong>: ìµœëŒ€ 10ìŒ, ë¹„ìš©&#x2F;ìˆ˜ëª…ì£¼ê¸°&#x2F;ë³´ì•ˆ ì •ì±…ì— ìœ ìš©</li><li><strong>ë²„ì „ ID(Version ID)</strong>: <strong>ë²„ì „ ê´€ë¦¬(Versioning)</strong> í™œì„±í™” ì‹œ ë¶€ì—¬</li></ul><blockquote><p><strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>  </p><ul><li><strong>5GB ì´ˆê³¼ â†’ Multi-part Upload í•„ìˆ˜</strong>  </li><li><strong>Versioning</strong>: ì‚­ì œ&#x2F;ë®ì–´ì“°ê¸° ë³´í˜¸, <strong>MFA Delete</strong> ì™€ í•¨ê»˜ ë³´ì•ˆ ê°•í™”</li></ul></blockquote><hr><h2 id="4-ì ‘ê·¼-ë°©ë²•-í¼ë¸”ë¦­-URL-vs-í”„ë¦¬ì‚¬ì¸ë“œ-URL"><a href="#4-ì ‘ê·¼-ë°©ë²•-í¼ë¸”ë¦­-URL-vs-í”„ë¦¬ì‚¬ì¸ë“œ-URL" class="headerlink" title="4) ì ‘ê·¼ ë°©ë²•: í¼ë¸”ë¦­ URL vs í”„ë¦¬ì‚¬ì¸ë“œ URL"></a>4) ì ‘ê·¼ ë°©ë²•: í¼ë¸”ë¦­ URL vs í”„ë¦¬ì‚¬ì¸ë“œ URL</h2><ul><li><strong>Public URL</strong>: ê°ì²´ê°€ <strong>í¼ë¸”ë¦­</strong>ì´ì–´ì•¼ ì ‘ê·¼ ê°€ëŠ¥(ê¸°ë³¸ì€ ì°¨ë‹¨ë¨).</li><li><strong>Pre-signed URL</strong>: <strong>ì„ì‹œ ê¶Œí•œì´ ì„œëª…ëœ URL</strong>. ë¹„ê³µê°œ ê°ì²´ë„ <strong>ì„œëª… ë§Œë£Œ ì‹œê°„ ë™ì•ˆ</strong> ì ‘ê·¼ ê°€ëŠ¥. ì•ˆì „í•œ 1íšŒì„± ê³µìœ ì— ì í•©.</li></ul><blockquote><p><strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: â€œê°ì²´ëŠ” ë¹„ê³µê°œì¸ë° ì™¸ë¶€ì™€ ì ê¹ ê³µìœ í•˜ê³  ì‹¶ë‹¤â€ â†’ <strong>Pre-signed URL</strong> ì •ë‹µ.</p></blockquote><hr><h2 id="5-í•„ìˆ˜-ë³´ì•ˆ-ìš´ì˜-ê¸°ëŠ¥-Security-Operations"><a href="#5-í•„ìˆ˜-ë³´ì•ˆ-ìš´ì˜-ê¸°ëŠ¥-Security-Operations" class="headerlink" title="5) í•„ìˆ˜ ë³´ì•ˆ&#x2F;ìš´ì˜ ê¸°ëŠ¥ (Security &amp; Operations)"></a>5) í•„ìˆ˜ ë³´ì•ˆ&#x2F;ìš´ì˜ ê¸°ëŠ¥ (Security &amp; Operations)</h2><ul><li><strong>ì•”í˜¸í™”(Encryption)</strong><ul><li><strong>SSE-S3</strong>(Amazon S3 managed keys) â€” ê°€ì¥ ê°„ë‹¨</li><li><strong>SSE-KMS</strong>(AWS KMS keys) â€” <strong>í‚¤ ì‚¬ìš© ê¶Œí•œ&#x2F;ê°ì‚¬</strong> í•„ìš” ì‹œ</li><li><strong>CSE(Client-Side Encryption)</strong> â€” í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì•”í˜¸í™” í›„ ì—…ë¡œë“œ</li></ul></li><li><strong>ë²„ì „ ê´€ë¦¬(Versioning)</strong> + <strong>MFA Delete</strong>: ì‹¤ìˆ˜&#x2F;ëœì„¬ì›¨ì–´ ëŒ€ì‘</li><li><strong>ìˆ˜ëª…ì£¼ê¸°(Lifecycle) ì •ì±…</strong>: <strong>Standard â†’ IA â†’ Glacier</strong> í‹°ì–´ë§, ìë™ ë§Œë£Œ&#x2F;ì•„ì¹´ì´ë¸Œ</li><li><strong>ë³µì œ(Replication)</strong><ul><li><strong>CRR(Cross-Region Replication)</strong>: DR&#x2F;ì§€ì—°ë‹¨ì¶•</li><li><strong>SRR(Same-Region Replication)</strong>: ë©€í‹°ê³„ì •&#x2F;ë©€í‹°ë²„í‚· ë¶„ë¦¬</li></ul></li><li><strong>ì•¡ì„¸ìŠ¤ ì œì–´(Access Control)</strong><ul><li><strong>IAM ì •ì±…(IAM Policy)</strong>, <strong>ë²„í‚· ì •ì±…(Bucket Policy)</strong> ì¤‘ì‹¬</li><li><strong>S3 Access Points</strong>&#x2F;**VPC ì—”ë“œí¬ì¸íŠ¸(Interface&#x2F;Gateway)**ë¡œ ë„¤íŠ¸ì›Œí¬ ê²©ë¦¬</li></ul></li><li><strong>ê°ì‚¬&#x2F;ë¡œê¹…(Audit&#x2F;Logging)</strong>: <strong>CloudTrail</strong>, <strong>Server Access Logging</strong>, <strong>S3 Object Ownership</strong></li></ul><blockquote><p><strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>  </p><ul><li><strong>SSE-KMS</strong> ì„ íƒ ì‹œ <strong>KMS í‚¤ ê¶Œí•œ</strong>(Encrypt&#x2F;Decrypt&#x2F;APIí˜¸ì¶œ)ì´ ì¶”ê°€ë¡œ í•„ìš”.  </li><li><strong>CRR</strong>ì€ <strong>ë²„ì „ë‹ì´ ì–‘ìª½ ëª¨ë‘ í™œì„±í™”</strong>ë˜ì–´ì•¼ ì‘ë™. ì†Œìœ ê¶Œ&#x2F;ê¶Œí•œ ì´ìŠˆ ìì£¼ ì¶œì œ.</li></ul></blockquote><hr><h2 id="6-ì •ì -ì›¹ì‚¬ì´íŠ¸-CDN"><a href="#6-ì •ì -ì›¹ì‚¬ì´íŠ¸-CDN" class="headerlink" title="6) ì •ì  ì›¹ì‚¬ì´íŠ¸ &amp; CDN"></a>6) ì •ì  ì›¹ì‚¬ì´íŠ¸ &amp; CDN</h2><ul><li><strong>Static Website Hosting</strong>: S3 ì •ì  ì›¹ ì‚¬ì´íŠ¸ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©(í¼ë¸”ë¦­ ì ‘ê·¼ í•„ìš”).  </li><li><strong>CloudFront</strong> ì•ë‹¨ ë°°ì¹˜ ê¶Œì¥: OAC(Origin Access Control)ë¡œ <strong>S3ëŠ” ë¹„ê³µê°œ</strong>, <strong>CloudFrontë§Œ ì ‘ê·¼</strong> â†’ ì„±ëŠ¥&#x2F;ë³´ì•ˆ ëª¨ë‘ í–¥ìƒ.</li></ul><blockquote><p><strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: â€œS3ë¥¼ í¼ë¸”ë¦­ìœ¼ë¡œ ì—´ì§€ ì•Šê³  ì •ì  ì‚¬ì´íŠ¸ ì œê³µ?â€ â†’ <strong>CloudFront + OAC</strong> íŒ¨í„´.</p></blockquote><hr><h2 id="7-ë°ì´í„°-ë ˆì´í¬-íŒ¨í„´-for-ML-Analytics"><a href="#7-ë°ì´í„°-ë ˆì´í¬-íŒ¨í„´-for-ML-Analytics" class="headerlink" title="7) ë°ì´í„° ë ˆì´í¬ íŒ¨í„´ (for ML&#x2F;Analytics)"></a>7) ë°ì´í„° ë ˆì´í¬ íŒ¨í„´ (for ML&#x2F;Analytics)</h2><ul><li><strong>ì›ì²œ ì €ì¥</strong>: S3ì— ì›ë³¸ ë°ì´í„° ì ì¬(ìŠ¤í‚¤ë§ˆ ì˜¨ ë¦¬ë“œ, <em>Schema-on-Read</em>).</li><li><strong>ì¹´íƒˆë¡œê·¸</strong>: <strong>AWS Glue Data Catalog</strong></li><li><strong>ì¿¼ë¦¬&#x2F;íƒìƒ‰</strong>: <strong>Amazon Athena</strong>(ì„œë²„ë¦¬ìŠ¤ SQL), <strong>Redshift Spectrum</strong></li><li><strong>ê±°ë²„ë„ŒìŠ¤</strong>: <strong>Lake Formation</strong>(ê¶Œí•œ&#x2F;ë°ì´í„° ì•¡ì„¸ìŠ¤ ì œì–´)</li><li><strong>í˜•ì‹ ìµœì í™”</strong>: <strong>Parquet&#x2F;ORC</strong> ë“± <strong>ì»¬ëŸ¼ë‚˜í˜•(Columnar)</strong> í¬ë§· ê¶Œì¥ (ìŠ¤ìº”&#x2F;ë¹„ìš© ì ˆê°)</li></ul><blockquote><p><strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: â€œS3 + Athena ë¹„ìš© ìµœì í™”?â€ â†’ <strong>Parquet + íŒŒí‹°ì…”ë‹(Partitioning) + í”„ë¦¬í”½ìŠ¤ ì„¤ê³„</strong>.</p></blockquote><hr><h2 id="8-ì½˜ì†”ì—ì„œ-ìì£¼-í•˜ëŠ”-ì‘ì—…-ìš”ì•½"><a href="#8-ì½˜ì†”ì—ì„œ-ìì£¼-í•˜ëŠ”-ì‘ì—…-ìš”ì•½" class="headerlink" title="8) ì½˜ì†”ì—ì„œ ìì£¼ í•˜ëŠ” ì‘ì—… ìš”ì•½"></a>8) ì½˜ì†”ì—ì„œ ìì£¼ í•˜ëŠ” ì‘ì—… ìš”ì•½</h2><ol><li><strong>ë²„í‚· ìƒì„±(Create Bucket)</strong>: ë¦¬ì „ ì„ íƒ â†’ ì´ë¦„ ì§€ì •(ê¸€ë¡œë²Œ ìœ ì¼) â†’ <strong>Block Public Access ON</strong>, <strong>SSE ì„¤ì •</strong>  </li><li><strong>ê°ì²´ ì—…ë¡œë“œ(Upload)</strong>: ë‹¨ì¼&#x2F;ë©€í‹°íŒŒíŠ¸ ì„ íƒ(5GB ì´ˆê³¼ ì‹œ ë©€í‹°íŒŒíŠ¸)  </li><li><strong>í´ë”ì²˜ëŸ¼ ì‚¬ìš©í•˜ê¸°</strong>: ì ‘ë‘ì‚¬(prefix)ë¡œ ë…¼ë¦¬ì  êµ¬ë¶„(ì‹¤ì œ ë””ë ‰í„°ë¦¬ëŠ” ì•„ë‹˜)  </li><li><strong>í”„ë¦¬ì‚¬ì¸ë“œ URL ìƒì„±</strong>: ì¼ì‹œì  ì™¸ë¶€ ê³µìœ   </li><li><strong>ë²„í‚· ì •ì±…&#x2F;ì•¡ì„¸ìŠ¤ í¬ì¸íŠ¸</strong>: ì„¸ë°€ ê¶Œí•œ&#x2F;ë„¤íŠ¸ì›Œí¬ ê²©ë¦¬ ì„¤ì •</li></ol><hr><h2 id="9-ìì£¼-ë‚˜ì˜¤ëŠ”-í•¨ì •-Exam-Gotchas"><a href="#9-ìì£¼-ë‚˜ì˜¤ëŠ”-í•¨ì •-Exam-Gotchas" class="headerlink" title="9) ìì£¼ ë‚˜ì˜¤ëŠ” í•¨ì •(Exam Gotchas)"></a>9) ìì£¼ ë‚˜ì˜¤ëŠ” í•¨ì •(Exam Gotchas)</h2><ul><li><strong>ë””ë ‰í„°ë¦¬ ê°œë… ì—†ìŒ</strong>: í‚¤ ë¬¸ìì—´ì— <code>/</code>ë¥¼ ì¨ì„œ <strong>prefix</strong>ë¥¼ í‰ë‚´ë‚¼ ë¿.</li><li><strong>5GB ì—…ë¡œë“œ ì œí•œ</strong>: ì´ˆê³¼ ì‹œ <strong>Multi-part Upload</strong> í•„ìˆ˜.</li><li><strong>CRR ì¡°ê±´</strong>: <strong>ì–‘ìª½ ë²„í‚· Versioning ON</strong> + ê¶Œí•œ&#x2F;ì†Œìœ ê¶Œ ê³ ë ¤.</li><li><strong>KMS ì‚¬ìš© ì‹œ ê¶Œí•œ ì˜¤ë¥˜</strong>: KMS í‚¤ ì •ì±…&#x2F;Grant&#x2F;IAM ê¶Œí•œ ëˆ„ë½ ì²´í¬.</li><li><strong>í¼ë¸”ë¦­ ì°¨ë‹¨ì´ ê¸°ë³¸</strong>: ì •ì  ì‚¬ì´íŠ¸&#x2F;í¼ë¸”ë¦­ íŒŒì¼ ë°°í¬ëŠ” <strong>CloudFront</strong> ê²½ìœ ê°€ ì•ˆì „.</li></ul><hr><h2 id="10-ML-ì—”ì§€ë‹ˆì–´ë¥¼-ìœ„í•œ-S3-ë¹ ë¥¸-ì²´í¬ë¦¬ìŠ¤íŠ¸"><a href="#10-ML-ì—”ì§€ë‹ˆì–´ë¥¼-ìœ„í•œ-S3-ë¹ ë¥¸-ì²´í¬ë¦¬ìŠ¤íŠ¸" class="headerlink" title="10) ML ì—”ì§€ë‹ˆì–´ë¥¼ ìœ„í•œ S3 ë¹ ë¥¸ ì²´í¬ë¦¬ìŠ¤íŠ¸"></a>10) ML ì—”ì§€ë‹ˆì–´ë¥¼ ìœ„í•œ S3 ë¹ ë¥¸ ì²´í¬ë¦¬ìŠ¤íŠ¸</h2><ul><li><input disabled="" type="checkbox"> <strong>ë°ì´í„° ì €ì¥ í¬ë§·</strong>: CSV â†’ <strong>Parquet</strong> ë³€í™˜ ê³ ë ¤(ì„±ëŠ¥&#x2F;ë¹„ìš©)  </li><li><input disabled="" type="checkbox"> <strong>ì ‘ê·¼ ì œì–´</strong>: IAM Role ê¸°ë°˜ ìµœì†Œ ê¶Œí•œ(least privilege)  </li><li><input disabled="" type="checkbox"> <strong>ì•”í˜¸í™”</strong>: SSE-KMS ê¸°ë³¸, í‚¤ ê¶Œí•œ ì ê²€(íŒŒì´í”„ë¼ì¸&#x2F;ë…¸íŠ¸ë¶&#x2F;ë°°ì¹˜)  </li><li><input disabled="" type="checkbox"> <strong>ìˆ˜ëª…ì£¼ê¸° ì •ì±…</strong>: í•™ìŠµ ë¡œê·¸&#x2F;ì¤‘ê°„ ì‚°ì¶œë¬¼ ìë™ ì •ë¦¬  </li><li><input disabled="" type="checkbox"> <strong>ê²½ë¡œ ê·œì•½</strong>: <code>s3://bucket/project/dataset/partition=.../</code> ì¼ê´€ì„±  </li><li><input disabled="" type="checkbox"> <strong>í”„ë¦¬ì‚¬ì¸ë“œ URL</strong>: ì¼ì‹œì  ë°ì´í„° ê³µìœ &#x2F;ê²€ìˆ˜ ìë™í™”ì— í™œìš©</li></ul><hr><h3 id="í•µì‹¬-ìš©ì–´-ìš”ì•½-KR-EN"><a href="#í•µì‹¬-ìš©ì–´-ìš”ì•½-KR-EN" class="headerlink" title="í•µì‹¬ ìš©ì–´ ìš”ì•½ (KR&#x2F;EN)"></a>í•µì‹¬ ìš©ì–´ ìš”ì•½ (KR&#x2F;EN)</h3><ul><li>ë²„í‚· <strong>Bucket</strong> &#x2F; ê°ì²´ <strong>Object</strong> &#x2F; í‚¤ <strong>Key</strong> &#x2F; ì ‘ë‘ì‚¬ <strong>Prefix</strong> &#x2F; ë²„ì „ ê´€ë¦¬ <strong>Versioning</strong>  </li><li>í”„ë¦¬ì‚¬ì¸ë“œ URL <strong>Pre-signed URL</strong> &#x2F; ìˆ˜ëª…ì£¼ê¸° ì •ì±… <strong>Lifecycle Policy</strong>  </li><li>ì„œë²„ì‚¬ì´ë“œ ì•”í˜¸í™” <strong>Server-Side Encryption (SSE-S3 &#x2F; SSE-KMS)</strong>  </li><li>êµì°¨ ë¦¬ì „ ë³µì œ <strong>Cross-Region Replication (CRR)</strong> &#x2F; ë™ì¼ ë¦¬ì „ ë³µì œ <strong>Same-Region Replication (SRR)</strong>  </li><li>ë°ì´í„° ë ˆì´í¬ <strong>Data Lake</strong> &#x2F; ìŠ¤í‚¤ë§ˆ ì˜¨ ë¦¬ë“œ <strong>Schema-on-Read</strong> &#x2F; ì»¬ëŸ¼ë‚˜ <strong>Columnar</strong></li></ul><hr><h2 id="ì¶”ê°€-ì°¸ê³ -ì‹¬í™”"><a href="#ì¶”ê°€-ì°¸ê³ -ì‹¬í™”" class="headerlink" title="ì¶”ê°€ ì°¸ê³ (ì‹¬í™”)"></a>ì¶”ê°€ ì°¸ê³ (ì‹¬í™”)</h2><ul><li><strong>S3 Storage Classes</strong>: Standard &#x2F; Standard-IA &#x2F; One Zone-IA &#x2F; Intelligent-Tiering &#x2F; Glacier Instant&#x2F;Flx&#x2F;Deep Archive  </li><li><strong>ë„¤íŠ¸ì›Œí¬ ìµœì í™”</strong>: <strong>S3 Transfer Acceleration</strong>, ë©€í‹°íŒŒíŠ¸ ë³‘ë ¬ ì—…ë¡œë“œ, VPC ì—”ë“œí¬ì¸íŠ¸  </li><li><strong>ë¹„ìš© ê´€ë¦¬</strong>: S3 Storage Lens, Lifecycle&#x2F;Intelligent-Tiering, íŒŒí‹°ì…”ë‹&#x2F;í”„ë¦¬í”½ìŠ¤ ì„¤ê³„</li></ul><hr><p><strong>ìš”ì•½</strong>: S3ëŠ” ML&#x2F;ë¶„ì„ ì›Œí¬ë¡œë“œì˜ â€œê³µìš© ë°ì´í„° í—ˆë¸Œâ€ì…ë‹ˆë‹¤. <strong>ë³´ì•ˆ ê¸°ë³¸ê°’</strong>, <strong>ë©€í‹°íŒŒíŠ¸ ì—…ë¡œë“œ</strong>, <strong>Versioning&#x2F;CRR</strong>, <strong>SSE-KMS</strong>, <strong>Athena+Parquet</strong> ê°™ì€ íŒ¨í„´ì„ í™•ì‹¤íˆ ìµíˆë©´ MLA-C01ì—ì„œ ê³ ë“ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p><h1 id="Amazon-S3-ì•”í˜¸í™”-ë°©ì‹-ì‰½ê²Œ-ì„¤ëª…í•˜ê¸°"><a href="#Amazon-S3-ì•”í˜¸í™”-ë°©ì‹-ì‰½ê²Œ-ì„¤ëª…í•˜ê¸°" class="headerlink" title="Amazon S3 ì•”í˜¸í™” ë°©ì‹ ì‰½ê²Œ ì„¤ëª…í•˜ê¸°"></a>Amazon S3 ì•”í˜¸í™” ë°©ì‹ ì‰½ê²Œ ì„¤ëª…í•˜ê¸°</h1><p>Amazon S3ì—ì„œ ë°ì´í„°ë¥¼ ì €ì¥í•  ë•Œ ë³´ì•ˆì„ ìœ„í•´ <strong>ì„œë²„ ì‚¬ì´ë“œ ì•”í˜¸í™”(Server-side encryption, SSE)</strong> ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br>ëŒ€í‘œì ìœ¼ë¡œ ìì£¼ ì“°ì´ëŠ” ë‘ ê°€ì§€ ë°©ì‹ì´ ìˆìŠµë‹ˆë‹¤.</p><hr><h2 id="1-SSE-S3-Server-side-encryption-with-Amazon-S3-managed-keys"><a href="#1-SSE-S3-Server-side-encryption-with-Amazon-S3-managed-keys" class="headerlink" title="1. SSE-S3 (Server-side encryption with Amazon S3 managed keys)"></a>1. SSE-S3 (Server-side encryption with Amazon S3 managed keys)</h2><ul><li><p><strong>ì„¤ëª…</strong><br>S3ê°€ ì§ì ‘ ì•”í˜¸í™” í‚¤ë¥¼ ê´€ë¦¬í•´ì£¼ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.<br>ì‚¬ìš©ìê°€ ë”°ë¡œ í‚¤ë¥¼ ë§Œë“¤ê±°ë‚˜ ê´€ë¦¬í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.<br>ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ë©´ S3ê°€ ìë™ìœ¼ë¡œ ì•”í˜¸í™”í•˜ê³ , ë‹¤ìš´ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ë³µí˜¸í™”í•´ ì¤ë‹ˆë‹¤.</p></li><li><p><strong>íŠ¹ì§•</strong></p><ul><li>ì‚¬ìš©í•˜ê¸° ê°€ì¥ ì‰½ìŠµë‹ˆë‹¤ (ì¶”ê°€ ì„¤ì • ê±°ì˜ í•„ìš” ì—†ìŒ).</li><li>ì•”í˜¸í™” í‚¤ëŠ” <strong>Amazon S3ê°€ ì „ì ìœ¼ë¡œ ê´€ë¦¬</strong>í•©ë‹ˆë‹¤.</li><li><code>AES-256</code> ì•”í˜¸í™” ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.</li><li>ë¹„ìš©ì€ ì¶”ê°€ë¡œ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.</li></ul></li><li><p><strong>ì‹œí—˜ í¬ì¸íŠ¸ (AWS Certified ML Engineer Associate)</strong>  </p><ul><li><strong>SSE-S3ëŠ” S3ê°€ í‚¤ë¥¼ ê´€ë¦¬í•œë‹¤</strong>ë¼ëŠ” ì ì´ í•µì‹¬.  </li><li>ì˜µì…˜ì„ í™œì„±í™”í•˜ê¸°ë§Œ í•˜ë©´ ë (ìš´ì˜ í¸ë¦¬ì„± â†‘).  </li><li>ë³´ì•ˆ ê·œì œê°€ ê°•í•˜ì§€ ì•Šê±°ë‚˜ ë‹¨ìˆœ ì €ì¥ì´ ëª©ì ì¼ ë•Œ ì í•©.</li></ul></li></ul><hr><h2 id="2-SSE-KMS-Server-side-encryption-with-AWS-Key-Management-Service-keys"><a href="#2-SSE-KMS-Server-side-encryption-with-AWS-Key-Management-Service-keys" class="headerlink" title="2. SSE-KMS (Server-side encryption with AWS Key Management Service keys)"></a>2. SSE-KMS (Server-side encryption with AWS Key Management Service keys)</h2><ul><li><p><strong>ì„¤ëª…</strong><br>AWS Key Management Service(KMS)ë¥¼ í†µí•´ ì•”í˜¸í™” í‚¤ë¥¼ ê´€ë¦¬í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.<br>ì¦‰, ì•”í˜¸í™” í‚¤ë¥¼ ì§ì ‘ ìƒì„±, ê´€ë¦¬, ê¶Œí•œ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br>ë” ì„¸ë°€í•œ ë³´ì•ˆ ê´€ë¦¬ê°€ í•„ìš”í•œ ê²½ìš°ì— ì‚¬ìš©ë©ë‹ˆë‹¤.</p></li><li><p><strong>íŠ¹ì§•</strong></p><ul><li><strong>ê³ ê°ì´ í‚¤ë¥¼ ì§ì ‘ ê´€ë¦¬ (Customer managed keys)</strong> ê°€ëŠ¥.  </li><li>í‚¤ ì‚¬ìš©ì— ëŒ€í•œ <strong>CloudTrail ë¡œê·¸</strong>ë¡œ ì¶”ì  ê°€ëŠ¥ â†’ ëˆ„ê°€, ì–¸ì œ, ì–´ë–¤ í‚¤ë¥¼ ì‚¬ìš©í–ˆëŠ”ì§€ ì•Œ ìˆ˜ ìˆìŒ.  </li><li>IAM ì •ì±…ì„ í†µí•´ ì„¸ë°€í•˜ê²Œ ì ‘ê·¼ ì œì–´ ê°€ëŠ¥ (ì˜ˆ: íŠ¹ì • ì‚¬ìš©ìë§Œ ë³µí˜¸í™” ê°€ëŠ¥).  </li><li>KMS í˜¸ì¶œ ë¹„ìš©ì´ ë°œìƒí•©ë‹ˆë‹¤.</li></ul></li><li><p><strong>ì‹œí—˜ í¬ì¸íŠ¸</strong></p><ul><li><strong>SSE-KMSëŠ” KMSì™€ í†µí•©ë˜ì–´ ìˆì–´ ì„¸ë°€í•œ ë³´ì•ˆÂ·ê°ì‚¬ ê´€ë¦¬ ê°€ëŠ¥</strong>.  </li><li>ê·œì œê°€ ìˆëŠ” ì‚°ì—…(ê¸ˆìœµ, í—¬ìŠ¤ì¼€ì–´ ë“±)ì—ì„œëŠ” SSE-KMSê°€ ìš”êµ¬ë  ìˆ˜ ìˆìŒ.  </li><li>ë¹„ìš©ê³¼ ì„±ëŠ¥(ì¶”ê°€ API í˜¸ì¶œ)ë„ ê³ ë ¤í•´ì•¼ í•¨.</li></ul></li></ul><hr><h2 id="ë¹„êµ-ìš”ì•½"><a href="#ë¹„êµ-ìš”ì•½" class="headerlink" title="ë¹„êµ ìš”ì•½"></a>ë¹„êµ ìš”ì•½</h2><table><thead><tr><th>í•­ëª©</th><th>SSE-S3</th><th>SSE-KMS</th></tr></thead><tbody><tr><td>í‚¤ ê´€ë¦¬</td><td>Amazon S3 ìë™ ê´€ë¦¬</td><td>AWS KMSì—ì„œ ì§ì ‘ ê´€ë¦¬ ê°€ëŠ¥</td></tr><tr><td>ë³´ì•ˆ ìˆ˜ì¤€</td><td>ê¸°ë³¸ì  (ë‹¨ìˆœ ì•”í˜¸í™”)</td><td>ê³ ê¸‰ (ì„¸ë°€í•œ ì œì–´, ë¡œê¹…)</td></tr><tr><td>ë¹„ìš©</td><td>ì¶”ê°€ ë¹„ìš© ì—†ìŒ</td><td>KMS ì‚¬ìš© ë¹„ìš© ë°œìƒ</td></tr><tr><td>ì£¼ìš” íŠ¹ì§•</td><td>ê°€ì¥ ê°„ë‹¨, ìë™ ì²˜ë¦¬</td><td>IAMÂ·CloudTrail í†µí•©, ê·œì œ ì¤€ìˆ˜ì— ì í•©</td></tr></tbody></table><hr><p>âœ… <strong>ì‹œí—˜ ëŒ€ë¹„ í•µì‹¬</strong>  </p><ul><li>SSE-S3: <strong>S3ê°€ í‚¤ ê´€ë¦¬</strong>, ê°„ë‹¨, ì €ë¹„ìš©  </li><li>SSE-KMS: <strong>KMSì™€ í†µí•©</strong>, ì„¸ë°€í•œ ì œì–´, ê°ì‚¬ ë¡œê·¸, ë¹„ìš© ë°œìƒ</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Amazon-S3-í•µì‹¬-ì •ë¦¬&quot;&gt;&lt;a href=&quot;#Amazon-S3-í•µì‹¬-ì •ë¦¬&quot; class=&quot;headerlink&quot; title=&quot;Amazon S3 í•µì‹¬ ì •ë¦¬&quot;&gt;&lt;/a&gt;Amazon S3 í•µì‹¬ ì •ë¦¬&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;stro</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_ML_ASSOCIATE_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-ML-ASSOCIATE-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
    <category term="AWS_ML_ASSOCIATE" scheme="https://kish191919.github.io/tags/AWS-ML-ASSOCIATE/"/>
    
  </entry>
  
  <entry>
    <title>(í•œêµ­ì–´) AWS ML Associate (4) - ETL íŒŒì´í”„ë¼ì¸ê³¼ ë°ì´í„° í¬ë§· ì´í•´</title>
    <link href="https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-4/"/>
    <id>https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-4/</id>
    <published>2025-09-15T02:06:05.000Z</published>
    <updated>2025-09-15T02:32:58.595Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ETL-íŒŒì´í”„ë¼ì¸ê³¼-ë°ì´í„°-í¬ë§·-ì´í•´"><a href="#ETL-íŒŒì´í”„ë¼ì¸ê³¼-ë°ì´í„°-í¬ë§·-ì´í•´" class="headerlink" title="ETL íŒŒì´í”„ë¼ì¸ê³¼ ë°ì´í„° í¬ë§· ì´í•´"></a>ETL íŒŒì´í”„ë¼ì¸ê³¼ ë°ì´í„° í¬ë§· ì´í•´</h1><h2 id="1-ETL-íŒŒì´í”„ë¼ì¸ì´ë€"><a href="#1-ETL-íŒŒì´í”„ë¼ì¸ì´ë€" class="headerlink" title="1. ETL íŒŒì´í”„ë¼ì¸ì´ë€?"></a>1. ETL íŒŒì´í”„ë¼ì¸ì´ë€?</h2><ul><li><strong>ETL</strong>ì€ <strong>Extract, Transform, Load</strong>ì˜ ì•½ìì…ë‹ˆë‹¤.<br>â†’ ë°ì´í„°ë¥¼ <strong>ì¶”ì¶œ â†’ ë³€í™˜ â†’ ì ì¬</strong>í•˜ëŠ” ì¼ë ¨ì˜ ê³¼ì •.</li><li>ì£¼ë¡œ **ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤(DWH)**ë¡œ ë°ì´í„°ë¥¼ ì˜®ê¸¸ ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤.</li><li>ë°ì´í„° ë ˆì´í¬ì—ì„œëŠ” <strong>ELT</strong>(Extract â†’ Load â†’ Transform) ë°©ì‹ì´ ë” ì¼ë°˜ì ì…ë‹ˆë‹¤.</li></ul><hr><h2 id="2-Extract-ì¶”ì¶œ"><a href="#2-Extract-ì¶”ì¶œ" class="headerlink" title="2. Extract (ì¶”ì¶œ)"></a>2. Extract (ì¶”ì¶œ)</h2><ul><li><strong>ì •ì˜</strong>: ì›ì²œ ì‹œìŠ¤í…œì—ì„œ <strong>ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë‹¨ê³„</strong></li><li><strong>ë°ì´í„° ì¶œì²˜</strong>:<ul><li>ë°ì´í„°ë² ì´ìŠ¤ (MySQL, PostgreSQL, Oracle ë“±)</li><li>CRM (ì˜ˆ: Salesforce)</li><li>ë¡œê·¸ íŒŒì¼</li><li>API</li><li>ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° (Kafka, Kinesis ë“±)</li></ul></li><li><strong>ì¤‘ìš” ê³ ë ¤ì‚¬í•­</strong>:<ul><li>ë°ì´í„° ë¬´ê²°ì„± ë³´ì¥ (ì¤‘ê°„ì— ì†ì‹¤&#x2F;ì—ëŸ¬ ë°œìƒ ì‹œ ì¬ì‹œë„ ì •ì±… í•„ìš”)</li><li>ì²˜ë¦¬ ë°©ì‹: <strong>ì‹¤ì‹œê°„, ê·¼ì‹¤ì‹œê°„(near real-time), ë°°ì¹˜(batch)</strong></li></ul></li></ul><hr><h2 id="3-Transform-ë³€í™˜"><a href="#3-Transform-ë³€í™˜" class="headerlink" title="3. Transform (ë³€í™˜)"></a>3. Transform (ë³€í™˜)</h2><ul><li><strong>ì •ì˜</strong>: ì¶”ì¶œí•œ ë°ì´í„°ë¥¼ <strong>ë¶„ì„&#x2F;ì €ì¥í•˜ê¸° ì í•©í•œ í˜•íƒœ</strong>ë¡œ ë³€í™˜</li><li><strong>ì£¼ìš” ì‘ì—…</strong>:<ul><li>ë°ì´í„° ì •ì œ (ì¤‘ë³µ ì œê±°, ì˜¤ë¥˜ ìˆ˜ì •)</li><li>ë°ì´í„° ë³´ê°• (ì¶”ê°€ ì •ë³´ í•©ì¹˜ê¸°)</li><li>í¬ë§· ë³€ê²½ (ë¬¸ìì—´ â†’ ë‚ ì§œ í˜•ì‹ ë³€í™˜ ë“±)</li><li>ì§‘ê³„&#x2F;ê³„ì‚° (í•©ê³„, í‰ê·  ë“±)</li><li>ì¸ì½”ë”©&#x2F;ë””ì½”ë”© (ì••ì¶• í•´ì œ, ì•”í˜¸ í•´ì œ, ì»¬ëŸ¼ í¬ë§· ë³€í™˜ ë“±)</li><li>ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ì œê±°, í‰ê· ê°’ ëŒ€ì²´, null ê°’ í—ˆìš© ì—¬ë¶€ í™•ì¸)</li></ul></li></ul><p><strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>:</p><ul><li><strong>ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë°©ì‹</strong>ì€ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í’ˆì§ˆê³¼ ì§ê²° â†’ <strong>í‰ê· &#x2F;ì¤‘ì•™ê°’ ëŒ€ì²´, ì‚­ì œ, ì˜ˆì¸¡ ê¸°ë°˜ ë³´ê°„(imputation)</strong> ë°©ë²• ìˆ™ì§€</li><li>SageMaker <strong>Processing Job, Data Wrangler</strong> ê°™ì€ ì„œë¹„ìŠ¤ í™œìš©ë²•ë„ ì‹œí—˜ì— ìì£¼ ë“±ì¥</li></ul><hr><h2 id="4-Load-ì ì¬"><a href="#4-Load-ì ì¬" class="headerlink" title="4. Load (ì ì¬)"></a>4. Load (ì ì¬)</h2><ul><li><strong>ì •ì˜</strong>: ë³€í™˜ëœ ë°ì´í„°ë¥¼ **ëª©ì ì§€(ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤, ë°ì´í„° ë ˆì´í¬ ë“±)**ì— ì €ì¥</li><li><strong>ë°©ë²•</strong>:<ul><li>ë°°ì¹˜ ì ì¬: ì¼ì • ì£¼ê¸°ë¡œ ëŒ€ëŸ‰ ë°ì´í„° ì ì¬</li><li>ìŠ¤íŠ¸ë¦¬ë° ì ì¬: ë°ì´í„°ê°€ ë“¤ì–´ì˜¤ëŠ” ì¦‰ì‹œ ì ì¬</li></ul></li><li><strong>ì¤‘ìš” ê³ ë ¤ì‚¬í•­</strong>:<ul><li>ì ì¬ ì‹œ ë°ì´í„° ë¬´ê²°ì„± í™•ì¸</li><li>ì ì¬ ì‹¤íŒ¨ ì‹œ ë³µêµ¬ ì „ëµ í•„ìš”</li></ul></li></ul><hr><h2 id="5-ETL-íŒŒì´í”„ë¼ì¸-ê´€ë¦¬"><a href="#5-ETL-íŒŒì´í”„ë¼ì¸-ê´€ë¦¬" class="headerlink" title="5. ETL íŒŒì´í”„ë¼ì¸ ê´€ë¦¬"></a>5. ETL íŒŒì´í”„ë¼ì¸ ê´€ë¦¬</h2><p>ETL ê³¼ì •ì€ <strong>ìë™í™”</strong>ì™€ <strong>ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜</strong>ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.</p><ul><li><strong>AWS Glue</strong> â€“ ETL ì‘ì—… ìë™í™” ë° ìŠ¤ì¼€ì¤„ë§</li><li><strong>AWS Step Functions</strong> â€“ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬</li><li><strong>Amazon MWAA (Managed Apache Airflow)</strong> â€“ ë³µì¡í•œ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ê´€ë¦¬</li><li><strong>Amazon EventBridge</strong> â€“ ì´ë²¤íŠ¸ ê¸°ë°˜ íŠ¸ë¦¬ê±°</li><li><strong>AWS Lambda</strong> â€“ ì„œë²„ë¦¬ìŠ¤ ê¸°ë°˜ ë°ì´í„° ì²˜ë¦¬</li></ul><p><strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>:</p><ul><li>GlueëŠ” <strong>ì„œë²„ë¦¬ìŠ¤ ETL</strong> ì„œë¹„ìŠ¤, Spark ê¸°ë°˜ ë™ì‘</li><li>Step FunctionsëŠ” <strong>ìƒíƒœ ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°</strong> ê´€ë¦¬</li><li>MWAAëŠ” <strong>Apache Airflow ê´€ë¦¬í˜• ì„œë¹„ìŠ¤</strong></li></ul><hr><h2 id="6-ì£¼ìš”-ë°ì´í„°-ì†ŒìŠ¤-ì¸í„°í˜ì´ìŠ¤"><a href="#6-ì£¼ìš”-ë°ì´í„°-ì†ŒìŠ¤-ì¸í„°í˜ì´ìŠ¤" class="headerlink" title="6. ì£¼ìš” ë°ì´í„° ì†ŒìŠ¤ ì¸í„°í˜ì´ìŠ¤"></a>6. ì£¼ìš” ë°ì´í„° ì†ŒìŠ¤ ì¸í„°í˜ì´ìŠ¤</h2><ul><li><strong>JDBC (Java Database Connectivity)</strong><ul><li>ìë°” ê¸°ë°˜, <strong>í”Œë«í¼ ë…ë¦½ì </strong>, í•˜ì§€ë§Œ <strong>ì–¸ì–´(Java) ì¢…ì†ì </strong></li></ul></li><li><strong>ODBC (Open Database Connectivity)</strong><ul><li>ë“œë¼ì´ë²„ í•„ìš”(í”Œë«í¼ ì¢…ì†), í•˜ì§€ë§Œ <strong>ì–¸ì–´ ë…ë¦½ì </strong></li></ul></li><li><strong>API</strong> â€“ ì™¸ë¶€ ì‹œìŠ¤í…œì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°</li><li><strong>ë¡œê·¸ íŒŒì¼</strong> â€“ ì„œë²„ ë¡œê·¸, ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸ ë“±</li><li><strong>ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„°</strong> â€“ Kafka, Kinesis ë“±</li></ul><hr><h2 id="7-ë°ì´í„°-í¬ë§·-ì •ë¦¬"><a href="#7-ë°ì´í„°-í¬ë§·-ì •ë¦¬" class="headerlink" title="7. ë°ì´í„° í¬ë§· ì •ë¦¬"></a>7. ë°ì´í„° í¬ë§· ì •ë¦¬</h2><h3 id="CSV-Comma-Separated-Values"><a href="#CSV-Comma-Separated-Values" class="headerlink" title="CSV (Comma-Separated Values)"></a>CSV (Comma-Separated Values)</h3><ul><li><strong>íŠ¹ì§•</strong>: í…ìŠ¤íŠ¸ ê¸°ë°˜, í–‰ ë‹¨ìœ„ ë°ì´í„°, êµ¬ë¶„ìëŠ” <code>,</code> ë˜ëŠ” <code>\t</code></li><li><strong>ì¥ì </strong>: ì‚¬ëŒì´ ì½ê¸° ì‰¬ì›€, ì´ì‹ì„± ë†’ìŒ</li><li><strong>ë‹¨ì </strong>: ëŒ€ê·œëª¨ ë°ì´í„° ì²˜ë¦¬ ì‹œ ë¹„íš¨ìœ¨ì </li><li><strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: Pandas, R, Excel ë“±ì—ì„œ ì†ì‰½ê²Œ ì²˜ë¦¬ ê°€ëŠ¥</li></ul><h3 id="JSON-JavaScript-Object-Notation"><a href="#JSON-JavaScript-Object-Notation" class="headerlink" title="JSON (JavaScript Object Notation)"></a>JSON (JavaScript Object Notation)</h3><ul><li><strong>íŠ¹ì§•</strong>: í‚¤-ê°’ ê¸°ë°˜, <strong>ë°˜ì •í˜•(semi-structured) ë°ì´í„°</strong> í‘œí˜„ ê°€ëŠ¥</li><li><strong>ì¥ì </strong>: ìœ ì—°í•œ ìŠ¤í‚¤ë§ˆ, ì¤‘ì²© êµ¬ì¡° ì§€ì›</li><li><strong>í™œìš©</strong>: API ì‘ë‹µ, ì„¤ì • íŒŒì¼, NoSQL DB(MongoDB ë“±)</li></ul><h3 id="Avro"><a href="#Avro" class="headerlink" title="Avro"></a>Avro</h3><ul><li><strong>íŠ¹ì§•</strong>: ë°”ì´ë„ˆë¦¬ í¬ë§·, ë°ì´í„°ì™€ ìŠ¤í‚¤ë§ˆë¥¼ í•¨ê»˜ ì €ì¥</li><li><strong>ì¥ì </strong>: íš¨ìœ¨ì ì¸ ì§ë ¬í™”(Serialization), <strong>ìŠ¤í‚¤ë§ˆ ì§„í™”(schema evolution)</strong> ì§€ì›</li><li><strong>í™œìš©</strong>: Kafka, Spark, Flink, Hadoop</li></ul><h3 id="Parquet"><a href="#Parquet" class="headerlink" title="Parquet"></a>Parquet</h3><ul><li><strong>íŠ¹ì§•</strong>: <strong>ì»¬ëŸ¼ ì§€í–¥(columnar)</strong> ì €ì¥ í¬ë§·</li><li><strong>ì¥ì </strong>: íŠ¹ì • ì»¬ëŸ¼ë§Œ ì½ê¸° ê°€ëŠ¥ â†’ ëŒ€ê·œëª¨ ë¶„ì„ì— ìµœì í™”</li><li><strong>í™œìš©</strong>: Redshift Spectrum, Spark, Hive, Athena</li><li><strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: <strong>ë¶„ì„ìš© ìµœì í™” í¬ë§·</strong>ìœ¼ë¡œ ìì£¼ ì–¸ê¸‰ë¨</li></ul><hr><h2 id="8-ì‹œí—˜-ëŒ€ë¹„-ìš”ì•½"><a href="#8-ì‹œí—˜-ëŒ€ë¹„-ìš”ì•½" class="headerlink" title="8. ì‹œí—˜ ëŒ€ë¹„ ìš”ì•½"></a>8. ì‹œí—˜ ëŒ€ë¹„ ìš”ì•½</h2><ul><li><strong>ETL vs ELT</strong>: DWHëŠ” ETL, Data LakeëŠ” ELT</li><li><strong>ë°ì´í„° í¬ë§· íŠ¹ì§• ë¹„êµ</strong>: CSV(ë‹¨ìˆœ), JSON(ìœ ì—°), Avro(ìŠ¤í‚¤ë§ˆ í¬í•¨), Parquet(ë¶„ì„ ìµœì í™”)</li><li><strong>AWS Glue, Step Functions, MWAA</strong>: ETL ê´€ë¦¬ í•µì‹¬ ì„œë¹„ìŠ¤</li><li><strong>ìŠ¤í‚¤ë§ˆ ì˜¨ ë¼ì´íŠ¸(schema-on-write)</strong> vs <strong>ìŠ¤í‚¤ë§ˆ ì˜¨ ë¦¬ë“œ(schema-on-read)</strong>: ì‹œí—˜ ë‹¨ê³¨</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ETL-íŒŒì´í”„ë¼ì¸ê³¼-ë°ì´í„°-í¬ë§·-ì´í•´&quot;&gt;&lt;a href=&quot;#ETL-íŒŒì´í”„ë¼ì¸ê³¼-ë°ì´í„°-í¬ë§·-ì´í•´&quot; class=&quot;headerlink&quot; title=&quot;ETL íŒŒì´í”„ë¼ì¸ê³¼ ë°ì´í„° í¬ë§· ì´í•´&quot;&gt;&lt;/a&gt;ETL íŒŒì´í”„ë¼ì¸ê³¼ ë°ì´í„° í¬ë§· ì´í•´&lt;/h1&gt;&lt;</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_ML_ASSOCIATE_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-ML-ASSOCIATE-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
    <category term="AWS_ML_ASSOCIATE" scheme="https://kish191919.github.io/tags/AWS-ML-ASSOCIATE/"/>
    
  </entry>
  
  <entry>
    <title>(í•œêµ­ì–´) AWS ML Associate (3) - ë°ì´í„°ì˜ ì„¸ ê°€ì§€ ìœ í˜•</title>
    <link href="https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-3/"/>
    <id>https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-3/</id>
    <published>2025-09-15T01:55:59.000Z</published>
    <updated>2025-09-15T04:13:20.934Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ë°ì´í„°-ì›¨ì–´í•˜ìš°ìŠ¤-ë°ì´í„°-ë ˆì´í¬-ë°ì´í„°-ë ˆì´í¬í•˜ìš°ìŠ¤-ë°ì´í„°-ë©”ì‹œ-ì •ë¦¬"><a href="#ë°ì´í„°-ì›¨ì–´í•˜ìš°ìŠ¤-ë°ì´í„°-ë ˆì´í¬-ë°ì´í„°-ë ˆì´í¬í•˜ìš°ìŠ¤-ë°ì´í„°-ë©”ì‹œ-ì •ë¦¬" class="headerlink" title="ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤, ë°ì´í„° ë ˆì´í¬, ë°ì´í„° ë ˆì´í¬í•˜ìš°ìŠ¤, ë°ì´í„° ë©”ì‹œ ì •ë¦¬"></a>ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤, ë°ì´í„° ë ˆì´í¬, ë°ì´í„° ë ˆì´í¬í•˜ìš°ìŠ¤, ë°ì´í„° ë©”ì‹œ ì •ë¦¬</h1><h2 id="1-ë°ì´í„°-ì›¨ì–´í•˜ìš°ìŠ¤-Data-Warehouse"><a href="#1-ë°ì´í„°-ì›¨ì–´í•˜ìš°ìŠ¤-Data-Warehouse" class="headerlink" title="1. ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ (Data Warehouse)"></a>1. ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ (Data Warehouse)</h2><p><strong>ì •ì˜</strong><br>ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ëŠ” <strong>ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì •ì œ(ETL)í•˜ì—¬ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì €ì¥</strong>í•˜ëŠ” ì¤‘ì•™ ì €ì¥ì†Œì…ë‹ˆë‹¤. ì£¼ë¡œ ë¶„ì„ê³¼ BI(Business Intelligence)ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.</p><p><strong>íŠ¹ì§•</strong></p><ul><li>ë³µì¡í•œ ì¿¼ë¦¬ì™€ ë¶„ì„ ì‘ì—…ì— ìµœì í™”  </li><li>ì‚¬ì „ì— ìŠ¤í‚¤ë§ˆ(schema)ë¥¼ ì •ì˜í•˜ê³  ë°ì´í„°ë¥¼ ì ì¬ (Schema-on-Write)  </li><li>ì£¼ë¡œ <strong>Star Schema</strong> ë˜ëŠ” <strong>Snowflake Schema</strong> ì‚¬ìš©  </li><li>ì½ê¸°(Read) ì¤‘ì‹¬ì˜ ì›Œí¬ë¡œë“œì— ê°•í•¨</li></ul><p><strong>ì˜ˆì‹œ</strong></p><ul><li>AWS: <strong>Amazon Redshift</strong>  </li><li>(ë¹„êµ) Google BigQuery, Azure Synapse</li></ul><p><strong>ì‹œí—˜ í¬ì¸íŠ¸</strong></p><ul><li><strong>ETL (Extract â†’ Transform â†’ Load)</strong> ê³¼ì •ì´ ì¤‘ìš”  </li><li>ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ëŠ” <strong>êµ¬ì¡°í™”ëœ ë°ì´í„°(Structured Data)</strong> ì¤‘ì‹¬ì´ë¼ëŠ” ì  ê¸°ì–µí•˜ê¸°</li></ul><hr><h2 id="2-ë°ì´í„°-ë ˆì´í¬-Data-Lake"><a href="#2-ë°ì´í„°-ë ˆì´í¬-Data-Lake" class="headerlink" title="2. ë°ì´í„° ë ˆì´í¬ (Data Lake)"></a>2. ë°ì´í„° ë ˆì´í¬ (Data Lake)</h2><p><strong>ì •ì˜</strong><br>ë°ì´í„° ë ˆì´í¬ëŠ” <strong>ì •í˜•, ë°˜ì •í˜•, ë¹„ì •í˜• ë°ì´í„°ë¥¼ ì›ë³¸ ê·¸ëŒ€ë¡œ ì €ì¥</strong>í•˜ëŠ” ì €ì¥ì†Œì…ë‹ˆë‹¤.  </p><p><strong>íŠ¹ì§•</strong></p><ul><li>ë°ì´í„°ëŠ” <strong>ì‚¬ì „ ìŠ¤í‚¤ë§ˆ ì •ì˜ ì—†ì´ ì›ë³¸(raw)</strong> í˜•íƒœë¡œ ì €ì¥ (Schema-on-Read)  </li><li>ëŒ€ê·œëª¨ ë°ì´í„° ì €ì¥ì— ìœ ë¦¬ (ì €ë¹„ìš©, í™•ì¥ì„±)  </li><li>ë°°ì¹˜, ì‹¤ì‹œê°„, ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ëª¨ë‘ ìˆ˜ìš© ê°€ëŠ¥  </li><li>í•„ìš”í•  ë•Œ ë°ì´í„°ë¥¼ ë³€í™˜(ELT)í•˜ì—¬ ë¶„ì„</li></ul><p><strong>ì˜ˆì‹œ</strong></p><ul><li>AWS: <strong>Amazon S3 (ë°ì´í„° ë ˆì´í¬ë¡œ ì‚¬ìš©)</strong>  </li><li>Azure Data Lake Storage, HDFS</li></ul><p><strong>ì‹œí—˜ í¬ì¸íŠ¸</strong></p><ul><li>ë°ì´í„° ë ˆì´í¬ëŠ” <strong>ELT (Extract â†’ Load â†’ Transform)</strong> ë°©ì‹  </li><li>ë¡œê·¸ ë°ì´í„°, IoT ì„¼ì„œ ë°ì´í„°, ì†Œì…œ ë¯¸ë””ì–´ ë°ì´í„° ë“± <strong>ë‹¤ì–‘í•œ ì›ì²œ ë°ì´í„°</strong> ì €ì¥ ê°€ëŠ¥</li></ul><hr><h2 id="3-ë°ì´í„°-ì›¨ì–´í•˜ìš°ìŠ¤-vs-ë°ì´í„°-ë ˆì´í¬"><a href="#3-ë°ì´í„°-ì›¨ì–´í•˜ìš°ìŠ¤-vs-ë°ì´í„°-ë ˆì´í¬" class="headerlink" title="3. ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ vs ë°ì´í„° ë ˆì´í¬"></a>3. ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ vs ë°ì´í„° ë ˆì´í¬</h2><table><thead><tr><th>êµ¬ë¶„</th><th>ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤</th><th>ë°ì´í„° ë ˆì´í¬</th></tr></thead><tbody><tr><td>ìŠ¤í‚¤ë§ˆ</td><td>Schema-on-Write (ì‚¬ì „ ì •ì˜)</td><td>Schema-on-Read (ì½ì„ ë•Œ ì •ì˜)</td></tr><tr><td>ì²˜ë¦¬ ë°©ì‹</td><td>ETL</td><td>ELT ë˜ëŠ” ë‹¨ìˆœ ì ì¬</td></tr><tr><td>ë°ì´í„° í˜•íƒœ</td><td>êµ¬ì¡°í™”ëœ ë°ì´í„° ì¤‘ì‹¬</td><td>ì •í˜• + ë¹„ì •í˜• ëª¨ë‘</td></tr><tr><td>ë¯¼ì²©ì„±</td><td>ë‚®ìŒ (ìŠ¤í‚¤ë§ˆ ë³€ê²½ ì–´ë ¤ì›€)</td><td>ë†’ìŒ (ì›ë³¸ ê·¸ëŒ€ë¡œ ì €ì¥)</td></tr><tr><td>ë¹„ìš©</td><td>ìƒëŒ€ì ìœ¼ë¡œ ë¹„ìŒˆ</td><td>ì €ë¹„ìš©, ëŒ€ê·œëª¨ ì €ì¥ì— ì í•©</td></tr></tbody></table><p><strong>ì‹œí—˜ì— ìì£¼ ë‚˜ì˜¤ëŠ” í¬ì¸íŠ¸</strong>  </p><ul><li>Redshift &#x3D; Data Warehouse  </li><li>S3 &#x3D; Data Lake  </li><li>Schema-on-Write â†” Schema-on-Read ì°¨ì´ë¥¼ ê¼­ ê¸°ì–µ</li></ul><hr><h2 id="4-ë°ì´í„°-ë ˆì´í¬í•˜ìš°ìŠ¤-Data-Lakehouse"><a href="#4-ë°ì´í„°-ë ˆì´í¬í•˜ìš°ìŠ¤-Data-Lakehouse" class="headerlink" title="4. ë°ì´í„° ë ˆì´í¬í•˜ìš°ìŠ¤ (Data Lakehouse)"></a>4. ë°ì´í„° ë ˆì´í¬í•˜ìš°ìŠ¤ (Data Lakehouse)</h2><p><strong>ì •ì˜</strong><br>ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ì™€ ë°ì´í„° ë ˆì´í¬ì˜ ì¥ì ì„ ê²°í•©í•œ <strong>í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜</strong>ì…ë‹ˆë‹¤.  </p><p><strong>íŠ¹ì§•</strong></p><ul><li>ì •í˜• + ë¹„ì •í˜• ë°ì´í„° ëª¨ë‘ ì§€ì›  </li><li>Schema-on-Write, Schema-on-Read ëª¨ë‘ ê°€ëŠ¥  </li><li>ê³ ì„±ëŠ¥ ë¶„ì„ + ë¨¸ì‹ ëŸ¬ë‹ í™œìš© ê°€ëŠ¥  </li><li>ACID íŠ¸ëœì­ì…˜ ë³´ì¥ (ë°ì´í„° ì •í•©ì„± ìœ ì§€)</li></ul><p><strong>ì˜ˆì‹œ</strong></p><ul><li>AWS: <strong>Lake Formation + S3 + Redshift Spectrum</strong>  </li><li>Databricks Lakehouse (Delta Lake)  </li><li>Azure Synapse Analytics</li></ul><p><strong>ì‹œí—˜ í¬ì¸íŠ¸</strong></p><ul><li><strong>Lakehouse &#x3D; ë°ì´í„° ë¶„ì„(ì›¨ì–´í•˜ìš°ìŠ¤) + ë¨¸ì‹ ëŸ¬ë‹&#x2F;ìœ ì—°ì„±(ë ˆì´í¬) ê²°í•©</strong>  </li><li>Redshift Spectrum: <strong>S3ì— ì €ì¥ëœ ë°ì´í„°</strong>ë¥¼ Redshiftì—ì„œ ì§ì ‘ ì¿¼ë¦¬</li></ul><hr><h1 id="ACID-íŠ¸ëœì­ì…˜-ë³´ì¥"><a href="#ACID-íŠ¸ëœì­ì…˜-ë³´ì¥" class="headerlink" title="ACID íŠ¸ëœì­ì…˜ ë³´ì¥"></a>ACID íŠ¸ëœì­ì…˜ ë³´ì¥</h1><h2 id="1-Atomicity-ì›ìì„±"><a href="#1-Atomicity-ì›ìì„±" class="headerlink" title="1. Atomicity (ì›ìì„±)"></a>1. Atomicity (ì›ìì„±)</h2><ul><li>í•˜ë‚˜ì˜ íŠ¸ëœì­ì…˜ì€ <strong>ëª¨ë‘ ì‹¤í–‰ë˜ê±°ë‚˜ ì „í˜€ ì‹¤í–‰ë˜ì§€ ì•Šì•„ì•¼ í•¨</strong>ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.</li><li>ì¤‘ê°„ì— ì‹¤íŒ¨í•˜ë©´ ì´ì „ê¹Œì§€ ì‹¤í–‰ëœ ì‘ì—…ë„ ëª¨ë‘ ë¡¤ë°±(ì·¨ì†Œ)ë˜ì–´ì•¼ í•©ë‹ˆë‹¤</li><li>ì˜ˆ: A ê³„ì¢Œì—ì„œ B ê³„ì¢Œë¡œ 10ë§Œì› ì†¡ê¸ˆ â†’ Aì—ì„œ ì¶œê¸ˆë§Œ ë˜ê³  Bì— ì…ê¸ˆì´ ì•ˆ ë˜ë©´ ì•ˆ ë¨. ë‘˜ ë‹¤ ì‹¤í–‰ë˜ê±°ë‚˜ ë‘˜ ë‹¤ ì‹¤í–‰ë˜ì§€ ì•Šì•„ì•¼ í•¨.</li></ul><h2 id="2-Consistency-ì¼ê´€ì„±"><a href="#2-Consistency-ì¼ê´€ì„±" class="headerlink" title="2. Consistency (ì¼ê´€ì„±)"></a>2. Consistency (ì¼ê´€ì„±)</h2><ul><li>íŠ¸ëœì­ì…˜ ì‹¤í–‰ ì „í›„ì— <strong>ë°ì´í„°ë² ì´ìŠ¤ì˜ ì œì•½ì¡°ê±´ê³¼ ê·œì¹™ì´ í•­ìƒ ì§€ì¼œì ¸ì•¼ í•¨</strong>ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.</li><li>ì˜ëª»ëœ ë°ì´í„° ìƒíƒœë¥¼ í—ˆìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.</li><li>ì˜ˆ: ì€í–‰ ê³„ì¢Œ ì”ì•¡ì´ ìŒìˆ˜ê°€ ë˜ë©´ ì•ˆ ëœë‹¤ëŠ” ê·œì¹™ì´ ìˆì„ ë•Œ, íŠ¸ëœì­ì…˜ì´ ëë‚œ í›„ì—ë„ ì´ ê·œì¹™ì€ í•­ìƒ ì§€ì¼œì ¸ì•¼ í•¨.</li></ul><h2 id="3-Isolation-ê²©ë¦¬ì„±"><a href="#3-Isolation-ê²©ë¦¬ì„±" class="headerlink" title="3. Isolation (ê²©ë¦¬ì„±)"></a>3. Isolation (ê²©ë¦¬ì„±)</h2><ul><li>ë™ì‹œì— ì—¬ëŸ¬ íŠ¸ëœì­ì…˜ì´ ì‹¤í–‰ë˜ë”ë¼ë„ <strong>ì„œë¡œ ê°„ì„­í•˜ì§€ ì•Šì•„ì•¼ í•¨</strong>ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.</li><li>ë§ˆì¹˜ íŠ¸ëœì­ì…˜ì´ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ëœ ê²ƒì²˜ëŸ¼ ê²°ê³¼ê°€ ë‚˜ì™€ì•¼ í•©ë‹ˆë‹¤.</li><li>ì˜ˆ: ë‘ ì‚¬ëŒì´ ë™ì‹œì— ê°™ì€ ì¢Œì„ì„ ì˜ˆë§¤í•  ë•Œ, ë‘˜ ë‹¤ ì˜ˆë§¤ ì„±ê³µì´ ë˜ë©´ ì•ˆ ë¨. í•˜ë‚˜ëŠ” ì„±ê³µ, í•˜ë‚˜ëŠ” ì‹¤íŒ¨í•´ì•¼ í•¨.</li></ul><h2 id="4-Durability-ì§€ì†ì„±"><a href="#4-Durability-ì§€ì†ì„±" class="headerlink" title="4. Durability (ì§€ì†ì„±)"></a>4. Durability (ì§€ì†ì„±)</h2><ul><li>íŠ¸ëœì­ì…˜ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ë©´, ê·¸ ê²°ê³¼ëŠ” <strong>ì‹œìŠ¤í…œ ì¥ì• ê°€ ë°œìƒí•˜ë”ë¼ë„ ì˜êµ¬ì ìœ¼ë¡œ ë³´ì¡´</strong>ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.</li><li>ì˜ˆ: ëˆì„ ì´ì²´í•˜ê³  â€œì„±ê³µâ€ ë©”ì‹œì§€ë¥¼ ë°›ì•˜ë‹¤ë©´, ì„œë²„ê°€ ë‹¤ìš´ë˜ë”ë¼ë„ ê·¸ ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ë°˜ì˜ë˜ì–´ ìˆì–´ì•¼ í•¨.</li></ul><hr><h1 id="ACIDì™€-ë¶„ì‚°-ì‹œìŠ¤í…œ-ì‹œí—˜ì—-ìì£¼-ë‚˜ì˜¤ëŠ”-ë¶€ë¶„"><a href="#ACIDì™€-ë¶„ì‚°-ì‹œìŠ¤í…œ-ì‹œí—˜ì—-ìì£¼-ë‚˜ì˜¤ëŠ”-ë¶€ë¶„" class="headerlink" title="ACIDì™€ ë¶„ì‚° ì‹œìŠ¤í…œ (ì‹œí—˜ì— ìì£¼ ë‚˜ì˜¤ëŠ” ë¶€ë¶„)"></a>ACIDì™€ ë¶„ì‚° ì‹œìŠ¤í…œ (ì‹œí—˜ì— ìì£¼ ë‚˜ì˜¤ëŠ” ë¶€ë¶„)</h1><ul><li>ì „í†µì ì¸ ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤(RDBMS: MySQL, PostgreSQL, Oracle ë“±)ëŠ” ACIDë¥¼ ê°•í•˜ê²Œ ë³´ì¥í•©ë‹ˆë‹¤.</li><li>í•˜ì§€ë§Œ **ë¶„ì‚° ì‹œìŠ¤í…œ(ë¹…ë°ì´í„°, NoSQL, í´ë¼ìš°ë“œ í™˜ê²½)**ì—ì„œëŠ” ì„±ëŠ¥ê³¼ í™•ì¥ì„±ì„ ìœ„í•´ ì¼ë¶€ ACID íŠ¹ì„±ì„ ì™„í™”í•˜ê¸°ë„ í•©ë‹ˆë‹¤.<ul><li>ì˜ˆ: DynamoDB, Cassandra ê°™ì€ NoSQL DBëŠ” ì™„ì „í•œ ACID ëŒ€ì‹  <strong>Eventually Consistent (ìµœì¢… ì¼ê´€ì„±)</strong> ëª¨ë¸ì„ ì œê³µí•˜ê¸°ë„ í•¨.</li></ul></li><li>ìµœê·¼ì—ëŠ” <strong>ë°ì´í„° ë ˆì´í¬&#x2F;ë ˆì´í¬í•˜ìš°ìŠ¤ í™˜ê²½</strong>ì—ì„œë„ <strong>Delta Lake, Apache Iceberg, AWS Lake Formation</strong> ê°™ì€ ê¸°ìˆ ì´ <strong>ACID íŠ¸ëœì­ì…˜ ë³´ì¥</strong>ì„ ì§€ì›í•˜ë©´ì„œ, ëŒ€ê·œëª¨ ë¶„ì„ í™˜ê²½ì—ì„œë„ ì•ˆì •ì„±ì„ í™•ë³´í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.</li></ul><hr><h1 id="ì‹œí—˜-í¬ì¸íŠ¸-AWS-Certified-ML-Engineer-Associate"><a href="#ì‹œí—˜-í¬ì¸íŠ¸-AWS-Certified-ML-Engineer-Associate" class="headerlink" title="ì‹œí—˜ í¬ì¸íŠ¸ (AWS Certified ML Engineer Associate)"></a>ì‹œí—˜ í¬ì¸íŠ¸ (AWS Certified ML Engineer Associate)</h1><ol><li><strong>ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤(Redshift)</strong> â†’ ACID ë³´ì¥ (RDBMS ê¸°ë°˜).</li><li><strong>ë°ì´í„° ë ˆì´í¬(S3)</strong> â†’ ì›ë˜ëŠ” ACID ë³´ì¥ ì—†ìŒ â†’ <strong>Delta Lake, Lake Formation</strong> ë“±ì„ í†µí•´ ACID ë³´ì¥ ì¶”ê°€ ê°€ëŠ¥.</li><li><strong>íŠ¸ëœì­ì…˜ ì‹¤íŒ¨ ì‹œ ë¡¤ë°± &#x2F; ì‹œìŠ¤í…œ ì¥ì•  ì‹œ ì§€ì†ì„± ë³´ì¥</strong> ê°™ì€ ê°œë…ì´ ì‹œí—˜ì—ì„œ ìì£¼ ì–¸ê¸‰ë¨.</li></ol><hr><h2 id="5-ë°ì´í„°-ë©”ì‹œ-Data-Mesh"><a href="#5-ë°ì´í„°-ë©”ì‹œ-Data-Mesh" class="headerlink" title="5. ë°ì´í„° ë©”ì‹œ (Data Mesh)"></a>5. ë°ì´í„° ë©”ì‹œ (Data Mesh)</h2><p><strong>ì •ì˜</strong><br>ë°ì´í„° ë©”ì‹œ(Data Mesh)ëŠ” <strong>íŠ¹ì • ê¸°ìˆ ì´ ì•„ë‹ˆë¼ ì¡°ì§ì˜ ë°ì´í„° ê´€ë¦¬ ë°©ì‹</strong>ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.  </p><p align="center">  <img src="/images/aws-ml-01.png" width="80%"></p><p><strong>í•µì‹¬ ê°œë…</strong></p><ul><li><strong>ë„ë©”ì¸ ê¸°ë°˜ ë°ì´í„° ê´€ë¦¬</strong>: ê° íŒ€&#x2F;ë¶€ì„œê°€ ìê¸° ë°ì´í„°ì— ëŒ€í•œ â€œì†Œìœ ê¶Œâ€ê³¼ â€œì±…ì„â€ì„ ê°€ì§  </li><li>ë°ì´í„°ëŠ” <strong>ë°ì´í„° ì œí’ˆ(Data Product)</strong> í˜•íƒœë¡œ ë‹¤ë¥¸ íŒ€ê³¼ ê³µìœ   </li><li>ì¤‘ì•™ì—ì„œ í‘œì¤€í™”ëœ ê±°ë²„ë„ŒìŠ¤ ì œê³µ (ë³´ì•ˆ, í’ˆì§ˆ, ê¶Œí•œ ê´€ë¦¬)  </li><li>AWS Glue Data Catalog, Lake Formation ë“±ì„ ì´ìš©í•´ êµ¬í˜„ ê°€ëŠ¥</li></ul><p><strong>ì‹œí—˜ í¬ì¸íŠ¸</strong></p><ul><li>ì‹œí—˜ì—ì„œëŠ” â€œë°ì´í„° ë©”ì‹œ &#x3D; ì¡°ì§ì &#x2F;ìš´ì˜ì  ê°œë…â€ì´ë¼ëŠ” ì ì„ êµ¬ë¶„í•´ì•¼ í•¨  </li><li>â€œë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤&#x2F;ë ˆì´í¬&#x2F;ë ˆì´í¬í•˜ìš°ìŠ¤â€ëŠ” <strong>ê¸°ìˆ ì  ê°œë…</strong>, â€œë°ì´í„° ë©”ì‹œâ€ëŠ” <strong>ì¡°ì§ì  íŒ¨ëŸ¬ë‹¤ì„</strong></li></ul><hr><h2 id="6-ì •ë¦¬-â€“-ì–¸ì œ-ë¬´ì—‡ì„-ì“¸ê¹Œ"><a href="#6-ì •ë¦¬-â€“-ì–¸ì œ-ë¬´ì—‡ì„-ì“¸ê¹Œ" class="headerlink" title="6. ì •ë¦¬ â€“ ì–¸ì œ ë¬´ì—‡ì„ ì“¸ê¹Œ?"></a>6. ì •ë¦¬ â€“ ì–¸ì œ ë¬´ì—‡ì„ ì“¸ê¹Œ?</h2><ul><li><p><strong>ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤</strong>  </p><ul><li>ì •í˜• ë°ì´í„°  </li><li>ë¹ ë¥´ê³  ë³µì¡í•œ ì¿¼ë¦¬  </li><li>BI&#x2F;ë¦¬í¬íŒ… ì¤‘ì‹¬</li></ul></li><li><p><strong>ë°ì´í„° ë ˆì´í¬</strong>  </p><ul><li>ì •í˜• + ë¹„ì •í˜• ë°ì´í„° í˜¼í•©  </li><li>ë¨¸ì‹ ëŸ¬ë‹&#x2F;ê³ ê¸‰ ë¶„ì„ ì¤€ë¹„  </li><li>ë¹„ìš© íš¨ìœ¨ì  ì €ì¥ì†Œ</li></ul></li><li><p><strong>ë°ì´í„° ë ˆì´í¬í•˜ìš°ìŠ¤</strong>  </p><ul><li>ë¶„ì„ + ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë‘ ì§€ì›  </li><li>ìœ ì—°ì„± + ì„±ëŠ¥ ëª¨ë‘ í•„ìš”í•  ë•Œ</li></ul></li><li><p><strong>ë°ì´í„° ë©”ì‹œ</strong>  </p><ul><li>ì¡°ì§ ê·œëª¨ê°€ í¬ê³ , ì—¬ëŸ¬ ë¶€ì„œê°€ ë°ì´í„° ê´€ë¦¬  </li><li>íŒ€ë³„ ë°ì´í„° ì†Œìœ ê¶Œê³¼ ì¤‘ì•™ ê±°ë²„ë„ŒìŠ¤ ê²°í•©</li></ul></li></ul><hr><p>ğŸ‘‰ <strong>ì‹œí—˜ ëŒ€ë¹„ í•µì‹¬ í‚¤ì›Œë“œ</strong>  </p><ul><li><strong>Schema-on-Write (Warehouse)</strong>  </li><li><strong>Schema-on-Read (Lake)</strong>  </li><li><strong>ETL â†” ELT ì°¨ì´</strong>  </li><li><strong>Redshift &#x3D; Data Warehouse &#x2F; S3 &#x3D; Data Lake</strong>  </li><li><strong>Redshift Spectrum &#x3D; Lakehouse í™œìš© ì˜ˆì‹œ</strong>  </li><li><strong>Data Mesh &#x3D; ê¸°ìˆ ì´ ì•„ë‹Œ ì¡°ì§ì  ê±°ë²„ë„ŒìŠ¤ íŒ¨ëŸ¬ë‹¤ì„</strong></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ë°ì´í„°-ì›¨ì–´í•˜ìš°ìŠ¤-ë°ì´í„°-ë ˆì´í¬-ë°ì´í„°-ë ˆì´í¬í•˜ìš°ìŠ¤-ë°ì´í„°-ë©”ì‹œ-ì •ë¦¬&quot;&gt;&lt;a href=&quot;#ë°ì´í„°-ì›¨ì–´í•˜ìš°ìŠ¤-ë°ì´í„°-ë ˆì´í¬-ë°ì´í„°-ë ˆì´í¬í•˜ìš°ìŠ¤-ë°ì´í„°-ë©”ì‹œ-ì •ë¦¬&quot; class=&quot;headerlink&quot; title=&quot;ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤, ë°ì´í„° ë ˆ</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_ML_ASSOCIATE_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-ML-ASSOCIATE-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
    <category term="AWS_ML_ASSOCIATE" scheme="https://kish191919.github.io/tags/AWS-ML-ASSOCIATE/"/>
    
  </entry>
  
  <entry>
    <title>(í•œêµ­ì–´) AWS ML Associate (2) - ë°ì´í„°ì˜ ì„¸ ê°€ì§€ ìœ í˜•</title>
    <link href="https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-2/"/>
    <id>https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-2/</id>
    <published>2025-09-15T01:41:19.000Z</published>
    <updated>2025-09-15T02:05:30.557Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ë°ì´í„°-ì—”ì§€ë‹ˆì–´ë§-ê¸°ì´ˆ"><a href="#ë°ì´í„°-ì—”ì§€ë‹ˆì–´ë§-ê¸°ì´ˆ" class="headerlink" title="ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ê¸°ì´ˆ"></a>ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ê¸°ì´ˆ</h1><p>ì´ë²ˆ ì„¹ì…˜ì€ AWS ì„œë¹„ìŠ¤ ìì²´ë³´ë‹¤ëŠ” <strong>ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ì˜ ê¸°ì´ˆ ê°œë…</strong>ì— ì´ˆì ì„ ë‘¡ë‹ˆë‹¤.<br>ì‹œí—˜ ê°€ì´ë“œì—ì„œë„ AWS ì„œë¹„ìŠ¤ë¿ ì•„ë‹ˆë¼ ë°ì´í„° ê´€ë ¨ ê¸°ë³¸ ê°œë…ì„ ì•Œì•„ì•¼ í•œë‹¤ê³  ëª…ì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.  </p><hr><h2 id="1-ë°ì´í„°ì˜-ì„¸-ê°€ì§€-ìœ í˜•"><a href="#1-ë°ì´í„°ì˜-ì„¸-ê°€ì§€-ìœ í˜•" class="headerlink" title="1. ë°ì´í„°ì˜ ì„¸ ê°€ì§€ ìœ í˜•"></a>1. ë°ì´í„°ì˜ ì„¸ ê°€ì§€ ìœ í˜•</h2><h3 id="â‘ -êµ¬ì¡°í™”-ë°ì´í„°-Structured-Data"><a href="#â‘ -êµ¬ì¡°í™”-ë°ì´í„°-Structured-Data" class="headerlink" title="â‘  êµ¬ì¡°í™” ë°ì´í„° (Structured Data)"></a>â‘  êµ¬ì¡°í™” ë°ì´í„° (Structured Data)</h3><ul><li><strong>ì •ì˜</strong>: ë¯¸ë¦¬ ì •ì˜ëœ ìŠ¤í‚¤ë§ˆ(ì—´, ìë£Œí˜• ë“±)ì— ë§ì¶° ì •ë¦¬ëœ ë°ì´í„°  </li><li><strong>íŠ¹ì§•</strong>: SQLë¡œ ì‰½ê²Œ ì§ˆì˜ ê°€ëŠ¥, í–‰&#x2F;ì—´ êµ¬ì¡°ë¡œ ì¼ê´€ì„± ìˆìŒ  </li><li><strong>ì˜ˆì‹œ</strong>:  <ul><li>ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤ (MySQL, PostgreSQL, Amazon RDS, Amazon Redshift)  </li><li>ì˜ ì •ë¦¬ëœ CSV íŒŒì¼  </li><li>ì „í˜•ì ì¸ ì—‘ì…€ ì‹œíŠ¸</li></ul></li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: RDB vs ë°ì´í„° ë ˆì´í¬ ì°¨ì´ë¥¼ êµ¬ë¶„í•´ì•¼ í•¨. Redshift(OLAP)ì™€ S3 ê¸°ë°˜ ë°ì´í„° ë ˆì´í¬ ì°¨ì´ë¥¼ ë¬¼ì„ ìˆ˜ ìˆìŒ.  </p><hr><h3 id="â‘¡-ë¹„êµ¬ì¡°í™”-ë°ì´í„°-Unstructured-Data"><a href="#â‘¡-ë¹„êµ¬ì¡°í™”-ë°ì´í„°-Unstructured-Data" class="headerlink" title="â‘¡ ë¹„êµ¬ì¡°í™” ë°ì´í„° (Unstructured Data)"></a>â‘¡ ë¹„êµ¬ì¡°í™” ë°ì´í„° (Unstructured Data)</h3><ul><li><strong>ì •ì˜</strong>: ìŠ¤í‚¤ë§ˆê°€ ì—†ê±°ë‚˜ ì¼ì •í•˜ì§€ ì•Šì€ ë°ì´í„°  </li><li><strong>íŠ¹ì§•</strong>: ë°”ë¡œ ì§ˆì˜í•  ìˆ˜ ì—†ìŒ. ì „ì²˜ë¦¬&#x2F;ë©”íƒ€ë°ì´í„° ì¶”ì¶œ í•„ìš”  </li><li><strong>ì˜ˆì‹œ</strong>:  <ul><li>í…ìŠ¤íŠ¸ ë¬¸ì„œ (ìœ„í‚¤ ë¬¸ì„œ, ì „ìì±… ë“±)  </li><li>ì˜¤ë””ì˜¤, ë™ì˜ìƒ, ì´ë¯¸ì§€ íŒŒì¼  </li><li>ì´ë©”ì¼, ì›Œë“œ ë¬¸ì„œ</li></ul></li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: ì´ë¯¸ì§€&#x2F;ì˜ìƒ&#x2F;í…ìŠ¤íŠ¸ â†’ Amazon Rekognition, Transcribe, Comprehend ê°™ì€ ì„œë¹„ìŠ¤ í™œìš©.  </p><hr><h3 id="â‘¢-ë°˜êµ¬ì¡°í™”-ë°ì´í„°-Semi-structured-Data"><a href="#â‘¢-ë°˜êµ¬ì¡°í™”-ë°ì´í„°-Semi-structured-Data" class="headerlink" title="â‘¢ ë°˜êµ¬ì¡°í™” ë°ì´í„° (Semi-structured Data)"></a>â‘¢ ë°˜êµ¬ì¡°í™” ë°ì´í„° (Semi-structured Data)</h3><ul><li><strong>ì •ì˜</strong>: ì™„ì „í•œ ìŠ¤í‚¤ë§ˆëŠ” ì—†ì§€ë§Œ, íƒœê·¸&#x2F;ê³„ì¸µ êµ¬ì¡° ë“± ì¼ë¶€ êµ¬ì¡°ì  íŠ¹ì§• ì¡´ì¬  </li><li><strong>ì˜ˆì‹œ</strong>:  <ul><li>JSON, XML  </li><li>ë¡œê·¸ íŒŒì¼ (ì›¹ ì„œë²„ ë¡œê·¸, ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸ ë“±)  </li><li>ì´ë©”ì¼ í—¤ë”</li></ul></li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: JSON&#x2F;ë¡œê·¸ â†’ Amazon Athena, Glue, OpenSearchë¡œ ì¿¼ë¦¬ ê°€ëŠ¥.  </p><hr><h2 id="2-ë°ì´í„°ì˜-íŠ¹ì„±-â€“-3V-ì‹œí—˜-ì¤‘ìš”"><a href="#2-ë°ì´í„°ì˜-íŠ¹ì„±-â€“-3V-ì‹œí—˜-ì¤‘ìš”" class="headerlink" title="2. ë°ì´í„°ì˜ íŠ¹ì„± â€“ 3V (ì‹œí—˜ ì¤‘ìš”!)"></a>2. ë°ì´í„°ì˜ íŠ¹ì„± â€“ 3V (ì‹œí—˜ ì¤‘ìš”!)</h2><p>AWS ì‹œí—˜ì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ” ê°œë…: <strong>ë°ì´í„°ì˜ 3V</strong><br>(Volume, Velocity, Variety)  </p><h3 id="â‘ -Volume-ë°ì´í„°-ì–‘"><a href="#â‘ -Volume-ë°ì´í„°-ì–‘" class="headerlink" title="â‘  Volume (ë°ì´í„° ì–‘)"></a>â‘  Volume (ë°ì´í„° ì–‘)</h3><ul><li><strong>ì •ì˜</strong>: ë°ì´í„°ì˜ í¬ê¸°  </li><li><strong>ì˜ˆì‹œ</strong>:  <ul><li>SNS â†’ í•˜ë£¨ ìˆ˜ TB ì´ìƒ  </li><li>ëŒ€í˜• ë¦¬í…Œì¼ëŸ¬ â†’ ìˆ˜ë…„ê°„ ê±°ë˜ ê¸°ë¡ ìˆ˜ PB</li></ul></li><li><strong>AWS ê´€ë ¨ ì„œë¹„ìŠ¤</strong>:  <ul><li>ëŒ€ìš©ëŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ â†’ <strong>Snowball, Snowmobile</strong>  </li><li>ìŠ¤í† ë¦¬ì§€ â†’ <strong>Amazon S3, EFS, FSx</strong></li></ul></li></ul><hr><h3 id="â‘¡-Velocity-ë°ì´í„°-ìƒì„±-ì²˜ë¦¬-ì†ë„"><a href="#â‘¡-Velocity-ë°ì´í„°-ìƒì„±-ì²˜ë¦¬-ì†ë„" class="headerlink" title="â‘¡ Velocity (ë°ì´í„° ìƒì„±&#x2F;ì²˜ë¦¬ ì†ë„)"></a>â‘¡ Velocity (ë°ì´í„° ìƒì„±&#x2F;ì²˜ë¦¬ ì†ë„)</h3><ul><li><strong>ì •ì˜</strong>: ë°ì´í„°ê°€ ìƒì„±&#x2F;ìˆ˜ì§‘&#x2F;ì²˜ë¦¬ë˜ëŠ” ì†ë„  </li><li><strong>ì˜ˆì‹œ</strong>:  <ul><li>IoT ì„¼ì„œ â†’ ë§¤ ms ë‹¨ìœ„ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°  </li><li>ì£¼ì‹ ê³ ë¹ˆë„ ê±°ë˜(HFT) â†’ ì‹¤ì‹œê°„ ì²˜ë¦¬ í•„ìˆ˜</li></ul></li><li><strong>AWS ê´€ë ¨ ì„œë¹„ìŠ¤</strong>:  <ul><li>ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° â†’ <strong>Kinesis Data Streams</strong>  </li><li>ê·¼ì‹¤ì‹œê°„(near real-time) ë°°ì¹˜ â†’ <strong>Kinesis Firehose, AWS Glue streaming ETL</strong></li></ul></li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: â€œì‹¤ì‹œê°„(real-time)â€ vs â€œê·¼ì‹¤ì‹œê°„(near real-time)â€ ì„œë¹„ìŠ¤ êµ¬ë¶„ ë¬¸ì œ ìì£¼ ë‚˜ì˜´.  </p><hr><h3 id="â‘¢-Variety-ë°ì´í„°-ë‹¤ì–‘ì„±"><a href="#â‘¢-Variety-ë°ì´í„°-ë‹¤ì–‘ì„±" class="headerlink" title="â‘¢ Variety (ë°ì´í„° ë‹¤ì–‘ì„±)"></a>â‘¢ Variety (ë°ì´í„° ë‹¤ì–‘ì„±)</h3><ul><li><strong>ì •ì˜</strong>: ë°ì´í„°ì˜ í˜•íƒœì™€ ì¶œì²˜ì˜ ë‹¤ì–‘ì„±  </li><li><strong>ì˜ˆì‹œ</strong>:  <ul><li>êµ¬ì¡°í™”: ê´€ê³„í˜• DB (RDS, Redshift)  </li><li>ë°˜êµ¬ì¡°í™”: JSON ë¡œê·¸ (CloudTrail ë¡œê·¸ ë“±)  </li><li>ë¹„êµ¬ì¡°í™”: í™˜ì í”¼ë“œë°± í…ìŠ¤íŠ¸, ì˜ë£Œ ì˜ìƒ</li></ul></li><li><strong>AWS ê´€ë ¨ ì„œë¹„ìŠ¤</strong>:  <ul><li>ë‹¤ì–‘í•œ í¬ë§· ì €ì¥&#x2F;ë¶„ì„ â†’ <strong>Lake Formation, Glue, Athena</strong></li></ul></li></ul><hr><h2 id="3-ì¶”ê°€ë¡œ-ì•Œì•„ë‘ë©´-ì¢‹ì€-ê°œë…"><a href="#3-ì¶”ê°€ë¡œ-ì•Œì•„ë‘ë©´-ì¢‹ì€-ê°œë…" class="headerlink" title="3. ì¶”ê°€ë¡œ ì•Œì•„ë‘ë©´ ì¢‹ì€ ê°œë…"></a>3. ì¶”ê°€ë¡œ ì•Œì•„ë‘ë©´ ì¢‹ì€ ê°œë…</h2><ul><li><p><strong>Veracity (ì§„ì‹¤ì„±, ì •í™•ì„±)</strong>  </p><ul><li>ê³µì‹ ì‹œí—˜ ê°€ì´ë“œì—” ì—†ì§€ë§Œ, ë°ì´í„°ì˜ ì‹ ë¢°ì„±ê³¼ í’ˆì§ˆì„ ëœ»í•¨.  </li><li>AWS Glue DataBrew, SageMaker Data Wranglerë¥¼ í†µí•´ ë°ì´í„° ì •ì œ ê°€ëŠ¥.</li></ul></li><li><p><strong>ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬</strong>  </p><ul><li>Completeness(ì™„ì „ì„±), Accuracy(ì •í™•ì„±), Consistency(ì¼ê´€ì„±) ë“±ì€ ì‹œí—˜ì—ì„œ ìì£¼ ì¶œì œ.</li></ul></li><li><p><strong>ë¡œê·¸ì™€ ë°˜êµ¬ì¡°í™” ë°ì´í„° ì²˜ë¦¬</strong>  </p><ul><li>CloudWatch Logs + Athenaë¡œ ì¿¼ë¦¬  </li><li>OpenSearchë¡œ ê²€ìƒ‰ ë° ë¶„ì„</li></ul></li></ul><hr><h2 id="ì •ë¦¬-ì‹œí—˜-ëŒ€ë¹„-í¬ì¸íŠ¸"><a href="#ì •ë¦¬-ì‹œí—˜-ëŒ€ë¹„-í¬ì¸íŠ¸" class="headerlink" title="ì •ë¦¬ (ì‹œí—˜ ëŒ€ë¹„ í¬ì¸íŠ¸)"></a>ì •ë¦¬ (ì‹œí—˜ ëŒ€ë¹„ í¬ì¸íŠ¸)</h2><ul><li><p><strong>ì„¸ ê°€ì§€ ë°ì´í„° ìœ í˜•</strong>  </p><ul><li>Structured (SQL ì§ˆì˜ ê°€ëŠ¥)  </li><li>Semi-structured (JSON&#x2F;ë¡œê·¸, ì¼ë¶€ êµ¬ì¡°)  </li><li>Unstructured (í…ìŠ¤íŠ¸&#x2F;ì˜ìƒ&#x2F;ì˜¤ë””ì˜¤, ì „ì²˜ë¦¬ í•„ìš”)</li></ul></li><li><p><strong>ë°ì´í„°ì˜ 3V</strong>  </p><ul><li>Volume â†’ í¬ê¸° (S3, Snowball)  </li><li>Velocity â†’ ì†ë„ (Kinesis, Firehose)  </li><li>Variety â†’ ë‹¤ì–‘ì„± (RDS, S3, Glue, Athena ë“±)</li></ul></li><li><p><strong>ì‹œí—˜ì—ì„œ ì˜ ë‚˜ì˜¤ëŠ” ë¶€ë¶„</strong>  </p><ul><li>Kinesis Data Streams vs Firehose ì°¨ì´  </li><li>Snowball vs Snowmobile ì„ íƒ ê¸°ì¤€  </li><li>ë°ì´í„° ë ˆì´í¬ vs ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ (S3 + Athena vs Redshift)  </li><li>Glue &#x2F; Data Wrangler &#x2F; EMR ë¹„êµ</li></ul></li></ul><hr><p>ğŸ‘‰ ì´ ì„¹ì…˜ì€ AWS ì„œë¹„ìŠ¤ ìì²´ë³´ë‹¤ëŠ” <strong>ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ê¸°ì´ˆ ê°œë…ì„ AWS í™˜ê²½ì— ì–´ë–»ê²Œ ì ìš©í•˜ëŠ”ì§€</strong> ë¬»ëŠ” ë¬¸ì œê°€ ì¶œì œë  ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤.  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ë°ì´í„°-ì—”ì§€ë‹ˆì–´ë§-ê¸°ì´ˆ&quot;&gt;&lt;a href=&quot;#ë°ì´í„°-ì—”ì§€ë‹ˆì–´ë§-ê¸°ì´ˆ&quot; class=&quot;headerlink&quot; title=&quot;ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ê¸°ì´ˆ&quot;&gt;&lt;/a&gt;ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ê¸°ì´ˆ&lt;/h1&gt;&lt;p&gt;ì´ë²ˆ ì„¹ì…˜ì€ AWS ì„œë¹„ìŠ¤ ìì²´ë³´ë‹¤ëŠ” &lt;strong&gt;ë°</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_ML_ASSOCIATE_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-ML-ASSOCIATE-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
    <category term="AWS_ML_ASSOCIATE" scheme="https://kish191919.github.io/tags/AWS-ML-ASSOCIATE/"/>
    
  </entry>
  
  <entry>
    <title>(í•œêµ­ì–´) AWS ML Associate (1) - AWS ML ì—”ì§€ë‹ˆì–´ ì–´ì†Œì‹œì—ì´íŠ¸(MLA-C01) í•œëˆˆì— ë³´ê¸°</title>
    <link href="https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-1/"/>
    <id>https://kish191919.github.io/2025/09/14/KO-AWS-ML-Associate-1/</id>
    <published>2025-09-14T20:54:26.000Z</published>
    <updated>2025-09-14T21:05:52.193Z</updated>
    
    <content type="html"><![CDATA[<h1 id="AWS-ML-ì—”ì§€ë‹ˆì–´-ì–´ì†Œì‹œì—ì´íŠ¸-MLA-C01-í•œëˆˆì—-ë³´ê¸°"><a href="#AWS-ML-ì—”ì§€ë‹ˆì–´-ì–´ì†Œì‹œì—ì´íŠ¸-MLA-C01-í•œëˆˆì—-ë³´ê¸°" class="headerlink" title="AWS ML ì—”ì§€ë‹ˆì–´ ì–´ì†Œì‹œì—ì´íŠ¸(MLA-C01) í•œëˆˆì— ë³´ê¸°"></a>AWS ML ì—”ì§€ë‹ˆì–´ ì–´ì†Œì‹œì—ì´íŠ¸(MLA-C01) í•œëˆˆì— ë³´ê¸°</h1><p>ì´ ê³¼ì •ì—ì„œëŠ” <strong>ë°ì´í„° ìˆ˜ì§‘â†’ë³€í™˜&#x2F;íŠ¹ì§•ê³µí•™â†’ëª¨ë¸ í•™ìŠµ&#x2F;íŠœë‹&#x2F;í‰ê°€â†’ìƒì„±í˜• AIâ†’MLOpsâ†’ë³´ì•ˆ&#x2F;ê±°ë²„ë„ŒìŠ¤</strong>ê¹Œì§€ ì‹¤ë¬´ íë¦„ì„ ë”°ë¼ê°€ë©°, <strong>SageMaker ì¤‘ì‹¬</strong>ìœ¼ë¡œ AWS ì„œë¹„ìŠ¤ë“¤ì„ ì—°ê²°í•´ ì´í•´í•©ë‹ˆë‹¤.</p><blockquote><h3 id="ì‹œí—˜-í¬ì¸íŠ¸"><a href="#ì‹œí—˜-í¬ì¸íŠ¸" class="headerlink" title="ì‹œí—˜ í¬ì¸íŠ¸"></a>ì‹œí—˜ í¬ì¸íŠ¸</h3><ul><li><strong>SageMaker ì „ë°˜</strong>(Processing&#x2F;Training&#x2F;Inference&#x2F;Deployment)</li><li><strong>Glue, EMR, Kinesis, S3, EFS, EBS</strong> í™œìš©</li><li><strong>ë°ì´í„° ë³€í™˜Â·íŠ¹ì§•ê³µí•™ ê¸°ë²•</strong> (ê²°ì¸¡ì¹˜, ì´ìƒì¹˜, ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬)</li><li><strong>ê¸°ë³¸ ML ì•Œê³ ë¦¬ì¦˜</strong> (XGBoost, Linear Learner ë“± SageMaker ë‚´ì¥ ì•Œê³ ë¦¬ì¦˜)</li><li><strong>ì„±ëŠ¥ ì¸¡ì • ì§€í‘œ</strong> (Precision, Recall, F1-score, Accuracy ë“±)</li><li><strong>í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹</strong> (SageMaker Automatic Model Tuning)</li><li><strong>Bedrock, Jumpstart, RAG, Guardrails</strong> ë“± ìƒì„±í˜• AI ê´€ë ¨ ì‹ ê¸°ëŠ¥</li><li><strong>MLOps</strong> (CI&#x2F;CD, íŒŒì´í”„ë¼ì¸, ë²„ì „ ê´€ë¦¬, ëª¨ë‹ˆí„°ë§, ì¬í•™ìŠµ)</li><li><strong>ë³´ì•ˆÂ·ì»´í”Œë¼ì´ì–¸ìŠ¤</strong> (IAM, KMS, VPC, CloudTrail, Config ë“±)</li></ul></blockquote><hr><h2 id="1-ë°ì´í„°-ìˆ˜ì§‘-ì €ì¥"><a href="#1-ë°ì´í„°-ìˆ˜ì§‘-ì €ì¥" class="headerlink" title="1. ë°ì´í„° ìˆ˜ì§‘ &amp; ì €ì¥"></a>1. ë°ì´í„° ìˆ˜ì§‘ &amp; ì €ì¥</h2><ul><li><strong>í˜•ì‹</strong>: ì •í˜•&#x2F;ë¹„ì •í˜• ë°ì´í„° (CSV, JSON, ì´ë¯¸ì§€, ë¡œê·¸ ë“±)</li><li><strong>ì €ì¥ì†Œ</strong>: <ul><li><strong>ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤</strong>: Redshift</li><li><strong>ë°ì´í„° ë ˆì´í¬</strong>: S3</li><li><strong>ë°ì´í„° ë ˆì´í¬í•˜ìš°ìŠ¤</strong>: Lake Formation</li></ul></li><li><strong>ìŠ¤íŠ¸ë¦¬ë°</strong>: Amazon Kinesis</li><li><strong>íŒŒì¼ ìŠ¤í† ë¦¬ì§€</strong>: EFS, FSx</li><li><strong>ë¸”ë¡ ìŠ¤í† ë¦¬ì§€</strong>: EBS</li></ul><hr><h2 id="2-ë°ì´í„°-ë³€í™˜-íŠ¹ì§•ê³µí•™"><a href="#2-ë°ì´í„°-ë³€í™˜-íŠ¹ì§•ê³µí•™" class="headerlink" title="2. ë°ì´í„° ë³€í™˜ &amp; íŠ¹ì§•ê³µí•™"></a>2. ë°ì´í„° ë³€í™˜ &amp; íŠ¹ì§•ê³µí•™</h2><ul><li><strong>EMR</strong>: Hadoop, Spark ê¸°ë°˜ ëŒ€ê·œëª¨ ë°ì´í„° ì²˜ë¦¬</li><li><strong>ê²°ì¸¡ì¹˜&#x2F;ì´ìƒì¹˜ ì²˜ë¦¬, ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬</strong></li><li><strong>SageMaker Processing, Data Wrangler</strong> í™œìš©</li><li><strong>AWS Glue</strong>: ETL íŒŒì´í”„ë¼ì¸ ìë™í™”</li></ul><hr><h2 id="3-ëª¨ë¸-í•™ìŠµ-íŠœë‹-í‰ê°€"><a href="#3-ëª¨ë¸-í•™ìŠµ-íŠœë‹-í‰ê°€" class="headerlink" title="3. ëª¨ë¸ í•™ìŠµ &amp; íŠœë‹ &amp; í‰ê°€"></a>3. ëª¨ë¸ í•™ìŠµ &amp; íŠœë‹ &amp; í‰ê°€</h2><ul><li><strong>ë‚´ì¥ ì•Œê³ ë¦¬ì¦˜</strong>: XGBoost, Linear Learner, K-means, PCA ë“±</li><li><strong>ë”¥ëŸ¬ë‹ ê¸°ì´ˆ</strong>: ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬, ì˜µí‹°ë§ˆì´ì €, í•™ìŠµë¥ , í™œì„±í™” í•¨ìˆ˜</li><li><strong>ì„±ëŠ¥ ì§€í‘œ</strong>: Precision, Recall, F1-score, Accuracy</li><li><strong>íŠœë‹</strong>: SageMaker Automatic Model Tuning (Hyperparameter Optimization)</li></ul><hr><h2 id="4-ìƒì„±í˜•-AI"><a href="#4-ìƒì„±í˜•-AI" class="headerlink" title="4. ìƒì„±í˜• AI"></a>4. ìƒì„±í˜• AI</h2><ul><li><strong>Bedrock</strong>: ì—¬ëŸ¬ íŒŒìš´ë°ì´ì…˜ ëª¨ë¸ API ì œê³µ</li><li><strong>RAG (Retrieval Augmented Generation)</strong>: ì™¸ë¶€ ë°ì´í„° ê²°í•©, ë²¡í„° DB í™œìš©</li><li><strong>Jumpstart</strong>: ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë¹ ë¥¸ í™œìš©</li><li><strong>Guardrails</strong>: ìœ í•´ ì½˜í…ì¸  ì°¨ë‹¨, PII ë³´í˜¸</li><li><strong>LLM Agent</strong>: ì‚¬ìš©ì ì •ì˜ íˆ´ê³¼ ì½”ë“œ ì—°ë™</li></ul><hr><h2 id="5-MLOps"><a href="#5-MLOps" class="headerlink" title="5. MLOps"></a>5. MLOps</h2><ul><li><strong>ë²„ì „ ê´€ë¦¬</strong>: ë°ì´í„°, ì½”ë“œ, ëª¨ë¸</li><li><strong>ìë™í™”</strong>: ë°ì´í„° ìˆ˜ì§‘, ì „ì²˜ë¦¬, í•™ìŠµ, ë°°í¬ íŒŒì´í”„ë¼ì¸</li><li><strong>CI&#x2F;CD</strong>: CodePipeline, CodeBuild, CodeDeploy</li><li><strong>ì»¨í…Œì´ë„ˆí™”</strong>: EKS, ECR</li><li><strong>ëª¨ë‹ˆí„°ë§</strong>: CloudWatch, Model Monitor</li><li><strong>ì¬í•™ìŠµ</strong>: ì§€ì†ì ì¸ ë°ì´í„° ë°˜ì˜</li></ul><hr><h2 id="6-ë³´ì•ˆ-ê±°ë²„ë„ŒìŠ¤"><a href="#6-ë³´ì•ˆ-ê±°ë²„ë„ŒìŠ¤" class="headerlink" title="6. ë³´ì•ˆ &amp; ê±°ë²„ë„ŒìŠ¤"></a>6. ë³´ì•ˆ &amp; ê±°ë²„ë„ŒìŠ¤</h2><ul><li><strong>Shared Responsibility Model</strong><ul><li>AWS: í´ë¼ìš°ë“œ ì¸í”„ë¼ ë³´ì•ˆ</li><li>ê³ ê°: ë°ì´í„°, ì ‘ê·¼ ì œì–´, ì•”í˜¸í™”</li></ul></li><li><strong>ë³´ì•ˆ ì„œë¹„ìŠ¤</strong>: IAM, KMS, Secrets Manager, Macie, WAF, Shield</li><li><strong>ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆ</strong>: VPC, PrivateLink</li><li><strong>ê±°ë²„ë„ŒìŠ¤ &amp; ë¹„ìš© ê´€ë¦¬</strong>: CloudTrail, Config, Trusted Advisor, Budgets, Cost Explorer</li><li><strong>Well-Architected ML Lens</strong>: ëª¨ë²” ì•„í‚¤í…ì²˜ ê°€ì´ë“œë¼ì¸</li></ul><hr><h2 id="ì‹œí—˜-ì¤€ë¹„-íŒ"><a href="#ì‹œí—˜-ì¤€ë¹„-íŒ" class="headerlink" title="ì‹œí—˜ ì¤€ë¹„ íŒ"></a>ì‹œí—˜ ì¤€ë¹„ íŒ</h2><ul><li>ê¸°ì¶œ ë° ìœ ì‚¬ ì‹œí—˜: <strong>ML Specialty, Data Engineer Associate</strong>ì™€ ê²¹ì¹˜ëŠ” ë¶€ë¶„ ë§ìŒ</li><li>ì‹¤ì œ ê²½í—˜ ì—†ì–´ë„ **í•¸ì¦ˆì˜¨ ë©(SageMaker Notebooks)**ì„ í™œìš©í•´ ì²´í—˜ í•„ìˆ˜</li><li>í•µì‹¬ ì„œë¹„ìŠ¤: <strong>SageMaker, Bedrock, Glue, EMR, Kinesis, S3</strong></li><li>ML ê¸°ë³¸ê¸° (ì•Œê³ ë¦¬ì¦˜, ì§€í‘œ, ì „ì²˜ë¦¬ ê¸°ë²•) ë°˜ë“œì‹œ ìˆ™ì§€</li></ul><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;AWS-ML-ì—”ì§€ë‹ˆì–´-ì–´ì†Œì‹œì—ì´íŠ¸-MLA-C01-í•œëˆˆì—-ë³´ê¸°&quot;&gt;&lt;a href=&quot;#AWS-ML-ì—”ì§€ë‹ˆì–´-ì–´ì†Œì‹œì—ì´íŠ¸-MLA-C01-í•œëˆˆì—-ë³´ê¸°&quot; class=&quot;headerlink&quot; title=&quot;AWS ML ì—”ì§€ë‹ˆì–´ ì–´ì†Œì‹œì—ì´íŠ¸(MLA-C01</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_ML_ASSOCIATE_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-ML-ASSOCIATE-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
    <category term="AWS_ML_ASSOCIATE" scheme="https://kish191919.github.io/tags/AWS-ML-ASSOCIATE/"/>
    
  </entry>
  
  <entry>
    <title>(í•œêµ­ì–´) AWS Certified AI Practitioner (41) - ê±°ë²„ë„ŒìŠ¤ &amp; ì»´í”Œë¼ì´ì–¸ìŠ¤ì˜ ì¤‘ìš”ì„±</title>
    <link href="https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-41/"/>
    <id>https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-41/</id>
    <published>2025-09-02T19:29:55.000Z</published>
    <updated>2025-09-02T19:55:57.955Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ê±°ë²„ë„ŒìŠ¤-ì»´í”Œë¼ì´ì–¸ìŠ¤ì˜-ì¤‘ìš”ì„±"><a href="#ê±°ë²„ë„ŒìŠ¤-ì»´í”Œë¼ì´ì–¸ìŠ¤ì˜-ì¤‘ìš”ì„±" class="headerlink" title="ê±°ë²„ë„ŒìŠ¤ &amp; ì»´í”Œë¼ì´ì–¸ìŠ¤ì˜ ì¤‘ìš”ì„±"></a>ê±°ë²„ë„ŒìŠ¤ &amp; ì»´í”Œë¼ì´ì–¸ìŠ¤ì˜ ì¤‘ìš”ì„±</h1><ul><li><strong>ì¡°ì§ì˜ AI ì´ë‹ˆì…”í‹°ë¸Œë¥¼ ê´€ë¦¬Â·ìµœì í™”Â·í™•ì¥</strong>í•˜ê¸° ìœ„í•œ ê¸°ë³¸ í† ëŒ€</li><li><strong>ì‹ ë¢° êµ¬ì¶•</strong>: ì±…ì„ ìˆëŠ” AI ìš´ì˜ì„ í†µí•´ ë‚´ë¶€Â·ì™¸ë¶€ ì´í•´ê´€ê³„ìì˜ ì‹ ë¢° í™•ë³´</li><li><strong>ìœ„í—˜ ì™„í™”</strong>: í¸í–¥, í”„ë¼ì´ë²„ì‹œ ì¹¨í•´, ì˜ë„ì¹˜ ì•Šì€ ê²°ê³¼ ë“±</li><li><strong>ì •ì±…Â·ê°€ì´ë“œÂ·ê°ë… ì²´ê³„</strong>ë¡œ ë²•Â·ê·œì œ ì •í•©ì„± í™•ë³´</li><li><strong>ë²•ì Â·í‰íŒ ë¦¬ìŠ¤í¬</strong> ì˜ˆë°©, <strong>ëŒ€ì¤‘ ì‹ ë¢°</strong> ì œê³ </li></ul><blockquote><p>ğŸ“Œ <strong>ì‹œí—˜ í¬ì¸íŠ¸(AWS&#x2F;í´ë¼ìš°ë“œ ê³µí†µ)</strong></p><ul><li>â€œì±…ì„ ìˆëŠ” AI(Responsible AI)â€ëŠ” <strong>ì •ì±…Â·ê°ë…Â·ëª¨ë‹ˆí„°ë§</strong>ì„ AI ìˆ˜ëª…ì£¼ê¸° ì „ë°˜(ì„¤ê³„â†’ê°œë°œâ†’ë°°í¬â†’ìš´ì˜)ì—ì„œ ìˆ˜í–‰í•˜ëŠ” ê²ƒì„ ëœ»í•¨.</li><li><strong>ê³µê³µÂ·ê¸ˆìœµÂ·ì˜ë£Œ</strong> ë“±ì€ ê·œì œ ìš”ê±´(ê°ì‚¬Â·ë³´ê´€Â·ì¶”ì ì„±)ì´ ê°•í™”ë¨.</li></ul></blockquote><hr><h1 id="ê±°ë²„ë„ŒìŠ¤-í”„ë ˆì„ì›Œí¬-ì˜ˆì‹œ"><a href="#ê±°ë²„ë„ŒìŠ¤-í”„ë ˆì„ì›Œí¬-ì˜ˆì‹œ" class="headerlink" title="ê±°ë²„ë„ŒìŠ¤ í”„ë ˆì„ì›Œí¬(ì˜ˆì‹œ)"></a>ê±°ë²„ë„ŒìŠ¤ í”„ë ˆì„ì›Œí¬(ì˜ˆì‹œ)</h1><ol><li><strong>AI ê±°ë²„ë„ŒìŠ¤ ìœ„ì›íšŒ êµ¬ì„±</strong><ul><li>ë²•ë¬´, ì»´í”Œë¼ì´ì–¸ìŠ¤, ë³´ì•ˆ&#x2F;ê°œì¸ì •ë³´, ë°ì´í„°, AI ê°œë°œ <strong>SME</strong>ê°€ ì°¸ì—¬</li></ul></li><li><strong>ì—­í• ê³¼ ì±…ì„ ì •ì˜</strong><ul><li><strong>ì •ì±…ìˆ˜ë¦½</strong>, <strong>ë¦¬ìŠ¤í¬ í‰ê°€</strong>, <strong>ìŠ¹ì¸&#x2F;ê²°ì • ì ˆì°¨</strong> ëª…í™•í™”</li></ul></li><li><strong>ì •ì±…Â·í”„ë¡œì„¸ìŠ¤ ìˆ˜ë¦½</strong><ul><li>ë°ì´í„° ê´€ë¦¬ â†’ ëª¨ë¸ ê°œë°œ&#x2F;ê²€ì¦ â†’ <strong>ë°°í¬&#x2F;ëª¨ë‹ˆí„°ë§</strong>ê¹Œì§€ <strong>ì „ ìˆ˜ëª…ì£¼ê¸° í‘œì¤€í™”</strong></li></ul></li></ol><blockquote><p>ğŸ§© <strong>AWSì—ì„œ ë„ì›€ ë˜ëŠ” ì„œë¹„ìŠ¤ ì˜ˆì‹œ</strong></p><ul><li><strong>AWS Config</strong>(ì„¤ì • ì¤€ìˆ˜ ì¶”ì ), <strong>CloudTrail</strong>(ê°ì‚¬ ë¡œê·¸), <strong>Inspector</strong>(ì·¨ì•½ì ), <strong>Audit Manager</strong>(ê°ì‚¬ìš© ì¦ì  ìˆ˜ì§‘), <strong>Artifact</strong>(ì»´í”Œë¼ì´ì–¸ìŠ¤ ìë£Œ), <strong>Trusted Advisor</strong>(ë³´ì•ˆ&#x2F;ë¹„ìš© ê¶Œê³ ).</li></ul></blockquote><p align="center">  <img src="/images/aws_basic_209.png" width="80%"></p><hr><h1 id="ê±°ë²„ë„ŒìŠ¤-ì‹¤í–‰-ì „ëµ"><a href="#ê±°ë²„ë„ŒìŠ¤-ì‹¤í–‰-ì „ëµ" class="headerlink" title="ê±°ë²„ë„ŒìŠ¤ ì‹¤í–‰ ì „ëµ"></a>ê±°ë²„ë„ŒìŠ¤ ì‹¤í–‰ ì „ëµ</h1><h2 id="1-ì •ì±…"><a href="#1-ì •ì±…" class="headerlink" title="1) ì •ì±…"></a>1) ì •ì±…</h2><ul><li>ë°ì´í„° ê´€ë¦¬, í•™ìŠµÂ·ê²€ì¦, ì¶œë ¥ ê²€ìˆ˜, ì•ˆì „Â·íœ´ë¨¼ ì˜¤ë²„ì‚¬ì´íŠ¸</li><li><strong>IP&#x2F;ì €ì‘ê¶Œ</strong>, <strong>í¸í–¥ ì™„í™”</strong>, <strong>ê°œì¸ì •ë³´ ë³´í˜¸</strong> í¬í•¨</li></ul><h2 id="2-ì •ê¸°-ë¦¬ë·°-Review-Cadence"><a href="#2-ì •ê¸°-ë¦¬ë·°-Review-Cadence" class="headerlink" title="2) ì •ê¸° ë¦¬ë·°(Review Cadence)"></a>2) ì •ê¸° ë¦¬ë·°(Review Cadence)</h2><ul><li><strong>ê¸°ìˆ  ë¦¬ë·°</strong>: ì„±ëŠ¥, ë°ì´í„° í’ˆì§ˆ, ì•Œê³ ë¦¬ì¦˜ ê°•ê±´ì„±</li><li><strong>ë¹„ê¸°ìˆ  ë¦¬ë·°</strong>: ì •ì±… ì¤€ìˆ˜, ì±…ì„ ìˆëŠ” AI ì›ì¹™, ê·œì œ ëŒ€ì‘</li><li><strong>ì£¼ê¸°</strong>: ì›”ê°„&#x2F;ë¶„ê¸°&#x2F;ì—°ê°„ + <strong>SME&#x2F;ë²•ë¬´&#x2F;ì‚¬ìš©ì</strong> ì°¸ì—¬</li><li><strong>ì¶œì‹œ ì „ í…ŒìŠ¤íŠ¸Â·ê²€ì¦ ì ˆì°¨</strong>ì™€ <strong>ì˜ì‚¬ê²°ì • ê¸°ì¤€</strong> ë¬¸ì„œí™”</li></ul><h2 id="3-íˆ¬ëª…ì„±-ê¸°ì¤€"><a href="#3-íˆ¬ëª…ì„±-ê¸°ì¤€" class="headerlink" title="3) íˆ¬ëª…ì„± ê¸°ì¤€"></a>3) íˆ¬ëª…ì„± ê¸°ì¤€</h2><ul><li>ëª¨ë¸&#x2F;ë°ì´í„°&#x2F;ì£¼ìš” ì˜ì‚¬ê²°ì • ê³µê°œ(ê°€ëŠ¥ ë²”ìœ„ ë‚´)</li><li><strong>í•œê³„Â·ê°€ëŠ¥Â·ì ìš©ì‚¬ë¡€</strong> ë¬¸ì„œí™”, <strong>í”¼ë“œë°± ì±„ë„</strong> ìš´ì˜</li></ul><h2 id="4-íŒ€-êµìœ¡"><a href="#4-íŒ€-êµìœ¡" class="headerlink" title="4) íŒ€ êµìœ¡"></a>4) íŒ€ êµìœ¡</h2><ul><li>ì •ì±…Â·ê°€ì´ë“œÂ·ëª¨ë²”ì‚¬ë¡€ êµìœ¡, <strong>í¸í–¥ ì™„í™”&#x2F;Responsible AI</strong> íŠ¸ë ˆì´ë‹</li><li><strong>êµì°¨ í˜‘ì—…</strong> ì¥ë ¤, ë‚´ë¶€ <strong>ìˆ˜ë£Œ&#x2F;ì¸ì¦</strong> ì œë„</li></ul><hr><h1 id="ë°ì´í„°-ê±°ë²„ë„ŒìŠ¤-ì „ëµ"><a href="#ë°ì´í„°-ê±°ë²„ë„ŒìŠ¤-ì „ëµ" class="headerlink" title="ë°ì´í„° ê±°ë²„ë„ŒìŠ¤ ì „ëµ"></a>ë°ì´í„° ê±°ë²„ë„ŒìŠ¤ ì „ëµ</h1><ul><li><strong>Responsible AI í”„ë ˆì„ì›Œí¬</strong>: ê³µì •ì„±Â·íˆ¬ëª…ì„±Â·ì±…ì„ì„± ì§€í‘œ ìš´ì˜, <strong>GenAI í¸í–¥&#x2F;ë¶€ì‘ìš© ëª¨ë‹ˆí„°ë§</strong></li><li><strong>ì¡°ì§ êµ¬ì¡°</strong>: ë°ì´í„° ê±°ë²„ë„ŒìŠ¤ ìœ„ì›íšŒ, <strong>Data Steward&#x2F;Owner&#x2F;Custodian</strong> ì—­í•  ì •ì˜</li><li><strong>ë°ì´í„° ê³µìœ </strong>: ë‚´ë¶€ ë³´ì•ˆ ê³µìœ í˜‘ì•½, <strong>ê°€ìƒí™”&#x2F;í˜ë”ë ˆì´ì…˜</strong>ìœ¼ë¡œ <strong>ì†Œìœ ê¶Œ ìœ ì§€+ì ‘ê·¼ì„± ì œê³µ</strong></li><li><strong>ë¬¸í™”</strong>: ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •, ê³µë™ ê±°ë²„ë„ŒìŠ¤ ë¬¸í™”</li></ul><h2 id="ğŸ“Œ-Data-Owner"><a href="#ğŸ“Œ-Data-Owner" class="headerlink" title="ğŸ“Œ Data Owner"></a>ğŸ“Œ Data Owner</h2><ul><li><strong>ì •ì˜</strong>: ë°ì´í„°ì˜ ìµœì¢… ì±…ì„ì (business ì±…ì„).</li><li><strong>ì£¼ìš” ì—­í• </strong>:<ul><li>ë°ì´í„°ê°€ <strong>ì •í™•í•˜ê³  ì ì ˆíˆ ì‚¬ìš©</strong>ë˜ëŠ”ì§€ ë³´ì¥.</li><li>ë°ì´í„° ì‚¬ìš© ëª©ì , ë³´ì¡´ ê¸°ê°„, ë³´ì•ˆ ìš”êµ¬ì‚¬í•­ ë“± <strong>ì •ì±…ì  ê²°ì •</strong> ë‹´ë‹¹.</li><li>ê·œì œ ë° ë²•ì  ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•˜ë„ë¡ ë³´ì¥.</li></ul></li><li><strong>ì˜ˆì‹œ</strong>: ê¸ˆìœµíšŒì‚¬ì—ì„œ ê³ ê° ë°ì´í„°ì˜ OwnerëŠ” <strong>Compliance íŒ€ì¥</strong> ë˜ëŠ” <strong>ë°ì´í„° ì±…ì„ ë¶€ì„œì¥</strong>.</li></ul><hr><h2 id="ğŸ“Œ-Data-Steward"><a href="#ğŸ“Œ-Data-Steward" class="headerlink" title="ğŸ“Œ Data Steward"></a>ğŸ“Œ Data Steward</h2><ul><li><strong>ì •ì˜</strong>: Data Ownerê°€ ì •í•œ ì •ì±…ì„ <strong>ì‹¤ì œ ê´€ë¦¬í•˜ê³  ì‹¤í–‰</strong>í•˜ëŠ” ì‚¬ëŒ.</li><li><strong>ì£¼ìš” ì—­í• </strong>:<ul><li>ë°ì´í„°ì˜ <strong>í’ˆì§ˆ ê´€ë¦¬</strong> (ì •í™•ì„±, ì¼ê´€ì„±, ìµœì‹ ì„±).</li><li>ë°ì´í„° í‘œì¤€, ì •ì˜, ë©”íƒ€ë°ì´í„° ê´€ë¦¬.</li><li>ì‚¬ìš©ìë“¤ì´ ë°ì´í„°ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ê°€ì´ë“œ ì œê³µ.</li></ul></li><li><strong>ì˜ˆì‹œ</strong>: ë°ì´í„° í’ˆì§ˆíŒ€, ë°ì´í„° ê±°ë²„ë„ŒìŠ¤ íŒ€ì›.</li></ul><hr><h2 id="ğŸ“Œ-Data-Custodian"><a href="#ğŸ“Œ-Data-Custodian" class="headerlink" title="ğŸ“Œ Data Custodian"></a>ğŸ“Œ Data Custodian</h2><ul><li><strong>ì •ì˜</strong>: ë°ì´í„°ë¥¼ <strong>ê¸°ìˆ ì ìœ¼ë¡œ ë³´ê´€Â·ìš´ì˜</strong>í•˜ëŠ” ì‚¬ëŒ.</li><li><strong>ì£¼ìš” ì—­í• </strong>:<ul><li>ë°ì´í„° ì €ì¥ì†Œ(DB, Data Lake, Warehouse) <strong>ë³´ì•ˆÂ·ë°±ì—…Â·ê¶Œí•œ ê´€ë¦¬</strong>.</li><li>ì¸í”„ë¼, ì ‘ê·¼ ì œì–´, ì•”í˜¸í™” ë“± ê¸°ìˆ ì  ê´€ë¦¬.</li><li>Data Owner&#x2F;Stewardì˜ ì •ì±…ì´ ê¸°ìˆ ì ìœ¼ë¡œ ì ìš©ë˜ë„ë¡ ë³´ì¥.</li></ul></li><li><strong>ì˜ˆì‹œ</strong>: DBA(Database Admin), í´ë¼ìš°ë“œ ì—”ì§€ë‹ˆì–´, ë³´ì•ˆíŒ€.</li></ul><h2 id="âœ…-ì„¸-ì—­í• ì˜-ì°¨ì´-ìš”ì•½"><a href="#âœ…-ì„¸-ì—­í• ì˜-ì°¨ì´-ìš”ì•½" class="headerlink" title="âœ… ì„¸ ì—­í• ì˜ ì°¨ì´ ìš”ì•½"></a>âœ… ì„¸ ì—­í• ì˜ ì°¨ì´ ìš”ì•½</h2><table><thead><tr><th>ì—­í• </th><th>ì±…ì„ ì˜ì—­</th><th>ì£¼ìš” ì´ˆì </th><th>ì˜ˆì‹œ ì§ë¬´</th></tr></thead><tbody><tr><td><strong>Data Owner</strong></td><td>ë°ì´í„°ì— ëŒ€í•œ <strong>ë¹„ì¦ˆë‹ˆìŠ¤ì  ì±…ì„</strong></td><td>ë²•ì &#x2F;ê·œì œ ì¤€ìˆ˜, ì •ì±… ìˆ˜ë¦½</td><td>Compliance ì±…ì„ì</td></tr><tr><td><strong>Data Steward</strong></td><td>ë°ì´í„°ì˜ <strong>ìš´ì˜ì  ê´€ë¦¬</strong></td><td>í’ˆì§ˆ, í‘œì¤€, ì •ì˜ ê´€ë¦¬</td><td>ë°ì´í„° ê±°ë²„ë„ŒìŠ¤ íŒ€</td></tr><tr><td><strong>Data Custodian</strong></td><td>ë°ì´í„°ì˜ <strong>ê¸°ìˆ ì  ê´€ë¦¬</strong></td><td>ë³´ì•ˆ, ì €ì¥, ì ‘ê·¼ ì œì–´</td><td>DBA, í´ë¼ìš°ë“œ ì—”ì§€ë‹ˆì–´</td></tr></tbody></table><p>ğŸ‘‰ ì‰½ê²Œ ë§í•˜ë©´:  </p><ul><li><strong>Owner</strong> &#x3D; â€œì´ ë°ì´í„°ì˜ ì£¼ì¸ì€ ëˆ„êµ¬ì¸ê°€?â€  </li><li><strong>Steward</strong> &#x3D; â€œë°ì´í„°ë¥¼ ì˜ ê´€ë¦¬í•˜ê³  ìˆëŠ”ê°€?â€  </li><li><strong>Custodian</strong> &#x3D; â€œë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ë³´ê´€í•˜ê³  ìˆëŠ”ê°€?â€</li></ul><hr><h1 id="í•µì‹¬-ë°ì´í„°-ê´€ë¦¬-ê°œë…"><a href="#í•µì‹¬-ë°ì´í„°-ê´€ë¦¬-ê°œë…" class="headerlink" title="í•µì‹¬ ë°ì´í„° ê´€ë¦¬ ê°œë…"></a>í•µì‹¬ ë°ì´í„° ê´€ë¦¬ ê°œë…</h1><ul><li><strong>ìˆ˜ëª…ì£¼ê¸°</strong>: ìˆ˜ì§‘ â†’ ì²˜ë¦¬ â†’ ì €ì¥ â†’ ì†Œë¹„ â†’ ë³´ê´€</li><li><strong>ë¡œê·¸</strong>: ì…ë ¥&#x2F;ì¶œë ¥, ì„±ëŠ¥, ì‹œìŠ¤í…œ ì´ë²¤íŠ¸ ì¶”ì </li><li><strong>ë°ì´í„° ë ˆì§€ë˜ì‹œ</strong>: ì €ì¥&#x2F;ì²˜ë¦¬ ìœ„ì¹˜(ë²•Â·í”„ë¼ì´ë²„ì‹œ, <strong>ë°ì´í„°-ì—°ì‚° ê·¼ì ‘ì„±</strong>)</li><li><strong>ëª¨ë‹ˆí„°ë§</strong>: í’ˆì§ˆ, ì´ìƒÂ·ë“œë¦¬í”„íŠ¸ íƒì§€</li><li><strong>ë¶„ì„</strong>: í†µê³„&#x2F;ì‹œê°í™”&#x2F;íƒìƒ‰</li><li><strong>ë³´ì¡´</strong>: ê·œì œ, ì¬í•™ìŠµ íˆìŠ¤í† ë¦¬, ë¹„ìš© ê³ ë ¤</li></ul><h3 id="ë°ì´í„°-ë¼ì¸ë¦¬ì§€-ì¶œì²˜Â·ì´ë ¥"><a href="#ë°ì´í„°-ë¼ì¸ë¦¬ì§€-ì¶œì²˜Â·ì´ë ¥" class="headerlink" title="ë°ì´í„° ë¼ì¸ë¦¬ì§€(ì¶œì²˜Â·ì´ë ¥)"></a>ë°ì´í„° ë¼ì¸ë¦¬ì§€(ì¶œì²˜Â·ì´ë ¥)</h3><ul><li><strong>ì¶œì²˜ í‘œì‹œ</strong>(ë°ì´í„°ì…‹&#x2F;DB&#x2F;ê¸°íƒ€, ë¼ì´ì„ ìŠ¤Â·ì´ìš©ì•½ê´€)</li><li><strong>ìˆ˜ì§‘Â·ì •ì œÂ·ì „ì²˜ë¦¬ ê³¼ì •</strong> ë¬¸ì„œí™”, <strong>ì¹´íƒˆë¡œê·¸í™”</strong>ë¡œ ì¶”ì ì„±Â·ì±…ì„ì„± ê°•í™”</li></ul><p align="center">  <img src="/images/aws_basic_210.png" width="80%"></p>------------------------------------------------------------------------<h1 id="AI-ì‹œìŠ¤í…œ-ë³´ì•ˆÂ·í”„ë¼ì´ë²„ì‹œ"><a href="#AI-ì‹œìŠ¤í…œ-ë³´ì•ˆÂ·í”„ë¼ì´ë²„ì‹œ" class="headerlink" title="AI ì‹œìŠ¤í…œ ë³´ì•ˆÂ·í”„ë¼ì´ë²„ì‹œ"></a>AI ì‹œìŠ¤í…œ ë³´ì•ˆÂ·í”„ë¼ì´ë²„ì‹œ</h1><h2 id="ìœ„í˜‘-íƒì§€"><a href="#ìœ„í˜‘-íƒì§€" class="headerlink" title="ìœ„í˜‘ íƒì§€"></a>ìœ„í˜‘ íƒì§€</h2><ul><li>ê°€ì§œ ì½˜í…ì¸ , ì¡°ì‘ ë°ì´í„°, ìë™í™” ê³µê²© íƒì§€</li><li>ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½&#x2F;ì‚¬ìš©ì í–‰íƒœ ë“± <strong>AI ê¸°ë°˜ íƒì§€</strong> ì ìš©</li></ul><h2 id="ì·¨ì•½ì -ê´€ë¦¬"><a href="#ì·¨ì•½ì -ê´€ë¦¬" class="headerlink" title="ì·¨ì•½ì  ê´€ë¦¬"></a>ì·¨ì•½ì  ê´€ë¦¬</h2><ul><li>ì†Œí”„íŠ¸ì›¨ì–´ ë²„ê·¸&#x2F;ëª¨ë¸ ì•½ì  ì ê²€</li><li><strong>ë³´ì•ˆ ì ê²€Â·ì¹¨íˆ¬ í…ŒìŠ¤íŠ¸Â·ì½”ë“œ ë¦¬ë·°</strong>, <strong>íŒ¨ì¹˜&#x2F;ì—…ë°ì´íŠ¸</strong> ì ˆì°¨</li></ul><h2 id="ì¸í”„ë¼-ë³´í˜¸"><a href="#ì¸í”„ë¼-ë³´í˜¸" class="headerlink" title="ì¸í”„ë¼ ë³´í˜¸"></a>ì¸í”„ë¼ ë³´í˜¸</h2><ul><li>í´ë¼ìš°ë“œ&#x2F;ì—£ì§€&#x2F;ë°ì´í„° ì €ì¥ì†Œ ë³´ì•ˆ</li><li><strong>ì ‘ê·¼í†µì œ</strong>, <strong>ë„¤íŠ¸ì›Œí¬ ë¶„ë¦¬</strong>, <strong>ì•”í˜¸í™”</strong>, <strong>ì¥ì•  ë‚´ì„±</strong></li></ul><h2 id="í”„ë¡¬í”„íŠ¸-ì¸ì ì…˜-ëŒ€ì‘"><a href="#í”„ë¡¬í”„íŠ¸-ì¸ì ì…˜-ëŒ€ì‘" class="headerlink" title="í”„ë¡¬í”„íŠ¸ ì¸ì ì…˜ ëŒ€ì‘"></a>í”„ë¡¬í”„íŠ¸ ì¸ì ì…˜ ëŒ€ì‘</h2><ul><li><strong>í•„í„°ë§&#x2F;ì •í™”&#x2F;ê²€ì¦</strong> ê°€ë“œë ˆì¼</li><li><strong>ì •ì±… ìš°íšŒ ì‹œë‚˜ë¦¬ì˜¤</strong> í…ŒìŠ¤íŠ¸(ë ˆë“œíŒ€), ì•ˆì „ ì¶œë ¥ ì •ì±…</li></ul><p align="center">  <img src="/images/aws_basic_211.png" width="80%"></p><h2 id="ì•”í˜¸í™”Â·í‚¤ê´€ë¦¬"><a href="#ì•”í˜¸í™”Â·í‚¤ê´€ë¦¬" class="headerlink" title="ì•”í˜¸í™”Â·í‚¤ê´€ë¦¬"></a>ì•”í˜¸í™”Â·í‚¤ê´€ë¦¬</h2><ul><li>ì €ì¥&#x2F;ì „ì†¡ <strong>ì•”í˜¸í™”</strong>, <strong>KMS ë“± í‚¤ë³´í˜¸</strong> ì—„ê²© ìš´ì˜</li></ul><hr><h1 id="ìš´ì˜-ëª¨ë‹ˆí„°ë§-ëª¨ë¸-ì¸í”„ë¼"><a href="#ìš´ì˜-ëª¨ë‹ˆí„°ë§-ëª¨ë¸-ì¸í”„ë¼" class="headerlink" title="ìš´ì˜ ëª¨ë‹ˆí„°ë§(ëª¨ë¸ &amp; ì¸í”„ë¼)"></a>ìš´ì˜ ëª¨ë‹ˆí„°ë§(ëª¨ë¸ &amp; ì¸í”„ë¼)</h1><ul><li><strong>ì •í™•ë„(Accuracy)</strong>, <strong>ì •ë°€ë„(Precision)</strong>, <strong>ì¬í˜„ìœ¨(Recall)</strong>, <strong>F1</strong></li><li><strong>ì§€ì—°ì‹œê°„</strong>(ì‘ë‹µ), <strong>CPU&#x2F;GPU&#x2F;ë„¤íŠ¸ì›Œí¬&#x2F;ìŠ¤í† ë¦¬ì§€</strong> ì§€í‘œ</li><li><strong>ì‹œìŠ¤í…œ ë¡œê·¸</strong>, <strong>í¸í–¥&#x2F;ê³µì •ì„±</strong>, <strong>ê·œì œÂ·ì •ì±… ì¤€ìˆ˜</strong></li></ul><blockquote><p>ğŸ“ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong></p><ul><li><strong>ì •ë°€ë„ vs ì¬í˜„ìœ¨</strong>: ë¶ˆê· í˜• ë°ì´í„°(ì‚¬ê¸°íƒì§€)ì—ì„œ <strong>F1</strong>ì´ ê· í˜• ì§€í‘œë¡œ ìì£¼ ì“°ì„.</li><li>ìš´ì˜ ì¤‘ <strong>ë°ì´í„°&#x2F;ëª¨ë¸ ë“œë¦¬í”„íŠ¸</strong> â†’ ì¬í•™ìŠµ ë˜ëŠ” í”¼ì²˜&#x2F;ì •ì±… ì¬ì ê²€.</li></ul></blockquote><hr><h1 id="AWS-ê³µìœ ì±…ì„ëª¨ë¸-Shared-Responsibility"><a href="#AWS-ê³µìœ ì±…ì„ëª¨ë¸-Shared-Responsibility" class="headerlink" title="AWS ê³µìœ ì±…ì„ëª¨ë¸(Shared Responsibility)"></a>AWS ê³µìœ ì±…ì„ëª¨ë¸(Shared Responsibility)</h1><ul><li><strong>AWS(í´ë¼ìš°ë“œì˜ ë³´ì•ˆ)</strong>: ì¸í”„ë¼&#x2F;í•˜ì´í¼ë°”ì´ì €&#x2F;ì‹œì„¤&#x2F;ë„¤íŠ¸ì›Œí¬ ë° <strong>ê´€ë¦¬í˜• ì„œë¹„ìŠ¤</strong>ì˜ ë³´ì•ˆ</li><li><strong>ê³ ê°(í´ë¼ìš°ë“œ ë‚´ ë³´ì•ˆ)</strong>: <strong>ë°ì´í„° ê´€ë¦¬, ì ‘ê·¼ì œì–´, ê°€ë“œë ˆì¼, ì•”í˜¸í™”</strong> ë“± ì• í”Œë¦¬ì¼€ì´ì…˜ ì¸¡</li><li><strong>ê³µìœ  í†µì œ</strong>: íŒ¨ì¹˜&#x2F;êµ¬ì„±&#x2F;ë³´ì•ˆ ì¸ì‹Â·êµìœ¡</li></ul><blockquote><p>ğŸ“Œ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong></p><ul><li><strong>Bedrock&#x2F;SageMaker ê°™ì€ ê´€ë¦¬í˜• ì„œë¹„ìŠ¤</strong>ë¼ë„ <strong>ë°ì´í„°Â·ì ‘ê·¼Â·ê°€ë“œë ˆì¼</strong>ì€ ê³ ê° ì±…ì„.</li><li><strong>KMS, IAM, CloudTrail</strong>ê³¼ì˜ ì—°ê³„ ì±…ì„ êµ¬ë¶„ ì´í•´.</li></ul></blockquote><p align="center">  <img src="/images/aws_basic_212.png" width="80%"></p>------------------------------------------------------------------------<h1 id="ë³´ì•ˆí˜•-ë°ì´í„°-ì—”ì§€ë‹ˆì–´ë§-ëª¨ë²”ì‚¬ë¡€"><a href="#ë³´ì•ˆí˜•-ë°ì´í„°-ì—”ì§€ë‹ˆì–´ë§-ëª¨ë²”ì‚¬ë¡€" class="headerlink" title="ë³´ì•ˆí˜• ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ëª¨ë²”ì‚¬ë¡€"></a>ë³´ì•ˆí˜• ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ëª¨ë²”ì‚¬ë¡€</h1><ul><li><strong>ë°ì´í„° í’ˆì§ˆ</strong>: ì™„ì „ì„±Â·ì •í™•ì„±Â·ì ì‹œì„±Â·ì¼ê´€ì„± <strong>í”„ë¡œíŒŒì¼ë§Â·ëª¨ë‹ˆí„°ë§</strong></li><li><strong>ë¼ì¸ë¦¬ì§€</strong>ì™€ <strong>ê°ì‚¬ ì¶”ì </strong> ìœ ì§€</li><li><strong>PETs(Privacy-Enhancing Tech)</strong>: ë§ˆìŠ¤í‚¹&#x2F;ë‚œë…í™”, <strong>ì•”í˜¸í™”&#x2F;í† í°í™”</strong></li><li><strong>ì ‘ê·¼í†µì œ</strong>: ëª…í™•í•œ ì •ì±…, <strong>RBAC&#x2F;ì„¸ë¶„ê¶Œí•œ</strong>, <strong>SSO&#x2F;MFA&#x2F;IAM</strong>, ì ‘ê·¼ ë¡œê¹…Â·ì£¼ê¸° ì ê²€(<strong>ìµœì†Œê¶Œí•œ</strong>)</li><li><strong>ë¬´ê²°ì„±</strong>: ë°±ì—…&#x2F;ë³µêµ¬ ì „ëµ, í†µì œ ì ê²€Â·í…ŒìŠ¤íŠ¸</li></ul><hr><h1 id="ìƒì„±í˜•-AI-ë³´ì•ˆ-ìŠ¤ì½”í•‘-ë§¤íŠ¸ë¦­ìŠ¤-ìš”ì•½"><a href="#ìƒì„±í˜•-AI-ë³´ì•ˆ-ìŠ¤ì½”í•‘-ë§¤íŠ¸ë¦­ìŠ¤-ìš”ì•½" class="headerlink" title="ìƒì„±í˜• AI ë³´ì•ˆ ìŠ¤ì½”í•‘ ë§¤íŠ¸ë¦­ìŠ¤(ìš”ì•½)"></a>ìƒì„±í˜• AI ë³´ì•ˆ ìŠ¤ì½”í•‘ ë§¤íŠ¸ë¦­ìŠ¤(ìš”ì•½)</h1><ul><li>GenAI ì•±ì„ <strong>ì†Œìœ Â·ì±…ì„ ìˆ˜ì¤€</strong>ì— ë”°ë¼ 5ë‹¨ê³„ë¡œ ë¶„ë¥˜:<ol><li><strong>ì†Œë¹„ì ì•±</strong>(ê³µê°œ GenAI ì‚¬ìš©) â†’ ì†Œìœ  ë‚®ìŒ</li><li><strong>ì—”í„°í”„ë¼ì´ì¦ˆ SaaS ê¸°ëŠ¥ í™œìš©</strong>(Einstein GPT ë“±)</li><li><strong>ì‚¬ì „í•™ìŠµ ëª¨ë¸ í™œìš©</strong>(Bedrock BM)</li><li><strong>íŒŒì¸íŠœë‹ ëª¨ë¸</strong>(Bedrock ì»¤ìŠ¤í…€, JumpStart)</li><li><strong>ì§ì ‘ í•™ìŠµ ëª¨ë¸</strong>(SageMaker í›ˆë ¨) â†’ ì†Œìœ  ë†’ìŒ</li></ol></li><li>ë‹¨ê³„ê°€ ì˜¬ë¼ê°ˆìˆ˜ë¡ <strong>ê±°ë²„ë„ŒìŠ¤&#x2F;ë²•Â·í”„ë¼ì´ë²„ì‹œ&#x2F;ë¦¬ìŠ¤í¬ í†µì œ</strong> ì±…ì„ì´ ì»¤ì§.</li></ul><blockquote><p>ğŸ“ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong></p><ul><li><strong>íŒŒì¸íŠœë‹ ë„ì… ì‹œ</strong> ë°ì´í„° ê±°ë²„ë„ŒìŠ¤Â·ë³´ì•ˆÂ·ê·œì œ ë¶€ë‹´ <strong>ìƒìŠ¹</strong>.</li><li><strong>Self-host&#x2F;Training</strong>ì€ ì±…ì„Â·ë¹„ìš©Â·ë¦¬ìŠ¤í¬ <strong>ìµœëŒ€</strong>.</li></ul></blockquote><p align="center">  <img src="/images/aws_basic_213.png" width="80%"></p>------------------------------------------------------------------------<h1 id="MLOps-ë¨¸ì‹ ëŸ¬ë‹-ìš´ì˜"><a href="#MLOps-ë¨¸ì‹ ëŸ¬ë‹-ìš´ì˜" class="headerlink" title="MLOps(ë¨¸ì‹ ëŸ¬ë‹ ìš´ì˜)"></a>MLOps(ë¨¸ì‹ ëŸ¬ë‹ ìš´ì˜)</h1><ul><li><strong>ê°œë°œâ†’ë°°í¬â†’ê°ì‹œâ†’ì¬í•™ìŠµ</strong>ì„ <strong>ìë™Â·ë°˜ë³µ</strong></li><li><strong>í•µì‹¬ ì›ì¹™</strong><ul><li><strong>ë²„ì „ê´€ë¦¬</strong>: ë°ì´í„°&#x2F;ì½”ë“œ&#x2F;ëª¨ë¸ ë¡¤ë°± ê°€ëŠ¥</li><li><strong>ìë™í™”</strong>: ìˆ˜ì§‘Â·ì „ì²˜ë¦¬Â·í•™ìŠµÂ·ê²€ì¦Â·ë°°í¬ íŒŒì´í”„ë¼ì¸</li><li><strong>CI</strong>: ëª¨ë¸ í…ŒìŠ¤íŠ¸ ìë™í™”</li><li><strong>CD</strong>: í”„ë¡œë•ì…˜ ë°°í¬ ìë™í™”</li><li><strong>ì§€ì† ì¬í•™ìŠµÂ·ëª¨ë‹ˆí„°ë§</strong>: ë“œë¦¬í”„íŠ¸Â·í’ˆì§ˆ ê°ì‹œ</li></ul></li></ul><h3 id="ì „í˜•ì ì¸-íŒŒì´í”„ë¼ì¸"><a href="#ì „í˜•ì ì¸-íŒŒì´í”„ë¼ì¸" class="headerlink" title="ì „í˜•ì ì¸ íŒŒì´í”„ë¼ì¸"></a>ì „í˜•ì ì¸ íŒŒì´í”„ë¼ì¸</h3><ol><li><strong>ë°ì´í„° ì¤€ë¹„</strong>(ETL&#x2F;Feature)</li><li><strong>ëª¨ë¸ ë¹Œë“œ&#x2F;í•™ìŠµ</strong></li><li><strong>í‰ê°€&#x2F;ì„ ì •</strong></li><li><strong>ë°°í¬(ìŠ¹ì¸Â·ìŠ¹ê¸‰)</strong></li><li><strong>ëª¨ë‹ˆí„°ë§&#x2F;ê²½ë³´ â†’ ì¬í•™ìŠµ ë£¨í”„</strong></li></ol><p align="center">  <img src="/images/aws_basic_215.png" width="80%"></p><blockquote><p>ğŸ§ª <strong>AWS ì—°ê³„ ì˜ˆì‹œ</strong></p><ul><li><strong>SageMaker Pipelines&#x2F;Model Registry&#x2F;Model Monitor</strong>, <strong>EventBridge + CodePipeline&#x2F;CodeBuild</strong>, <strong>CloudWatch</strong>, <strong>Step Functions</strong></li></ul></blockquote><h2 id="Phases-of-Machine-Learning-Project"><a href="#Phases-of-Machine-Learning-Project" class="headerlink" title="Phases of Machine Learning Project"></a>Phases of Machine Learning Project</h2><p align="center">  <img src="/images/aws_basic_214.png" width="80%"></p><hr><h2 id="ìš”ì•½-ì²´í¬ë¦¬ìŠ¤íŠ¸-ì‹œí—˜-ëŒ€ë¹„"><a href="#ìš”ì•½-ì²´í¬ë¦¬ìŠ¤íŠ¸-ì‹œí—˜-ëŒ€ë¹„" class="headerlink" title="ìš”ì•½ ì²´í¬ë¦¬ìŠ¤íŠ¸(ì‹œí—˜ ëŒ€ë¹„)"></a>ìš”ì•½ ì²´í¬ë¦¬ìŠ¤íŠ¸(ì‹œí—˜ ëŒ€ë¹„)</h2><ul><li><strong>Responsible AI</strong>: ê³µì •ì„±Â·ì„¤ëª…ê°€ëŠ¥ì„±Â·íˆ¬ëª…ì„±Â·ì•ˆì „Â·í†µì œ ê°€ëŠ¥ì„±</li><li><strong>ê±°ë²„ë„ŒìŠ¤ ì²´ê³„</strong>: ìœ„ì›íšŒ, R&amp;R, ì •ì±…, ë¦¬ë·°&#x2F;ìŠ¹ì¸, íˆ¬ëª…ì„±, êµìœ¡</li><li><strong>ë°ì´í„° ê±°ë²„ë„ŒìŠ¤</strong>: ë¼ì¸ë¦¬ì§€, ë ˆì§€ë˜ì‹œ, í’ˆì§ˆ&#x2F;ë³´ì¡´, ê³µìœ &#x2F;í˜ë”ë ˆì´ì…˜</li><li><strong>ë³´ì•ˆ</strong>: í”„ë¡¬í”„íŠ¸ ì¸ì ì…˜ ê°€ë“œë ˆì¼, ì•”í˜¸í™”Â·í‚¤ê´€ë¦¬, ì·¨ì•½ì Â·íŒ¨ì¹˜, ì¸í”„ë¼ ë³´í˜¸</li><li><strong>ëª¨ë‹ˆí„°ë§ ì§€í‘œ</strong>: Accuracy&#x2F;Precision&#x2F;Recall&#x2F;F1&#x2F;Latency + ì¸í”„ë¼</li><li><strong>ê³µìœ ì±…ì„</strong>: í´ë¼ìš°ë“œ <strong>of</strong> vs <strong>in</strong> ë³´ì•ˆ êµ¬ë¶„</li><li><strong>MLOps</strong>: ë²„ì „Â·ìë™í™”Â·CI&#x2F;CDÂ·ì¬í•™ìŠµÂ·ëª¨ë‹ˆí„°ë§</li><li><strong>GenAI ìŠ¤ì½”í”„</strong>: Pre-trained â†” Fine-tuned â†” Self-trainedì— ë”°ë¥¸ <strong>ì±…ì„ ì¦ê°€</strong></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ê±°ë²„ë„ŒìŠ¤-ì»´í”Œë¼ì´ì–¸ìŠ¤ì˜-ì¤‘ìš”ì„±&quot;&gt;&lt;a href=&quot;#ê±°ë²„ë„ŒìŠ¤-ì»´í”Œë¼ì´ì–¸ìŠ¤ì˜-ì¤‘ìš”ì„±&quot; class=&quot;headerlink&quot; title=&quot;ê±°ë²„ë„ŒìŠ¤ &amp;amp; ì»´í”Œë¼ì´ì–¸ìŠ¤ì˜ ì¤‘ìš”ì„±&quot;&gt;&lt;/a&gt;ê±°ë²„ë„ŒìŠ¤ &amp;amp; ì»´í”Œë¼ì´ì–¸ìŠ¤ì˜ ì¤‘ìš”ì„±&lt;/h1&gt;&lt;ul&gt;
</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(41) - Governance &amp; Compliance in AI</title>
    <link href="https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-41/"/>
    <id>https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-41/</id>
    <published>2025-09-02T19:29:51.000Z</published>
    <updated>2025-12-03T18:23:48.555Z</updated>
    
    <content type="html"><![CDATA[<p><a id="top"></a></p><style>.toc-grid{  display:grid;  grid-template-columns:1fr 1fr; /* í™”ë©´ ë°˜ë°˜ */  gap:6px 20px;  align-items:start;}@media (max-width:760px){  .toc-grid{ grid-template-columns:1fr; }}/* ì„¹ì…˜ íƒ€ì´í‹€ì€ ë‘ ì¹¼ëŸ¼ ì „ì²´ë¥¼ ì°¨ì§€ */.toc-section{  grid-column:1 / -1;  margin:12px 0 6px;  font-size:1.1rem;  font-weight:700;}/* ë§í¬ ê³µí†µ ìŠ¤íƒ€ì¼ */.toc-grid a{ display:block; padding:2px 0; word-break:keep-all; }</style><div class="toc-grid"><h3 class="toc-section">ë‚´ ì†Œê°œ ë° ì „ë°˜ì ì¸ ì§ˆë¬¸</h3><a href="#a1">ë‚˜ì˜ ì†Œê°œ</a><a href="#a2">ì™œ ì´ì§í•˜ë‹ˆ?</a><a href="#a4">ë³´ì‰ì´ë€ ê·¸ë¦¬ê³  ì§€ì›ë™ê¸°?</a><a href="#recent-project">ìµœê·¼ í”„ë¡œì íŠ¸</a><a href="#data-warehouse-tech">ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ ê¸°ìˆ </a><a href="#dq-multi-point-good">ë°ì´í„° í’ˆì§ˆê´€ë¦¬ - ì—¬ëŸ¬í¬ì¸íŠ¸ ê²€ì¦ &amp; good data</a><a href="#etl-design-ca7-glue">ETL ì„¤ê³„ - CA7ì™€ Glue ì´ìš©</a><a href="#issue-data-volume">ì´ìŠˆ - ë°ì´í„° ë³¼ë¥¨ì¦ê°€ 3~4TB</a><a href="#issue-schema-change">ì´ìŠˆ - ìŠ¤í‚¤ë§ˆ ë³€ê²½</a><h3 class="toc-section">ë°ì´í„° í’ˆì§ˆê³¼ ë³´ì•ˆ</h3><a href="#dq-unit-test">ë°ì´í„° í’ˆì§ˆê´€ë¦¬ - ìœ ë‹›í…ŒìŠ¤íŠ¸</a><a href="#security-compliance">ë³´ì•ˆê³¼ ê·œì • (e.g. AWS, Azure)</a><h3 class="toc-section">ê¸°ìˆ  ë‚´ìš©</h3><a href="#alteryx-usage">Alteryx ì‚¬ìš©ê¸°ê°„</a><a href="#alteryx-definition">Alteryx ì •ì˜ ë° ì‚¬ìš©ì‚¬ë¡€</a><a href="#alteryx-limitations">Alteryx ë‹¨ì </a><a href="#teradata-usage">í…Œë¼ë°ì´í„° ì‚¬ìš©ê¸°ê°„</a><a href="#teradata-definition">í…Œë¼ë°ì´í„° ì •ì˜ ë° ì‚¬ìš©ì‚¬ë¡€</a><a href="#teradata-performance">í…Œë¼ë°ì´í„°ê°€ ë†’ì€ ì„±ëŠ¥ì„ ë°œíœ˜í• ìˆ˜ ìˆëŠ” ì´ìœ </a><a href="#teradata-pi">í…Œë¼ë°ì´í„°ì˜ Primary Index (PI) ì—­í• </a><a href="#teradata-skew">ë°íƒ€ë°ì´í„° ë°ì´í„° ë¶ˆê· í˜•ì„ ì–´ë–»ê²Œ í•´ê²°?</a><a href="#teradata-secondary-index">í…Œë¼ë°ì´í„°ì˜ Secondary Index ì´ë€</a><a href="#teradata-partition">Teradata íŒŒí‹°ì…˜</a><a href="#teradata-troubleshooting">í…Œë¼ë°ì´í„° ë¬¸ì œí•´ê²°</a><a href="#alteryx-teradata">Alteryxì™€ Teradata ì‚¬ìš©</a><a href="#neo4j">Neo4J ê´€ë ¨í•´ì„œ</a><h3 class="toc-section">í–‰ë™ ê·œì •</h3><a href="#manager-absence-decision">ë§¤ë‹ˆì €ê°€ ë¶€ì¬ì‹œ ê²°ì •í•´ì•¼í•  ê²½ìš°</a><a href="#team-disagreement-sla">íŒ€ì› ì˜ê²¬ ë‹¤ë¦„ - SLA 20ë¶„ ì§€ì—° - í’ˆì§ˆí•´ê²°</a><a href="#manager-disagreement-refresh-partition">ìƒì‚¬ ì˜ê²¬ ë‹¤ë¦„ - refresh only ë³€ê²½ëœ íŒŒí‹°ì…˜ë§Œ</a><a href="#diffent-personality">ë‹¤ë¥¸ ì„±í–¥ì˜ ì‚¬ëŒê³¼ í˜‘ë™</a><a href="#helped-teammate">íŒ€ë™ë£Œ ì„±ê³µì‹œí‚¤ê¸°</a><a href="#urgent-vs-important">ê¸‰í•œì¼ê³¼ ì¤‘ìš”í•œì¼ì˜ ìš°ì„ ìˆœìœ„ - ê¸‰í•œê²ƒ ë¨¼ì €</a><a href="#tech-challenge-1-5tb">ê¸°ìˆ  ë¬¸ì œ ë„ì „ - 1.5TB ì²˜ë¦¬</a><a href="#improvement-large-data">ê°œì„  ì‚¬ë¡€ - í° ë°ì´í„° ì²˜ë¦¬ (ìœ„ ë™ì¼)</a><a href="#production-connect-stop">ìƒì‚° ë¬¸ì œ - ì»¤ë„¥íŠ¸ Stop</a><a href="#process-improvement-connect-stop">ìë°œì  í”„ë¡œì„¸ìŠ¤ ê°œì„  - ì»¤ë„¥íŠ¸ Stop</a><a href="#kafka-realtime-connect-check">Kafka ì‹¤ì‹œê°„ ë°ì´í„°ì—ì„œ ê³ ë ¤í•  ë¶€ë¶„ - ì»¤ë„¥íŠ¸ ìƒíƒœí™•ì¸</a><a href="#quality-issue-currency">í’ˆì§ˆ ë¬¸ì œ - í†µí™”ë‹¨ìœ„ ì—ëŸ¬</a><a href="#failure-column-validation">ì‹¤íŒ¨,ì‹¤ìˆ˜ - ì»¬ëŸ¼ê²€ì¦X, í†µí™”ë‹¨ìœ„ ì—ëŸ¬</a><a href="#project-delay-schema-change">í”„ë¡œì íŠ¸ ì§€ì—° - ìŠ¤í‚¤ë§ˆ ë³€ê²½</a><a href="#team-lead-source-missing">íŒ€ ë¦¬ë“œ &amp; ì†”ì„  - ì†ŒìŠ¤ ì…ë ¥ ì•ˆë¨</a><a href="#team-lead-datatype-mismatch">ë¦¬ë”ì‹¶ ì‚¬ë¡€ - data type mismatch</a><a href="#above-and-beyond-responsibility">ì§€ì‹œë°›ì§€ì•Šì€ ì¼ - add load_date / ìƒì‚¬ ì˜ê²¬ë‹¤ë¦„ ë™ì¼</a><a href="#tight-schedule-pressure">íƒ€ì´íŠ¸í•œ ìŠ¤ì¼€ì¤„ &amp; ì••ë°• - ì¼ ë‚˜ëˆ„ê³  ëŒ€í™”, íŠ¸ë™</a><a href="#multi-national-collaboration">ì—¬ëŸ¬ ë¯¼ì¡± ê°™ì´ ê·¼ë¬´ - sync ë¯¸íŒ…, ë¯¸íŒ…ìš”ì•½</a><a href="#cross-team-collaboration">ë‹¤ë¥¸ íŒ€ í˜‘ì—… - ìš©ì–´ í†µì¼</a><a href="#customer-request">ê³ ê°ì´ ë§ˆì§€ë§‰ì— ë³€ê²½ìš”ì²­ì‹œ - ìŠ¤í‚¤ë§ˆë³€ê²½</a><a href="#customer-request-offen">ê³ ê°ì´ ìì£¼ ë³€ê²½ì‚¬í•­ì„ ìš”ì²­í• ë•Œ - ìš”ì²­ì„ ê·¸ë£¹í•‘í•¨</a><a href="#non-technical">ë¹„ê°œë°œìì—ê²Œ ê¸°ìˆ ì ì¸ ë‚´ìš©ì„ ì‰½ê²Œ ì„¤ëª…í•  ìˆ˜ ìˆë‚˜ìš”?</a><a href="#issue-spark-memory">ì´ìŠˆ - Spark memory ë¬¸ì œ</a><h3 class="toc-section">ETL / ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜</h3><a href="#data-orchestration">Data Orchestration - (CA7, Glue, Airflow)</a><a href="#etl-pipeline-optimization">ETL pipeline ìµœì í™” - SLA 6ì‹œ</a><a href="#aws-glue-experience">AWS Glue ì‚¬ìš©ê²½í—˜ - ETL services</a><a href="#no-current-glue">í˜„ì¬ glueë¥¼ ì‚¬ìš©í•˜ì§€ëŠ” ì•ŠëŠ”ë‹¤</a><h3 class="toc-section">ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤</h3><a href="#redshift-intro">Redshift ë€?</a><a href="#redshift-columnar">Redshift Columnar Storage</a><a href="#snowflake-advantages">Snowflake ì¥ì  (zero-copy, time travel)</a><a href="#databricks-experience">Databricks ì‚¬ìš©ê²½í—˜ - Anomaly detection</a><a href="#partition-strategy">íŒŒí‹°ì…˜ ì „ëµ</a><a href="#oracle-range-partitioning">ë°ì´í„° ëª¨ë¸ë§ & Architecture - ì˜¤ë¼í´ range partitioning<</a><a href="#data-normalization">ì •ê·œí™” vs ë¹„ì •ê·œí™”</a><a href="#star-snowflake-schema">Star &amp; Snowflake ìŠ¤í‚¤ë§ˆ</a><h3 class="toc-section">íŒŒì´ì¬/ìŠ¤íŒŒí¬/í•˜ë‘¡</h3><a href="#python-sql-spark">Python, SQL, Spark, PySpark</a><a href="#spark-hadoop-ingestion">ê²½í—˜ - ìŠ¤íŒŒí¬/í•˜ë‘¡ ingestion</a><a href="#aws-experience">ê²½í—˜ - AWS ë§ì´ ì‚¬ìš©í–ˆë‹ˆ?</a><a href="#strengths-weaknesses">ì¥ì ê³¼ ë‹¨ì </a><a href="#stress">ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ì–´ë–»ê²Œ í’‰ë‹ˆê¹Œ?</a><a href="#motto">ì‚¶ì˜ ëª¨í† ëŠ”?</a><a href="#powertech">íŒŒì›Œí…ì—ì„œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì‚¬ìš©</a><a href="#final-remarks">ë§ˆì§€ë§‰ìœ¼ë¡œ í•˜ê³  ì‹¶ì€ ë§</a></div><h3 id="a1">ë‚˜ì˜ ì†Œê°œ</h3>Thank you for having me for an interview and my name is Sunghwan ki but you can go by DannyI work as Data Engineer with 6 years experience in building ETL process, especially in the financial industry.Currently I lead the projects that use the Kafka, Oracle, and Spark where I focus on near real-time data processing and optimization.I primarily use Python to build data pipelines, and recently, I completed on a project where I built a data warehouse using AWS Glue and Redshift.Before joining PNC, I spent roughly seven years working in data analytics, where I primarily used Tableau and MySql to analyze the data<p>To better performance, I completed the Masterâ€™s degree in Data Science last year and also I hold the AWS certifications and continue to pursue additional cloud-related credentials to further strengthen my expertise</p><h3 id="a2">ì™œ ì´ì§í•˜ë‹ˆ?</h3>Iâ€™ve truly enjoyed my time at PNC and  Iâ€™ve spent over six years working on meaningful projects and improved my technical skills.  Now I feel I ready for a new challenge that allows me to expand further.  Technology is evolving faster than ever, and I want to keep learning and developing new skills.for me Itâ€™s not about leaving something behind â€” itâ€™s about taking the next step toward work Iâ€™m truly passionate about.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="a4">ë³´ì‰ì´ë€ ê·¸ë¦¬ê³  ì§€ì›ë™ê¸°</h3>Boeing is one of the worldâ€™s largest aerospace and defense companies. It designs and builds commercial airplanes like the 737 and 777.Also, Boeingâ€™s work connects people, supports global transportation, and contributes to national security and space exploration.That's why I applied to this company to builds products with real-world impact. <p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="recent-project">Recent project (ìµœê·¼ í”„ë¡œì íŠ¸)</h3>Currently, I am working on building a near real time pipeline that ingests kafka topic data into Oracle Exadata and then into Hadoop platform.In the past, stakeholders had to rely on the previous dayâ€™s data to make decisions. But now with this new pipeline, data from Kafka is ingested into Hadoop in every 10 minutes and then visualized through Tableau dashboards.This project significantly reduced data latency and helped business team to make faster decision.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="data-warehouse-tech">ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ ê¸°ìˆ  (e.g. Amazon Redshift, Snowflake ì‚¬ìš©ê²½í—˜)</h3>I have experience using Redshift to build the cloud data warehousing. In one of my project, I built an analytics pipeline to process and analyze mobile user log data. To achieve this, I designed a workflow where the logs data were first ingested into Amazon S3, and then processed using AWS Glue, which loaded the data into Redshift. Once the data was in Redshift, I used Amazon QuickSight to build interactive dashboards that visualized key user activity such as session duration, clickstream patterns, and device usage. This solution provided business stakeholders with actionable insights.In terms of Snowflake, I used it as a cloud data warehouse to support BI-driven insights. I connected Snowflake to ingest the S3 data by using snowpipe and then connected to Tableau to build interactive dashboards that visualized key metrics.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="dq-multi-point-good">ë°ì´í„° í’ˆì§ˆê´€ë¦¬ - ì—¬ëŸ¬í¬ì¸íŠ¸ ê²€ì¦ &amp; good data</h3>When it comes to data quality, I apply validation at multiple stages of the pipeline.During ingestion, I perform schema validation and basic checks such as null values, data types, and duplicates. As the data moves through transformations, I apply additional business-rule validations to ensure the results make sense before loading them into downstream systems.In addition, I worked closely with business team to define what â€œgood dataâ€ means for their use cases.  And we ensured that the dashboards in Tableau reflected clean, reliable information for decision-making.In one project, I worked with the fraud prevention team, where my role was to deliver data they could fully trust. For them, â€œgood dataâ€ meant accurate, up-to-date, and reliable information without duplication or errors. Because the quality of data directly impacted their fraud detection models, I focused not only on data delivery but also on maintaining high quality through validation and monitoring.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="etl-design-ca7-glue">ETL ì„¤ê³„ - CA7ì™€ Glue ì´ìš©</h3>Iâ€™ve designed and implemented both batch and near real-time ETL pipelines. For near real-time workloads, I built pipelines that ingest Kafka streaming data into Oracle Exadata and Hadoop every ten minutes. I used PySpark for transformations and I used the CA7, a mainframe-based scheduler, to orchestrate the dependencies across these jobs. CA7 ensured that each PySpark workflow ran in the correct sequence and at the right time and it was critical for the batch operations.I also have experience building cloud-native ETL solutions. In one project, I used AWS Glue studio to design the ETL workflows. Glueâ€™s built-in transformations, and job orchestration features made it easier to manage the logic. Iâ€™ve also worked with AWS EMR and Spark for larger-scale data processing and aggregation pipelines.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="issue-data-volume">ì´ìŠˆ - ë°ì´í„° ë³¼ë¥¨ì¦ê°€ 3~4TB </h3>One of the biggest challenges I faced recently was with a Kafka-to-Hadoop data pipeline, where Oracle Exadata was used as a staging area. Initially, the volume of data coming from Kafka was about 1 TB per day, but it suddenly increased to 3 or 4 TB per day. Even though the data was automatically deleted after being loaded into Hadoop, new data was coming in faster than it could be deleted, so Exadata started running out of space. To handle this, I increased the number of Spark jobs to speed up data movement into Hadoop. But this caused to slow down the Exadata and it created a bottleneck issue. Then I suddenly thought about compressing the data, and fortunately, I discovered that EXADATA has a built-in compression feature â€” and the best part is that the data doesnâ€™t need to be decompressed when itâ€™s moved to Hadoop. Using this compression method, I was able to reduce the data size by almost 70% in Exadata.  After that, I reduced the number of Spark jobs, which helped Exadata run better and stabilized the pipeline. That experience really taught me how to look at the problem from a different angle, and find a solution that improves both performance and efficiency.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="issue-schema-change">ì´ìŠˆ - ìŠ¤í‚¤ë§ˆ ë³€ê²½</h3>I remember there was a project that we were integrating data from multiple sources into a central data warehouse. The challenge was that one of the upstream systems frequently changed its schema without notice. And it caused our ETL jobs to fail and delayed reporting for business users. My responsibility was to make the pipeline more resilient so that these schema changes would not break the entire data flow. I implemented a schema validation and auto-adjustment process. Using PySpark, I built a job that compared incoming data schemas against our expected schema. If a non-critical column changed such as a new column being added, the pipeline could adapt automatically without failing. For critical mismatches, the system flagged the issue, generated incident, and provided fallback logic to continue processing the data. This reduced ETL job failures by more than 90% and ensured that the business team continued to receive the data even when upstream systems changed its schema unexpectedly.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h2 id="í’ˆì§ˆê³¼-ë³´ì•ˆ-ë‚´ìš©"><a href="#í’ˆì§ˆê³¼-ë³´ì•ˆ-ë‚´ìš©" class="headerlink" title="í’ˆì§ˆê³¼ ë³´ì•ˆ ë‚´ìš©"></a>í’ˆì§ˆê³¼ ë³´ì•ˆ ë‚´ìš©</h2><h3 id="dq-unit-test">ë°ì´í„° í’ˆì§ˆê´€ë¦¬ - ìœ ë‹›í…ŒìŠ¤íŠ¸</h3>I usually use Pytest for unit testing in Python. Itâ€™s simpler and more readable than the built-in unittest module, and it allows to write tests quickly without creating test classes. In Pytest, test functions simply start with test_, and I use the assert statement to verify the results.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pytest</span><br><span class="line"><span class="keyword">from</span> calculator <span class="keyword">import</span> add, divide  <span class="comment"># calculator.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_add</span>():</span><br><span class="line">    <span class="keyword">assert</span> add(<span class="number">2</span>, <span class="number">3</span>) == <span class="number">5</span></span><br><span class="line">    <span class="keyword">assert</span> add(-<span class="number">1</span>, <span class="number">1</span>) == <span class="number">0</span></span><br></pre></td></tr></table></figure><p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="quality-issue-currency">í’ˆì§ˆ ë¬¸ì œ - í†µí™”ë‹¨ìœ„ ì—ëŸ¬</h3>During a new ETL rollout, one of our reports was showing incorrect revenue numbers. After investigating, I found that the issue came from an inconsistent currency conversion in the transformation logic. I quickly fixed the script, reprocessed the data, and added the automated checks to compare daily results with historical trends. After that, the data became much more accurate, and the same issue never happened again. This experience reminded me how important it is to validate data thoroughly before going to production.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="security-compliance">ë³´ì•ˆê³¼ ê·œì • (AWS, Azure)</h3>In my current role, we have a dedicated security and compliance team that handles overall data governance. So if I need access to certain sensitive databases or tables, I first have to get approval from that team. This helps make sure only the right people can have an access to the data. On the data engineering side, I am responsible for protecting sensitive data during our ETL processes. That means identifying PII data and masking them, so even if someone sees the data, itâ€™s not readable. Actually, We strictly follow the principle of least privilege. We assign only the minimum required permissions.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h2 id="ê¸°ìˆ -ë‚´ìš©"><a href="#ê¸°ìˆ -ë‚´ìš©" class="headerlink" title="ê¸°ìˆ  ë‚´ìš©"></a>ê¸°ìˆ  ë‚´ìš©</h2><h3 id="alteryx-usage">Alteryx ì‚¬ìš©ê¸°ê°„</h3>I used Alteryx for about a year in the past, but these days I primarily work with AWS Glue Studio. When processing large datasets, I found that Alteryx tends to slow down because it is not optimized for big-data workloads. However, AWS Glue Studio runs on top of Apache Spark, so it provides much better performance and scalability for heavy ETL transformations.<h3 id="alteryx-definition">Alteryx ì •ì˜ ë° ì‚¬ìš©ì‚¬ë¡€</h3>Alteryx is a no-code data analytics platform that allows users to join and transform data quickly using a drag-and-drop workflow. I used Alteryx primarily for data preparation and automation tasksâ€”such as joining datasets, performing aggregations, and generating analytical outputs for business users. For exmaple, I created workflows that pulled data from MySQL and csv files, applied cleanup and transformation logic, and produced standardized outputs for Tableau dashboards. At that time, the workload was relatively small â€” around 50 to 100 MB of data per day â€” so it performed well without any issues.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="alteryx-limitations">Alteryx ë‹¨ì </h3>Alteryx tends to be slower when processing large datasets because it runs on local machine resources and doesnâ€™t scale horizontally like Spark or distributed cloud platforms. In my experience, workflows processing tens or hundreds of millions of records became slow or unstable. For that reason, I often moved heavy ETL workloads to AWS Glue or Spark<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="teradata-usage">í…Œë¼ë°ì´í„° ì‚¬ìš©ê¸°ê°„</h3>I have around two years of experience with Teradata, mainly using it with Hadoop system. In our setup, Hadoop stored large amounts of mobile user data, and Teradata accessed that data through QueryGrid and easily combine and query the data. We then connected Tableau to Teradata and set up an hourly refresh, so the dashboards always showed the latest mobile behavior insights.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="teradata-definition">í…Œë¼ë°ì´í„° ì •ì˜ ë° ì‚¬ìš©ì‚¬ë¡€</h3>Teradata is a massively parallel processing (MPP) relational database designed for large-scale data warehousing. I used Teradata for about two years, mainly for querying and analyzing large datasets and supporting ETL pipelines. Iâ€™ve used Teradata connectors like QueryGrid to work with Hadoop data. In my case, I use Spark for large-scale ETL processing, store the data in Hadoop platform. I mostly brought large datasets from Hadoop into Teradata so I could analyze them easily and fast.<h3 id="teradata-performance">í…Œë¼ë°ì´í„°ê°€ ë†’ì€ ì„±ëŠ¥ì„ ë°œíœ˜í• ìˆ˜ ìˆëŠ” ì´ìœ </h3>Teradata leverages an MPP architecture where data is distributed across multiple AMPs (Access Module Processors). Each AMP works independently to store and process its portion of data and it enables parallel execution. Because of this distribution mechanism, Teradata can handle large volumes of data with high performance.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="teradata-pi">í…Œë¼ë°ì´í„°ì˜ Primary Index (PI) ì—­í• </h3>A Primary Index determines how data is distributed across AMPs. Choosing the right PI is crucial because it ensures even data distribution. A well-chosen PI improves join performance and overall query efficiency. (Teradata ë‚´ë¶€ì—ì„œëŠ” ë°ì´í„°ë¥¼ ì €ì¥í•  ë•Œ Primary Index ì»¬ëŸ¼ì— í•´ì‹œ í•¨ìˆ˜ë¥¼ ì ìš©í•´ì„œ Hash Valueë¥¼ ë§Œë“¤ê³ , ê·¸ ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ì–´ë–¤ AMPì— ì €ì¥í• ì§€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.)<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> customer (</span><br><span class="line">    customer_id <span class="type">INTEGER</span>,</span><br><span class="line">    name <span class="type">VARCHAR</span>(<span class="number">100</span>)</span><br><span class="line">)</span><br><span class="line"><span class="keyword">PRIMARY</span> INDEX (customer_id);</span><br></pre></td></tr></table></figure><p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="teradata-skew">ë°íƒ€ë°ì´í„° ë°ì´í„° ë¶ˆê· í˜•ì„ ì–´ë–»ê²Œ í•´ê²°?</h3>Data skew occurs when data is unevenly distributed across AMPs, causing some AMPs to process significantly more data than others. This leads to slower query performance. To handle skew, I typically review PI selection, check for unique columns, or use a different distribution strategy. Sometimes, creating a multicolumn PI or using a HASHBY method can help balance the distribution.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> customer_new</span><br><span class="line"><span class="keyword">PRIMARY</span> INDEX (new_column)</span><br><span class="line"><span class="keyword">AS</span> customer</span><br><span class="line"><span class="keyword">WITH</span> <span class="keyword">NO</span> DATA;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT INTO</span> customer_new</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> customer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> customer;</span><br><span class="line"></span><br><span class="line">RENAME <span class="keyword">TABLE</span> customer_new <span class="keyword">TO</span> customer;</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># orders_stage : ìŠ¤í…Œì´ì§• í…Œì´ë¸”</span><br><span class="line"># orders_nopi : NoPI í…Œì´ë¸” (<span class="keyword">Primary</span> Index ì—†ìŒ)</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT INTO</span> orders_nopi</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> orders_stage</span><br><span class="line">HASH <span class="keyword">BY</span> customer_id;</span><br></pre></td></tr></table></figure><p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="teradata-secondary-index">í…Œë¼ë°ì´í„°ì˜ Secondary Index ì´ë€</h3>A Secondary Index is useful when frequently queried columns are not part of the Primary Index. It accelerates data access without redistributing data. However, because Secondary Indexes require additional maintenance, I usually add them only when a business-critical query pattern consistently needs optimization.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># SI ì¶”ê°€í•˜ê¸°</span><br><span class="line"><span class="keyword">ALTER TABLE</span> your_table_name</span><br><span class="line"><span class="keyword">ADD</span> INDEX (column_name);</span><br></pre></td></tr></table></figure><p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="teradata-partition">Teradata íŒŒí‹°ì…˜</h3>Partitioning allows tables to be divided into manageable segments, usually based on date. This improves query performance because Teradata only scans relevant partitions instead of the whole table. I commonly used date-based partitioning.<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> sales_daily (</span><br><span class="line">    order_id     <span class="type">INTEGER</span>,</span><br><span class="line">    order_date   <span class="type">DATE</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> RANGE_N(order_date <span class="operator">&gt;=</span> <span class="type">DATE</span> <span class="string">&#x27;2023-01-01&#x27;</span></span><br><span class="line">                     <span class="keyword">EACH</span> <span class="type">INTERVAL</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">DAY</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> sales</span><br><span class="line"><span class="keyword">WHERE</span> order_date <span class="operator">&gt;=</span> <span class="type">DATE</span> <span class="string">&#x27;2023-05-01&#x27;</span></span><br><span class="line">  <span class="keyword">AND</span> order_date <span class="operator">&lt;</span>  <span class="type">DATE</span> <span class="string">&#x27;2023-06-01&#x27;</span>;</span><br></pre></td></tr></table></figure><p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="teradata-troubleshooting">í…Œë¼ë°ì´í„° ë¬¸ì œí•´ê²°</h3>One of the most common issues I faced with Teradata was slow query performance when working with large tables, especially when the table wasnâ€™t partitioned. In those cases, Teradata had to scan the entire table, which made daily jobs take much longer than expected.To fix this, I added date-based partitions so Teradata only scanned the specific partition needed for each query. This small change made a big difference. the queries became much faster and more stable. It also helped reduce the load on the system and improved overall performance.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="alteryx-teradata">Alteryxì™€ Teradata ì‚¬ìš©</h3>I think ETL pipelines between Alteryx and Teradata are built using Alteryxâ€™s In-DB tools. Alteryx generates SQL and pushes all heavy transformations to the Teradata MPP engine, which handles large-scale joins and aggregations efficiently. Alteryx simply orchestrates the workflow, while Teradata performs the actual processing. This approach combines the ease of use of Alteryx with the scalability of Teradata.<h3 id="neo4j">Neo4J ê´€ë ¨í•´ì„œ</h3>Although I havenâ€™t used Neo4j in production, But Iâ€™m interested in graph databases. I would like to have the opportunity to learn and apply Neo4j in future projects.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h2 id="í–‰ë™-ë©´ì ‘-ì§ˆë¬¸"><a href="#í–‰ë™-ë©´ì ‘-ì§ˆë¬¸" class="headerlink" title="í–‰ë™ ë©´ì ‘ ì§ˆë¬¸"></a>í–‰ë™ ë©´ì ‘ ì§ˆë¬¸</h2><h3 id="manager-absence-decision">ë§¤ë‹ˆì €ê°€ ë¶€ì¬ì‹œ ê²°ì •í•´ì•¼í•  ê²½ìš°</h3>A few months ago, there is a configuration issue during a production release. And it caused to delay the data. At that time, my manager was not available, but the fix required his approval. I quickly analyzed the impact, documented the issue and solution, and escalated it to the department lead for temporary approval. I clearly communicated the risk and rollback plan, implemented the fix, and monitored results until the system was stable. When my manager returned, I shared a full summary and documentation for review. This taught me how to act responsibly under pressure. And I also learned to make quick but careful decisions and keep communication clear with others.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="team-disagreement-sla">íŒ€ì› ì˜ê²¬ ë‹¤ë¦„ - SLA 20ë¶„ ì§€ì—° - í’ˆì§ˆí•´ê²°</h3>Yes, Iâ€™ve experienced disagreements within the team. One example was during a near real-time data pipeline project. We were loading Kafka data into Hadoop, and the pipeline often missed our 10-minute SLA â€” sometimes it took over 20 minutes. some of the team members wanted to focus on improving Spark performance, while others, including me, thought the main issue was data quality because of inconsistent records and schema mismatches. To find the real cause, I checked the logs and monitoring reports and found that about 70% of the delays were due to data validation errors, not Spark processing speed. Based on that insight, I proposed a short proof-of-concept to implement stronger schema validation and fallback rules in QA environment and it worked. After implementing it in production, the number of failures dropped significantly and we regained our SLA. Once the team saw the data and results, everyone agreed to proceed with quality improvements first, then revisit performance tuning. This experience taught me that using measurable data, clear communication, and structured tests is much more effective than letting opinions dominate technical decisions.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="manager-disagreement-refresh-partition">ìƒì‚¬ ì˜ê²¬ ë‹¤ë¦„ - refresh only ë³€ê²½ëœ íŒŒí‹°ì…˜ë§Œ</h3>If I donâ€™t agree with my managerâ€™s opinion, I first make sure I fully understand their reasoning and goals. Then I share my perspective, supported by data or examples, rather than emotion. For instance, in one project, my manager suggested running a full data reload every day to ensure data completeness. I understood his concern but also knew it would be inefficient, since most of the customer master data rarely changed. So I analyzed the update patterns and designed a process to refresh only the partitions containing changed customer records, instead of reloading the entire dataset. After testing it together in staging, we confirmed that this approach maintained accuracy while reducing runtime from over 3 hours to about 40 minutes. That experience taught me that presenting clear evidence and focusing on the common goal â€” not on whoâ€™s right or wrong. It helps turn disagreements into productive discussions.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="diffent-personality">ë‹¤ë¥¸ ì„±í–¥ì˜ ì‚¬ëŒê³¼ í˜‘ë™</h3>In one of my previous projects, I worked closely with a senior engineer whose personality was quite different from mine. Iâ€™m generally organized and prefer to plan tasks carefully before execution, but he preferred to take a more spontaneous (ìŠ¤íŒ¬í…Œë‹ˆì–´ìŠ¤), â€œjust try it and fix laterâ€ approach. At first, this difference caused some tension because I wanted to review the design and test cases before deployment, while he wanted to move fast to meet deadlines. Instead of arguing, I suggested we combine both styles â€” I would document the structure and validation rules, and he could focus on rapid prototyping. By dividing responsibilities that way, we were able to deliver the pipeline faster and maintain quality. Over time, I also learned to be more flexible and open to trying quick experiments. And he started to appreciate the value of planning and testing as well. That experience taught me that personality differences can actually strengthen a team when you focus on complementary strengths rather than conflicts.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="helped-teammate">íŒ€ë™ë£Œ ì„±ê³µì‹œí‚¤ê¸°</h3>In one project, I worked with a junior data engineer who was new to our Spark-based ETL environment. She was struggling to understand how our partitioning and scheduling logic worked, and her job often failed in production. Instead of just fixing it for her, I scheduled a short session to walk her through how the Spark job read data from Oracle, wrote it into Hadoop platform. I also helped her debug one of her failing jobs step by step and showed her how to check logs and handle schema mismatches. Within a few weeks, she became confident enough to manage her own pipelines and even automated some validation scripts. Seeing her grow and succeed made me realize that helping others not only strengthens the team but also improves overall project quality.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="urgent-vs-important">ê¸‰í•œì¼ê³¼ ì¤‘ìš”í•œì¼ì˜ ìš°ì„ ìˆœìœ„ - ê¸‰í•œê²ƒ ë¨¼ì €</h3>I usually start by understanding the impact of each task. If something is urgent and affects business operations or other teams, I handle it first. But I also make sure not to ignore important long-term work. For example, once our production ETL job failed right before a reporting deadline. I paused my ongoing optimization task, fixed the ETL issue immediately, and restored the pipeline so the business could get their reports on time. After that, I resumed my optimization work. I believe good prioritization means balancing immediate needs with long-term improvements.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="tech-challenge-1-5tb">ê¸°ìˆ  ë¬¸ì œ ë„ì „ - 1.5TB ì²˜ë¦¬</h3>One of the most challenging technical problems I faced was optimizing a large Spark ETL job that processed about 1.5 TB everyday. The job was taking more than 5 hours to complete, which caused delays in our downstream dashboards and reports. I started by analyzing the Spark UI and noticed heavy shuffling and many small output files. To fix it, I adjusted the partition strategy, used broadcast joins for smaller tables, and combined small files before writing to Hadoop. I also added data filtering early in the pipeline to reduce unnecessary computation. After these changes, the runtime dropped from 5 hours to under 3 hours, and the cluster cost was reduced by almost 30%. That experience taught me how small technical optimizations can have a big business impact when working with large-scale data.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="improvement-large-data">ê°œì„  ì‚¬ë¡€ - í° ë°ì´í„° ì²˜ë¦¬ (ìœ„ ë™ì¼)</h3>I remember that one of our daily ETL jobs was taking more than 5 hours to finish. It processed a large amount of log data from multiple sources, and sometimes it even failed because of memory issues. I reviewed the Spark job and found that it was using too many small files and unnecessary joins. I optimized the job by adjusting the partition size, adding proper filters early in the transformation, and combining small files before loading. After the changes, the job ran in less than 3 hours and became much more stable. This improvement not only saved computing costs but also made our data available earlier for reporting every morning.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="production-connect-stop">ìƒì‚° ë¬¸ì œ - ì»¤ë„¥íŠ¸ Stop</h3>When a production issue happens, I stay calm and focus on finding the root cause quickly. For example, one night our Kafka-to-Hadoop pipeline failed, and the business dashboards in Tableau were missing data the next morning. I immediately checked the Kafka Connect logs and found that the sink connector had stopped due to a network issue. I manually restarted the connector and confirmed that the data started flowing again. Afterward, I created a monitoring script using curl commands that checks the connector status every 10 minutes. If it fails, the script automatically creates an incident and sends an alert to our team. This experience taught me the importance of not only fixing issues quickly but also building automation to prevent the same problem from happening again.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="process-improvement-connect-stop">ìë°œì  í”„ë¡œì„¸ìŠ¤ ê°œì„  - ì»¤ë„¥íŠ¸ Stop</h3>In one project, I noticed that one of our data pipelines sometimes failed overnight, but the team would only find out the next morning. This caused delays in daily reports and frustration for analysts waiting for updated data. Even though it wasnâ€™t part of my assigned tasks, I decided to create an automatic alert system. I built a small Python script that checked job completion logs and create INC if a failure occurred. After testing it for a week, I presented it to the team, and we integrated it into our pipeline. Since then, weâ€™ve been able to respond to failures immediately, reducing downtime and improving data reliability. That experience taught me the value of being proactive â€” small improvements can make a big difference to the whole team.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="kafka-realtime-connect-check">Kafka ì‹¤ì‹œê°„ ë°ì´í„°ì—ì„œ ê³ ë ¤í•  ë¶€ë¶„ - ì»¤ë„¥íŠ¸ ìƒíƒœí™•ì¸</h3>When designing Kafka pipelines, I focus on a few key areas to ensure performance and reliability. First, I choose the right topic partitioning strategy based on data size. And then I make sure that Kafka connectors are properly configured with retry mechanisms in case of failures. For monitoring, I built a script that uses a curl command to check the status of the all Kafka sink connectors every 10 minutes. If the one of the connectors is down or thereâ€™s an issue with the Kafka broker, the script automatically generates an incident, triggering an alert to my team. This setup helped us catch issues and significantly reduced downtime.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="failure-column-validation">ì‹¤íŒ¨,ì‹¤ìˆ˜ - ì»¬ëŸ¼ê²€ì¦X, í†µí™”ë‹¨ìœ„ ì—ëŸ¬</h3>Yes, I made a mistake during a data validation process. I was in charge of checking the output of a new ETL job before it went live. I verified the total record count but forgot to double-check the column-level transformations. After deployment, we found that one column had an incorrect currency conversion rate, and it caused wrong numbers to show up in a few business reports. As soon as I realized the issue, I corrected the transformation logic, reprocessed the data, and updated the reports. After that, I added column-level validation rules and a simple Python script that automatically compares key fields between the source and target tables before deployment. That experience taught me how even a small mistake can affect business reports, so now I always check both the data structure and actual values carefully before sign-off.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="project-delay-schema-change">í”„ë¡œì íŠ¸ ì§€ì—° - ìŠ¤í‚¤ë§ˆ ë³€ê²½</h3>Yes, Iâ€™ve experienced that before.In one project, our data ingestion pipeline was delayed because the upstream system changed its schema without notice. This caused our ETL jobs to fail and delayed daily reports for the client. As soon as the client raised concerns, I explained the issue clearly, shared the revised delivery plan, and sent daily updates so they could see our progress. Meanwhile, I worked with my team to add automatic schema validation and fallback logic in the pipeline, so future schema changes wouldnâ€™t break the process again. After we implemented the fix, the pipeline became more stable, and the client appreciated our quick communication and the long-term solution we put in place.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="team-lead-source-missing">íŒ€ ë¦¬ë“œ & ì†”ì„  - ì†ŒìŠ¤ ì…ë ¥ ì•ˆë¨</h3>In one project, we had a very tight deadline to deliver a new ETL workflow for daily reporting. However, a few tasks were delayed because some external data sources were not delivered on schedule, and that caused downstream jobs in Spark to fail during testing. To get things back on track, I took the initiative to organize short daily stand-up meetings and created a shared progress tracker in Confluence so everyone â€” including the data and QA teams â€” could see real-time task status. This helped us identify blockers early, communicate clearly, and reassign tasks based on team availability. Within a week, we recovered the lost time and successfully completed the workflow before the deadline. The reporting system went live as planned, and we avoided last-minute production issues. That experience taught me that strong coordination and clear communication are just as important as technical skills when leading a project under tight timelines.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="team-lead-datatype-mismatch">ë¦¬ë”ì‹¶ ì‚¬ë¡€ - data type mismatch</h3>During a data migration project, we faced a serious issue when one of the ETL jobs started failing right before a major release. Everyone was under pressure, and the team was unsure how to proceed. Even though I wasnâ€™t the official lead, I took the initiative to organize an emergency meeting with the data, QA, and infrastructure teams. I divided the investigation into parts â€” one team checked data source changes, another team looked at schema issues, and I focused on debugging the Spark job logic. After identifying that a data type mismatch in one column was causing the failure, we quickly fixed it and ran validation tests together. The release went smoothly, and my manager later recognized my leadership for coordinating the teams under tight deadlines. That experience taught me that real leadership often means stepping up and guiding the team toward a solution â€” even without having a formal title.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="above-and-beyond-responsibility">ì§€ì‹œë°›ì§€ì•Šì€ ì¼ - add load_date / ìƒì‚¬ì™€ ì˜ê²¬ì´ ë§ì§€ ì•ˆìŒì‚¬ë¡€ì™€ ë™ì¼</h3>A few months ago, I noticed that one of our nightly ETL jobs in production was running slower and occasionally failing, even though it wasnâ€™t part of the pipelines I was directly responsible for. Instead of ignoring it, I decided to investigate on my own time because it was delaying downstream reports for the business team. After checking the logs, I found that the job was performing a full table scan on a very large dataset every night. To fix the issue, I first added a new LOAD_DATE column to the target table to track daily data loads. Then, I rewrote the logic to process only new and updated records based on this column and created partitions on LOAD_DATE to improve query performance and data management efficiency. After validating the logic, I worked with the scheduler team to test and deploy the fix safely. The result was dramatic â€” runtime dropped from over 3 hour to under forty minutes, and the business team could access their dashboards much earlier every morning. Even though it wasnâ€™t my assigned task, I took ownership because I knew the issue was affecting overall business operations. That experience taught me that going above and beyond means proactively solving problems that impact the team â€” not just completing my own tickets.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="tight-schedule-pressure">íƒ€ì´íŠ¸í•œ ìŠ¤ì¼€ì¤„ & ì••ë°• - ì¼ ë‚˜ëˆ„ê³  ëŒ€í™”, íŠ¸ë™</h3>When I face tight deadlines or high-pressure situations, I stay calm and break the work into smaller parts. For example, in one project, our team had to build a new ETL workflow in less than two weeks because of a last-minute client request. Instead of stressing out, I focused on what was most important, assigned tasks clearly, and set up short daily check-ins to track progress. I also kept open communication with both the team and stakeholders, making sure everyone understood what we could realistically deliver. By staying organized and working together, we completed the project on time with great results. This experience taught me that under pressure, clear priorities, steady communication, and teamwork are the keys to success.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="multi-national-collaboration">ì—¬ëŸ¬ ë¯¼ì¡± ê°™ì´ ê·¼ë¬´ - sync ë¯¸íŒ…, ë¯¸íŒ…ìš”ì•½</h3>Currently, I work on a data integration project with team members from the U.S., India, and Europe. At first, coordination was difficult because of time zone differences and different communication styles. To improve collaboration, I organized short daily sync meetings that overlapped our working hours and encouraged open discussions so everyone could share progress or blockers. I also started sending clear written summaries after each meeting so teammates in different time zones could stay updated. As a result, we reduced misunderstandings, improved task handoffs between regions, and delivered the pipeline earlier than planned. This experience taught me how to adapt to different working styles and use team diversity to achieve results.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="cross-team-collaboration">ë‹¤ë¥¸ íŒ€ í˜‘ì—… - ìš©ì–´ í†µì¼</h3>In one of my projects, I worked closely with software engineers and business analysts to improve how we tracked and analyzed user behavior. The engineers were responsible for sending user activity data into our database, and my role was to clean and transform that data so it could be used for reporting and analysis. I noticed that each team had slightly different definitions for key metrics, like â€œactive usersâ€ or â€œsessions,â€ which caused confusion in reports. So, I organized a short meeting to align on clear definitions and updated our data dictionary to make sure everyone used the same terms. After that, the reports became much more consistent, and the business team was able to make decisions faster and with more confidence. It was a great experience showing how clear communication and teamwork can really improve data quality and trust.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="customer-request">ê³ ê°ì´ ë§ˆì§€ë§‰ì— ë³€ê²½ìš”ì²­ì‹œ - ìŠ¤í‚¤ë§ˆë³€ê²½</h3>When a customer requests changes right before the final release, I believe itâ€™s important to balance flexibility with stability. First, I listen carefully to understand why the change is needed â€” whether itâ€™s a business-critical fix or just a nice-to-have improvement. Then I assess the impact on scope, timeline, and quality. If the change is minor and doesnâ€™t risk the release, I coordinate quickly with the team to implement and test it. However, if the change is major or could affect stability, I clearly communicate the risks and propose alternatives â€” such as including it in the next patch or minor release. The most important thing is to be honest about the situation, and focus on finding solutions. This way, the customer knows youâ€™re listening, and the project stays on track.For example, in one project, a client requested a schema change right before deployment. I analyzed the dependency, explained that it would delay the release by two days, and suggested deploying the current version first and adding the change in the next release. The client agreed, and we delivered on time without compromising quality.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="customer-request-offen">ê³ ê°ì´ ìì£¼ ë³€ê²½ì‚¬í•­ì„ ìš”ì²­í• ë•Œ - ìš”ì²­ì„ ê·¸ë£¹í•‘í•¨</h3>When customers often ask for changes, I try to handle it in a clear way. First, I listen carefully to understand why they want the change â€” maybe their business needs have changed or something wasnâ€™t clear before. Then I explain what the change means for the project â€” like how it might affect the schedule or workload â€” so they can decide whatâ€™s most important. If there are many small requests, I suggest grouping them together or saving them for the next update.In one project, the customer kept asking for new data checks. I made a simple list to track all the requests and talked with them once a week to decide which ones to do first. That way, they felt listened to, and our team could work in an organized way without confusion.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="non-technical">ë¹„ê°œë°œìì—ê²Œ ê¸°ìˆ ì ì¸ ë‚´ìš©ì„ ì‰½ê²Œ ì„¤ëª…í•  ìˆ˜ ìˆë‚˜ìš”?</h3>Yes, I always try to explain technical topics in a simple and clear way, especially when talking to non-technical people. I focus on using everyday language instead of technical terms, and I give real examples that relate to their work or daily life. For example, when explaining data pipelines, I might say itâ€™s like a factory line â€” data comes in as raw material, goes through cleaning and transformation, and comes out as a finished product ready for analysis. I believe being able to translate complex ideas into simple concepts is an important skill for teamwork and communication.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="issue-spark-memory">ì´ìŠˆ - Spark memory ë¬¸ì œ</h3>One of the most common issues I encounter is out-of-memory (OOM) errors. To address this, First, I review the PySpark code to identify any operational command like collect() or toPandas() that might be pulling too much data into the driver. If I find them, I either remove or replace them. I also use broadcast joins when dealing with small tables to minimize shuffle operations, it can reduce memory usage. Another important step is avoiding Python UDFs if it is possible to use native Spark SQL functions. Additionally, when I need to reuse the intermediate results, I use caching it and also I use MEMORY_AND_DISK storage option to avoid overwhelming the memory. Finally, I adjust partition sizes using coalesce() or repartition() to optimize resource usage during shuffle operations. By applying these techniques, Iâ€™ve been able to effectively prevent and troubleshoot memory-related issues in Spark jobs.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="etl-pipeline-optimization">ETL pipeline ìµœì í™” - SLA 6ì‹œë¡œ ë§ì¶”ê¸°</h3>I had a situation where our SLA required the data to be fully available by 6 AM, But one day, the amount of source data suddenly increased â€” almost three times more than usual. Because of that, our Spark job didnâ€™t finish until 8 AM. So I increased the number of partitions to allow more parallel processing. I also checked our resource settings and made sure the job had enough memory and CPU by adjusting the scheduler pool and YARN resorce manager.After these changes, the job completed before 6 AM the next day, and we were able to meet the SLA again. This experience helped me understand how important it is to tune the Spark jobs and monitor them carefully, especially when data volume suddenly increase.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="aws-glue-experience">AWS Glue ì‚¬ìš©ê²½í—˜ - ETL services</h3>I have experience building ETL workflows using AWS Glue. In one of my project, I built an analytics pipeline to process and analyze mobile user log data. Iâ€™ve used Glue to extract data from S3 and then transform and load into Redshift every 10 minutes Also, Iâ€™ve utilized Glue Crawlers to automatically detect schema changes and keep the data catalog updated for querying in Athena as well.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="no-current-glue">í˜„ì¬ glueë¥¼ ì‚¬ìš©í•˜ì§€ëŠ” ì•ŠëŠ”ë‹¤.</h3>We are currently using CA7 mainframe along with PySpark scripts for our ETL processes mainly. CA7 is a mainframe-based job scheduling and workflow automation tool. It's used to manage and schedule batch jobs, ensuring the tasks run in the right order and at the right time. We have not changed this Orchestration tool Because Our data workflows have been integrated into a mainframe-based CA7 scheduling system for a long time and switching would introduce additional operational costs. Lastly Our team continues to manage and monitor all ETL workflows within the CA7 environment.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="redshift-intro">Redshift ë€?</h3>Redshift is designed for high-speed querying using massively parallel processing (MPP). This makes it great for analyzing large datasets quickly. we can start small and scale up by increasing the node size or number of nodes as the data grows. Data is stored in columnar format, which speeds up analytical queries and reduces I/O.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="redshift-columnar">Redshift Columnar Storage</h3>When we execute queries like SUM(), AVG(), or filtering on specific columns, the database only needs to read the relevant columns, not entire rows. This speeds up reading performance in data warehousing and analytics. Since each column typically contains similar types of data, it compresses more efficiently than row-based data. Also, it only reads the selected columns, the amount of data scanned is reduced.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="snowflake-advantages">ìŠ¤ë…¸ìš°í”Œë ˆì´í¬ ì¥ì  (zero-copy cloning and time travel)</h3>I can instantly clone entire databases or tables without duplicating data and it saves cost and time. Also, there is a Time Travel function and it lets us query or restore data from a previous point in time. It is useful for recovering the data.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="databricks-experience">Databricks ì‚¬ìš©ê²½í—˜ - Anomaly detection</h3>On the Databricks side, I primarily work with the Azure-hosted version of Databricks. Recently, I developed an end-to-end scalable pipeline for computer vision anomaly detection. As you can see my portfolio website. You can see its notebook and model. I use the PyTorch and Hugging Face to train and build the model.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="partition-strategy">íŒŒí‹°ì…˜ ì „ëµ (Spark, Redshift, Snowflake)</h3>Partitioning strategy depends on query patterns and data volume. Regarding the Oracle Exadata, I Used range partitioning by date column to support daily ingestion and quickly delete old data by simply dropping partition.In Spark, I used dynamic partition overwrite with partitionBy("date") when writing Parquet files, and adjusted the number of partitions with coalesce or repartition commands to avoid creating too many small files.In Redshift, I defined DISTKEY and SORTKEY based on the columns that were most frequently used in joins and filters, which helped improve query performance and reduce data movement across nodes.In Snowflake, I rely on its automatic micro-partitioning feature, which breaks data into 16MB blocks and optimizes storage and query performance without any manual intervention. However, for very large tables where queries frequently filter on specific columnsâ€”such as date, I define a cluster key to further improve performance and these approach improved query speed as well.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="oracle-range-partitioning">ë°ì´í„° ëª¨ë¸ë§ & Architecture - ì˜¤ë¼í´ range partitioning</h3>I have strong experience in data modeling and architecture, especially in designing data pipelines at PNC. In Oracle Exadata, I designed the tables using range partitioning by day, so that Kafka data was automatically separated into daily partitions. This made it much easier to manage large volumes of data, speed up queries, and improve overall performance. For example, instead of using a traditional delete command, we could simply drop an entire partition when the data was no longer needed.  And This is not only optimized storage space but also kept query performance fast and efficient, since queries only scanned the relevant partitions rather than the entire table.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="data-normalization">ë°ì´í„° ì •ê·œí™”ì™€ ë¹„ì •ê·œí™”ì˜ ì°¨ì´ì </h3>Normalized data is typically used in OLTP systems. It separates data into multiple related tables to reduce redundancy and maintain data integrity. This helps ensure consistency during insert, update, and delete operations, but often requires multiple joins to retrieve data.Denormalized data is more common in OLAP systems. It intentionally duplicates data by combining related fields into fewer tables, which improves read performance and speeds up complex analytical queries.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="star-snowflake-schema">Star & Snowflake ìŠ¤í‚¤ë§ˆ (ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ì—ì„œ ìŠ¤íƒ€ ìŠ¤í‚¤ë§ˆ ì‚¬ìš©)</h3>In most data warehouses, the Star Schema is used because it provides high query performance, especially for analytical workloads, and has a simple structure consisting of a central fact table connected to denormalized dimension tables. This simplicity also makes it well suited for BI tools like Tableau or Power BI.But the Snowflake Schema is also usedâ€”especially when storage efficiency or data normalization is a higher priority. It tends to introduce more joins, which can affect query performance. Therefore, Star Schema is generally preferred in data warehouse environments.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="python-sql-spark">Python, SQL, Spark, and PySpark</h3>I am working with Python, SQL, Spark, and PySpark throughout my career as a data engineer. Python has been my primary programming language for building ETL pipelines. I've used it in both production and QA environments, including developing data ingestion frameworks.SQL is a core part of my daily workflow. Iâ€™ve written complex analytical queries and optimized SQL for performance on databases like Oracle Exadata.With Spark, Iâ€™ve built scalable data processing pipelines for both batch and near real-time use cases. Iâ€™ve used Spark in distributed environments, primarily through PySpark, to perform transformations, aggregations, and joins on large datasets.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="spark-hadoop-ingestion">ê²½í—˜ - ìŠ¤íŒŒí¬/í•˜ë‘¡ ë°ì´í„° ingestion</h3>On the Hadoop and Spark side, I designed frameworks to handle large-scale data ingestion and transformation. For example, data coming from Oracle first needed to be cleaned before it could be used for reporting. I built PySpark jobs that automatically parse the data and removed duplicate records, handled missing values, and converted the data into optimized formats like Parquet and stored it at hadoop platform. At the same time, I added metadata and validation rules so that we could easily track the data and confirm its accuracy.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="aws-experience">ê²½í—˜ - AWS ë§ì´ ì‚¬ìš©í–ˆë‹ˆ?</h3>If you take a look at my portfolio website, youâ€™ll see that most of my projects are built using AWS. I actively use AWS to quickly build and experiment with different data architectures. Since data tools are evolving so fast, I use EMR service to easily install and try out big data tools like Spark, Hadoop, and Kafka. For storing data, I normally use RDS or S3. Overall, AWS has been a great platform for me to learn, experiment, and build end-to-end data pipelines.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="strengths-weaknesses">ì¥ì ê³¼ ë‹¨ì </h3>My biggest strengths are my flexibility and adaptability. Wherever I work, work environments change daily and throughout the day. And there are certain projects that require individual attention and others that involve a teamwork approach. My flexibility and adaptability have allowed me to meet the expectations and even go beyond them. Also, I get along with people around me. This kind of personality makes the work environment more comfortable and easierAs far as my weaknesses, I sometimes put in too much time on what I like to do. With my mentorâ€™s help, I started using a daily checklist to plan and prioritize my work. Now I make sure I pace myself better and focus on finishing the most important tasks first. Itâ€™s helped me become more balanced and efficient.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="stress">ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ì–´ë–»ê²Œ í’‰ë‹ˆê¹Œ?</h3>When I feel stressed, I try to handle it in a healthy and productive way. First, I take a short break to clear my mind â€” even a short walk or a few minutes of quiet time helps me refocus. I also like to organize my tasks and set priorities. Once I have a clear plan, the stress usually goes down because I can see what needs to be done first. Outside of work, I relieve stress by exercising and spending time with my family or friends. These activities help me recharge and come back to work with more energy and focus.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="motto">ì‚¶ì˜ ëª¨í† ëŠ”?</h3>My life motto is â€œStay curious, stay humble, and keep growing.â€ I believe learning never stops, no matter how much experience you have. Staying curious helps me discover new ideas, staying humble keeps me open to feedback, and continuous growth gives me purpose in both my career and personal life.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="powertech">íŒŒì›Œí…ì—ì„œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì‚¬ìš©</h3>When I worked at Hyundai Powertech, we produced car transmissions. Each transmission needed a small gasket to fill the gap between parts, but the gap size was different for each transmission â€” sometimes 1 mm, 1.5 mm, or 2 mm. Because of this, the company had to keep all gasket sizes in stock, which wasted storage space and money. I collected the production log from the machines on the floor and analyze them and trained machine learning models to predict which gasket size would be needed for each transmission. Among several models, XGBoost performed the best. By using this prediction model, we reduced inventory levels and saved costs by ordering only the needed gasket sizes.- XGBoost is an efficient and high-performance boosting algorithm that combines many small decision trees to make strong and accurate predictions.<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h3 id="final-remarks">ë§ˆì§€ë§‰ìœ¼ë¡œ í•˜ê³  ì‹¶ì€ ë§</h3>May I ask which technologies your team works with most often, and what types of projects are currently the main focus?May I ask what qualities you think are most important to succeed in this position?<p><a href="#top">ë§¨ ìœ„ë¡œ</a></p><h1 id="Governance-Compliance-in-AI"><a href="#Governance-Compliance-in-AI" class="headerlink" title="Governance &amp; Compliance in AI"></a>Governance &amp; Compliance in AI</h1><h2 id="Why-Governance-and-Compliance-Matter"><a href="#Why-Governance-and-Compliance-Matter" class="headerlink" title="Why Governance and Compliance Matter"></a>Why Governance and Compliance Matter</h2><p>Governance is about managing, optimizing, and scaling AI initiatives inside an organization.  </p><ul><li>It builds <strong>trust</strong> in AI systems.  </li><li>Ensures <strong>responsible and trustworthy practices</strong>.  </li><li>Mitigates risks such as bias, privacy violations, or unintended outcomes.  </li><li>Aligns AI systems with <strong>legal and regulatory requirements</strong>.  </li><li>Protects against <strong>legal and reputational risks</strong>.  </li><li>Fosters <strong>public trust and confidence</strong> in AI deployment.</li></ul><p>ğŸ“Œ <strong>Exam tip</strong>: Expect questions that connect governance with <em>trust, compliance, and risk management</em>. AWS often tests your understanding of <em>why</em> governance is necessary, not just <em>how</em>.</p><hr><h2 id="Governance-Framework"><a href="#Governance-Framework" class="headerlink" title="Governance Framework"></a>Governance Framework</h2><p>A typical governance approach includes:</p><ol><li><strong>AI Governance Board &#x2F; Committee</strong>  <ul><li>Cross-functional: legal, compliance, data privacy, and AI experts.</li></ul></li><li><strong>Defined Roles and Responsibilities</strong>  <ul><li>Oversight, policy-making, risk assessments, decision-making.</li></ul></li><li><strong>Policies &amp; Procedures</strong>  <ul><li>Covering the full AI lifecycle: data management â†’ training â†’ deployment â†’ monitoring.</li></ul></li></ol><h3 id="AWS-Governance-Tools-likely-on-exam"><a href="#AWS-Governance-Tools-likely-on-exam" class="headerlink" title="AWS Governance Tools (likely on exam):"></a>AWS Governance Tools (likely on exam):</h3><ul><li><strong>AWS Config</strong> â€“ continuous monitoring and compliance tracking.  </li><li><strong>Amazon Inspector</strong> â€“ automated vulnerability management.  </li><li><strong>AWS CloudTrail</strong> â€“ records API calls for auditing.  </li><li><strong>AWS Audit Manager</strong> â€“ helps with compliance evidence collection.  </li><li><strong>AWS Trusted Advisor</strong> â€“ best practice checks (cost, security, performance).</li></ul><p align="center">  <img src="/images/aws_basic_209.png" width="80%"></p><hr><h2 id="Governance-Strategies"><a href="#Governance-Strategies" class="headerlink" title="Governance Strategies"></a>Governance Strategies</h2><ul><li><strong>Policies</strong>: Responsible AI guidelines (data handling, training, bias mitigation, IP protection).  </li><li><strong>Review Cadence</strong>: Reviews monthly, quarterly, or annually, with technical + legal experts.  </li><li><strong>Review Types</strong>:  <ul><li><em>Technical</em>: model performance, data quality, robustness.  </li><li><em>Non-technical</em>: legal, compliance, ethical considerations.</li></ul></li><li><strong>Transparency</strong>: Publish model details, training data sources, decisions made, limitations.  </li><li><strong>Team Training</strong>: Policies, responsible AI, bias mitigation, cross-functional collaboration.</li></ul><hr><h2 id="Data-Governance"><a href="#Data-Governance" class="headerlink" title="Data Governance"></a>Data Governance</h2><ul><li><strong>Responsible AI Principles</strong>: fairness, accountability, transparency, bias monitoring.  </li><li><strong>Governance Roles</strong>:  <ul><li><em>Data Owner</em>: accountable for data.  </li><li><em>Data Steward</em>: ensures quality, compliance.  </li><li><em>Data Custodian</em>: manages technical storage&#x2F;security.</li></ul></li><li><strong>Data Sharing</strong>: secure sharing agreements, virtualization, federation.  </li><li><strong>Data Culture</strong>: encourage data-driven decision-making.</li></ul><h3 id="Data-Management-Concepts"><a href="#Data-Management-Concepts" class="headerlink" title="Data Management Concepts"></a>Data Management Concepts</h3><ul><li><strong>Lifecycle</strong>: collection â†’ processing â†’ storage â†’ use â†’ archival.  </li><li><strong>Logging</strong>: track inputs, outputs, metrics, events.  </li><li><strong>Residency</strong>: where data is stored&#x2F;processed (important for GDPR &amp; HIPAA).  </li><li><strong>Monitoring</strong>: quality, anomalies, drift.  </li><li><strong>Retention</strong>: meet regulations and manage storage costs.</li></ul><h3 id="Data-Lineage"><a href="#Data-Lineage" class="headerlink" title="Data Lineage"></a>Data Lineage</h3><ul><li><strong>Source citation</strong>: datasets, licenses, permissions.  </li><li><strong>Origins</strong>: collection, cleaning, transformations.  </li><li><strong>Cataloging</strong>: organize &amp; document datasets.  </li><li>Provides <strong>traceability &amp; accountability</strong>.</li></ul><p align="center">  <img src="/images/aws_basic_210.png" width="80%"></p><hr><h2 id="Security-Privacy-for-AI"><a href="#Security-Privacy-for-AI" class="headerlink" title="Security &amp; Privacy for AI"></a>Security &amp; Privacy for AI</h2><ul><li><strong>Threat Detection</strong>: fake content, manipulated data, automated attacks.  </li><li><strong>Vulnerability Management</strong>: penetration tests, code reviews, patching.  </li><li><strong>Infrastructure Protection</strong>: secure cloud platforms, access controls, encryption, redundancy.  </li><li><strong>Prompt Injection Defense</strong>: input sanitization, guardrails.  </li><li><strong>Encryption</strong>: always encrypt data at rest &amp; in transit; manage keys securely.</li></ul><p align="center">  <img src="/images/aws_basic_211.png" width="80%"></p><hr><h2 id="Monitoring-AI-Systems"><a href="#Monitoring-AI-Systems" class="headerlink" title="Monitoring AI Systems"></a>Monitoring AI Systems</h2><ul><li><strong>Model Metrics</strong>:  <ul><li>Accuracy  </li><li>Precision (true positives &#x2F; predicted positives)  </li><li>Recall (true positives &#x2F; actual positives)  </li><li>F1-score (balance between precision &amp; recall)  </li><li>Latency (response time)</li></ul></li><li><strong>Infrastructure Monitoring</strong>: CPU&#x2F;GPU, network, storage, logs.  </li><li><strong>Bias &amp; Fairness Monitoring</strong>: required for compliance.</li></ul><hr><h2 id="AWS-Shared-Responsibility-Model"><a href="#AWS-Shared-Responsibility-Model" class="headerlink" title="AWS Shared Responsibility Model"></a>AWS Shared Responsibility Model</h2><ul><li><strong>AWS responsibility â€“ Security <em>of</em> the Cloud</strong><br>Infrastructure: hardware, networking, managed services like S3, SageMaker, Bedrock.  </li><li><strong>Customer responsibility â€“ Security <em>in</em> the Cloud</strong><br>Data management, encryption, access controls, guardrails.  </li><li><strong>Shared controls</strong>: patch management, configuration management, training.</li></ul><p>ğŸ“Œ <strong>Exam tip</strong>: Always remember the <em>â€œof the cloudâ€ vs. â€œin the cloudâ€</em> split.</p><p align="center">  <img src="/images/aws_basic_212.png" width="80%"></p><hr><h2 id="Secure-Data-Engineering-Best-Practices"><a href="#Secure-Data-Engineering-Best-Practices" class="headerlink" title="Secure Data Engineering Best Practices"></a>Secure Data Engineering Best Practices</h2><ul><li><strong>Data Quality</strong>: complete, accurate, timely, consistent.  </li><li><strong>Privacy Enhancements</strong>: masking, obfuscation, encryption, tokenization.  </li><li><strong>Access Control</strong>: RBAC (role-based access), fine-grained permissions, SSO, MFA.  </li><li><strong>Data Integrity</strong>: error-free, backed up, lineage maintained, audit trails in place.</li></ul><hr><h2 id="Generative-AI-Security-Scoping-Matrix"><a href="#Generative-AI-Security-Scoping-Matrix" class="headerlink" title="Generative AI Security Scoping Matrix"></a>Generative AI Security Scoping Matrix</h2><p>Levels of ownership and security responsibility:  </p><ol><li><strong>Consumer App</strong> â€“ very low ownership (e.g., using ChatGPT directly).  </li><li><strong>Enterprise App</strong> â€“ SaaS with GenAI features (e.g., Salesforce GPT).  </li><li><strong>Pre-trained Models</strong> â€“ use Bedrock base models without training.  </li><li><strong>Fine-tuned Models</strong> â€“ customize models with your data.  </li><li><strong>Self-trained Models</strong> â€“ full ownership, trained from scratch.</li></ol><p>ğŸ“Œ <strong>Exam tip</strong>: The more control you have â†’ the more <strong>security and compliance responsibility</strong> you carry.  </p><p align="center">  <img src="/images/aws_basic_213.png" width="80%"></p><hr><h2 id="MLOps-Machine-Learning-Operations"><a href="#MLOps-Machine-Learning-Operations" class="headerlink" title="MLOps (Machine Learning Operations)"></a>MLOps (Machine Learning Operations)</h2><p>Extension of DevOps for ML:  </p><ul><li><strong>Version Control</strong>: data, code, models.  </li><li><strong>Automation</strong>: pipelines for ingestion, preprocessing, training.  </li><li><strong>CI&#x2F;CD</strong>: continuous testing and delivery of models.  </li><li><strong>Retraining</strong>: incorporate new data.  </li><li><strong>Monitoring</strong>: catch drift, ensure fairness and performance.</li></ul><p>Example ML pipeline:  </p><ol><li>Data prep  </li><li>Build model  </li><li>Evaluate model  </li><li>Select best candidate  </li><li>Deploy to production  </li><li>Monitor + retrain</li></ol><p>ğŸ“Œ <strong>Exam tip</strong>: AWS may test your knowledge of <strong>SageMaker pipelines, model registry, and monitoring tools</strong> as part of MLOps.  </p><p align="center">  <img src="/images/aws_basic_215.png" width="80%"></p><h2 id="Phases-of-Machine-Learning-Project"><a href="#Phases-of-Machine-Learning-Project" class="headerlink" title="Phases of Machine Learning Project"></a>Phases of Machine Learning Project</h2><p align="center">  <img src="/images/aws_basic_214.png" width="80%"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a id=&quot;top&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;style&gt;
.toc-grid{
  display:grid;
  grid-template-columns:1fr 1fr; /* í™”ë©´ ë°˜ë°˜ */
  gap:6px 20px;
  align-items:start;</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(40) - Generative AI Capabilities, Challenges, and Compliance</title>
    <link href="https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-40/"/>
    <id>https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-40/</id>
    <published>2025-09-02T19:05:58.000Z</published>
    <updated>2025-09-02T19:29:34.719Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Generative-AI-Capabilities-Challenges-and-Compliance"><a href="#Generative-AI-Capabilities-Challenges-and-Compliance" class="headerlink" title="Generative AI: Capabilities, Challenges, and Compliance"></a>Generative AI: Capabilities, Challenges, and Compliance</h1><h2 id="Capabilities-of-Generative-AI"><a href="#Capabilities-of-Generative-AI" class="headerlink" title="Capabilities of Generative AI"></a>Capabilities of Generative AI</h2><p>Generative AI (GenAI) has several strengths that make it powerful and attractive for businesses:</p><ul><li><strong>Adaptability</strong> â€“ can quickly adjust to new tasks and domains.  </li><li><strong>Responsiveness</strong> â€“ provides real-time answers and interactions.  </li><li><strong>Simplicity</strong> â€“ users can interact with natural language prompts instead of coding.  </li><li><strong>Creativity &amp; Exploration</strong> â€“ useful for brainstorming, content creation, and generating novel ideas.  </li><li><strong>Data Efficiency</strong> â€“ can extract insights even from smaller datasets if pretrained well.  </li><li><strong>Personalization</strong> â€“ adapts to individual user needs, preferences, or styles.  </li><li><strong>Scalability</strong> â€“ works across millions of queries and users simultaneously.</li></ul><p>ğŸ‘‰ <em>Exam tip</em>: Expect questions about how businesses benefit from these capabilitiesâ€”especially scalability, personalization, and adaptability.</p><hr><h2 id="Challenges-of-Generative-AI"><a href="#Challenges-of-Generative-AI" class="headerlink" title="Challenges of Generative AI"></a>Challenges of Generative AI</h2><p>Despite its strengths, GenAI comes with risks:</p><ul><li><strong>Regulatory violations</strong> â€“ hard to ensure compliance with laws (GDPR, HIPAA, etc.).  </li><li><strong>Social risks</strong> â€“ spread of misinformation or harmful content.  </li><li><strong>Data security &amp; privacy</strong> â€“ sensitive data may be leaked or misused.  </li><li><strong>Toxicity</strong> â€“ generating offensive or inappropriate outputs.  </li><li><strong>Hallucinations</strong> â€“ generating content that <em>sounds</em> correct but is false.  </li><li><strong>Interpretability</strong> â€“ difficult to understand <em>why</em> the model produced an output.  </li><li><strong>Nondeterminism</strong> â€“ the same prompt may return different results each time.  </li><li><strong>Plagiarism &amp; cheating</strong> â€“ students or professionals misusing AI for essays, tests, or applications.</li></ul><p>ğŸ‘‰ <em>Exam tip</em>: Be familiar with â€œhallucinations,â€ â€œtoxicity,â€ and â€œnondeterminismâ€ as common weaknesses of large language models.</p><hr><h2 id="Toxicity"><a href="#Toxicity" class="headerlink" title="Toxicity"></a>Toxicity</h2><ul><li><strong>Definition</strong>: AI generates content that is offensive, disturbing, or inappropriate.  </li><li><strong>Challenge</strong>: Deciding what counts as â€œtoxicâ€ vs. â€œfree expression.â€ Even quoting harmful text can raise issues.  </li><li><strong>Mitigation</strong>:<ul><li>Curate training datasets to remove offensive content.  </li><li>Use <strong>guardrails</strong> (like <em>Guardrails for Amazon Bedrock</em>) to filter harmful or unwanted outputs.</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_200.png" width="80%"></p><hr><h2 id="Hallucinations"><a href="#Hallucinations" class="headerlink" title="Hallucinations"></a>Hallucinations</h2><ul><li><strong>Definition</strong>: Model produces content that <em>sounds correct</em> but is wrong.  </li><li><strong>Cause</strong>: Next-word probability sampling in LLMs.  </li><li><strong>Example</strong>: Claiming an author wrote books they never wrote.  </li><li><strong>Mitigation</strong>:<ul><li>Educate users: AI outputs must be verified.  </li><li>Cross-check with independent sources.  </li><li>Label outputs as <strong>â€œunverified.â€</strong></li></ul></li></ul><p align="center">  <img src="/images/aws_basic_201.png" width="80%"></p><hr><h2 id="Plagiarism-Cheating"><a href="#Plagiarism-Cheating" class="headerlink" title="Plagiarism &amp; Cheating"></a>Plagiarism &amp; Cheating</h2><ul><li><strong>Concern</strong>: GenAI used to write essays, job applications, or exams.  </li><li><strong>Debate</strong>: Should this be embraced as new tech or banned?  </li><li><strong>Mitigation</strong>: Detection tools are being developed to identify AI-generated text.</li></ul><p align="center">  <img src="/images/aws_basic_202.png" width="80%"></p><hr><h2 id="Prompt-Misuses"><a href="#Prompt-Misuses" class="headerlink" title="Prompt Misuses"></a>Prompt Misuses</h2><ol><li><strong>Poisoning</strong> â€“ malicious or biased data injected into training â†’ harmful outputs.  <ul><li>Example: model suggests eating rocks due to poisoned data.</li></ul></li><li><strong>Hijacking &#x2F; Prompt Injection</strong> â€“ attacker embeds hidden instructions in prompts.  <ul><li>Example: â€œGenerate a Python script to delete files.â€</li></ul></li></ol><p align="center">  <img src="/images/aws_basic_203.png" width="80%"></p><ol start="3"><li><strong>Exposure</strong> â€“ risk of revealing private or sensitive data in outputs.</li></ol><p align="center">  <img src="/images/aws_basic_204.png" width="80%"></p><ol start="4"><li><strong>Prompt Leaking</strong> â€“ model unintentionally exposes previous prompts or confidential information.</li></ol><p align="center">  <img src="/images/aws_basic_205.png" width="80%"></p><ol start="5"><li><strong>Jailbreaking</strong> â€“ bypassing safety constraints to force restricted outputs.  <ul><li><strong>Many-shot jailbreaking</strong> (providing many examples) has been shown to trick models.</li></ul></li></ol><p align="center">  <img src="/images/aws_basic_206.png" width="80%"></p><p>ğŸ‘‰ <em>Exam tip</em>: Know the definitions of <strong>prompt injection, jailbreaking, and poisoning</strong>. These are hot topics in AI security.</p><hr><h2 id="Regulated-Workloads"><a href="#Regulated-Workloads" class="headerlink" title="Regulated Workloads"></a>Regulated Workloads</h2><p>Some industries have stricter compliance requirements:</p><ul><li><strong>Financial services</strong> â€“ mortgage, credit scoring.  </li><li><strong>Healthcare</strong> â€“ patient records, diagnostics.  </li><li><strong>Aerospace &amp; defense</strong> â€“ sensitive designs, federal oversight.</li></ul><p>ğŸ‘‰ <em>Regulated workload</em> &#x3D; requires audits, reporting, or special security requirements.</p><hr><h2 id="Compliance-Challenges"><a href="#Compliance-Challenges" class="headerlink" title="Compliance Challenges"></a>Compliance Challenges</h2><p>AI compliance is difficult because:</p><ul><li><strong>Complexity &amp; opacity</strong> â€“ hard to audit AI decision-making.  </li><li><strong>Dynamism</strong> â€“ AI models evolve over time.  </li><li><strong>Emergent capabilities</strong> â€“ models may do things they werenâ€™t trained for.  </li><li><strong>Unique risks</strong> â€“ bias, misinformation, privacy violations.  </li><li><strong>Algorithmic bias</strong> â€“ skewed training data leads to discrimination.  </li><li><strong>Human bias</strong> â€“ developers themselves can introduce bias.  </li><li><strong>Accountability</strong> â€“ algorithms must be explainable, but often arenâ€™t.</li></ul><h3 id="Regulatory-frameworks"><a href="#Regulatory-frameworks" class="headerlink" title="Regulatory frameworks"></a>Regulatory frameworks</h3><ul><li><strong>EU</strong>: <em>Artificial Intelligence Act</em> â€“ fairness, human rights, non-discrimination.  </li><li><strong>US</strong>: Several states&#x2F;cities have their own AI regulations.</li></ul><p align="center">  <img src="/images/aws_basic_207.png" width="80%"></p><hr><h2 id="AWS-Compliance"><a href="#AWS-Compliance" class="headerlink" title="AWS Compliance"></a>AWS Compliance</h2><p>AWS supports compliance with <strong>140+ standards and certifications</strong>, including:  </p><ul><li><strong>NIST</strong> (National Institute of Standards and Technology)  </li><li><strong>ENISA</strong> (EU cybersecurity)  </li><li><strong>ISO</strong> (International Organization for Standardization)  </li><li><strong>SOC</strong> (System and Organization Controls)  </li><li><strong>HIPAA</strong> (healthcare)  </li><li><strong>GDPR</strong> (EU data privacy)  </li><li><strong>PCI DSS</strong> (payment card data)</li></ul><p>ğŸ‘‰ <em>Exam tip</em>: AWS provides compliance-ready infrastructure, but <strong>you (the customer) are responsible</strong> for compliance of your applications (Shared Responsibility Model).</p><hr><h2 id="Model-Cards-AWS-AI-Service-Cards"><a href="#Model-Cards-AWS-AI-Service-Cards" class="headerlink" title="Model Cards &amp; AWS AI Service Cards"></a>Model Cards &amp; AWS AI Service Cards</h2><ul><li><strong>Model Cards</strong> &#x3D; standardized documentation for ML models.  <ul><li>Include datasets, sources, biases, training details, intended use, and risk ratings.  </li><li><em>Example</em>: SageMaker Model Cards help with audits.</li></ul></li><li><strong>AWS AI Service Cards</strong> &#x3D; AWS documentation about responsible AI practices in its services (e.g., Rekognition, Textract).</li></ul><p>ğŸ‘‰ These improve <strong>transparency, trust, and accountability</strong>.</p><p align="center">  <img src="/images/aws_basic_208.png" width="80%"></p><hr><h2 id="Key-Takeaways-for-the-Exam"><a href="#Key-Takeaways-for-the-Exam" class="headerlink" title="Key Takeaways for the Exam"></a>Key Takeaways for the Exam</h2><ul><li>Understand <strong>capabilities vs. challenges</strong> of GenAI.  </li><li>Be able to explain <strong>toxicity, hallucinations, plagiarism, nondeterminism</strong>.  </li><li>Know <strong>prompt misuse techniques</strong> (poisoning, injection, exposure, jailbreaking).  </li><li>Be familiar with <strong>regulated workloads</strong> and compliance frameworks (HIPAA, GDPR, PCI DSS).  </li><li>Recognize <strong>Model Cards</strong> and <strong>AWS AI Service Cards</strong> as governance tools.</li></ul><hr><p>âœ… With this, youâ€™ll be ready for questions on <strong>responsible AI, compliance, and GenAI risks</strong> in AWS certification exams.  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Generative-AI-Capabilities-Challenges-and-Compliance&quot;&gt;&lt;a href=&quot;#Generative-AI-Capabilities-Challenges-and-Compliance&quot; class=&quot;headerl</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(í•œêµ­ì–´) AWS Certified AI Practitioner (40) - ìƒì„±í˜• AIì˜ ì—­ëŸ‰ê³¼ ê³¼ì œ</title>
    <link href="https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-40/"/>
    <id>https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-40/</id>
    <published>2025-09-02T19:05:54.000Z</published>
    <updated>2025-09-02T19:50:52.616Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ìƒì„±í˜•-AIì˜-ì—­ëŸ‰ê³¼-ê³¼ì œ-ì‹œí—˜-í¬ì¸íŠ¸-í¬í•¨"><a href="#ìƒì„±í˜•-AIì˜-ì—­ëŸ‰ê³¼-ê³¼ì œ-ì‹œí—˜-í¬ì¸íŠ¸-í¬í•¨" class="headerlink" title="ìƒì„±í˜• AIì˜ ì—­ëŸ‰ê³¼ ê³¼ì œ (ì‹œí—˜ í¬ì¸íŠ¸ í¬í•¨)"></a>ìƒì„±í˜• AIì˜ ì—­ëŸ‰ê³¼ ê³¼ì œ (ì‹œí—˜ í¬ì¸íŠ¸ í¬í•¨)</h1><p>ì•„ë˜ ë‚´ìš©ì€ ê°•ì˜ìë£Œì™€ ëŒ€ë³¸ì„ ë°”íƒ•ìœ¼ë¡œ <strong>ì‰½ê³  ìì—°ìŠ¤ëŸ½ê²Œ</strong> ì •ë¦¬&#x2F;í™•ì¥í•œ ê²ƒì…ë‹ˆë‹¤. íŠ¹íˆ <strong>AWS ìê²©ì¦(íŠ¹íˆ AWS Certified AI Practitioner,MLâ€“Specialty, SAP&#x2F;Architect)</strong> ëŒ€ë¹„ì— ìœ ë¦¬í•˜ë„ë¡ <strong>ì‹œí—˜ì— ìì£¼ ë‚˜ì˜¤ëŠ” ê°œë…</strong>ê³¼ <strong>ì‹¤ë¬´ íŒ</strong>ì„ í•¨ê»˜ ë„£ì—ˆìŠµë‹ˆë‹¤.</p><hr><h2 id="1-ìƒì„±í˜•-AIê°€-ì˜í•˜ëŠ”-ê²ƒ-Capabilities"><a href="#1-ìƒì„±í˜•-AIê°€-ì˜í•˜ëŠ”-ê²ƒ-Capabilities" class="headerlink" title="1) ìƒì„±í˜• AIê°€ ì˜í•˜ëŠ” ê²ƒ (Capabilities)"></a>1) ìƒì„±í˜• AIê°€ ì˜í•˜ëŠ” ê²ƒ (Capabilities)</h2><ul><li><strong>ì ì‘ì„±(Adaptability)</strong>: ë‹¤ì–‘í•œ ë„ë©”ì¸ê³¼ íƒœìŠ¤í¬ë¡œ ë¹ ë¥´ê²Œ ì „ì´Â·ì ìš© ê°€ëŠ¥</li><li><strong>ë°˜ì‘ì„±(Responsiveness)</strong>: í”„ë¡¬í”„íŠ¸ì— ì¦‰ì‹œ ì‘ë‹µ, ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ì— ì í•©</li><li><strong>ë‹¨ìˆœì„±(Simplicity)</strong>: ì‚¬ìš©ì ì…ì¥ì—ì„  í”„ë¡¬í”„íŠ¸ë§Œ ì˜ ì“°ë©´ ë³µì¡í•œ ì‘ì—…ë„ ê°€ëŠ¥</li><li><strong>ì°½ì˜ì„±Â·íƒìƒ‰(Creativity &amp; Exploration)</strong>: ì•„ì´ë””ì–´ ë°œì‚°, ì´ˆì•ˆ&#x2F;í”„ë¡œí† íƒ€ì´í•‘ì— ê°•í•¨</li><li><strong>ë°ì´í„° íš¨ìœ¨(Data Efficiency)</strong>: ì‚¬ì „í•™ìŠµ ë•ë¶„ì— ë¹„êµì  ì ì€ ì¶”ê°€ ë°ì´í„°ë¡œë„ íŠœë‹ ê°€ëŠ¥</li><li><strong>ê°œì¸í™”(Personalization)</strong>: í”„ë¡¬í”„íŠ¸&#x2F;ì„¸ì…˜&#x2F;ë¯¸ì„¸ì¡°ì •ìœ¼ë¡œ ì‚¬ìš©ì ë§¥ë½ ë°˜ì˜</li><li><strong>í™•ì¥ì„±(Scalability)</strong>: ì„œë²„ë¦¬ìŠ¤&#x2F;ì˜¤í† ìŠ¤ì¼€ì¼ë§ ì¡°í•©ìœ¼ë¡œ ëŒ€ê·œëª¨ íŠ¸ë˜í”½ ì²˜ë¦¬ ìš©ì´</li></ul><blockquote><p><strong>ì‹œí—˜ í¬ì¸íŠ¸</strong><br>â€œìƒì„±í˜• AIì˜ ì¥ì â€ì„ ë¬»ëŠ” ë¬¸í•­ì—ì„œëŠ” <em>ì°½ì˜ì„±, ì ì‘ì„±, ê°œì¸í™”, í™•ì¥ì„±</em> ë“±ì„ í‚¤ì›Œë“œë¡œ ê¸°ì–µí•˜ì„¸ìš”.</p></blockquote><hr><h2 id="2-ìƒì„±í˜•-AIì˜-ì£¼ìš”-ê³¼ì œ-Challenges"><a href="#2-ìƒì„±í˜•-AIì˜-ì£¼ìš”-ê³¼ì œ-Challenges" class="headerlink" title="2) ìƒì„±í˜• AIì˜ ì£¼ìš” ê³¼ì œ (Challenges)"></a>2) ìƒì„±í˜• AIì˜ ì£¼ìš” ê³¼ì œ (Challenges)</h2><ul><li><strong>ê·œì œ ìœ„ë°˜</strong>: ì‚°ì—… ê·œì œ(ê¸ˆìœµ, ì˜ë£Œ ë“±)ì™€ ì§€ì—­ ê·œì •(GDPR ë“±) ë¯¸ì¤€ìˆ˜ ìœ„í—˜</li><li><strong>ì‚¬íšŒì  ë¦¬ìŠ¤í¬</strong>: í—ˆìœ„ì •ë³´ í™•ì‚°, ì°¨ë³„&#x2F;í¸í–¥ ê°•í™”, ì €ì‘ê¶Œ ë¶„ìŸ ë“±</li><li><strong>ë°ì´í„° ë³´ì•ˆÂ·ê°œì¸ì •ë³´</strong>: í”„ë¡¬í”„íŠ¸Â·ë¡œê·¸Â·í•™ìŠµë°ì´í„°ì—ì„œì˜ PII ë…¸ì¶œ</li><li><strong>ìœ í•´ì„±(Toxicity)</strong>: ê³µê²©ì Â·ë¶€ì ì ˆí•œ ë°œí™” ìƒì„±</li><li><strong>í™˜ê°(Hallucination)</strong>: ê·¸ëŸ´ë“¯í•˜ì§€ë§Œ ì‚¬ì‹¤ì´ ì•„ë‹Œ ë‚´ìš© ìƒì„±</li><li><strong>í•´ì„ê°€ëŠ¥ì„±(Interpretability)</strong> ë¶€ì¡±</li><li><strong>ë¹„ê²°ì •ì„±(Nondeterminism)</strong>: ê°™ì€ ì…ë ¥ì—ë„ ì¶œë ¥ì´ ë§¤ë²ˆ ë‹¬ë¼ì§</li><li><strong>í‘œì ˆÂ·ë¶€ì •í–‰ìœ„</strong>: ì—ì„¸ì´ ëŒ€í•„, ì½”ë“œ ë¶€ì • ì‚¬ìš© ë“±</li></ul><blockquote><p><strong>ì‹œí—˜ í¬ì¸íŠ¸</strong><br>â€œí™˜ê°â€ ì •ì˜ì™€ <strong>ëŒ€ì‘ì±…(RAG, ì¶œì²˜ëª…ì‹œ, ê²€ì¦ í”„ë¡œì„¸ìŠ¤)</strong>, â€œë¹„ê²°ì •ì„±â€ ì œì–´(ì˜¨ë„&#x2F;íƒ‘P&#x2F;ë””í„°ë¯¸ë‹ˆìŠ¤í‹± ë””ì½”ë”©) ê°™ì€ ì‹¤ë¬´ì  ì™„í™”ì±…ì„ ìì£¼ ë¬¼ì–´ë´…ë‹ˆë‹¤.</p></blockquote><hr><h2 id="3-ìœ í•´ì„±-Toxicity"><a href="#3-ìœ í•´ì„±-Toxicity" class="headerlink" title="3) ìœ í•´ì„±(Toxicity)"></a>3) ìœ í•´ì„±(Toxicity)</h2><ul><li><strong>ë¬¸ì œ</strong>: ê³µê²©ì &#x2F;ë¶ˆì¾Œ&#x2F;ë¶€ì ì ˆ ì½˜í…ì¸  ìƒì„±. ì¸ìš©(quote) í—ˆìš© ì—¬ë¶€ ë“± ê²½ê³„ê°€ ëª¨í˜¸.</li><li><strong>ëŒ€ì‘</strong><ul><li><strong>ë°ì´í„° ì •ì œ</strong>: í•™ìŠµÂ·íŠœë‹ ë°ì´í„°ì—ì„œ ìœ í•´í‘œí˜„ ì œê±°&#x2F;ì™„í™”</li><li><strong>ê°€ë“œë ˆì¼</strong>: <strong>Guardrails for Amazon Bedrock</strong>ë¡œ ì£¼ì œ ì°¨ë‹¨, ìš•ì„¤&#x2F;ì¦ì˜¤í‘œí˜„ í•„í„°, PII ë§ˆìŠ¤í‚¹</li><li><strong>íœ´ë¨¼ ë¦¬ë·°</strong>: <strong>Amazon A2I</strong>ë¡œ ì €ì‹ ë¢° ê²°ê³¼ì˜ ì¸ê°„ ê²€ìˆ˜</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_200.png" width="80%"></p>------------------------------------------------------------------------<h2 id="4-í™˜ê°-Hallucinations"><a href="#4-í™˜ê°-Hallucinations" class="headerlink" title="4) í™˜ê°(Hallucinations)"></a>4) í™˜ê°(Hallucinations)</h2><ul><li><strong>ì •ì˜</strong>: ê·¸ëŸ´ë“¯í•˜ì§€ë§Œ <strong>ì‚¬ì‹¤ì´ ì•„ë‹Œ ì£¼ì¥</strong>ì„ ìƒì„±(LLMì˜ í™•ë¥ ì  ìƒ˜í”Œë§ íŠ¹ì„±).</li><li><strong>ëŒ€ì‘</strong><ul><li><strong>RAG</strong>(Retrieval-Augmented Generation): <strong>ë²¡í„° ê²€ìƒ‰ + ì¸ìš©</strong>ìœ¼ë¡œ ìµœì‹ Â·ì •í™• ê·¼ê±° ì œì‹œ</li><li><strong>ì¶œë ¥ì— ì¶œì²˜ í‘œê¸°&#x2F;â€œë¯¸ê²€ì¦(Needs Verification)â€ ë¼ë²¨</strong></li><li>**ì˜¨ë„(temperature)â†“, íƒ‘Pâ†“**ë¡œ <strong>ë³´ìˆ˜ì  ë””ì½”ë”©</strong></li><li><strong>ì¤‘ìš” ì‘ë‹µì€ 2ì°¨ ê²€ì¦(ì™¸ë¶€ ì†ŒìŠ¤&#x2F;ì‚¬ëŒ)</strong></li><li><strong>SageMaker Clarify</strong>ë¡œ <strong>ì •í™•ë„&#x2F;ê°•ê±´ì„±</strong> í‰ê°€ ë° ë“œë¦¬í”„íŠ¸ ê°ì‹œ</li></ul></li></ul><blockquote><p><strong>ì‹œí—˜ í¬ì¸íŠ¸</strong><br>â€œí™˜ê°ì„ ì¤„ì´ëŠ” ë°©ë²•?â€ â†’ <strong>RAG, ê°€ë“œë ˆì¼, ë””ì½”ë”© íŒŒë¼ë¯¸í„° íŠœë‹, ì¶œì²˜í‘œê¸°, íœ´ë¨¼ ê²€ì¦</strong>.</p></blockquote><p align="center">  <img src="/images/aws_basic_201.png" width="80%"></p><hr><h2 id="5-í‘œì ˆÂ·ë¶€ì •í–‰ìœ„"><a href="#5-í‘œì ˆÂ·ë¶€ì •í–‰ìœ„" class="headerlink" title="5) í‘œì ˆÂ·ë¶€ì •í–‰ìœ„"></a>5) í‘œì ˆÂ·ë¶€ì •í–‰ìœ„</h2><ul><li><strong>ì´ìŠˆ</strong>: ê³¼ì œ ëŒ€í•„, ì‘ì„± ìƒ˜í”Œ ìœ„ì¡°, ì¶œì²˜ ì¶”ì  ì–´ë ¤ì›€</li><li><strong>ëŒ€ì‘</strong><ul><li><strong>ì¶œì²˜ ìš”êµ¬</strong>(ì°¸ê³ ë¬¸í—Œ&#x2F;ë§í¬ ì˜ë¬´í™”)</li><li><strong>ê²€ì¶œê¸° ë³‘í–‰</strong>(ì™„ë²½í•˜ì§„ ì•ŠìŒ) + <strong>í”„ë¡œì„¸ìŠ¤ ê¸°ë°˜ í‰ê°€</strong>(ë©´ë‹´Â·êµ¬ìˆ Â·ë²„ì „ê´€ë¦¬)</li><li><strong>ê°€ë“œë ˆì¼</strong>ë¡œ ì‹œí—˜Â·ì±„ì  ë§¥ë½ì—ì„œ ê³¼ë„í•œ ìë™í™” ë°©ì§€</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_202.png" width="80%"></p><hr><h2 id="6-í”„ë¡¬í”„íŠ¸-ì˜¤ë‚¨ìš©-ê³µê²©-ìœ í˜•ê³¼-ë°©ì–´"><a href="#6-í”„ë¡¬í”„íŠ¸-ì˜¤ë‚¨ìš©-ê³µê²©-ìœ í˜•ê³¼-ë°©ì–´" class="headerlink" title="6) í”„ë¡¬í”„íŠ¸ ì˜¤ë‚¨ìš©(ê³µê²©) ìœ í˜•ê³¼ ë°©ì–´"></a>6) í”„ë¡¬í”„íŠ¸ ì˜¤ë‚¨ìš©(ê³µê²©) ìœ í˜•ê³¼ ë°©ì–´</h2><h3 id="6-1-ê³µê²©-ìœ í˜•"><a href="#6-1-ê³µê²©-ìœ í˜•" class="headerlink" title="6-1) ê³µê²© ìœ í˜•"></a>6-1) ê³µê²© ìœ í˜•</h3><ul><li><strong>ë°ì´í„° ì¤‘ë…(Training&#x2F;Prompt Poisoning)</strong>: ì•…ì„±Â·í¸í–¥ ë°ì´í„° ì£¼ì…</li><li><strong>í”„ë¡¬í”„íŠ¸ ì¸ì ì…˜&#x2F;í•˜ì´ì¬í‚¹</strong>: ì€ë°€ ì§€ì‹œë¬¸ìœ¼ë¡œ ëª¨ë¸ í–‰íƒœ ì™œê³¡(í—ˆìœ„ì •ë³´, ì•…ì„±ì½”ë“œ ìœ ë„)</li></ul><p align="center">  <img src="/images/aws_basic_203.png" width="80%"></p><ul><li><strong>ë…¸ì¶œ(Exposure)</strong>: í›ˆë ¨Â·ì¶”ë¡  ì¤‘ ë¯¼ê°ì •ë³´ ë…¸ì¶œ</li></ul><p align="center">  <img src="/images/aws_basic_204.png" width="80%"></p><ul><li><strong>í”„ë¡¬í”„íŠ¸ ë¦¬í‚¹</strong>: ë‚´ë¶€ í”„ë¡¬í”„íŠ¸&#x2F;ì‹œìŠ¤í…œ ì§€ì¹¨ ìœ ì¶œ</li></ul><p align="center">  <img src="/images/aws_basic_205.png" width="80%"></p><ul><li><strong>íƒˆì˜¥(Jailbreaking)</strong>: ì•ˆì „ì¥ì¹˜ ìš°íšŒ(ë‹¤ì¤‘ ì˜ˆì‹œ â€œmany-shotâ€ ë“± ê¸°ë²• í™œìš©)</li></ul><p align="center">  <img src="/images/aws_basic_206.png" width="80%"></p><h3 id="6-2-ë°©ì–´-ì „ëµ-AWS-ê´€ì "><a href="#6-2-ë°©ì–´-ì „ëµ-AWS-ê´€ì " class="headerlink" title="6-2) ë°©ì–´ ì „ëµ (AWS ê´€ì )"></a>6-2) ë°©ì–´ ì „ëµ (AWS ê´€ì )</h3><ul><li><strong>Bedrock Guardrails</strong>: ê¸ˆì§€ ì£¼ì œ&#x2F;ìš•ì„¤&#x2F;PII í•„í„°, í†¤Â·ìŠ¤íƒ€ì¼ ê·œì¹™</li><li><strong>ë„¤íŠ¸ì›Œí¬Â·ì•”í˜¸í™”</strong>: <strong>VPC ì—”ë“œí¬ì¸íŠ¸</strong>, <strong>AWS KMS</strong>ë¡œ ì €ì¥&#x2F;ì „ì†¡ ì•”í˜¸í™”</li><li><strong>ìµœì†Œê¶Œí•œ(IAM)</strong> &amp; <strong>SageMaker Role Manager</strong>ë¡œ ì—­í•  ê¸°ë°˜ ì ‘ê·¼</li><li><strong>ì…ë ¥ ì •í™”</strong>: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¶„ë¦¬, â€œ<strong>ì§€ì‹œë³´ë‹¤ ì•ˆì „ì •ì±… ìš°ì„ </strong>â€œ ê·œì¹™ ì‚½ì…</li><li><strong>ì¶œë ¥ ê²€ì¦</strong>: ì½˜í…ì¸  í•„í„°, <strong>A2I íœ´ë¨¼ë¦¬ë·°</strong></li><li><strong>ë¡œê¹…Â·ê°ì‚¬</strong>: <strong>CloudWatch&#x2F;CloudTrail</strong>ë¡œ ì¶”ì , ì´ìƒ ì§•í›„ ì•Œë¦¼</li><li><strong>ë°ì´í„° ê²©ë¦¬</strong>: <strong>SageMaker ë„¤íŠ¸ì›Œí¬ ê²©ë¦¬ ëª¨ë“œ</strong>(ì•„ì›ƒë°”ìš´ë“œ ì°¨ë‹¨), ë¯¼ê° ë°ì´í„° ë¹„ë…¸ì¶œ</li></ul><blockquote><p><strong>ì‹œí—˜ í¬ì¸íŠ¸</strong><br>â€œí”„ë¡¬í”„íŠ¸ ì¸ì ì…˜ ëŒ€ì‘ì±…â€ â†’ <strong>ê°€ë“œë ˆì¼, ì…ë ¥ ì •í™”, ìµœì†Œê¶Œí•œ, VPCÂ·KMS, ë¡œê¹…&#x2F;ê°ì‚¬, íœ´ë¨¼ ë¦¬ë·°</strong>.</p></blockquote><hr><h2 id="7-ê·œì œ-ëŒ€ìƒ-ì›Œí¬ë¡œë“œ-Regulated-Workloads"><a href="#7-ê·œì œ-ëŒ€ìƒ-ì›Œí¬ë¡œë“œ-Regulated-Workloads" class="headerlink" title="7) ê·œì œ ëŒ€ìƒ ì›Œí¬ë¡œë“œ(Regulated Workloads)"></a>7) ê·œì œ ëŒ€ìƒ ì›Œí¬ë¡œë“œ(Regulated Workloads)</h2><ul><li><strong>ì‚°ì—…</strong>: ê¸ˆìœµ, ì˜ë£Œ, í•­ê³µìš°ì£¼ ë“±ì€ <strong>ì¶”ê°€ ê·œì œ&#x2F;ê°ì‚¬&#x2F;ë³´ê´€&#x2F;ë³´ì•ˆìš”ê±´</strong> í•„ìš”</li><li><strong>ì˜ˆì‹œ</strong>: ì‹ ìš©Â·ëŒ€ì¶œ ì‹¬ì‚¬ ê²°ê³¼(ëª¨ë¸ ì¶œë ¥)ê°€ ê·œì œ ëŒ€ìƒ â†’ <strong>ê²°ì •ê·¼ê±° ë³´ê´€Â·ì„¤ëª… ê°€ëŠ¥ì„±</strong> í•„ìˆ˜</li></ul><blockquote><p><strong>ì‹œí—˜ í¬ì¸íŠ¸</strong><br><strong>ê³µìœ  ì±…ì„ ëª¨ë¸</strong>(Shared Responsibility Model) ê¸°ì–µ:</p><ul><li><strong>AWS</strong>: í´ë¼ìš°ë“œ â€œ<strong>of</strong>â€œ ë³´ì•ˆ(ë°ì´í„°ì„¼í„°Â·í•˜ë“œì›¨ì–´Â·ê¸°ë³¸ ì„œë¹„ìŠ¤)</li><li><strong>ê³ ê°</strong>: í´ë¼ìš°ë“œ â€œ<strong>in</strong>â€œ ë³´ì•ˆ(ë°ì´í„° ë¶„ë¥˜, ì ‘ê·¼í†µì œ, ì•”í˜¸í™” ì„¤ì •, ëª¨ë¸ ê±°ë²„ë„ŒìŠ¤)</li></ul></blockquote><hr><h2 id="8-AI-í‘œì¤€Â·ì»´í”Œë¼ì´ì–¸ìŠ¤-ê³¼ì œ"><a href="#8-AI-í‘œì¤€Â·ì»´í”Œë¼ì´ì–¸ìŠ¤-ê³¼ì œ" class="headerlink" title="8) AI í‘œì¤€Â·ì»´í”Œë¼ì´ì–¸ìŠ¤ ê³¼ì œ"></a>8) AI í‘œì¤€Â·ì»´í”Œë¼ì´ì–¸ìŠ¤ ê³¼ì œ</h2><ul><li><strong>ë³µì¡ì„±Â·ë¶ˆíˆ¬ëª…ì„±</strong>: ì˜ì‚¬ê²°ì • ê²½ë¡œ ê°ì‚¬ ë‚œì´ë„</li><li><strong>ë™ì  ë³€í™”</strong>: ëª¨ë¸Â·ë°ì´í„°ê°€ ì‹œê°„ì— ë”°ë¼ ë³€í•¨(ë²„ì „ê´€ë¦¬&#x2F;ì¶”ì  í•„ìš”)</li><li><strong>ì˜ˆê¸°ì¹˜ ëª»í•œ ëŠ¥ë ¥</strong>: ì˜ë„ì¹˜ ì•Šì€ í™œìš© ê°€ëŠ¥ì„±</li><li><strong>ê³ ìœ  ìœ„í—˜</strong>: ì•Œê³ ë¦¬ì¦˜ í¸í–¥, í”„ë¼ì´ë²„ì‹œ ì¹¨í•´, í—ˆìœ„ì •ë³´</li><li><strong>ì±…ì„ì„±</strong>: <strong>ì„¤ëª…ê°€ëŠ¥ì„±</strong> ìš”êµ¬(ëª¨ë¸ ë‚´ë¶€&#x2F;ì™¸ë¶€ ì„¤ëª…, ì¶œë ¥ ê·¼ê±° ì œê³µ)</li><li><strong>ê·œì œ íŠ¸ë Œë“œ</strong>: EU <strong>AI Act</strong>, ë¯¸êµ­(ì£¼Â·ë„ì‹œë³„) ê·œì • ë“± â†’ <strong>ê³µì •Â·ë¹„ì°¨ë³„Â·ì¸ê¶Œ</strong> ê°•ì¡°</li></ul><p align="center">  <img src="/images/aws_basic_207.png" width="80%"></p><h3 id="AWS-ì»´í”Œë¼ì´ì–¸ìŠ¤-ìƒíƒœê³„-ëŒ€í‘œ"><a href="#AWS-ì»´í”Œë¼ì´ì–¸ìŠ¤-ìƒíƒœê³„-ëŒ€í‘œ" class="headerlink" title="AWS ì»´í”Œë¼ì´ì–¸ìŠ¤ ìƒíƒœê³„(ëŒ€í‘œ)"></a>AWS ì»´í”Œë¼ì´ì–¸ìŠ¤ ìƒíƒœê³„(ëŒ€í‘œ)</h3><ul><li><strong>ISO&#x2F;NIST&#x2F;ENISA&#x2F;SOC&#x2F;HIPAA&#x2F;GDPR&#x2F;PCI DSS</strong> ë“± ë‹¤ìˆ˜ ì¸ì¦(ì„œë¹„ìŠ¤ë³„ ì§€ì› ë²”ìœ„ ìƒì´)</li><li><strong>í•´ì•¼ í•  ì¼</strong>: ì„œë¹„ìŠ¤ ì¸ì¦ í™•ì¸ + <strong>ìì²´ ì›Œí¬ë¡œë“œì— ëŒ€í•œ ì¶”ê°€ í†µì œ&#x2F;ê°ì‚¬</strong> ì„¤ê³„</li></ul><hr><h2 id="9-í•´ì„ê°€ëŠ¥ì„±-vs-ì„¤ëª…ê°€ëŠ¥ì„±"><a href="#9-í•´ì„ê°€ëŠ¥ì„±-vs-ì„¤ëª…ê°€ëŠ¥ì„±" class="headerlink" title="9) í•´ì„ê°€ëŠ¥ì„± vs ì„¤ëª…ê°€ëŠ¥ì„±"></a>9) í•´ì„ê°€ëŠ¥ì„± vs ì„¤ëª…ê°€ëŠ¥ì„±</h2><ul><li><strong>í•´ì„ê°€ëŠ¥ì„±(Interpretability)</strong>: â€œ<strong>ì™œ&#x2F;ì–´ë–»ê²Œ</strong> ê·¸ ê²°ì •ì´ ë‚˜ì™”ëŠ”ê°€â€ë¥¼ <strong>ëª¨ë¸ êµ¬ì¡° ìì²´</strong>ë¡œ ì´í•´<ul><li>ë†’ì„ìˆ˜ë¡ ë³´í†µ <strong>ì„±ëŠ¥ì€ ë‹¨ìˆœ</strong>(ì„ í˜•&#x2F;ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ë“±)</li></ul></li><li><strong>ì„¤ëª…ê°€ëŠ¥ì„±(Explainability)</strong>: ë‚´ë¶€ë¥¼ ëª°ë¼ë„ <strong>ì…ì¶œë ¥ ê´€ê³„ ì„¤ëª…</strong>(íŠ¹ì„± ì¤‘ìš”ë„, ë¶€ë¶„ì˜ì¡´ ë“±)<ul><li><strong>SageMaker Clarify</strong>: <strong>SHAP ê¸°ë°˜</strong> ì¤‘ìš”ë„, ë°”ì´ì–´ìŠ¤ ì¸¡ì •Â·ì„¤ëª… ì œê³µ</li><li><strong>PDP(Partial Dependence Plot)</strong>: í•˜ë‚˜ì˜ íŠ¹ì„±ì´ ì˜ˆì¸¡ì— ë¯¸ì¹˜ëŠ” í‰ê· ì  ì˜í–¥ ì‹œê°í™”</li></ul></li></ul><blockquote><p><strong>ì‹œí—˜ í¬ì¸íŠ¸</strong><br><strong>Clarify &#x3D; ë°”ì´ì–´ìŠ¤ íƒì§€ + ì„¤ëª…ê°€ëŠ¥ì„± ë„êµ¬(íŠ¹ì„±ê¸°ì—¬&#x2F;SHAP, ë°ì´í„°Â·ëª¨ë¸ í¸í–¥ ì¸¡ì •)</strong>.</p></blockquote><hr><h2 id="10-ëª¨ë¸-ì¹´ë“œ-ì„œë¹„ìŠ¤-ì¹´ë“œ"><a href="#10-ëª¨ë¸-ì¹´ë“œ-ì„œë¹„ìŠ¤-ì¹´ë“œ" class="headerlink" title="10) ëª¨ë¸ ì¹´ë“œ &amp; ì„œë¹„ìŠ¤ ì¹´ë“œ"></a>10) ëª¨ë¸ ì¹´ë“œ &amp; ì„œë¹„ìŠ¤ ì¹´ë“œ</h2><ul><li><strong>ëª¨ë¸ ì¹´ë“œ(Model Cards)</strong>: ëª¨ë¸ì˜ <strong>ì˜ë„ëœ ì‚¬ìš©, ìœ„í—˜ë“±ê¸‰, ë°ì´í„° ì¶œì²˜&#x2F;ë¼ì´ì„ ìŠ¤&#x2F;í¸í–¥, í•™ìŠµÂ·í‰ê°€ ì§€í‘œ</strong> ë¬¸ì„œí™”<ul><li><strong>SageMaker Model Cards</strong>ë¡œ ì¤‘ì•™í™” ê´€ë¦¬ â†’ <strong>ê°ì‚¬Â·ê·œì œ ëŒ€ì‘</strong>ì— ìœ ë¦¬</li></ul></li><li><strong>AWS AI Service Cards</strong>: BedrockÂ·TextractÂ·Rekognition ë“± <strong>ì„œë¹„ìŠ¤ ìˆ˜ì¤€ì˜ ì±…ì„ê° ìˆëŠ” ì„¤ê³„Â·í•œê³„Â·ê¶Œì¥ ì‚¬ìš©</strong> ë¬¸ì„œ</li></ul><blockquote><p><strong>ì‹œí—˜ í¬ì¸íŠ¸</strong><br>â€œê°ì‚¬ ì¤€ë¹„&#x2F;ê·œì œ ëŒ€ì‘ ë¬¸ì„œí™”?â€ â†’ <strong>SageMaker Model Cards &#x2F; AWS AI Service Cards</strong>.</p></blockquote><p align="center">  <img src="/images/aws_basic_208.png" width="80%"></p><hr><h2 id="11-ìš´ì˜-ì¤‘-í’ˆì§ˆÂ·ê±°ë²„ë„ŒìŠ¤"><a href="#11-ìš´ì˜-ì¤‘-í’ˆì§ˆÂ·ê±°ë²„ë„ŒìŠ¤" class="headerlink" title="11) ìš´ì˜ ì¤‘ í’ˆì§ˆÂ·ê±°ë²„ë„ŒìŠ¤"></a>11) ìš´ì˜ ì¤‘ í’ˆì§ˆÂ·ê±°ë²„ë„ŒìŠ¤</h2><ul><li><strong>SageMaker Model Monitor</strong>: ë°ì´í„°&#x2F;í’ˆì§ˆ ë“œë¦¬í”„íŠ¸ ê°ì‹œ, ì„ê³„ì¹˜ ìœ„ë°˜ ì•Œë¦¼ â†’ <strong>ì¬í•™ìŠµ íŠ¸ë¦¬ê±°</strong></li><li><strong>SageMaker Model Registry</strong>: ëª¨ë¸ <strong>ë²„ì „Â·ë©”íƒ€ë°ì´í„°Â·ìŠ¹ì¸ ìƒíƒœ</strong> ê´€ë¦¬, <strong>ë°°í¬ ìë™í™”</strong> ì—°ê³„</li><li><strong>SageMaker Pipelines</strong>: ML CI&#x2F;CD(ì²˜ë¦¬â†’í•™ìŠµâ†’íŠœë‹â†’ê²€ì¦â†’ë“±ë¡â†’ë°°í¬) ìë™í™”</li><li><strong>SageMaker Role Manager</strong>: í˜ë¥´ì†Œë‚˜(DS&#x2F;ML Ops ë“±)ë³„ ìµœì†Œê¶Œí•œ ì„¤ê³„</li></ul><hr><h2 id="12-ë°ì´í„°Â·í¸í–¥-ë‹¤ë£¨ê¸°"><a href="#12-ë°ì´í„°Â·í¸í–¥-ë‹¤ë£¨ê¸°" class="headerlink" title="12) ë°ì´í„°Â·í¸í–¥ ë‹¤ë£¨ê¸°"></a>12) ë°ì´í„°Â·í¸í–¥ ë‹¤ë£¨ê¸°</h2><ul><li><strong>SageMaker Data Wrangler</strong>: ì „ì²˜ë¦¬Â·ì‹œê°í™”Â·í’ˆì§ˆì ê²€, <strong>ì–¸ë”ë¦¬í”„ë ˆì  í‹°ë“œ ê·¸ë£¹ ë³´ê°•</strong>(ë°ì´í„° ì¦ê°•)</li><li><strong>SageMaker Feature Store</strong>: ì¬ì‚¬ìš© ê°€ëŠ¥í•œ <strong>ê³ í’ˆì§ˆ í”¼ì²˜ ì¹´íƒˆë¡œê·¸</strong>ë¡œ ì¼ê´€ì„± í™•ë³´</li><li><strong>Clarify ë°”ì´ì–´ìŠ¤ ì§€í‘œ</strong>: ìƒ˜í”Œë§ í¸í–¥Â·ë¼ë²¨ í¸í–¥Â·ì„±ëŠ¥ í¸í–¥ ë“±<br><strong>í†µê³„ì  ì¸¡ì •</strong></li></ul><hr><h2 id="13-ì‹¤ë¬´-ì²´í¬ë¦¬ìŠ¤íŠ¸-ìš”ì•½"><a href="#13-ì‹¤ë¬´-ì²´í¬ë¦¬ìŠ¤íŠ¸-ìš”ì•½" class="headerlink" title="13) ì‹¤ë¬´ ì²´í¬ë¦¬ìŠ¤íŠ¸ (ìš”ì•½)"></a>13) ì‹¤ë¬´ ì²´í¬ë¦¬ìŠ¤íŠ¸ (ìš”ì•½)</h2><ol><li><strong>ìš”ê±´ íŒŒì•…</strong>: ê·œì œ&#x2F;ê°ì‚¬&#x2F;ë°ì´í„° êµ­ì™¸ë°˜ì¶œ&#x2F;ë³´ê´€ê¸°ê°„</li><li><strong>ì•„í‚¤í…ì²˜ ë³´ì•ˆ</strong>: VPC, KMS, í”„ë¼ì´ë¹— ì„œë¸Œë„·, ì—”ë“œí¬ì¸íŠ¸ ì •ì±…</li><li><strong>ê°€ë“œë ˆì¼</strong>: Bedrock Guardrails(ì£¼ì œ&#x2F;PII&#x2F;í†¤), ì½˜í…ì¸  í•„í„°</li><li><strong>RAG</strong>: ìµœì‹ ì„±Â·ì •í™•ì„±Â·ì¶œì²˜ í™•ë³´, <strong>â€œë¯¸ê²€ì¦â€ ë¼ë²¨</strong></li><li><strong>ë¡œê¹…&#x2F;ê°ì‚¬</strong>: CloudWatch&#x2F;CloudTrail, í”„ë¡¬í”„íŠ¸&#x2F;ì‘ë‹µ ê°ì‚¬ ê°€ëŠ¥ì„±</li><li><strong>ê±°ë²„ë„ŒìŠ¤</strong>: Model Cards, Registry, Pipelines, Model Monitor</li><li><strong>ì„¤ëª…ê°€ëŠ¥ì„±</strong>: Clarify(SHAP, í¸í–¥), PDP&#x2F;íŠ¹ì„±ì¤‘ìš”ë„ ë³´ê³ </li><li><strong>íœ´ë¨¼ ì¸ë”ë£¨í”„</strong>: ì €ì‹ ë¢° ì¼€ì´ìŠ¤ A2I ë¼ìš°íŒ…</li><li><strong>ë¹„ê²°ì •ì„± ì œì–´</strong>: temperature&#x2F;top-p&#x2F;beam ì¬í˜„ì„± ê°€ì´ë“œ(ì™„ì „ ê²°ì •ì  ë³´ì¥ì€ ì–´ë ¤ì›€)</li><li><strong>êµìœ¡</strong>: ì‚¬ìš©ìì—ê²Œ í™˜ê°Â·ì €ì‘ê¶ŒÂ·ë³´ì•ˆ ì¸ì§€ êµìœ¡</li></ol><hr><h2 id="14-ë¯¸ë‹ˆ-í€´ì¦ˆ-ì‹œí—˜-ëŒ€ë¹„"><a href="#14-ë¯¸ë‹ˆ-í€´ì¦ˆ-ì‹œí—˜-ëŒ€ë¹„" class="headerlink" title="14) ë¯¸ë‹ˆ í€´ì¦ˆ(ì‹œí—˜ ëŒ€ë¹„)"></a>14) ë¯¸ë‹ˆ í€´ì¦ˆ(ì‹œí—˜ ëŒ€ë¹„)</h2><ol><li><p><strong>í™˜ê°ì„ ì¤„ì´ëŠ” ê°€ì¥ íš¨ê³¼ì ì¸ ì•„í‚¤í…ì²˜ íŒ¨í„´ì€?</strong><br>â†’ <strong>RAG + ì¶œì²˜í‘œê¸° + ì €ì˜¨ë„ ë””ì½”ë”© + íœ´ë¨¼ê²€ì¦</strong></p></li><li><p><strong>ê·œì œ ì‚°ì—…ì—ì„œ ëª¨ë¸ ê²°ì •ì„ ì„¤ëª…Â·ê°ì‚¬í•˜ë ¤ë©´ ì–´ë–¤ AWS ê¸°ëŠ¥ì„ ì¡°í•©?</strong><br>â†’ <strong>Model Cards + Clarify(ì„¤ëª…&#x2F;í¸í–¥) + Model Monitor(ë“œë¦¬í”„íŠ¸) + Registry(ë²„ì „&#x2F;ìŠ¹ì¸)</strong></p></li><li><p><strong>í”„ë¡¬í”„íŠ¸ ì¸ì ì…˜&#x2F;íƒˆì˜¥ ë°©ì§€ì±… 3ê°€ì§€?</strong><br>â†’ <strong>Guardrails</strong>, <strong>ì…ë ¥ ì •í™”Â·ì‹œìŠ¤í…œí”„ë¡¬í”„íŠ¸ ë³´í˜¸</strong>, <strong>IAM ìµœì†Œê¶Œí•œÂ·VPC&#x2F;KMS</strong>, (í•„ìš” ì‹œ <strong>A2I</strong>)</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ìƒì„±í˜•-AIì˜-ì—­ëŸ‰ê³¼-ê³¼ì œ-ì‹œí—˜-í¬ì¸íŠ¸-í¬í•¨&quot;&gt;&lt;a href=&quot;#ìƒì„±í˜•-AIì˜-ì—­ëŸ‰ê³¼-ê³¼ì œ-ì‹œí—˜-í¬ì¸íŠ¸-í¬í•¨&quot; class=&quot;headerlink&quot; title=&quot;ìƒì„±í˜• AIì˜ ì—­ëŸ‰ê³¼ ê³¼ì œ (ì‹œí—˜ í¬ì¸íŠ¸ í¬í•¨)&quot;&gt;&lt;/a&gt;ìƒì„±í˜• AIì˜ ì—­ëŸ‰ê³¼ </summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(í•œêµ­ì–´) AWS Certified AI Practitioner (39) - Responsible AI &amp; Security</title>
    <link href="https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-39/"/>
    <id>https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-39/</id>
    <published>2025-09-02T18:55:18.000Z</published>
    <updated>2025-09-02T19:05:30.690Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Responsible-AI-Security-ì±…ì„-ìˆëŠ”-AIì™€-ë³´ì•ˆ"><a href="#Responsible-AI-Security-ì±…ì„-ìˆëŠ”-AIì™€-ë³´ì•ˆ" class="headerlink" title="Responsible AI &amp; Security (ì±…ì„ ìˆëŠ” AIì™€ ë³´ì•ˆ)"></a>Responsible AI &amp; Security (ì±…ì„ ìˆëŠ” AIì™€ ë³´ì•ˆ)</h1><h2 id="1-Responsible-AI-ì±…ì„-ìˆëŠ”-AI"><a href="#1-Responsible-AI-ì±…ì„-ìˆëŠ”-AI" class="headerlink" title="1. Responsible AI (ì±…ì„ ìˆëŠ” AI)"></a>1. Responsible AI (ì±…ì„ ìˆëŠ” AI)</h2><ul><li><strong>ëª©í‘œ</strong>: AI ì‹œìŠ¤í…œì´ <strong>íˆ¬ëª…ì„±</strong>ê³¼ <strong>ì‹ ë¢°ì„±</strong>ì„ ê°€ì§€ë„ë¡ ì„¤ê³„  </li><li><strong>ì¤‘ìš”ì„±</strong>: ì‚¬ìš©ìê°€ ê²°ê³¼ë¥¼ ì‹ ë¢°í•˜ê³ , ë¶€ì •ì  ê²°ê³¼ë‚˜ ìœ„í—˜ì„ ì¤„ì¼ ìˆ˜ ìˆìŒ  </li><li><strong>ì ìš© ë²”ìœ„</strong>: AI <strong>ì „ì²´ ë¼ì´í”„ì‚¬ì´í´</strong>  <ul><li>ì„¤ê³„(Design) â†’ ê°œë°œ(Development) â†’ ë°°í¬(Deployment) â†’ ëª¨ë‹ˆí„°ë§(Monitoring) â†’ í‰ê°€(Evaluation)</li></ul></li></ul><h2 id="2-Security-ë³´ì•ˆ"><a href="#2-Security-ë³´ì•ˆ" class="headerlink" title="2. Security (ë³´ì•ˆ)"></a>2. Security (ë³´ì•ˆ)</h2><ul><li><strong>3ëŒ€ ì›ì¹™</strong>: CIA ì›ì¹™  <ul><li><strong>Confidentiality (ê¸°ë°€ì„±)</strong>: ë¯¼ê°í•œ ë°ì´í„° ë³´í˜¸  </li><li><strong>Integrity (ë¬´ê²°ì„±)</strong>: ë°ì´í„°ê°€ ë³€ì¡°ë˜ì§€ ì•Šë„ë¡ ë³´ì¥  </li><li><strong>Availability (ê°€ìš©ì„±)</strong>: í•„ìš”í•œ ì‚¬ëŒì´ í•„ìš”í•œ ì‹œì ì— ë°ì´í„° ì ‘ê·¼ ê°€ëŠ¥</li></ul></li><li><strong>ì ìš© ëŒ€ìƒ</strong>: ì¡°ì§ì˜ ë°ì´í„°, ì •ë³´ ìì‚°, IT ì¸í”„ë¼ ì „ë°˜</li></ul><hr><h1 id="Governance-Compliance"><a href="#Governance-Compliance" class="headerlink" title="Governance &amp; Compliance"></a>Governance &amp; Compliance</h1><h2 id="1-Governance-ê±°ë²„ë„ŒìŠ¤"><a href="#1-Governance-ê±°ë²„ë„ŒìŠ¤" class="headerlink" title="1. Governance (ê±°ë²„ë„ŒìŠ¤)"></a>1. Governance (ê±°ë²„ë„ŒìŠ¤)</h2><ul><li><strong>ëª©ì </strong>: ë¦¬ìŠ¤í¬ ê´€ë¦¬ + ë¹„ì¦ˆë‹ˆìŠ¤ ìš´ì˜ì—ì„œ ê°€ì¹˜ ì°½ì¶œ  </li><li><strong>ë°©ë²•</strong>: ëª…í™•í•œ ì •ì±…, ê°€ì´ë“œë¼ì¸, ê°ë… ì²´ê³„ í•„ìš”  </li><li><strong>íš¨ê³¼</strong>: AI ì‹œìŠ¤í…œì´ ë²•ë¥  ë° ê·œì œ ìš”êµ¬ì‚¬í•­ì— ë¶€í•©í•˜ë„ë¡ í•˜ê³ , <strong>ì‚¬ìš©ì ì‹ ë¢°</strong>ë¥¼ ê°•í™”</li></ul><h2 id="2-Compliance-ì»´í”Œë¼ì´ì–¸ìŠ¤"><a href="#2-Compliance-ì»´í”Œë¼ì´ì–¸ìŠ¤" class="headerlink" title="2. Compliance (ì»´í”Œë¼ì´ì–¸ìŠ¤)"></a>2. Compliance (ì»´í”Œë¼ì´ì–¸ìŠ¤)</h2><ul><li><strong>ì •ì˜</strong>: ê·œì •ê³¼ ì§€ì¹¨ì„ ì¤€ìˆ˜í•˜ëŠ” ê²ƒ  </li><li><strong>ì¤‘ìš” ë¶„ì•¼</strong>: ê¸ˆìœµ, ì˜ë£Œ, ë²•ë¥  ê°™ì€ ë¯¼ê°í•œ ì˜ì—­ì—ì„œëŠ” <strong>ë²•ì  ê·œì œ ì¤€ìˆ˜</strong>ê°€ í•µì‹¬</li></ul><hr><h1 id="Core-Dimensions-of-Responsible-AI"><a href="#Core-Dimensions-of-Responsible-AI" class="headerlink" title="Core Dimensions of Responsible AI"></a>Core Dimensions of Responsible AI</h1><ol><li><strong>ê³µì •ì„±(Fairness)</strong> â€“ ì°¨ë³„ ë°©ì§€, í¬ìš©ì„± í™•ë³´  </li><li><strong>ì„¤ëª… ê°€ëŠ¥ì„±(Explainability)</strong> â€“ ëª¨ë¸ì´ ì–´ë–¤ ì´ìœ ë¡œ ê²°ê³¼ë¥¼ ëƒˆëŠ”ì§€ ì´í•´ ê°€ëŠ¥  </li><li><strong>í”„ë¼ì´ë²„ì‹œ &amp; ë³´ì•ˆ(Privacy &amp; Security)</strong> â€“ ê°œì¸ì´ ìì‹ ì˜ ë°ì´í„° ì‚¬ìš© ì—¬ë¶€ë¥¼ í†µì œ  </li><li><strong>íˆ¬ëª…ì„±(Transparency)</strong> â€“ ëª¨ë¸ì˜ ë™ì‘ê³¼ í•œê³„ë¥¼ ëª…í™•íˆ ì•Œ ìˆ˜ ìˆì–´ì•¼ í•¨  </li><li><strong>ì •í™•ì„± &amp; ê°•ê±´ì„±(Veracity &amp; Robustness)</strong> â€“ ì˜ˆê¸°ì¹˜ ëª»í•œ ìƒí™©ì—ì„œë„ ì•ˆì •ì ì´ì–´ì•¼ í•¨  </li><li><strong>ê±°ë²„ë„ŒìŠ¤(Governance)</strong> â€“ ì±…ì„ ìˆëŠ” AI ìš´ì˜ ì²´ê³„ ìˆ˜ë¦½  </li><li><strong>ì•ˆì „ì„±(Safety)</strong> â€“ ì‚¬íšŒì™€ ê°œì¸ì—ê²Œ ì•ˆì „í•˜ê³  ìœ ìµí•´ì•¼ í•¨  </li><li><strong>ì œì–´ ê°€ëŠ¥ì„±(Controllability)</strong> â€“ ì¸ê°„ì˜ ê°€ì¹˜ì™€ ì˜ë„ë¥¼ ë°˜ì˜í•  ìˆ˜ ìˆì–´ì•¼ í•¨</li></ol><hr><h1 id="Responsible-AI-â€“-AWS-ì„œë¹„ìŠ¤-í™œìš©"><a href="#Responsible-AI-â€“-AWS-ì„œë¹„ìŠ¤-í™œìš©" class="headerlink" title="Responsible AI â€“ AWS ì„œë¹„ìŠ¤ í™œìš©"></a>Responsible AI â€“ AWS ì„œë¹„ìŠ¤ í™œìš©</h1><ul><li><p><strong>Amazon Bedrock</strong></p><ul><li>ëª¨ë¸ ì„±ëŠ¥ í‰ê°€(ì‚¬ëŒ&#x2F;ìë™)  </li><li><strong>Guardrails</strong>: ë¯¼ê° ë°ì´í„°(PII) ë§ˆìŠ¤í‚¹, ìœ í•´ ì½˜í…ì¸  ì°¨ë‹¨</li></ul></li><li><p><strong>SageMaker Clarify</strong></p><ul><li>ì •í™•ë„, ê°•ê±´ì„±, ìœ í•´ì„±(Toxicity) í‰ê°€  </li><li><strong>Bias ê°ì§€</strong>: ì˜ˆ) ë°ì´í„°ê°€ ì¤‘ë…„ì¸µì— ì¹˜ìš°ì³ ìˆìŒ</li></ul></li><li><p><strong>SageMaker Data Wrangler</strong></p><ul><li>í¸í–¥ëœ ë°ì´í„° ë³´ì • â†’ <strong>ë°ì´í„° ì¦ê°•(Augmentation)</strong> ê¸°ëŠ¥</li></ul></li><li><p><strong>SageMaker Model Monitor</strong></p><ul><li>ìš´ì˜ ì¤‘ ëª¨ë¸ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ (ë“œë¦¬í”„íŠ¸ íƒì§€)</li></ul></li><li><p><strong>Amazon Augmented AI (A2I)</strong></p><ul><li>ëª¨ë¸ì´ ë‚´ë†“ì€ ê²°ê³¼ì— ëŒ€í•´ <strong>ì‚¬ëŒì´ ì§ì ‘ ë¦¬ë·°</strong> ê°€ëŠ¥</li></ul></li><li><p><strong>Governance ê´€ë ¨ ê¸°ëŠ¥</strong></p><ul><li>SageMaker Role Manager (ê¶Œí•œ ê´€ë¦¬)  </li><li>Model Cards (ëª¨ë¸ ë¬¸ì„œí™”)  </li><li>Model Dashboard (ì¤‘ì•™í™”ëœ ëª¨ë¸ ê´€ë¦¬)</li></ul></li><li><p><strong>AWS AI Service Cards</strong></p><ul><li>ì„œë¹„ìŠ¤ë³„ ì±…ì„ ìˆëŠ” AI ë¬¸ì„œ ì œê³µ  </li><li>ì‚¬ìš© ëª©ì , ì œí•œ ì‚¬í•­, ìµœì í™” Best Practice í¬í•¨  </li><li>ì‹œí—˜ì—ì„œ ë“±ì¥í•  ìˆ˜ ìˆìŒ â†’ <strong>Service Cards &#x3D; Responsible AI ë¬¸ì„œ</strong></li></ul></li></ul><hr><h1 id="Interpretability-Explainability-í•´ì„-ê°€ëŠ¥ì„±ê³¼-ì„¤ëª…-ê°€ëŠ¥ì„±"><a href="#Interpretability-Explainability-í•´ì„-ê°€ëŠ¥ì„±ê³¼-ì„¤ëª…-ê°€ëŠ¥ì„±" class="headerlink" title="Interpretability &amp; Explainability (í•´ì„ ê°€ëŠ¥ì„±ê³¼ ì„¤ëª… ê°€ëŠ¥ì„±)"></a>Interpretability &amp; Explainability (í•´ì„ ê°€ëŠ¥ì„±ê³¼ ì„¤ëª… ê°€ëŠ¥ì„±)</h1><ul><li><p><strong>Interpretability (í•´ì„ ê°€ëŠ¥ì„±)</strong>  </p><ul><li>ì‚¬ëŒì´ ëª¨ë¸ì˜ **ê²°ì • ì›ì¸(Why &amp; How)**ì„ ì´í•´í•  ìˆ˜ ìˆëŠ” ì •ë„  </li><li>í•´ì„ì„±ì´ ë†’ì„ìˆ˜ë¡ ì„±ëŠ¥ì€ ë‚®ì•„ì§ˆ ìˆ˜ ìˆìŒ  </li><li>ì˜ˆ: ì„ í˜• íšŒê·€ â†’ í•´ì„ ìš©ì´í•˜ì§€ë§Œ ë‹¨ìˆœ &#x2F; ì‹ ê²½ë§ â†’ ì„±ëŠ¥ ë†’ì§€ë§Œ í•´ì„ ì–´ë ¤ì›€</li></ul></li><li><p><strong>Explainability (ì„¤ëª… ê°€ëŠ¥ì„±)</strong>  </p><ul><li>ëª¨ë¸ ë‚´ë¶€ë¥¼ ì™„ì „íˆ ì•Œì§€ ëª»í•´ë„ <strong>ì…ë ¥ê³¼ ì¶œë ¥ ê´€ê³„ë¥¼ ì„¤ëª…</strong>í•  ìˆ˜ ìˆëŠ” ê²ƒ  </li><li>ì‹œí—˜ í¬ì¸íŠ¸: <strong>ExplainabilityëŠ” Interpretabilityë³´ë‹¤ ëœ êµ¬ì²´ì ì´ì§€ë§Œ ì¶©ë¶„í•  ìˆ˜ ìˆë‹¤</strong></li></ul></li></ul><p align="center">  <img src="/images/aws_basic_197.png" width="80%"></p><hr><h1 id="High-Interpretability-ëª¨ë¸-ì˜ˆì‹œ"><a href="#High-Interpretability-ëª¨ë¸-ì˜ˆì‹œ" class="headerlink" title="High Interpretability ëª¨ë¸ ì˜ˆì‹œ"></a>High Interpretability ëª¨ë¸ ì˜ˆì‹œ</h1><h3 id="Decision-Trees"><a href="#Decision-Trees" class="headerlink" title="Decision Trees"></a>Decision Trees</h3><ul><li>ë¶„ë¥˜(Classification) &amp; íšŒê·€(Regression) ì‘ì—…ì— ì‚¬ìš©  </li><li>íŠ¹ì§• ê°’ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ë¶„ë¦¬ (ì˜ˆ: â€œë‚˜ì´ &gt; 30?â€)  </li><li>ì‹œê°ì ìœ¼ë¡œ ì´í•´í•˜ê¸° ì‰½ì§€ë§Œ <strong>Overfitting ìœ„í—˜</strong> ì¡´ì¬</li></ul><p align="center">  <img src="/images/aws_basic_198.png" width="80%"></p><hr><h1 id="Partial-Dependence-Plots-PDP"><a href="#Partial-Dependence-Plots-PDP" class="headerlink" title="Partial Dependence Plots (PDP)"></a>Partial Dependence Plots (PDP)</h1><ul><li><strong>íŠ¹ì • í”¼ì²˜ê°€ ê²°ê³¼ì— ì–´ë–¤ ì˜í–¥ì„ ì£¼ëŠ”ì§€ ì‹œê°í™”</strong>  </li><li>ë‹¤ë¥¸ í”¼ì²˜ëŠ” ê³ ì •í•œ ìƒíƒœì—ì„œ ë‹¨ì¼ í”¼ì²˜ ë³€í™”ë§Œ ê´€ì°°  </li><li>â€œë¸”ë™ë°•ìŠ¤ ëª¨ë¸(Neural Network)â€ í•´ì„ì— ìœ ìš©</li></ul><p align="center">  <img src="/images/aws_basic_199.png" width="80%"></p><hr><h1 id="Human-Centered-Design-HCD-for-Explainable-AI"><a href="#Human-Centered-Design-HCD-for-Explainable-AI" class="headerlink" title="Human-Centered Design (HCD) for Explainable AI"></a>Human-Centered Design (HCD) for Explainable AI</h1><p>AI ì‹œìŠ¤í…œ ì„¤ê³„ ì‹œ <strong>ì¸ê°„ ì¤‘ì‹¬</strong>ìœ¼ë¡œ ê³ ë ¤í•´ì•¼ í•  ì‚¬í•­:</p><ol><li><strong>ì˜ì‚¬ê²°ì • ê°•í™”</strong> â€“ ìœ„í—˜ê³¼ ì˜¤ë¥˜ë¥¼ ìµœì†Œí™”  </li><li><strong>ëª…í™•ì„±Â·ë‹¨ìˆœì„±Â·ì‚¬ìš©ì„±</strong> â€“ ë³µì¡í•œ í™˜ê²½ì—ì„œë„ ì‰½ê²Œ ì‚¬ìš© ê°€ëŠ¥í•´ì•¼ í•¨  </li><li><strong>ì±…ì„ì„±ê³¼ ì„±ì°°(Reflexivity)</strong> â€“ ì˜ì‚¬ê²°ì • ê³¼ì •ì„ ë˜ëŒì•„ë³´ê³  ì±…ì„ì§ˆ ìˆ˜ ìˆì–´ì•¼ í•¨  </li><li><strong>í¸í–¥ ì—†ëŠ” ê²°ì •</strong> â€“ ë°ì´í„°ì™€ ì¸ê°„ ëª¨ë‘ì˜ í¸í–¥ì„ ìµœì†Œí™”  </li><li><strong>ì¸ê°„ &amp; AI í•™ìŠµ</strong> â€“ RLHF(ì¸ê°„ í”¼ë“œë°± í•™ìŠµ) + ê°œì¸í™”  </li><li><strong>ì‚¬ìš©ì ì¤‘ì‹¬ ì„¤ê³„</strong> â€“ ë‹¤ì–‘í•œ ì‚¬ìš©ìì¸µì´ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ê³„</li></ol><hr><h1 id="ğŸ“Œ-ì‹œí—˜-ëŒ€ë¹„-í•µì‹¬-í¬ì¸íŠ¸"><a href="#ğŸ“Œ-ì‹œí—˜-ëŒ€ë¹„-í•µì‹¬-í¬ì¸íŠ¸" class="headerlink" title="ğŸ“Œ ì‹œí—˜ ëŒ€ë¹„ í•µì‹¬ í¬ì¸íŠ¸"></a>ğŸ“Œ ì‹œí—˜ ëŒ€ë¹„ í•µì‹¬ í¬ì¸íŠ¸</h1><ul><li>Responsible AIì˜ <strong>í•µì‹¬ ì°¨ì›(Fairness, Explainability, Safety, Controllability ë“±)</strong> ê¸°ì–µ  </li><li><strong>AWS Responsible AI ì„œë¹„ìŠ¤ ë§¤í•‘</strong>:<ul><li>Clarify &#x3D; Bias íƒì§€ &amp; Explainability  </li><li>Data Wrangler &#x3D; ë°ì´í„° í¸í–¥ ìˆ˜ì •  </li><li>Model Monitor &#x3D; ìš´ì˜ ì¤‘ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§  </li><li>A2I &#x3D; ì¸ê°„ ê²€í†   </li><li>Bedrock Guardrails &#x3D; ì½˜í…ì¸  í•„í„°ë§</li></ul></li><li><strong>Service Cards</strong> &#x3D; ì±…ì„ ìˆëŠ” AI ë¬¸ì„œí™” ë„êµ¬ (ì‹œí—˜ ë‹¨ê³¨)  </li><li>Interpretability vs Explainability ì°¨ì´ ë°˜ë“œì‹œ ìˆ™ì§€</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Responsible-AI-Security-ì±…ì„-ìˆëŠ”-AIì™€-ë³´ì•ˆ&quot;&gt;&lt;a href=&quot;#Responsible-AI-Security-ì±…ì„-ìˆëŠ”-AIì™€-ë³´ì•ˆ&quot; class=&quot;headerlink&quot; title=&quot;Responsible AI &amp;amp;</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(39) - Responsible AI, Security, Governance, and Compliance</title>
    <link href="https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-39/"/>
    <id>https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-39/</id>
    <published>2025-09-02T18:55:14.000Z</published>
    <updated>2025-09-02T19:27:42.927Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Responsible-AI-Security-Governance-and-Compliance"><a href="#Responsible-AI-Security-Governance-and-Compliance" class="headerlink" title="Responsible AI, Security, Governance, and Compliance"></a>Responsible AI, Security, Governance, and Compliance</h1><p>This section is less about building models and more about ensuring <strong>trust, safety, and compliance</strong> when deploying AI. While it may feel text-heavy, itâ€™s very important for the <strong>AWS AI certification exam</strong>. Letâ€™s go step by step.</p><hr><h2 id="Responsible-AI"><a href="#Responsible-AI" class="headerlink" title="Responsible AI"></a>Responsible AI</h2><p><strong>Definition:</strong> Responsible AI ensures that AI systems are <strong>transparent, trustworthy, and beneficial to society</strong>. It reduces risks and negative outcomes across the entire AI lifecycle:  </p><ul><li><strong>Design â†’ Development â†’ Deployment â†’ Monitoring â†’ Evaluation</strong></li></ul><h3 id="Key-Dimensions-of-Responsible-AI"><a href="#Key-Dimensions-of-Responsible-AI" class="headerlink" title="Key Dimensions of Responsible AI"></a>Key Dimensions of Responsible AI</h3><ol><li><strong>Fairness</strong> â€“ Promote inclusion and prevent discrimination.  </li><li><strong>Explainability</strong> â€“ Ensure humans can understand why a model made a decision.  </li><li><strong>Privacy &amp; Security</strong> â€“ Individuals must control when and how their data is used.  </li><li><strong>Transparency</strong> â€“ Clear visibility into how models operate and their limitations.  </li><li><strong>Veracity &amp; Robustness</strong> â€“ Models should remain reliable even in unexpected scenarios.  </li><li><strong>Governance</strong> â€“ Define, implement, and enforce responsible AI practices.  </li><li><strong>Safety</strong> â€“ AI should benefit individuals and society, minimizing harm.  </li><li><strong>Controllability</strong> â€“ Ensure models can be aligned with human values and intent.</li></ol><p>ğŸ‘‰ <strong>Exam Tip:</strong> Expect questions about <strong>bias detection, explainability vs. interpretability, and fairness in AI systems</strong>.</p><hr><h2 id="Security"><a href="#Security" class="headerlink" title="Security"></a>Security</h2><p>For AI systems, security must uphold the <strong>CIA triad</strong>:  </p><ul><li><strong>Confidentiality</strong> â€“ Data is protected from unauthorized access.  </li><li><strong>Integrity</strong> â€“ Data and model predictions are reliable and unchanged.  </li><li><strong>Availability</strong> â€“ AI services are accessible when needed.</li></ul><p>This applies not just to data, but also to <strong>infrastructure and organizational assets</strong>.</p><hr><h2 id="Governance-Compliance"><a href="#Governance-Compliance" class="headerlink" title="Governance &amp; Compliance"></a>Governance &amp; Compliance</h2><ul><li><strong>Governance</strong> â€“ Defines policies, oversight, and processes to align AI with <strong>legal and regulatory requirements</strong>, while improving trust.  </li><li><strong>Compliance</strong> â€“ Ensures adherence to regulations (critical in <strong>healthcare, finance, and legal sectors</strong>).</li></ul><p>ğŸ‘‰ <strong>Exam Tip:</strong> If a question mentions <strong>regulations, risk management, or improving trust</strong>, the answer usually relates to <strong>governance and compliance</strong>.</p><hr><h2 id="AWS-Services-for-Responsible-AI"><a href="#AWS-Services-for-Responsible-AI" class="headerlink" title="AWS Services for Responsible AI"></a>AWS Services for Responsible AI</h2><p>AWS provides multiple tools to implement responsible AI:</p><ul><li><p><strong>Amazon Bedrock</strong>  </p><ul><li>Human or automated model evaluation.  </li><li><strong>Guardrails</strong>: block harmful content, filter undesirable topics, redact PII (Personally Identifiable Information).</li></ul></li><li><p><strong>SageMaker Clarify</strong>  </p><ul><li>Evaluate models for <strong>accuracy, robustness, and toxicity</strong>.  </li><li>Detect bias (e.g., data over-representing middle-aged groups).</li></ul></li><li><p><strong>SageMaker Data Wrangler</strong>  </p><ul><li>Fix dataset bias (e.g., use data augmentation for underrepresented groups).</li></ul></li><li><p><strong>SageMaker Model Monitor</strong>  </p><ul><li>Monitor model quality in production, detect drift, and trigger alerts.</li></ul></li><li><p><strong>Amazon Augmented AI (A2I)</strong>  </p><ul><li>Human review of low-confidence model predictions.</li></ul></li><li><p><strong>Governance Tools</strong>  </p><ul><li><strong>Model Cards</strong> â€“ Document model details (intended use, risks, training data).  </li><li><strong>Model Dashboard</strong> â€“ View and track all models in one place.  </li><li><strong>Role Manager</strong> â€“ Define access controls for different personas (e.g., data scientist vs. MLOps engineer).</li></ul></li><li><p><strong>AWS AI Service Cards</strong>  </p><ul><li>Official documentation that describes intended use cases, limitations, and best practices for responsible AI.</li></ul></li></ul><hr><h2 id="Interpretability-vs-Explainability"><a href="#Interpretability-vs-Explainability" class="headerlink" title="Interpretability vs. Explainability"></a>Interpretability vs. Explainability</h2><h3 id="Interpretability"><a href="#Interpretability" class="headerlink" title="Interpretability"></a>Interpretability</h3><ul><li>The degree to which a human can <strong>understand the cause of a modelâ€™s decision</strong>.  </li><li>High interpretability &#x3D; models are transparent but often less powerful.  </li><li><strong>Trade-off:</strong>  <ul><li>Linear regression &#x3D; <strong>high interpretability, low performance</strong>.  </li><li>Neural networks &#x3D; <strong>low interpretability, high performance</strong>.</li></ul></li></ul><h3 id="Explainability"><a href="#Explainability" class="headerlink" title="Explainability"></a>Explainability</h3><ul><li>Explains <strong>inputs and outputs</strong> without knowing exactly how the model works.  </li><li>Example: â€œGiven income and credit history, the model predicts loan approval.â€  </li><li>Often enough for compliance and trust, even if the model itself is complex.</li></ul><p>ğŸ‘‰ <strong>Exam Tip:</strong> If a question mentions <strong>â€œwhy and howâ€ â†’ interpretability</strong>, but if it says <strong>â€œexplain results to stakeholdersâ€ â†’ explainability</strong>.</p><p align="center">  <img src="/images/aws_basic_197.png" width="80%"></p><hr><h2 id="High-Interpretability-Models"><a href="#High-Interpretability-Models" class="headerlink" title="High Interpretability Models"></a>High Interpretability Models</h2><ul><li><strong>Decision Trees</strong>  <ul><li>Simple, rule-based splits (e.g., â€œIs income &gt; $50K?â€).  </li><li>Easy to interpret and visualize.  </li><li>Risk: prone to <strong>overfitting</strong> if too many branches.</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_198.png" width="80%"></p><hr><h2 id="Tools-for-Black-Box-Models"><a href="#Tools-for-Black-Box-Models" class="headerlink" title="Tools for Black-Box Models"></a>Tools for Black-Box Models</h2><ul><li><strong>Partial Dependence Plots (PDPs)</strong>  <ul><li>Show how a single feature impacts predictions while holding others constant.  </li><li>Useful for black-box models like neural networks.  </li><li>Example: income vs. probability of loan approval.</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_199.png" width="80%"></p><hr><h2 id="Human-Centered-Design-HCD-for-AI"><a href="#Human-Centered-Design-HCD-for-AI" class="headerlink" title="Human-Centered Design (HCD) for AI"></a>Human-Centered Design (HCD) for AI</h2><p>AI should be designed with <strong>human needs first</strong>:</p><ol><li><strong>Amplify decision-making</strong> â€“ Especially in stressful environments (e.g., healthcare).  </li><li><strong>Clarity &amp; simplicity</strong> â€“ Easy-to-use AI interfaces.  </li><li><strong>Bias mitigation</strong> â€“ Train decision-makers to recognize bias and ensure datasets are balanced.  </li><li><strong>Human + AI learning</strong>  <ul><li><strong>Cognitive apprenticeship</strong>: AI learns from human experts.  </li><li><strong>Personalization</strong>: adapt to user needs.</li></ul></li><li><strong>User-centered design</strong> â€“ Accessible to a wide variety of users.</li></ol><hr><h2 id="Key-Takeaways-for-the-Exam"><a href="#Key-Takeaways-for-the-Exam" class="headerlink" title="Key Takeaways for the Exam"></a>Key Takeaways for the Exam</h2><ul><li><strong>Responsible AI</strong> &#x3D; fairness, transparency, explainability, bias mitigation.  </li><li><strong>Security</strong> &#x3D; confidentiality, integrity, availability.  </li><li><strong>Governance</strong> &#x3D; policies + oversight.  </li><li><strong>Compliance</strong> &#x3D; following regulations.  </li><li><strong>AWS Tools to Know</strong>: Bedrock Guardrails, SageMaker Clarify, Data Wrangler, Model Monitor, A2I, Model Cards, Model Dashboard, Role Manager.  </li><li><strong>Trade-off</strong>: High interpretability â†’ low performance, and vice versa.  </li><li><strong>Decision Trees &amp; PDPs</strong> &#x3D; ways to improve explainability.  </li><li><strong>HCD</strong> ensures AI is human-friendly and trustworthy.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Responsible-AI-Security-Governance-and-Compliance&quot;&gt;&lt;a href=&quot;#Responsible-AI-Security-Governance-and-Compliance&quot; class=&quot;headerlink&quot; t</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(38) - ML Governance &amp; Productivity</title>
    <link href="https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-38/"/>
    <id>https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-38/</id>
    <published>2025-09-02T18:34:17.000Z</published>
    <updated>2025-09-02T18:54:53.776Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Amazon-SageMaker-â€“-ML-Governance-Productivity-Exam-friendly-Guide"><a href="#Amazon-SageMaker-â€“-ML-Governance-Productivity-Exam-friendly-Guide" class="headerlink" title="Amazon SageMaker â€“ ML Governance &amp; Productivity (Exam-friendly Guide)"></a>Amazon SageMaker â€“ ML Governance &amp; Productivity (Exam-friendly Guide)</h1><p>This rewrite keeps things simple, adds missing context, and highlights what typically shows up on AWS exams.</p><hr><h2 id="Why-â€œML-Governanceâ€-matters"><a href="#Why-â€œML-Governanceâ€-matters" class="headerlink" title="Why â€œML Governanceâ€ matters"></a>Why â€œML Governanceâ€ matters</h2><p>Once a model is in production, you need to <strong>know what it does, who can touch it, how itâ€™s behaving, and how it changes over time</strong>. SageMaker gives you a set of tools to do exactly that.</p><hr><h2 id="Model-documentation-visibility"><a href="#Model-documentation-visibility" class="headerlink" title="Model documentation &amp; visibility"></a>Model documentation &amp; visibility</h2><h3 id="SageMaker-Model-Cards"><a href="#SageMaker-Model-Cards" class="headerlink" title="SageMaker Model Cards"></a>SageMaker <strong>Model Cards</strong></h3><ul><li>A living document for each model: <strong>intended use</strong>, <strong>risk rating</strong>, <strong>training data &amp; method</strong>, <strong>evaluation metrics</strong>, and <strong>owners</strong>.</li><li>Think of it as â€œREADME + audit sheetâ€ for compliance and handoffs.</li></ul><p><strong>Exam tip:</strong> If a question mentions <em>â€œdocumenting model intent, risks, and lineage for auditorsâ€</em>, the answer is <strong>Model Cards</strong>.</p><p align="center">  <img src="/images/aws_basic_187.png" width="80%"></p> <hr><h3 id="SageMaker-Model-Dashboard"><a href="#SageMaker-Model-Dashboard" class="headerlink" title="SageMaker Model Dashboard"></a>SageMaker <strong>Model Dashboard</strong></h3><ul><li>A <strong>central place</strong> to <strong>view, search, and explore</strong> every model across accounts&#x2F;teams (from the SageMaker console).</li><li>Lets you <strong>track which models are deployed</strong> to endpoints.</li><li>Surfaces <strong>warnings</strong> when thresholds are breached (data quality, model quality, bias, explainability drift).</li></ul><p><strong>Use it for:</strong> â€œWhich models are live?â€ â€œWhich ones are failing data-quality checks?â€</p><p align="center">  <img src="/images/aws_basic_188.png" width="80%"></p> <hr><h3 id="SageMaker-Role-Manager"><a href="#SageMaker-Role-Manager" class="headerlink" title="SageMaker Role Manager"></a>SageMaker <strong>Role Manager</strong></h3><ul><li>Define <strong>least-privilege roles</strong> by <strong>persona</strong> (e.g., <em>data scientist</em>, <em>MLOps engineer</em>).</li><li>Speeds up secure access setup for Studio, training jobs, endpoints, registries, etc.</li></ul><p><strong>Exam tip:</strong> If you see <em>â€œquickly provision SageMaker permissions for different job functionsâ€</em>, pick <strong>Role Manager</strong>.</p><hr><h2 id="Model-quality-lifecycle"><a href="#Model-quality-lifecycle" class="headerlink" title="Model quality &amp; lifecycle"></a>Model quality &amp; lifecycle</h2><h3 id="SageMaker-Model-Monitor"><a href="#SageMaker-Model-Monitor" class="headerlink" title="SageMaker Model Monitor"></a>SageMaker <strong>Model Monitor</strong></h3><ul><li>Continuously or on a schedule, checks <strong>data drift</strong> (inputs no longer look like training data), <strong>model drift</strong> (performance drops), <strong>bias&#x2F;explainability drift</strong>, and <strong>data quality</strong>.</li><li>Sends <strong>alerts</strong> so you can <strong>fix pipelines</strong> or <strong>retrain</strong>.</li></ul><p><strong>Example:</strong> A loan-approval model starts approving borrowers below the target credit scoreâ€”Model Monitor flags drift â†’ you retrain with recent data.</p><p><strong>Exam tip:</strong> <em>Detecting drift in production</em> â†’ <strong>Model Monitor</strong>.</p><p align="center">  <img src="/images/aws_basic_189.png" width="80%"></p><hr><h3 id="SageMaker-Model-Registry"><a href="#SageMaker-Model-Registry" class="headerlink" title="SageMaker Model Registry"></a>SageMaker <strong>Model Registry</strong></h3><ul><li>Central repo to <strong>catalog, version, approve, deploy, and share</strong> models.</li><li>Supports <strong>approval states</strong> (e.g., <em>Pending</em>, <em>Approved</em>, <em>Rejected</em>), <strong>metadata</strong>, and <strong>automated deployments</strong> from the registry.</li></ul><p><strong>Exam tip:</strong> <em>Model versioning + approval workflow + promotion to prod</em> â†’ <strong>Model Registry</strong>.</p><p align="center">  <img src="/images/aws_basic_190.png" width="80%"></p><hr><h2 id="CI-CD-for-ML"><a href="#CI-CD-for-ML" class="headerlink" title="CI&#x2F;CD for ML"></a>CI&#x2F;CD for ML</h2><h3 id="SageMaker-Pipelines"><a href="#SageMaker-Pipelines" class="headerlink" title="SageMaker Pipelines"></a>SageMaker <strong>Pipelines</strong></h3><p>Automates the path from data to deployment (MLOps). A pipeline is built from <strong>Steps</strong>:</p><ul><li><strong>Processing</strong> â€“ data prep&#x2F;feature engineering (Data Wrangler&#x2F;processing jobs).</li><li><strong>Training</strong> â€“ train a model.</li><li><strong>Tuning</strong> â€“ hyperparameter optimization (HPO).</li><li><strong>AutoML</strong> â€“ train automatically with Autopilot.</li><li><strong>Model</strong> â€“ create&#x2F;register a SageMaker Model (often into <strong>Model Registry</strong>).</li><li><strong>ClarifyCheck</strong> â€“ bias&#x2F;explainability checks vs baselines.</li><li><strong>QualityCheck</strong> â€“ data&#x2F;model quality checks vs baselines.</li></ul><p><strong>Why Pipelines:</strong> Reproducible, faster iterations, fewer manual errors, and easy promotion Dev â†’ Staging â†’ Prod.</p><p><strong>Exam tip:</strong> <em>â€œAutomate build&#x2F;train&#x2F;test&#x2F;deploy and attach gates for quality checksâ€</em> â†’ <strong>Pipelines</strong> (+ <strong>ClarifyCheck&#x2F;QualityCheck</strong> steps).</p><p align="center">  <img src="/images/aws_basic_191.png" width="80%"></p><hr><h2 id="Build-faster-with-prebuilt-models-no-code-tools"><a href="#Build-faster-with-prebuilt-models-no-code-tools" class="headerlink" title="Build faster with prebuilt models &amp; no-code tools"></a>Build faster with prebuilt models &amp; no-code tools</h2><h3 id="SageMaker-JumpStart"><a href="#SageMaker-JumpStart" class="headerlink" title="SageMaker JumpStart"></a>SageMaker <strong>JumpStart</strong></h3><ul><li>An <strong>ML Hub</strong> of pre-trained <strong>foundation models (FMs)</strong> and task models (CV&#x2F;NLP) from providers like <strong>Hugging Face, Meta, Stability AI, Databricks</strong>, etc.</li><li>You can <strong>fine-tune on your data</strong>, then <strong>deploy on SageMaker</strong> with full control (instance types, autoscaling, serverless, etc.).</li><li>Also includes <strong>prebuilt solutions</strong> (demand forecasting, fraud detection, credit scoring, computer vision).</li></ul><p><strong>When to use:</strong> You need a strong baseline fast, or a packaged solution to customize.</p><p align="center">  <img src="/images/aws_basic_192.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_193.png" width="80%"></p><hr><h3 id="SageMaker-Canvas-No-code"><a href="#SageMaker-Canvas-No-code" class="headerlink" title="SageMaker Canvas (No-code)"></a>SageMaker <strong>Canvas</strong> (No-code)</h3><ul><li><strong>Visual interface</strong> to build models (classification, regression, forecasting) without writing code.</li><li>Can use <strong>Autopilot (AutoML)</strong> under the hood.</li><li>Integrates with <strong>Data Wrangler</strong> for prep and can <strong>pull ready-to-use models</strong> from <strong>Bedrock&#x2F;JumpStart</strong>.</li><li><strong>Ready-to-use models:</strong> Comprehend (sentiment, entities), Rekognition (vision), Textract (document OCR).</li></ul><p><strong>Use it for:</strong> Analysts and business users who want predictions without Python.</p><p><strong>Exam tip:</strong> <em>â€œNo-code model building for business teamsâ€</em> â†’ <strong>Canvas</strong>.</p><p align="center">  <img src="/images/aws_basic_194.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_195.png" width="80%"></p><hr><h2 id="Responsible-AI-explainability"><a href="#Responsible-AI-explainability" class="headerlink" title="Responsible AI &amp; explainability"></a>Responsible AI &amp; explainability</h2><h3 id="SageMaker-Clarify"><a href="#SageMaker-Clarify" class="headerlink" title="SageMaker Clarify"></a>SageMaker <strong>Clarify</strong></h3><ul><li><strong>Bias detection</strong> (dataset &amp; model), <strong>explainability</strong> (global + per-prediction), and <strong>foundation-model evaluations</strong> (e.g., tone, helpfulness).</li><li>Works both <strong>pre-deployment</strong> (validate) and <strong>post-deployment</strong> (debug).</li></ul><p><strong>Typical questions:</strong><br>â€œWhy was this loan denied?â€ â†’ use Clarify <strong>SHAP-based</strong> explanations to rank influential features.<br>â€œDetect bias in a dataset&#x2F;modelâ€ â†’ <strong>Clarify</strong> with statistical metrics.</p><p><strong>Bias types to recognize (human context):</strong> - <strong>Sampling bias</strong> â€“ training data isnâ€™t representative. - <strong>Measurement bias</strong> â€“ flawed or skewed instrumentation&#x2F;labels. - <strong>Observer bias</strong> â€“ human annotators influence labels. - <strong>Confirmation bias</strong> â€“ interpreting data to fit expectations.</p><hr><h2 id="Human-in-the-loop-HITL"><a href="#Human-in-the-loop-HITL" class="headerlink" title="Human-in-the-loop (HITL)"></a>Human-in-the-loop (HITL)</h2><h3 id="SageMaker-Ground-Truth-and-Ground-Truth-Plus"><a href="#SageMaker-Ground-Truth-and-Ground-Truth-Plus" class="headerlink" title="SageMaker Ground Truth (and Ground Truth Plus)"></a>SageMaker <strong>Ground Truth</strong> (and Ground Truth Plus)</h3><ul><li><strong>Human feedback for ML</strong>: high-quality <strong>data labeling</strong>, <strong>model evaluation</strong>, and <strong>preference alignment</strong>.</li><li>Reviewers: <strong>your employees</strong>, <strong>vetted vendors</strong>, or <strong>Amazon Mechanical Turk</strong>.</li><li><strong>RLHF</strong> (Reinforcement Learning from Human Feedback) support: human preferences contribute to a <strong>reward</strong> signal for model alignment.</li><li><strong>Plus</strong> adds managed, expert labeling teams and project management.</li></ul><p><strong>Exam tip:</strong> <em>â€œCollect labeled data at scale with human reviewersâ€</em> â†’ <strong>Ground Truth</strong> (or <strong>Ground Truth Plus</strong> if fully managed).</p><hr><h2 id="Open-source-tracking"><a href="#Open-source-tracking" class="headerlink" title="Open-source tracking"></a>Open-source tracking</h2><h3 id="MLflow-on-SageMaker"><a href="#MLflow-on-SageMaker" class="headerlink" title="MLflow on SageMaker"></a><strong>MLflow on SageMaker</strong></h3><ul><li>Launch <strong>MLflow Tracking Servers</strong> from Studio to <strong>track experiments&#x2F;runs</strong>, metrics, and artifacts.</li><li>Fully integrated with SageMaker resources.</li></ul><p><strong>When to use:</strong> Your team already uses MLflow but wants AWS-managed infra around it.</p><hr><h2 id="Extra-features-that-show-up-on-exams"><a href="#Extra-features-that-show-up-on-exams" class="headerlink" title="Extra features that show up on exams"></a>Extra features that show up on exams</h2><ul><li><p><strong>Network Isolation mode</strong><br>Run training&#x2F;inference <strong>containers without any outbound internet</strong> (no S3&#x2F;VPC&#x2F;Internet). Use this for <strong>strict data-exfiltration controls</strong>.<br><strong>Keyword:</strong> â€œ<strong>No egress</strong>, fully isolated jobâ€.</p></li><li><p><strong>DeepAR</strong> (built-in algorithm) For <strong>time-series forecasting</strong>, based on <strong>RNNs</strong>.<br><strong>Keyword match:</strong> â€œ<strong>forecast time series</strong>â€œ â†’ <strong>DeepAR</strong>.</p></li></ul><hr><h2 id="One-page-cheat-sheet-what-to-pick-when"><a href="#One-page-cheat-sheet-what-to-pick-when" class="headerlink" title="One-page cheat sheet (what to pick when)"></a>One-page cheat sheet (what to pick when)</h2><ul><li><strong>Document model purpose &amp; risks</strong> â†’ <em>Model Cards</em></li><li><strong>See&#x2F;search all models, find violations</strong> â†’ <em>Model Dashboard</em></li><li><strong>Detect drift&#x2F;quality issues in prod</strong> â†’ <em>Model Monitor</em></li><li><strong>Versioning, approvals, promote to prod</strong> â†’ <em>Model Registry</em></li><li><strong>Automate buildâ†’trainâ†’testâ†’deploy</strong> â†’ <em>Pipelines</em> (+Clarify&#x2F;Quality checks)</li><li><strong>Pretrained models &amp; packaged solutions</strong> â†’ <em>JumpStart</em></li><li><strong>No-code model building</strong> â†’ <em>Canvas</em> (uses Autopilot, integrates with Bedrock&#x2F;JumpStart)</li><li><strong>Bias &amp; explainability</strong> â†’ <em>Clarify</em></li><li><strong>Human labeling&#x2F;evaluation&#x2F;RLHF</strong> â†’ <em>Ground Truth &#x2F; Ground Truth Plus</em></li><li><strong>Strict security (no outbound)</strong> â†’ <em>Network Isolation</em></li><li><strong>Time-series forecasting</strong> â†’ <em>DeepAR</em></li></ul><hr><h2 id="Mini-scenario-practice-exam-style"><a href="#Mini-scenario-practice-exam-style" class="headerlink" title="Mini scenario practice (exam-style)"></a>Mini scenario practice (exam-style)</h2><ol><li><p><strong>â€œAuditors request one place to see each modelâ€™s purpose, training details, and risk.â€</strong><br>â†’ <strong>Model Cards</strong></p></li><li><p><strong>â€œAlert when live model inputs diverge from training data distribution.â€</strong><br>â†’ <strong>Model Monitor</strong> (data drift)</p></li><li><p><strong>â€œPromote a tested model from Staging to Prod with an approval gate.â€</strong><br>â†’ <strong>Model Registry</strong> + <strong>Pipelines</strong></p></li><li><p><strong>â€œBusiness analysts want to build predictions with no code.â€</strong><br>â†’ <strong>Canvas</strong> (Autopilot)</p></li><li><p><strong>â€œFine-tune a foundation model and deploy on SageMaker.â€</strong><br>â†’ <strong>JumpStart</strong></p></li><li><p><strong>â€œEnsure training job cannot reach the internet or S3.â€</strong><br>â†’ <strong>Network Isolation mode</strong></p></li><li><p><strong>â€œForecast sales for the next 30 days.â€</strong><br>â†’ <strong>DeepAR</strong></p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Amazon-SageMaker-â€“-ML-Governance-Productivity-Exam-friendly-Guide&quot;&gt;&lt;a href=&quot;#Amazon-SageMaker-â€“-ML-Governance-Productivity-Exam-frie</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(í•œêµ­ì–´) AWS Certified AI Practitioner (38) - SageMaker ML ê±°ë²„ë„ŒìŠ¤ ë° í™•ì¥ ê¸°ëŠ¥</title>
    <link href="https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-38/"/>
    <id>https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-38/</id>
    <published>2025-09-02T18:34:11.000Z</published>
    <updated>2025-09-02T18:54:53.776Z</updated>
    
    <content type="html"><![CDATA[<h1 id="SageMaker-â€“-ML-ê±°ë²„ë„ŒìŠ¤-ë°-í™•ì¥-ê¸°ëŠ¥"><a href="#SageMaker-â€“-ML-ê±°ë²„ë„ŒìŠ¤-ë°-í™•ì¥-ê¸°ëŠ¥" class="headerlink" title="SageMaker â€“ ML ê±°ë²„ë„ŒìŠ¤ ë° í™•ì¥ ê¸°ëŠ¥"></a>SageMaker â€“ ML ê±°ë²„ë„ŒìŠ¤ ë° í™•ì¥ ê¸°ëŠ¥</h1><h2 id="SageMaker-ê±°ë²„ë„ŒìŠ¤-ë„êµ¬"><a href="#SageMaker-ê±°ë²„ë„ŒìŠ¤-ë„êµ¬" class="headerlink" title="SageMaker ê±°ë²„ë„ŒìŠ¤ ë„êµ¬"></a>SageMaker ê±°ë²„ë„ŒìŠ¤ ë„êµ¬</h2><p>ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ì‹¤ì œ ì„œë¹„ìŠ¤ì— ë°°í¬í–ˆë‹¤ë©´, <strong>ê±°ë²„ë„ŒìŠ¤(Governance)</strong> ê°€ í•„ìˆ˜ì ì…ë‹ˆë‹¤. SageMakerëŠ” ì´ë¥¼ ìœ„í•´ ë‹¤ì–‘í•œ ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.</p><h3 id="1-SageMaker-Model-Cards"><a href="#1-SageMaker-Model-Cards" class="headerlink" title="1. SageMaker Model Cards"></a>1. SageMaker Model Cards</h3><ul><li>ëª¨ë¸ì˜ <strong>í•„ìˆ˜ ì •ë³´</strong>ë¥¼ ë¬¸ì„œí™”í•˜ëŠ” ì¹´ë“œ í˜•ì‹</li><li>ì˜ˆì‹œ:<ul><li>ëª¨ë¸ì˜ ì˜ë„ëœ ì‚¬ìš© ëª©ì </li><li>ëª¨ë¸ ë¦¬ìŠ¤í¬ ë“±ê¸‰</li><li>í•™ìŠµ ë°ì´í„° ë° í›ˆë ¨ ê³¼ì • ìƒì„¸</li></ul></li><li>ì‹œí—˜ í¬ì¸íŠ¸: <strong>â€œModel Cards &#x3D; ëª¨ë¸ ë¬¸ì„œí™”â€</strong></li></ul><p align="center">  <img src="/images/aws_basic_187.png" width="80%"></p> <hr><h3 id="2-SageMaker-Model-Dashboard"><a href="#2-SageMaker-Model-Dashboard" class="headerlink" title="2. SageMaker Model Dashboard"></a>2. SageMaker Model Dashboard</h3><ul><li><strong>ëª¨ë“  ëª¨ë¸ì„ ì¤‘ì•™ì—ì„œ ì¡°íšŒÂ·ê²€ìƒ‰Â·íƒìƒ‰</strong>í•  ìˆ˜ ìˆëŠ” í¬í„¸</li><li>ì˜ˆì‹œ:<ul><li>ì–´ë–¤ ëª¨ë¸ì´ í˜„ì¬ ë°°í¬ë˜ì–´ ì¶”ë¡ (Inference)ì— ì‚¬ìš©ë˜ëŠ”ì§€ ì¶”ì  ê°€ëŠ¥</li></ul></li><li>í’ˆì§ˆ ê´€ë¦¬:<ul><li>ë°ì´í„° í’ˆì§ˆ, ëª¨ë¸ í’ˆì§ˆ, í¸í–¥(Bias), ì„¤ëª… ê°€ëŠ¥ì„±(Explainability) ìœ„ë°˜ ì—¬ë¶€ í™•ì¸</li></ul></li><li>ì‹œí—˜ í¬ì¸íŠ¸: <strong>â€œì¤‘ì•™ ëŒ€ì‹œë³´ë“œ, í’ˆì§ˆ ë° í¸í–¥ ëª¨ë‹ˆí„°ë§â€</strong></li></ul><p align="center">  <img src="/images/aws_basic_188.png" width="80%"></p> ------------------------------------------------------------------------<h3 id="3-SageMaker-Role-Manager"><a href="#3-SageMaker-Role-Manager" class="headerlink" title="3. SageMaker Role Manager"></a>3. SageMaker Role Manager</h3><ul><li>ì‚¬ìš©ì ì—­í• ê³¼ ê¶Œí•œì„ ì •ì˜í•˜ëŠ” ê¸°ëŠ¥</li><li>ì˜ˆì‹œ:<ul><li>ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸, MLOps ì—”ì§€ë‹ˆì–´, ë°ì´í„° ì—”ì§€ë‹ˆì–´</li></ul></li><li><strong>ê±°ë²„ë„ŒìŠ¤ì™€ ë³´ì•ˆ ê´€ë¦¬</strong>ë¥¼ ìœ„í•œ í•µì‹¬ ê¸°ëŠ¥</li></ul><hr><h2 id="SageMaker-Model-Monitor"><a href="#SageMaker-Model-Monitor" class="headerlink" title="SageMaker Model Monitor"></a>SageMaker Model Monitor</h2><ul><li><strong>ìš´ì˜ í™˜ê²½ì—ì„œ ëª¨ë¸ í’ˆì§ˆì„ ëª¨ë‹ˆí„°ë§</strong>í•˜ëŠ” ê¸°ëŠ¥</li><li>ì—°ì†ì (Continuous) ë˜ëŠ” ì£¼ê¸°ì (On-Schedule) ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥</li><li>í¸ì°¨(Drift) ë°œìƒ ì‹œ ì•Œë¦¼ ì œê³µ â†’ ë°ì´í„° ìˆ˜ì •Â·ì¬í•™ìŠµ í•„ìš”</li><li>ì˜ˆì‹œ:<ul><li>ëŒ€ì¶œ ìŠ¹ì¸ ëª¨ë¸ì´ ì‹œê°„ì´ ì§€ë‚˜ë©´ì„œ ì˜ëª»ëœ ì‹ ìš© ì ìˆ˜ ì‚¬ìš©ìì—ê²Œ ëŒ€ì¶œì„ ìŠ¹ì¸í•˜ëŠ” ê²½ìš°</li></ul></li><li>ì‹œí—˜ í¬ì¸íŠ¸: <strong>â€œModel Monitor &#x3D; ìš´ì˜ ì¤‘ ëª¨ë¸ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ &amp; ë“œë¦¬í”„íŠ¸ ê°ì§€â€</strong></li></ul><p align="center">  <img src="/images/aws_basic_189.png" width="80%"></p><hr><h2 id="SageMaker-Model-Registry"><a href="#SageMaker-Model-Registry" class="headerlink" title="SageMaker Model Registry"></a>SageMaker Model Registry</h2><ul><li><strong>ëª¨ë¸ ì¤‘ì•™ ì €ì¥ì†Œ</strong>: ë²„ì „ ê´€ë¦¬, ë©”íƒ€ë°ì´í„° ê´€ë¦¬, ìŠ¹ì¸ ìƒíƒœ ê´€ë¦¬</li><li>ì£¼ìš” ê¸°ëŠ¥:<ul><li>ëª¨ë¸ ì¹´íƒˆë¡œê·¸í™”</li><li>ëª¨ë¸ ìŠ¹ì¸(Approval) í”„ë¡œì„¸ìŠ¤ ì ìš©</li><li>ìë™ ë°°í¬ ë° íŒ€ ê³µìœ </li></ul></li><li>ì‹œí—˜ í¬ì¸íŠ¸: <strong>â€œModel Registry &#x3D; ë²„ì „ ê´€ë¦¬ + ìŠ¹ì¸ + ìë™í™”â€</strong></li></ul><p align="center">  <img src="/images/aws_basic_190.png" width="80%"></p>------------------------------------------------------------------------<h2 id="SageMaker-Pipelines"><a href="#SageMaker-Pipelines" class="headerlink" title="SageMaker Pipelines"></a>SageMaker Pipelines</h2><ul><li><strong>ML ì›Œí¬í”Œë¡œìš° ìë™í™” ë„êµ¬</strong> (CI&#x2F;CD for ML)</li><li>ë°ì´í„° ì¤€ë¹„ â†’ ëª¨ë¸ í•™ìŠµ â†’ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ â†’ ë°°í¬ê¹Œì§€ ìë™í™”</li><li>ì¥ì :<ul><li>ë¹ ë¥¸ ë°˜ë³µ(Iteration)</li><li>ìˆ˜ë™ ì‘ì—… ì œê±° â†’ ì˜¤ë¥˜ ê°ì†Œ</li><li>ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš°</li></ul></li><li>ì£¼ìš” Step ìœ í˜•:<ul><li>Processing: ë°ì´í„° ì²˜ë¦¬&#x2F;í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§</li><li>Training: ëª¨ë¸ í•™ìŠµ</li><li>Tuning: í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”</li><li>AutoML: ìë™ í•™ìŠµ</li><li>Model: ëª¨ë¸ ìƒì„±Â·ë“±ë¡</li><li>ClarifyCheck: ë°ì´í„°Â·ëª¨ë¸ í¸í–¥, ì„¤ëª… ê°€ëŠ¥ì„± í™•ì¸</li><li>QualityCheck: ë°ì´í„°Â·ëª¨ë¸ í’ˆì§ˆ ì ê²€</li></ul></li><li>ì‹œí—˜ í¬ì¸íŠ¸: <strong>â€œPipelines &#x3D; CI&#x2F;CD for ML, Step ìœ í˜• êµ¬ë¶„â€</strong></li></ul><p align="center">  <img src="/images/aws_basic_191.png" width="80%"></p>------------------------------------------------------------------------<h2 id="SageMaker-JumpStart"><a href="#SageMaker-JumpStart" class="headerlink" title="SageMaker JumpStart"></a>SageMaker JumpStart</h2><ul><li><strong>ë¯¸ë¦¬ í•™ìŠµëœ ëª¨ë¸ í—ˆë¸Œ</strong></li><li>ì œê³µ ëª¨ë¸:<ul><li>Hugging Face, Meta, Stability AI, Databricks ë“±</li></ul></li><li>ì‚¬ìš© ì‚¬ë¡€:<ul><li>ìˆ˜ìš” ì˜ˆì¸¡, ì‹ ìš© ì ìˆ˜ ì˜ˆì¸¡, ì‚¬ê¸° íƒì§€, ì´ë¯¸ì§€ ë¶„ë¥˜</li></ul></li><li>íŠ¹ì§•:<ul><li>ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ëŠ¥</li><li>SageMakerì—ì„œ ì§ì ‘ ë°°í¬</li></ul></li><li>ì‹œí—˜ í¬ì¸íŠ¸: <strong>â€œJumpStart &#x3D; ë¯¸ë¦¬ í•™ìŠµëœ ëª¨ë¸ &amp; ì†”ë£¨ì…˜â€</strong></li></ul><p align="center">  <img src="/images/aws_basic_192.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_193.png" width="80%"></p><hr><h2 id="SageMaker-Canvas"><a href="#SageMaker-Canvas" class="headerlink" title="SageMaker Canvas"></a>SageMaker Canvas</h2><ul><li><strong>ë…¸ì½”ë“œ(No-Code) ì¸í„°í˜ì´ìŠ¤</strong>ë¡œ ML ëª¨ë¸ êµ¬ì¶• ê°€ëŠ¥</li><li>ê¸°ëŠ¥:<ul><li>Bedrock&#x2F;JumpStart ëª¨ë¸ í™œìš©</li><li>AutoML(SageMaker Autopilot ê¸°ë°˜)ë¡œ ë§ì¶¤í˜• ëª¨ë¸ ìƒì„±</li><li>Data Wranglerì™€ ì—°ê³„ëœ ë°ì´í„° ì¤€ë¹„ ê°€ëŠ¥</li></ul></li><li>í†µí•© ëª¨ë¸:<ul><li>Rekognition(ì´ë¯¸ì§€ ë¶„ì„)</li><li>Comprehend(í…ìŠ¤íŠ¸ ë¶„ì„)</li><li>Textract(ë¬¸ì„œ ë¶„ì„)</li></ul></li><li>ì‹œí—˜ í¬ì¸íŠ¸: <strong>â€œCanvas &#x3D; ë¹„ê°œë°œìë„ ML ëª¨ë¸ êµ¬ì¶• ê°€ëŠ¥â€</strong></li></ul><p align="center">  <img src="/images/aws_basic_194.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_195.png" width="80%"></p><hr><h2 id="MLFlow-on-SageMaker"><a href="#MLFlow-on-SageMaker" class="headerlink" title="MLFlow on SageMaker"></a>MLFlow on SageMaker</h2><ul><li>ì˜¤í”ˆì†ŒìŠ¤ <strong>ML ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬ íˆ´</strong></li><li>ê¸°ëŠ¥:<ul><li>ì‹¤í—˜ ì¶”ì , ê²°ê³¼ ê´€ë¦¬</li><li>SageMaker Studio ë‚´ì—ì„œ MLFlow Tracking Server ì‹¤í–‰ ê°€ëŠ¥</li></ul></li><li>ì‹œí—˜ í¬ì¸íŠ¸: <strong>â€œMLFlow &#x3D; ì˜¤í”ˆì†ŒìŠ¤ ML ì‹¤í—˜ ê´€ë¦¬â€</strong></li></ul><p align="center">  <img src="/images/aws_basic_196.png" width="80%"></p><hr><h2 id="SageMaker-ì¶”ê°€-ê¸°ëŠ¥"><a href="#SageMaker-ì¶”ê°€-ê¸°ëŠ¥" class="headerlink" title="SageMaker ì¶”ê°€ ê¸°ëŠ¥"></a>SageMaker ì¶”ê°€ ê¸°ëŠ¥</h2><ol><li><strong>Network Isolation Mode</strong><ul><li>ì™¸ë¶€ ë„¤íŠ¸ì›Œí¬(ì‹¬ì§€ì–´ S3ë„) ì°¨ë‹¨ â†’ ë°ì´í„° ìœ ì¶œ ë°©ì§€</li><li>ì‹œí—˜ í¬ì¸íŠ¸: <strong>â€œNetwork Isolation &#x3D; ë³´ì•ˆ ê°•í™”, ì™¸ë¶€ ì ‘ê·¼ ë¶ˆê°€â€</strong></li></ul></li><li><strong>DeepAR Forecasting Algorithm</strong><ul><li><strong>ì‹œê³„ì—´ ì˜ˆì¸¡</strong> ì•Œê³ ë¦¬ì¦˜</li><li>ë‚´ë¶€ì ìœ¼ë¡œ RNN(Recurrent Neural Network) ì‚¬ìš©</li><li>ì‹œí—˜ í¬ì¸íŠ¸: <strong>â€œDeepAR &#x3D; ì‹œê³„ì—´ ì˜ˆì¸¡â€</strong></li></ul></li></ol><hr><h2 id="ì‹œí—˜-ëŒ€ë¹„-ìš”ì•½"><a href="#ì‹œí—˜-ëŒ€ë¹„-ìš”ì•½" class="headerlink" title="ì‹œí—˜ ëŒ€ë¹„ ìš”ì•½"></a>ì‹œí—˜ ëŒ€ë¹„ ìš”ì•½</h2><ul><li>Model Cards â†’ ëª¨ë¸ ë¬¸ì„œí™”</li><li>Model Dashboard â†’ ì¤‘ì•™ í¬í„¸, í’ˆì§ˆÂ·í¸í–¥ ì¶”ì </li><li>Model Monitor â†’ ìš´ì˜ ì¤‘ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ &amp; ë“œë¦¬í”„íŠ¸ ê°ì§€</li><li>Model Registry â†’ ë²„ì „ ê´€ë¦¬ + ìŠ¹ì¸ + ìë™ ë°°í¬</li><li>Pipelines â†’ CI&#x2F;CD for ML</li><li>JumpStart â†’ ë¯¸ë¦¬ í•™ìŠµëœ ëª¨ë¸ &amp; ì†”ë£¨ì…˜</li><li>Canvas â†’ ë…¸ì½”ë“œ ML ëª¨ë¸ë§</li><li>Clarify â†’ ëª¨ë¸ ì„¤ëª…ë ¥ &amp; í¸í–¥ íƒì§€</li><li>Ground Truth â†’ RLHF, ë°ì´í„° ë¼ë²¨ë§</li><li>DeepAR â†’ ì‹œê³„ì—´ ì˜ˆì¸¡</li><li>Network Isolation â†’ ë³´ì•ˆ ê°•í™”</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;SageMaker-â€“-ML-ê±°ë²„ë„ŒìŠ¤-ë°-í™•ì¥-ê¸°ëŠ¥&quot;&gt;&lt;a href=&quot;#SageMaker-â€“-ML-ê±°ë²„ë„ŒìŠ¤-ë°-í™•ì¥-ê¸°ëŠ¥&quot; class=&quot;headerlink&quot; title=&quot;SageMaker â€“ ML ê±°ë²„ë„ŒìŠ¤ ë° í™•ì¥ ê¸°ëŠ¥&quot;&gt;&lt;/a&gt;SageM</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
</feed>
