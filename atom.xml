<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Danny&#39;s Blog</title>
  
  <subtitle>Data, AI, and Tech Insight</subtitle>
  <link href="https://kish191919.github.io/atom.xml" rel="self"/>
  
  <link href="https://kish191919.github.io/"/>
  <updated>2025-08-19T10:55:35.586Z</updated>
  <id>https://kish191919.github.io/</id>
  
  <author>
    <name>Danny Ki</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>AWS-Certified-AI-Practitioner(9)</title>
    <link href="https://kish191919.github.io/2025/08/19/AWS-Certified-AI-Practitioner-9/"/>
    <id>https://kish191919.github.io/2025/08/19/AWS-Certified-AI-Practitioner-9/</id>
    <published>2025-08-19T10:53:35.000Z</published>
    <updated>2025-08-19T10:55:35.586Z</updated>
    
    <content type="html"><![CDATA[<h1 id="🛡️-Amazon-Bedrock-–-Guardrails"><a href="#🛡️-Amazon-Bedrock-–-Guardrails" class="headerlink" title="🛡️ Amazon Bedrock – Guardrails"></a>🛡️ Amazon Bedrock – Guardrails</h1><h2 id="📌-What-Are-Guardrails"><a href="#📌-What-Are-Guardrails" class="headerlink" title="📌 What Are Guardrails?"></a>📌 What Are Guardrails?</h2><p>Guardrails in <strong>Amazon Bedrock</strong> are a way to control and filter interactions between users and Foundation Models (FMs).<br>They help ensure that AI responses are <strong>safe, reliable, and compliant</strong> with your requirements.</p><p align="center">  <img src="/images/aws_basic_62.png" width="80%"></p><hr><h2 id="🔑-Key-Features-of-Guardrails"><a href="#🔑-Key-Features-of-Guardrails" class="headerlink" title="🔑 Key Features of Guardrails"></a>🔑 Key Features of Guardrails</h2><ul><li><strong>Filter harmful content</strong>: Block hate speech, insults, sexual, violent, or misconduct content.  </li><li><strong>Block specific topics</strong>: Deny responses related to sensitive or restricted subjects (e.g., recipes, medical advice).  </li><li><strong>Protect privacy</strong>: Automatically detect and remove <strong>PII (Personally Identifiable Information)</strong> such as emails, phone numbers, or addresses.  </li><li><strong>Reduce hallucinations</strong>: Add contextual grounding so the model gives <strong>factual and relevant answers</strong>.  </li><li><strong>Custom word filters</strong>: Upload your own list of banned words or phrases.  </li><li><strong>Multiple guardrails</strong>: Apply different guardrails for different use cases and stack them together.  </li><li><strong>Monitoring &amp; analysis</strong>: Track user inputs that violate guardrails to improve system safety.</li></ul><hr><h2 id="⚙️-Example-Use-Cases"><a href="#⚙️-Example-Use-Cases" class="headerlink" title="⚙️ Example Use Cases"></a>⚙️ Example Use Cases</h2><h3 id="1-Block-Restricted-Topics"><a href="#1-Block-Restricted-Topics" class="headerlink" title="1. Block Restricted Topics"></a>1. Block Restricted Topics</h3><ul><li><strong>Scenario</strong>: You don’t want your model to answer food recipe requests.  </li><li><strong>User prompt</strong>: “Suggest me something to cook tonight.”  </li><li><strong>Guardrail response</strong>: “Sorry, this is a restricted topic.”</li></ul><h3 id="2-Mask-PII-Privacy-Protection"><a href="#2-Mask-PII-Privacy-Protection" class="headerlink" title="2. Mask PII (Privacy Protection)"></a>2. Mask PII (Privacy Protection)</h3><ul><li><strong>User prompt</strong>: “Draft an email to <a href="mailto:&#x73;&#x74;&#x65;&#x70;&#x68;&#x61;&#110;&#101;&#x40;&#x65;&#x78;&#97;&#109;&#112;&#x6c;&#x65;&#x2e;&#x63;&#111;&#109;">stephane@example.com</a> and cc <a href="mailto:&#x6a;&#111;&#104;&#110;&#x40;&#101;&#120;&#x61;&#x6d;&#x70;&#108;&#x65;&#46;&#x63;&#x6f;&#x6d;">john@example.com</a>.”  </li><li><strong>Guardrail action</strong>: Automatically masks emails →<br>To: [PII Removed], CC: [PII Removed]</li></ul><p>This ensures <strong>user privacy is protected</strong>.</p><hr><h2 id="🛠️-How-to-Configure-a-Guardrail"><a href="#🛠️-How-to-Configure-a-Guardrail" class="headerlink" title="🛠️ How to Configure a Guardrail"></a>🛠️ How to Configure a Guardrail</h2><ol><li><strong>Create Guardrail</strong> – Define a name and blocked message (e.g., <em>“Sorry, the model cannot answer this question.”</em>).  </li><li><strong>Set Filters</strong>  <ul><li>Content filters: hate, insults, sexual, violence, misconduct.  </li><li>Denied topics: e.g., recipes, sensitive domains.  </li><li>Word filters: add custom banned terms.  </li><li>PII filters: mask emails, phone numbers, etc.  </li><li>Regex filters: remove any pattern-based info (like credit card numbers).  </li><li>Grounding: reduce hallucinations by checking answer relevance.</li></ul></li><li><strong>Test the Guardrail</strong> – Run a prompt and see if it blocks or masks correctly.  </li><li><strong>Apply to Models</strong> – You can assign guardrails to any supported Foundation Model (e.g., Anthropic, Sonnet).  </li><li><strong>Stack Multiple Guardrails</strong> – Combine several guardrails for stricter control.</li></ol><hr><h2 id="✅-Why-Use-Guardrails"><a href="#✅-Why-Use-Guardrails" class="headerlink" title="✅ Why Use Guardrails?"></a>✅ Why Use Guardrails?</h2><ul><li>Ensure <strong>responsible AI</strong> usage.  </li><li>Protect your business from <strong>legal, ethical, and compliance risks</strong>.  </li><li>Enhance <strong>user trust</strong> by safeguarding privacy and filtering harmful content.  </li><li>Maintain <strong>high-quality, relevant, and safe outputs</strong> from AI models.</li></ul><p>👉 <strong>In summary:</strong><br>Amazon Bedrock Guardrails are like <strong>safety rules for your AI</strong>, helping you filter content, protect privacy, and keep AI responses accurate and responsible.</p><hr><h2 id="📝-Amazon-Bedrock-Guardrails-Summary-Table"><a href="#📝-Amazon-Bedrock-Guardrails-Summary-Table" class="headerlink" title="📝 Amazon Bedrock Guardrails Summary Table"></a>📝 Amazon Bedrock Guardrails Summary Table</h2><table><thead><tr><th>Category</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td><strong>Purpose</strong></td><td>Control and filter interactions between users and Foundation Models (FMs)</td><td>Prevent AI from producing unsafe or irrelevant outputs</td></tr><tr><td><strong>Content Filtering</strong></td><td>Blocks harmful categories (hate, violence, sexual, misconduct, insults)</td><td>User asks: “Write a violent story.” → Response blocked</td></tr><tr><td><strong>Denied Topics</strong></td><td>Restrict responses on specific topics you define</td><td>Recipes, medical advice, legal guidance</td></tr><tr><td><strong>PII Protection</strong></td><td>Detect and remove Personally Identifiable Information</td><td>Emails, phone numbers, credit cards masked</td></tr><tr><td><strong>Word Filters</strong></td><td>Custom banned words&#x2F;phrases can be uploaded</td><td>Block profanity or sensitive business terms</td></tr><tr><td><strong>Regex Patterns</strong></td><td>Remove data that matches a specific structure</td><td>Mask credit card numbers: 1234-5678-9012-3456</td></tr><tr><td><strong>Grounding (Reduce Hallucinations)</strong></td><td>Ensures responses are relevant and fact-based</td><td>Prevents AI from “making up” answers</td></tr><tr><td><strong>Multiple Guardrails</strong></td><td>You can stack several guardrails together for stricter control</td><td>One for PII + one for harmful content</td></tr><tr><td><strong>Monitoring</strong></td><td>Logs violations to analyze and improve system safety</td><td>Track how often guardrails are triggered</td></tr><tr><td><strong>Blocked Response Message</strong></td><td>Customizable message shown when prompt is blocked</td><td>“Sorry, this question cannot be answered.”</td></tr></tbody></table><hr><h2 id="✅-Key-Benefits"><a href="#✅-Key-Benefits" class="headerlink" title="✅ Key Benefits"></a>✅ Key Benefits</h2><ul><li><strong>Responsible AI</strong> → Prevents harmful or irrelevant responses  </li><li><strong>Enhanced Privacy</strong> → Removes PII and sensitive data  </li><li><strong>Trust &amp; Compliance</strong> → Keeps outputs aligned with regulations and ethics  </li><li><strong>Flexibility</strong> → You can tailor guardrails to your business needs</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;🛡️-Amazon-Bedrock-–-Guardrails&quot;&gt;&lt;a href=&quot;#🛡️-Amazon-Bedrock-–-Guardrails&quot; class=&quot;headerlink&quot; title=&quot;🛡️ Amazon Bedrock – Guardrail</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="AI" scheme="https://kish191919.github.io/categories/Dev/AI/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Certification" scheme="https://kish191919.github.io/tags/Certification/"/>
    
  </entry>
  
  <entry>
    <title>AWS-Certified-AI-Practitioner(8)</title>
    <link href="https://kish191919.github.io/2025/08/15/AWS-Certified-AI-Practitioner-8/"/>
    <id>https://kish191919.github.io/2025/08/15/AWS-Certified-AI-Practitioner-8/</id>
    <published>2025-08-15T22:37:17.000Z</published>
    <updated>2025-08-15T22:45:17.194Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📚-GenAI-Core-Concepts-–-Tokenization-Context-Window-Embeddings"><a href="#📚-GenAI-Core-Concepts-–-Tokenization-Context-Window-Embeddings" class="headerlink" title="📚 GenAI Core Concepts – Tokenization, Context Window, Embeddings"></a>📚 GenAI Core Concepts – Tokenization, Context Window, Embeddings</h1><p>These are foundational concepts in Generative AI.<br>They appear frequently in exams and are critical to understanding how LLMs work.</p><hr><h2 id="1-🔹-Tokenization"><a href="#1-🔹-Tokenization" class="headerlink" title="1. 🔹 Tokenization"></a>1. 🔹 Tokenization</h2><p><strong>Definition</strong><br>The process of converting <strong>raw text</strong> into a sequence of smaller units called <strong>tokens</strong>.<br>Tokens are what the model processes internally.</p><p><strong>Types of Tokenization</strong></p><ol><li><strong>Word-based tokenization</strong>  <ul><li>Splits text into words.</li><li>Example: <code>&quot;The cat sat&quot;</code> → <code>[&quot;The&quot;, &quot;cat&quot;, &quot;sat&quot;]</code></li></ul></li><li><strong>Subword tokenization</strong>  <ul><li>Breaks words into smaller meaningful parts.</li><li>Helps handle long or rare words more efficiently.  </li><li>Example: <code>&quot;unacceptable&quot;</code> → <code>&quot;un&quot;</code> + <code>&quot;acceptable&quot;</code></li></ul></li></ol><p><strong>Why it matters</strong></p><ul><li>Each token has an <strong>ID</strong> so the model works with numbers, not raw text.</li><li>Tokenization impacts <strong>cost</strong> and <strong>context window usage</strong> (fewer tokens → more space for content).</li><li>Punctuation and symbols are also tokens.</li></ul><p><strong>Example</strong><br>Sentence: <code>&quot;Danny, Good job!! Learning AI technology is incredibly difficult, but it&#39;s worth it.&quot;</code>  </p><ul><li><code>&quot;Danny&quot;</code> &#x3D; token  </li><li><code>&quot;,&quot;</code> &#x3D; token</li></ul><p align="center">  <img src="/images/aws_basic_58.png" width="80%"></p><p><strong>Exam Tip</strong></p><ul><li>Try the <a href="https://platform.openai.com/tokenizer">OpenAI Tokenizer</a> to see how text is split.</li><li>Models charge and limit based on <strong>token count</strong>, not word count.</li></ul><hr><h2 id="2-🔹-Context-Window"><a href="#2-🔹-Context-Window" class="headerlink" title="2. 🔹 Context Window"></a>2. 🔹 Context Window</h2><p><strong>Definition</strong><br>The number of tokens an LLM can process at once for generating a response.<br>This includes both <strong>input tokens</strong> (your prompt) and <strong>output tokens</strong> (model’s answer).</p><p><strong>Why it matters</strong></p><ul><li>Larger context windows → more information → more coherent answers.</li><li>But larger windows require <strong>more memory, more processing power</strong>, and <strong>higher cost</strong>.</li></ul><p><strong>Context Window Examples</strong></p><table><thead><tr><th>Model</th><th>Context Window (tokens)</th><th>Approx. Words</th></tr></thead><tbody><tr><td>GPT-4 Turbo</td><td>128,000</td><td>~96,000 words</td></tr><tr><td>Claude 2.1</td><td>200,000</td><td>~150,000 words</td></tr><tr><td>Google Gemini 1.5 Pro</td><td>1,000,000</td><td>~700,000 words</td></tr><tr><td>Research versions</td><td>10,000,000</td><td>~7M words</td></tr></tbody></table><p><strong>Perspective</strong></p><ul><li>1M tokens ≈ 1 hour of video, 11 hours of audio, 30,000+ lines of code, or ~700k words.</li></ul><p align="center">  <img src="/images/aws_basic_59.png" width="60%"></p><p><strong>Exam Tip</strong></p><ul><li>When choosing a model for your use case, <strong>context window size</strong> is often the <strong>first factor</strong> to check.</li></ul><hr><h2 id="3-🔹-Embeddings"><a href="#3-🔹-Embeddings" class="headerlink" title="3. 🔹 Embeddings"></a>3. 🔹 Embeddings</h2><p><strong>Definition</strong><br>A way to represent data (text, images, audio) as <strong>high-dimensional numeric vectors</strong>.<br>Each vector stores multiple features about the input.</p><p><strong>Process</strong></p><ol><li><strong>Tokenization</strong> – Convert text into tokens.</li><li><strong>Token IDs</strong> – Assign each token a numeric ID.</li><li><strong>Embedding Model</strong> – Convert each token ID into a <strong>vector</strong> (list of numbers).</li></ol><p>Example: <code>&quot;The cat sat on the mat&quot;</code>  </p><ul><li><code>&quot;cat&quot;</code> → <code>[0.025, -0.12, 0.33, ...]</code> (100+ dimensions possible)</li></ul><p align="center">  <img src="/images/aws_basic_60.png" width="80%"></p><p><strong>Why High-Dimensional Vectors?</strong></p><ul><li>Can store multiple features per token:<ul><li><strong>Semantic meaning</strong> (what it means)</li><li><strong>Syntactic role</strong> (function in sentence – subject, verb, etc.)</li><li><strong>Sentiment</strong> (positive&#x2F;negative&#x2F;neutral tone)</li><li>Other learned features</li></ul></li><li>Enables <strong>similarity search</strong>: tokens with similar meaning have similar embeddings.</li></ul><hr><h3 id="3-1-Visualizing-Embeddings"><a href="#3-1-Visualizing-Embeddings" class="headerlink" title="3.1. Visualizing Embeddings"></a>3.1. Visualizing Embeddings</h3><p>Humans can visualize <strong>2D or 3D</strong>, but embeddings are often <strong>100+ dimensions</strong>.<br>We use <strong>dimensionality reduction</strong> to make them viewable:</p><p><strong>Example in 2D</strong>:</p><ul><li><code>&quot;dog&quot;</code> and <code>&quot;puppy&quot;</code> → close together (semantic similarity)</li><li><code>&quot;cat&quot;</code> → nearby (animal)</li><li><code>&quot;house&quot;</code> → far away (different concept)</li></ul><p><strong>Example with colors</strong>:</p><ul><li>Assign colors based on embedding values.</li><li>Similar colors &#x3D; similar meaning.</li></ul><p align="center">  <img src="/images/aws_basic_61.png" width="80%"></p><hr><h3 id="3-2-Embeddings-in-RAG-Search"><a href="#3-2-Embeddings-in-RAG-Search" class="headerlink" title="3.2. Embeddings in RAG &amp; Search"></a>3.2. Embeddings in RAG &amp; Search</h3><ul><li>Stored in a <strong>vector database</strong> (e.g., OpenSearch, Pinecone, FAISS, Redis Vector).</li><li>Used for <strong>KNN search</strong> (k-nearest neighbors) to find the closest semantic matches.</li><li>Power search applications:  <ul><li>Input <code>&quot;dog&quot;</code> → retrieves <code>&quot;puppy&quot;</code>, <code>&quot;canine&quot;</code>, <code>&quot;pet&quot;</code>.</li></ul></li></ul><p><strong>Exam Tip</strong></p><ul><li>Vector similarity search &#x3D; <strong>KNN Search</strong> in vector DBs.</li><li>In AWS context, OpenSearch Serverless is common for storing and querying embeddings.</li></ul><hr><h2 id="4-📌-Quick-Summary-Table"><a href="#4-📌-Quick-Summary-Table" class="headerlink" title="4. 📌 Quick Summary Table"></a>4. 📌 Quick Summary Table</h2><table><thead><tr><th>Concept</th><th>What it is</th><th>Why it matters</th><th>Example</th></tr></thead><tbody><tr><td>Tokenization</td><td>Split text into tokens</td><td>Tokens are the unit LLMs process; affects cost&#x2F;context</td><td><code>&quot;unacceptable&quot;</code> → <code>&quot;un&quot;</code>, <code>&quot;acceptable&quot;</code></td></tr><tr><td>Context Window</td><td>Max tokens LLM can handle at once</td><td>Larger &#x3D; more info but higher cost</td><td>GPT-4 Turbo: 128k tokens</td></tr><tr><td>Embeddings</td><td>Numeric vector representation of data</td><td>Enables semantic search &amp; RAG</td><td><code>&quot;dog&quot;</code> vector close to <code>&quot;puppy&quot;</code></td></tr></tbody></table><hr><p>✅ <strong>Key Exam Pointers</strong>:</p><ul><li>Token &#x3D; smallest processing unit in LLMs (words, subwords, punctuation).</li><li>Context window &#x3D; total input + output tokens model can handle.</li><li>Embeddings store multiple features in high-dimensional space for search &amp; retrieval.</li><li>KNN search is the standard for finding similar embeddings in vector DBs.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📚-GenAI-Core-Concepts-–-Tokenization-Context-Window-Embeddings&quot;&gt;&lt;a href=&quot;#📚-GenAI-Core-Concepts-–-Tokenization-Context-Window-Embe</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="AI" scheme="https://kish191919.github.io/categories/Dev/AI/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Certification" scheme="https://kish191919.github.io/tags/Certification/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(7)</title>
    <link href="https://kish191919.github.io/2025/08/15/AWS-Certified-AI-Practitioner-7/"/>
    <id>https://kish191919.github.io/2025/08/15/AWS-Certified-AI-Practitioner-7/</id>
    <published>2025-08-15T21:07:36.000Z</published>
    <updated>2025-08-15T22:52:15.195Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📚-Amazon-Bedrock-–-Setting-up-RAG-Knowledge-Base-Hands-on"><a href="#📚-Amazon-Bedrock-–-Setting-up-RAG-Knowledge-Base-Hands-on" class="headerlink" title="📚 Amazon Bedrock – Setting up RAG &amp; Knowledge Base (Hands-on)"></a>📚 Amazon Bedrock – Setting up RAG &amp; Knowledge Base (Hands-on)</h1><p>This guide explains how to set up a <strong>Retrieval-Augmented Generation (RAG)</strong> pipeline and a <strong>Knowledge Base</strong> in Amazon Bedrock, using Amazon S3 for storage and Amazon OpenSearch Serverless as the vector database.</p><hr><h2 id="1-🔍-Prerequisites"><a href="#1-🔍-Prerequisites" class="headerlink" title="1. 🔍 Prerequisites"></a>1. 🔍 Prerequisites</h2><ul><li><strong>IAM User</strong> (not root user)</li><li><strong>Administrator Access</strong> policy for the IAM user</li><li>AWS services:<ul><li>Amazon Bedrock</li><li>Amazon S3</li><li>Amazon OpenSearch Serverless (or external vector DB)</li></ul></li><li>PDF or text document to upload (e.g., <code>evolution_of_the_internet_detailed.pdf</code>)</li></ul><hr><h2 id="2-🛠-Step-by-Step-Setup"><a href="#2-🛠-Step-by-Step-Setup" class="headerlink" title="2. 🛠 Step-by-Step Setup"></a>2. 🛠 Step-by-Step Setup</h2><h3 id="Step-1-–-Create-an-IAM-User"><a href="#Step-1-–-Create-an-IAM-User" class="headerlink" title="Step 1 – Create an IAM User"></a>Step 1 – Create an IAM User</h3><ol><li><p>Go to <strong>IAM Console → Users → Create User</strong>.</p></li><li><p>Enter a username (e.g., <code>stephane</code>).</p></li><li><p>Enable <strong>AWS Management Console Access</strong>.</p></li><li><p>Set a custom password.</p></li><li><p>Attach the <strong>AdministratorAccess</strong> policy.</p></li><li><p>Save the sign-in URL, username, and password.</p></li><li><p>Log in as the IAM user (not root).</p> <p align="center"></li></ol>  <img src="/images/aws_basic_31.png" width="70%">  </p><hr><h3 id="Step-2-–-Create-a-Knowledge-Base-in-Amazon-Bedrock"><a href="#Step-2-–-Create-a-Knowledge-Base-in-Amazon-Bedrock" class="headerlink" title="Step 2 – Create a Knowledge Base in Amazon Bedrock"></a>Step 2 – Create a Knowledge Base in Amazon Bedrock</h3><ol><li>In <strong>Amazon Bedrock</strong>, go to <strong>Knowledge Bases → Create Knowledge Base</strong>.</li><li>Set the name (default is fine).</li></ol><p align="center">  <img src="/images/aws_basic_36.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_37.png" width="70%"></p><ol start="3"><li><strong>IAM permissions</strong> → <em>Create and use a new service role</em>.</li><li><strong>Data Source</strong> → Select <strong>Amazon S3</strong>.</li><li>Alternative sources (optional):<ul><li>Web crawler (webpages)</li><li>Confluence</li><li>Salesforce</li><li>SharePoint</li></ul></li></ol><p align="center">  <img src="/images/aws_basic_32.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_33.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_34.png" width="20%"></p><p align="center">  <img src="/images/aws_basic_35.png" width="20%"></p><hr><h3 id="Step-3-–-Create-an-Amazon-S3-Bucket-Upload-Documents"><a href="#Step-3-–-Create-an-Amazon-S3-Bucket-Upload-Documents" class="headerlink" title="Step 3 – Create an Amazon S3 Bucket &amp; Upload Documents"></a>Step 3 – Create an Amazon S3 Bucket &amp; Upload Documents</h3><ol><li>Go to <strong>Amazon S3 → Create bucket</strong>.<ul><li>Region: <strong>us-east-1</strong></li><li>Bucket name: <strong>must be globally unique</strong> (e.g., <code>my-demo-bucket-knowledgebase-danny</code>)</li></ul></li><li>Upload your document:<ul><li>Example: <code>evolution_of_the_internet_detailed.pdf</code></li></ul></li><li>Confirm the object appears in the bucket.</li></ol><p align="center">  <img src="/images/aws_basic_38.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_39.png" width="70%"></p><hr><h3 id="Step-4-–-Connect-S3-to-Bedrock-Knowledge-Base"><a href="#Step-4-–-Connect-S3-to-Bedrock-Knowledge-Base" class="headerlink" title="Step 4 – Connect S3 to Bedrock Knowledge Base"></a>Step 4 – Connect S3 to Bedrock Knowledge Base</h3><ol><li>In Bedrock KB creation:<ul><li>Select your S3 bucket as the <strong>data source</strong>.</li><li>Click <strong>Next</strong>.</li></ul></li></ol><p align="center">  <img src="/images/aws_basic_40.png" width="70%"></p><ol start="2"><li><strong>Embedding Model</strong>:<ul><li>Select <strong>Amazon Titan Text Embeddings V2</strong> (default dimensions).</li></ul></li><li><strong>Vector Database</strong>:<ul><li>For AWS exam → <strong>Amazon OpenSearch Serverless</strong> is the common choice.</li><li>External free option → <strong>Pinecone</strong> (free tier available).</li></ul></li><li>Complete the KB creation.</li></ol><p>⚠️ <strong>Cost Warning</strong>:<br>Amazon OpenSearch Serverless minimum cost is ~<strong>$172&#x2F;month</strong> (2 OCUs at $0.24&#x2F;hour).<br>Delete resources after use to avoid charges.</p><p align="center">  <img src="/images/aws_basic_41.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_42.png" width="70%"></p><hr><h3 id="Step-5-–-Sync-Data-to-Vector-Database"><a href="#Step-5-–-Sync-Data-to-Vector-Database" class="headerlink" title="Step 5 – Sync Data to Vector Database"></a>Step 5 – Sync Data to Vector Database</h3><ol><li>Open your Knowledge Base.</li><li>Click <strong>Sync</strong> to push S3 data → embeddings → vector database.</li><li>In OpenSearch Service:<ul><li>View your <strong>collection</strong> and <strong>indexes</strong>.</li><li>Each chunk of your document is stored as a vector.</li></ul></li></ol><p align="center">  <img src="/images/aws_basic_43.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_44.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_45.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_46.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_47.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_48.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_49.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_50.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_51.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_52.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_53.png" width="70%"></p><hr><h3 id="Step-6-–-Test-the-Knowledge-Base"><a href="#Step-6-–-Test-the-Knowledge-Base" class="headerlink" title="Step 6 – Test the Knowledge Base"></a>Step 6 – Test the Knowledge Base</h3><ol><li>Configure a model (e.g., <strong>Anthropic Claude Haiku</strong>).</li><li>Ask a question (e.g., <code>&quot;Who invented the World Wide Web?&quot;</code>).</li><li>Bedrock will:<ul><li>Perform <strong>vector similarity search</strong> (KNN search).</li><li>Retrieve relevant chunks from the KB.</li><li>Augment the prompt with retrieved text.</li><li>Generate an answer with <strong>source citations</strong>.</li></ul></li><li>Click the source link → View the PDF in S3.</li></ol><p align="center">  <img src="/images/aws_basic_54.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_55.png" width="70%"></p><hr><h2 id="3-🧠-How-It-Works-Internally"><a href="#3-🧠-How-It-Works-Internally" class="headerlink" title="3. 🧠 How It Works Internally"></a>3. 🧠 How It Works Internally</h2><h2 id="📈-RAG-Data-Flow-Diagram"><a href="#📈-RAG-Data-Flow-Diagram" class="headerlink" title="📈 RAG Data Flow Diagram"></a>📈 RAG Data Flow Diagram</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">flowchart TD</span><br><span class="line">    A[📂 Amazon S3 PDF] --&gt; B[✂️ Chunking &amp; Embedding Creation&lt;br/&gt;(Amazon Titan)]</span><br><span class="line">    B --&gt; C[🗄 Vector Database&lt;br/&gt;OpenSearch Serverless]</span><br><span class="line">    C --&gt; D[🔍 KNN Similarity Search]</span><br><span class="line">    D --&gt; E[📑 Relevant Chunks Retrieved]</span><br><span class="line">    E --&gt; F[📝 Combined with Original Query&lt;br/&gt;→ Augmented Prompt]</span><br><span class="line">    F --&gt; G[🤖 Foundation Model Generates Answer]</span><br></pre></td></tr></table></figure><ul><li><strong>Chunking</strong>: Splits the document into smaller parts.</li><li><strong>Embeddings</strong>: Numeric vector representation of text.</li><li><strong>KNN Search</strong>: Finds the <code>k</code> most semantically similar chunks.</li><li><strong>Augmented Prompt</strong>: Original query + retrieved text → better answer.</li></ul><hr><h2 id="4-🛑-Cleanup-Avoid-Unnecessary-Costs"><a href="#4-🛑-Cleanup-Avoid-Unnecessary-Costs" class="headerlink" title="4. 🛑 Cleanup (Avoid Unnecessary Costs)"></a>4. 🛑 Cleanup (Avoid Unnecessary Costs)</h2><p>After testing:</p><ol><li><strong>Delete Knowledge Base</strong> in Bedrock.</li><li><strong>Delete OpenSearch Serverless collection</strong>.</li><li>(Optional) Keep S3 bucket (low cost) or delete it.</li></ol><p align="center">  <img src="/images/aws_basic_56.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_57.png" width="80%"></p><hr><h2 id="5-📌-Exam-Tips"><a href="#5-📌-Exam-Tips" class="headerlink" title="5. 📌 Exam Tips"></a>5. 📌 Exam Tips</h2><ul><li><strong>Always use IAM user</strong> (root user cannot create Bedrock KB).</li><li><strong>Vector DB Options in AWS</strong>:<ul><li>OpenSearch (real-time search, KNN)</li><li>Aurora PostgreSQL (pgvector)</li><li>Neptune Analytics (graph-based RAG)</li><li>S3 Vectors (low cost, sub-second search)</li></ul></li><li><strong>External</strong>: Pinecone, Redis, MongoDB Atlas Vector Search.</li><li>Bedrock KB supports multiple data sources, not just S3.</li><li><strong>Remember</strong>: RAG &#x3D; Retrieve external data + Augment prompt + Generate answer.</li></ul><hr><p>✅ <strong>Summary</strong>:<br>You’ve created a Bedrock Knowledge Base with Amazon S3 + OpenSearch, generated embeddings with Titan, performed KNN search, and tested retrieval-augmented responses with citations.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📚-Amazon-Bedrock-–-Setting-up-RAG-Knowledge-Base-Hands-on&quot;&gt;&lt;a href=&quot;#📚-Amazon-Bedrock-–-Setting-up-RAG-Knowledge-Base-Hands-on&quot; cl</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="AI" scheme="https://kish191919.github.io/categories/Dev/AI/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Certification" scheme="https://kish191919.github.io/tags/Certification/"/>
    
  </entry>
  
  <entry>
    <title>AWS-Certified-AI-Practitioner(6)</title>
    <link href="https://kish191919.github.io/2025/08/15/AWS-Certified-AI-Practitioner-6/"/>
    <id>https://kish191919.github.io/2025/08/15/AWS-Certified-AI-Practitioner-6/</id>
    <published>2025-08-15T20:21:28.000Z</published>
    <updated>2025-08-15T21:07:12.986Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📚-Amazon-Bedrock-–-RAG-Knowledge-Base"><a href="#📚-Amazon-Bedrock-–-RAG-Knowledge-Base" class="headerlink" title="📚 Amazon Bedrock – RAG &amp; Knowledge Base"></a>📚 Amazon Bedrock – RAG &amp; Knowledge Base</h1><h2 id="1-🔍-What-is-RAG"><a href="#1-🔍-What-is-RAG" class="headerlink" title="1. 🔍 What is RAG?"></a>1. 🔍 What is RAG?</h2><p><strong>RAG (Retrieval-Augmented Generation)</strong> &#x3D;  </p><blockquote><p><strong>Retrieve</strong> information from an external data source → <strong>Augment</strong> the prompt → <strong>Generate</strong> a more accurate answer.</p></blockquote><ul><li><strong>Retrieval</strong>: Searches for latest or domain-specific data outside the model’s training set.</li><li><strong>Augmented Generation</strong>: Combines retrieved data with the original query before sending it to the model.</li><li><strong>No Fine-tuning Required</strong>: Can inject up-to-date information without retraining the model.</li></ul><hr><h2 id="2-🏗-How-It-Works-Step-by-Step"><a href="#2-🏗-How-It-Works-Step-by-Step" class="headerlink" title="2. 🏗 How It Works (Step-by-Step)"></a>2. 🏗 How It Works (Step-by-Step)</h2><ol><li><strong>Data Storage</strong><ul><li>Store documents in Amazon S3, Confluence, SharePoint, Salesforce, webpages, etc.</li></ul></li><li><strong>Vector Embedding Creation</strong><ul><li>Bedrock automatically chunks data into smaller parts.</li><li>Uses embedding models like Amazon Titan or Cohere to convert text into vectors.</li></ul></li><li><strong>Vector Database Storage</strong><ul><li>Stores embeddings in a vector database (e.g., OpenSearch, Aurora, Neptune, S3 Vectors).</li></ul></li><li><strong>Query Processing</strong><ul><li>User enters a question → RAG searches for semantically similar vectors in the DB.</li></ul></li><li><strong>Prompt Augmentation</strong><ul><li>Search results are combined with the original query → <strong>Augmented Prompt</strong>.</li></ul></li><li><strong>Answer Generation</strong><ul><li>A Foundation Model (Claude, Titan Text, Llama, etc.) generates a final answer with citations.</li></ul></li></ol>  <p align="center">  <img src="/images/aws_basic_27.png" width="100%">  </p><hr><h2 id="3-🛠-Key-Components"><a href="#3-🛠-Key-Components" class="headerlink" title="3. 🛠 Key Components"></a>3. 🛠 Key Components</h2><table><thead><tr><th>Component</th><th>Description</th><th>AWS &#x2F; External Options</th></tr></thead><tbody><tr><td><strong>Data Source</strong></td><td>Location where source data is stored</td><td>Amazon S3, Confluence, SharePoint, Salesforce, webpages</td></tr><tr><td><strong>Embedding Model</strong></td><td>Converts text into vector embeddings</td><td>Amazon Titan, Cohere</td></tr><tr><td><strong>Vector Database</strong></td><td>Stores and retrieves vector data</td><td><strong>AWS:</strong> OpenSearch, Aurora, Neptune Analytics, S3 Vectors<br><strong>External:</strong> MongoDB, Redis, Pinecone</td></tr><tr><td><strong>Foundation Model</strong></td><td>Generates the final answer</td><td>Claude, Titan Text, Llama, etc.</td></tr></tbody></table><hr><h2 id="4-📊-AWS-Vector-Database-Comparison-Exam-Focused"><a href="#4-📊-AWS-Vector-Database-Comparison-Exam-Focused" class="headerlink" title="4. 📊 AWS Vector Database Comparison (Exam-Focused)"></a>4. 📊 AWS Vector Database Comparison (Exam-Focused)</h2><table><thead><tr><th>Service</th><th>Key Features</th><th>Best For</th></tr></thead><tbody><tr><td><strong>Amazon OpenSearch Service</strong></td><td>Real-time search, KNN, serverless&#x2F;managed modes</td><td>Large-scale real-time search &amp; analytics</td></tr><tr><td><strong>Aurora PostgreSQL</strong></td><td>Relational DB with vector search</td><td>Integrating RAG into RDBMS systems</td></tr><tr><td><strong>Neptune Analytics</strong></td><td>Graph-based RAG (GraphRAG)</td><td>Relationship-focused or graph analytics</td></tr><tr><td><strong>S3 Vectors</strong></td><td>Low cost, high durability, sub-second queries</td><td>Cost-effective, long-term storage</td></tr></tbody></table>  <p align="center">  <img src="/images/aws_basic_28.png" width="100%">  </p><hr><h2 id="5-📈-Data-Flow-Example"><a href="#5-📈-Data-Flow-Example" class="headerlink" title="5. 📈 Data Flow Example"></a>5. 📈 Data Flow Example</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">flowchart TD</span><br><span class="line">    A[📂 Data Source&lt;br/&gt;Amazon S3 / Confluence / SharePoint / Salesforce / Webpages]</span><br><span class="line">    B[🔹 Chunking &amp; Embedding Creation&lt;br/&gt;Split docs + Generate vector embeddings&lt;br/&gt;(Amazon Titan, Cohere)]</span><br><span class="line">    C[🗄 Vector Database Storage&lt;br/&gt;OpenSearch / Aurora / Neptune / S3 Vectors]</span><br><span class="line">    D[🔍 Similarity Search&lt;br/&gt;Convert query to vector &amp; run KNN search]</span><br><span class="line">    E[📑 Relevant Documents Retrieved]</span><br><span class="line">    F[📝 Augmented Prompt Creation&lt;br/&gt;Merge query + retrieved content]</span><br><span class="line">    G[🤖 Foundation Model Generates Answer&lt;br/&gt;Context-aware response with citations]</span><br><span class="line"></span><br><span class="line">    A --&gt; B --&gt; C --&gt; D --&gt; E --&gt; F --&gt; G</span><br></pre></td></tr></table></figure><h2 id="📌-Why-KNN-Search-Appears-in-the-RAG-Data-Flow"><a href="#📌-Why-KNN-Search-Appears-in-the-RAG-Data-Flow" class="headerlink" title="📌 Why KNN Search Appears in the RAG Data Flow"></a>📌 Why KNN Search Appears in the RAG Data Flow</h2><p>In Amazon Bedrock’s RAG workflow, <strong>KNN (k-Nearest Neighbors) search</strong> is used because it is the core method for retrieving the most relevant documents from a vector database.</p><h3 id="1-Vector-Embeddings"><a href="#1-Vector-Embeddings" class="headerlink" title="1) Vector Embeddings"></a>1) Vector Embeddings</h3><ul><li>Documents and queries are converted into <strong>vector embeddings</strong> (arrays of numbers) using an embedding model such as <strong>Amazon Titan</strong> or <strong>Cohere</strong>.</li><li>Each vector represents the semantic meaning of the text.</li></ul><h3 id="2-Similarity-Comparison"><a href="#2-Similarity-Comparison" class="headerlink" title="2) Similarity Comparison"></a>2) Similarity Comparison</h3><ul><li>To find the most relevant document for a query, the system compares the <strong>query vector</strong> with <strong>document vectors</strong> stored in the database.</li><li><strong>Distance metrics</strong> (e.g., Cosine Similarity, Euclidean Distance) measure how close two vectors are in the vector space.</li></ul><h3 id="3-KNN-Search"><a href="#3-KNN-Search" class="headerlink" title="3) KNN Search"></a>3) KNN Search</h3><ul><li><strong>KNN (k-Nearest Neighbors)</strong> search retrieves the top <strong>k</strong> most similar vectors to the query vector.</li><li>“Nearest” means smallest distance (highest similarity score).</li><li>This step ensures the retrieved documents are the most contextually relevant to the user’s question.</li></ul><h3 id="4-AWS-External-Database-Support"><a href="#4-AWS-External-Database-Support" class="headerlink" title="4) AWS &amp; External Database Support"></a>4) AWS &amp; External Database Support</h3><ul><li><strong>AWS Native</strong>: Amazon OpenSearch Service (supports Approximate k-NN), Aurora PostgreSQL (with pgvector), Neptune Analytics, S3 Vectors.</li><li><strong>External</strong>: Pinecone, MongoDB with Atlas Vector Search, Redis with Vector capabilities.</li></ul><h3 id="5-Exam-Tip"><a href="#5-Exam-Tip" class="headerlink" title="5) Exam Tip"></a>5) Exam Tip</h3><ul><li>In AWS exam contexts, if you see “vector similarity search” or “semantic search” mentioned, it usually refers to <strong>k-NN search</strong>.</li><li>OpenSearch Service’s <strong>Approximate k-NN</strong> is often the recommended choice for large-scale, real-time semantic search in RAG architectures.</li></ul><p><strong>Summary</strong>:<br>KNN search is in the RAG workflow because it’s the standard method for <strong>finding the most semantically relevant documents</strong> from a vector database before augmenting the prompt for the foundation model.</p><hr><h2 id="6-💡-Common-Use-Cases"><a href="#6-💡-Common-Use-Cases" class="headerlink" title="6. 💡 Common Use Cases"></a>6. 💡 Common Use Cases</h2><ol><li><strong>Customer Service Chatbot</strong><ul><li>KB: Product manuals, FAQs, troubleshooting guides</li><li>Retrieves and answers product-related queries</li></ul></li><li><strong>Legal Research</strong><ul><li>KB: Laws, case precedents, regulations</li><li>Answers legal questions with precise citations</li></ul></li><li><strong>Healthcare Q&amp;A</strong><ul><li>KB: Diseases, treatments, research papers</li><li>Provides medical information based on trusted documents</li></ul></li></ol><hr><h2 id="7-🧪-Hands-On-Example-–-Chat-with-Your-Document"><a href="#7-🧪-Hands-On-Example-–-Chat-with-Your-Document" class="headerlink" title="7. 🧪 Hands-On Example – Chat with Your Document"></a>7. 🧪 Hands-On Example – Chat with Your Document</h2><ul><li><p><strong>Goal</strong>: Build a Q&amp;A system based on uploaded documents</p></li><li><p><strong>Steps</strong></p><ol><li>Navigate to <strong>Builder Tools → Knowledge Bases</strong></li><li>Select <strong>Chat with your document</strong></li><li>Upload a document</li><li>Ask a question:  <ul><li><em>Example:</em> “Who invented the World Wide Web?”</li></ul></li><li>The model searches the document, finds relevant chunks, and generates a response with citations</li></ol></li><li><p><strong>Error Handling</strong>: If the document doesn’t contain relevant info, the model should respond with “I cannot find the answer in the provided data.”</p><p align="center"><img src="/images/aws_basic_29.png" width="100%"></p>  <p align="center"><img src="/images/aws_basic_30.png" width="100%"></p></li></ul><hr><h2 id="8-📌-Key-Points-for-the-Exam"><a href="#8-📌-Key-Points-for-the-Exam" class="headerlink" title="8. 📌 Key Points for the Exam"></a>8. 📌 Key Points for the Exam</h2><ul><li><strong>Definition</strong>: RAG &#x3D; Retrieve external data + augment the prompt → better answers</li><li><strong>Bedrock’s Role</strong>: Automates embedding creation, KB management, and FM connection</li><li><strong>AWS Vector DB Options</strong>: OpenSearch, Aurora, Neptune, S3 Vectors</li><li><strong>Data Sources</strong>: Amazon S3, Confluence, SharePoint, Salesforce, webpages</li><li><strong>Use Cases</strong>: Chatbots, legal research, healthcare Q&amp;A</li><li><strong>Practice Tip</strong>: Use “Chat with your document” to understand KB operations</li></ul><hr><p>✅ <strong>Extra Exam Tip</strong>  </p><ul><li><strong>OpenSearch</strong> → large-scale search &amp; analytics  </li><li><strong>Neptune</strong> → relationship&#x2F;graph-based data  </li><li><strong>S3 Vectors</strong> → low cost &amp; durability  </li><li>Bedrock allows <strong>real-time data integration without fine-tuning</strong></li></ul><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📚-Amazon-Bedrock-–-RAG-Knowledge-Base&quot;&gt;&lt;a href=&quot;#📚-Amazon-Bedrock-–-RAG-Knowledge-Base&quot; class=&quot;headerlink&quot; title=&quot;📚 Amazon Bedroc</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="AI" scheme="https://kish191919.github.io/categories/Dev/AI/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Certification" scheme="https://kish191919.github.io/tags/Certification/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(5)</title>
    <link href="https://kish191919.github.io/2025/08/15/AWS-Certified-AI-Practitioner-5/"/>
    <id>https://kish191919.github.io/2025/08/15/AWS-Certified-AI-Practitioner-5/</id>
    <published>2025-08-15T19:09:05.000Z</published>
    <updated>2025-08-15T20:10:32.134Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📊-Amazon-Bedrock-–-Model-Evaluation-Guide"><a href="#📊-Amazon-Bedrock-–-Model-Evaluation-Guide" class="headerlink" title="📊 Amazon Bedrock – Model Evaluation Guide"></a>📊 Amazon Bedrock – Model Evaluation Guide</h1><p>Evaluating a Foundation Model (FM) is essential for <strong>quality control</strong>, <strong>business impact measurement</strong>, and <strong>bias detection</strong>. Amazon Bedrock offers multiple ways to evaluate models—both automatically and through human feedback—along with technical and business metrics.</p><hr><h2 id="1-🔄-Automatic-Evaluation"><a href="#1-🔄-Automatic-Evaluation" class="headerlink" title="1. 🔄 Automatic Evaluation"></a>1. 🔄 Automatic Evaluation</h2><p>Amazon Bedrock can <strong>automatically score</strong> a model’s performance on predefined tasks.</p><p><strong>Built-in Task Types</strong></p><ul><li>Text summarization</li><li>Question answering</li><li>Text classification</li><li>Open-ended text generation</li></ul><p><strong>How It Works</strong></p><ol><li><strong>Benchmark Dataset</strong>  <ul><li>Curated datasets with <strong>questions</strong> and <strong>ideal answers</strong>.</li><li>Can be AWS-provided or custom-made for your business.</li></ul></li><li><strong>Model Testing</strong>  <ul><li>Model receives the benchmark questions.</li><li>Generates answers for each.</li></ul></li><li><strong>Automated Comparison</strong>  <ul><li>Another “judge model” compares the model’s answers to benchmark answers.</li><li>Produces a <strong>score</strong> using metrics like ROUGE, BLEU, or BERTScore.</li></ul></li></ol><p><strong>Benefits</strong></p><ul><li>Fast and consistent scoring.</li><li>Detects bias, inefficiency, and scalability issues.</li><li>Minimal administrative effort.</li></ul><p align="center">  <img src="/images/aws_basic_20.png" width="100%"></p><hr><h2 id="2-🧑-Human-Evaluation"><a href="#2-🧑-Human-Evaluation" class="headerlink" title="2. 🧑 Human Evaluation"></a>2. 🧑 Human Evaluation</h2><p>Human reviewers assess the model’s answers against benchmarks.</p><p><strong>Who Can Review?</strong></p><ul><li>Internal employees</li><li>Subject Matter Experts (SMEs)</li></ul><p><strong>Evaluation Methods</strong></p><ul><li>Thumbs up&#x2F;down</li><li>Ranking answers</li><li>Custom scoring systems</li></ul><p><strong>Advantages</strong></p><ul><li>Handles nuanced, domain-specific judgment.</li><li>Flexible — supports both built-in and custom tasks.</li></ul><p align="center">  <img src="/images/aws_basic_23.png" width="100%"></p><hr><h2 id="3-📏-Automated-Evaluation-Metrics"><a href="#3-📏-Automated-Evaluation-Metrics" class="headerlink" title="3. 📏 Automated Evaluation Metrics"></a>3. 📏 Automated Evaluation Metrics</h2><h3 id="ROUGE-–-Recall-Oriented-Understudy-for-Gisting-Evaluation"><a href="#ROUGE-–-Recall-Oriented-Understudy-for-Gisting-Evaluation" class="headerlink" title="ROUGE – Recall-Oriented Understudy for Gisting Evaluation"></a><strong>ROUGE</strong> – <em>Recall-Oriented Understudy for Gisting Evaluation</em></h3><ul><li>Measures overlap between reference and generated text.</li><li><strong>ROUGE-N:</strong> Matches n-grams (sequence of N words).</li><li><strong>ROUGE-L:</strong> Longest common word sequence between texts.</li><li><strong>Best for:</strong> Summarization and translation evaluation.</li></ul><h3 id="BLEU-–-Bilingual-Evaluation-Understudy"><a href="#BLEU-–-Bilingual-Evaluation-Understudy" class="headerlink" title="BLEU – Bilingual Evaluation Understudy"></a><strong>BLEU</strong> – <em>Bilingual Evaluation Understudy</em></h3><ul><li>Evaluates translation quality.</li><li>Considers <strong>precision</strong> and penalizes overly short outputs.</li><li>Uses combinations of 1–4 n-grams.</li><li><strong>Best for:</strong> Machine translation.</li></ul><h3 id="BERTScore"><a href="#BERTScore" class="headerlink" title="BERTScore"></a><strong>BERTScore</strong></h3><ul><li>Measures <strong>semantic similarity</strong> using BERT embeddings.</li><li>Compares meaning, not just words.</li><li>Uses <strong>cosine similarity</strong> to quantify closeness.</li><li><strong>Best for:</strong> Capturing nuance and context in text.</li></ul><h3 id="Perplexity"><a href="#Perplexity" class="headerlink" title="Perplexity"></a><strong>Perplexity</strong></h3><ul><li>How well the model predicts the next token.</li><li><strong>Lower is better</strong> → More confident and accurate predictions.</li><li><strong>Best for:</strong> Language fluency evaluation.</li></ul><p align="center">  <img src="/images/aws_basic_21.png" width="100%"></p><hr><h2 id="4-💼-Business-Metrics"><a href="#4-💼-Business-Metrics" class="headerlink" title="4. 💼 Business Metrics"></a>4. 💼 Business Metrics</h2><table><thead><tr><th>Metric</th><th>Purpose</th><th>Example</th></tr></thead><tbody><tr><td><strong>User Satisfaction</strong></td><td>Gauge user happiness with model outputs</td><td>Survey results for an e-commerce chatbot</td></tr><tr><td><strong>ARPU (Average Revenue Per User)</strong></td><td>Track revenue per user from AI features</td><td>Monitor sales after AI recommendations</td></tr><tr><td><strong>Cross-Domain Performance</strong></td><td>Test ability to handle varied domains&#x2F;tasks</td><td>Multi-category product recommendations</td></tr><tr><td><strong>Conversion Rate</strong></td><td>Measure success in driving actions</td><td>% of clicks leading to purchases</td></tr><tr><td><strong>Efficiency</strong></td><td>Check computational and resource efficiency</td><td>Reduce infrastructure costs while keeping accuracy</td></tr></tbody></table><hr><h2 id="5-📚-RAG-Knowledge-Base-in-Bedrock"><a href="#5-📚-RAG-Knowledge-Base-in-Bedrock" class="headerlink" title="5. 📚 RAG &amp; Knowledge Base in Bedrock"></a>5. 📚 RAG &amp; Knowledge Base in Bedrock</h2><p><strong>RAG (Retrieval-Augmented Generation)</strong></p><ul><li>Lets the model <strong>pull external, real-time data</strong> beyond its training.</li><li>Bedrock automatically creates <strong>vector embeddings</strong> from your data and stores them in your chosen database.</li><li><strong>Use Case:</strong> Keeping responses updated with the latest inventory, market data, or news.</li></ul><p><strong>Flow:</strong></p><ol><li>Convert documents → embeddings.</li><li>Store in vector DB.</li><li>At query time, retrieve relevant data.</li><li>Inject into prompt → model generates enriched answer.</li></ol><p align="center">  <img src="/images/aws_basic_22.png" width="100%"></p><hr><h2 id="6-📝-Why-This-Matters-for-Exams-Real-Projects"><a href="#6-📝-Why-This-Matters-for-Exams-Real-Projects" class="headerlink" title="6. 📝 Why This Matters for Exams &amp; Real Projects"></a>6. 📝 Why This Matters for Exams &amp; Real Projects</h2><ul><li><strong>Exams:</strong> Expect questions on evaluation metrics (ROUGE, BLEU, BERTScore, Perplexity), benchmark datasets, and bias detection.</li><li><strong>Real-world:</strong> Proper evaluation ensures your AI system is accurate, fair, efficient, and profitable.</li></ul><hr><h2 id="🔍-Quick-Visual-Summary"><a href="#🔍-Quick-Visual-Summary" class="headerlink" title="🔍 Quick Visual Summary"></a>🔍 Quick Visual Summary</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">flowchart TD</span><br><span class="line">    A[Benchmark Questions + Answers] --&gt; B[Model Generates Answers]</span><br><span class="line">    B --&gt; C[Judge Model or Human Reviewer]</span><br><span class="line">    C --&gt; D[Calculate Metrics: ROUGE, BLEU, BERTScore, Perplexity]</span><br><span class="line">    D --&gt; E[Business Metrics: Satisfaction, ARPU, Conversion, Efficiency]</span><br><span class="line">    E --&gt; F[Continuous Feedback Loop for Model Improvement]</span><br></pre></td></tr></table></figure><p>✅ With this evaluation framework, you can ensure your Amazon Bedrock-powered models are not only technically sound but also deliver measurable business value.</p><h2 id="7-🚀-How-to-Perform-an-Evaluation-in-Amazon-Bedrock"><a href="#7-🚀-How-to-Perform-an-Evaluation-in-Amazon-Bedrock" class="headerlink" title="7. 🚀 How to Perform an Evaluation in Amazon Bedrock"></a>7. 🚀 How to Perform an Evaluation in Amazon Bedrock</h2><p>Once you understand the theory behind model evaluation, here’s how to <strong>actually run</strong> an evaluation in AWS Bedrock.</p><h3 id="Step-by-Step-Guide"><a href="#Step-by-Step-Guide" class="headerlink" title="Step-by-Step Guide"></a>Step-by-Step Guide</h3><ol><li><p><strong>Go to the Evaluations Page</strong></p><ul><li>In the AWS Management Console, open <strong>Amazon Bedrock</strong>.</li><li>From the left-hand menu, click <strong>Evaluations</strong>.</li></ul><p align="center"></li></ol>  <img src="/images/aws_basic_24.png" width="100%">  </p><ol start="2"><li><p><strong>Click “Create Evaluation”</strong></p><ul><li>This starts the setup process.</li><li>You will choose <strong>Automatic</strong> or <strong>Human</strong> evaluation here.</li><li>For a quick start, select <strong>Automatic</strong>.</li></ul></li><li><p><strong>Select Model(s) to Evaluate</strong></p><ul><li>Choose the foundation model(s) you want to test.</li><li>You can select multiple models if you want a performance comparison.</li></ul></li><li><p><strong>Choose Task Type</strong></p><ul><li>Pick from built-in tasks:<ul><li>Text summarization</li><li>Question answering</li><li>Text classification</li><li>Open-ended text generation</li></ul></li><li>Or upload a <strong>custom prompt dataset</strong>.</li></ul></li><li><p><strong>Select Dataset</strong></p><ul><li><strong>Option 1:</strong> Use AWS <strong>curated benchmark datasets</strong> (fast and standardized).</li><li><strong>Option 2:</strong> <strong>Upload your own dataset</strong> (CSV or JSONL format).<ul><li>Make sure it contains prompt–answer pairs for accurate scoring.</li></ul></li></ul></li><li><p><strong>Set Evaluation Metrics</strong></p><ul><li>AWS will automatically use metrics like:<ul><li>ROUGE</li><li>BLEU</li><li>BERTScore</li><li>Perplexity</li></ul></li><li>You can adjust depending on your evaluation goal.</li></ul></li></ol>  <p align="center">  <img src="/images/aws_basic_25.png" width="100%">  </p>  <p align="center">  <img src="/images/aws_basic_26.png" width="100%">  </p><ol start="7"><li><p><strong>Run the Evaluation</strong></p><ul><li>Click <strong>Start Evaluation</strong>.</li><li>AWS will:<ol><li>Send your prompts to the model.</li><li>Collect generated answers.</li><li>Compare against reference answers.</li><li>Generate a score report.</li></ol></li></ul></li><li><p><strong>View Results</strong></p><ul><li>Once complete, view the <strong>Evaluation Report</strong>.</li><li>Report includes:<ul><li>Score by metric (e.g., ROUGE-L &#x3D; 0.82)</li><li>Response examples</li><li>Any detected bias signals</li></ul></li><li>Use results to fine-tune your prompts or model choice.</li></ul></li></ol><hr><h3 id="📌-Pro-Tips"><a href="#📌-Pro-Tips" class="headerlink" title="📌 Pro Tips"></a>📌 Pro Tips</h3><ul><li><strong>Compare Multiple Models</strong><br>Running the same dataset on different models helps you choose the best for your use case.</li><li><strong>Test with Business Data</strong><br>Use real company data to see how the model performs in your specific domain.</li><li><strong>Iterate</strong><br>Re-run evaluations after prompt engineering or fine-tuning to measure improvements.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📊-Amazon-Bedrock-–-Model-Evaluation-Guide&quot;&gt;&lt;a href=&quot;#📊-Amazon-Bedrock-–-Model-Evaluation-Guide&quot; class=&quot;headerlink&quot; title=&quot;📊 Amazo</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="AI" scheme="https://kish191919.github.io/categories/Dev/AI/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Certification" scheme="https://kish191919.github.io/tags/Certification/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(4)</title>
    <link href="https://kish191919.github.io/2025/08/14/AWS-Certified-AI-Practitioner-4/"/>
    <id>https://kish191919.github.io/2025/08/14/AWS-Certified-AI-Practitioner-4/</id>
    <published>2025-08-15T00:12:51.000Z</published>
    <updated>2025-08-15T02:33:16.269Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📚-Amazon-Bedrock-Fine-Tuning-Model-Selection"><a href="#📚-Amazon-Bedrock-Fine-Tuning-Model-Selection" class="headerlink" title="📚 Amazon Bedrock Fine-Tuning &amp; Model Selection"></a>📚 Amazon Bedrock Fine-Tuning &amp; Model Selection</h1><hr><h2 id="1-Different-Providers-Model-Capabilities"><a href="#1-Different-Providers-Model-Capabilities" class="headerlink" title="1. Different Providers &amp; Model Capabilities"></a>1. Different Providers &amp; Model Capabilities</h2><ul><li><strong>Providers</strong>: Anthropic, Amazon, DeepSeek, Stability AI, etc.</li><li>Models vary in strengths:<ul><li><strong>Claude 3.5 Haiku</strong> → Best for text tasks.</li><li><strong>Amazon Nova Reel</strong> → Text-to-video &#x2F; Image-to-video.</li></ul></li><li><strong>Exam Tip</strong>: You will not be tested on <em>which is best</em>, only on <strong>what each can or cannot do</strong>.</li></ul><hr><h2 id="2-Comparing-Models"><a href="#2-Comparing-Models" class="headerlink" title="2. Comparing Models"></a>2. Comparing Models</h2><ul><li><strong>Compare Mode</strong>: Test models side-by-side in Bedrock playground.</li><li>Compare by:<ul><li>✅ Capabilities (text, image, video)</li><li>✅ Output style&#x2F;format</li><li>✅ Speed (latency)</li><li>✅ Cost (token usage)</li></ul></li><li>Example:<ul><li><strong>Nova Micro</strong>: ❌ No image upload, faster, shorter responses.</li><li><strong>Claude 3.5 Sonnet</strong>: ✅ Image support, longer&#x2F;more detailed answers.</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_11.png" width="100%"></p><hr><h2 id="3-Fine-Tuning-Methods-–-Comparison-Table"><a href="#3-Fine-Tuning-Methods-–-Comparison-Table" class="headerlink" title="3. Fine-Tuning Methods – Comparison Table"></a>3. Fine-Tuning Methods – Comparison Table</h2><table><thead><tr><th>Feature</th><th>Instruction-Based Fine-Tuning</th><th>Continued Pre-Training</th><th>Transfer Learning</th></tr></thead><tbody><tr><td><strong>Data Type</strong></td><td>Labeled (prompt–response pairs)</td><td>Unlabeled (raw text)</td><td>Labeled or Unlabeled</td></tr><tr><td><strong>Goal</strong></td><td>Improve performance on domain-specific tasks</td><td>Make model expert in a specific domain</td><td>Adapt a pre-trained model to a new but related task</td></tr><tr><td><strong>Example</strong></td><td>Train chatbot to respond in a specific tone</td><td>Feed all AWS docs to become AWS expert</td><td>Adapt GPT for medical text classification</td></tr><tr><td><strong>Changes Model Weights?</strong></td><td>✅ Yes</td><td>✅ Yes</td><td>✅ Yes</td></tr><tr><td><strong>Complexity</strong></td><td>Medium</td><td>High</td><td>Varies</td></tr><tr><td><strong>Cost</strong></td><td>Lower (less data)</td><td>Higher (more data)</td><td>Varies</td></tr><tr><td><strong>Exam Keyword</strong></td><td><strong>“Labeled data”</strong>, “prompt-response”</td><td><strong>“Unlabeled data”</strong>, “domain adaptation”</td><td>“Adapt model to new task”</td></tr><tr><td><strong>Bedrock Support</strong></td><td>Supported on some models</td><td>Supported on some models</td><td>General ML concept (not Bedrock-specific)</td></tr></tbody></table><blockquote><p>Instruction-based Fine Tuning</p></blockquote><p align="center">  <img src="/images/aws_basic_16.png" width="100%"></p><blockquote><p>Continued Pre-training</p></blockquote><p align="center">  <img src="/images/aws_basic_17.png" width="100%"></p>---<h2 id="4-Messaging-Fine-Tuning"><a href="#4-Messaging-Fine-Tuning" class="headerlink" title="4. Messaging Fine-Tuning"></a>4. Messaging Fine-Tuning</h2><ul><li><strong>Single-Turn Messaging</strong>:<ul><li>One Q → One A</li><li>Optional <code>system</code> context</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_18.png" width="100%"></p><ul><li><strong>Multi-Turn Messaging</strong>:<ul><li>Full conversations, alternating <code>user</code> and <code>assistant</code></li><li>Used for chatbot training in multi-step dialog</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_19.png" width="100%"></p><hr><h2 id="5-Transfer-Learning"><a href="#5-Transfer-Learning" class="headerlink" title="5. Transfer Learning"></a>5. Transfer Learning</h2><ul><li><strong>Definition</strong>: Using a pre-trained model for a new but related task.</li><li>Common in:<ul><li>Image classification</li><li>NLP (BERT, GPT)</li></ul></li><li><strong>Exam Tip</strong>: If question is general ML → choose <em>Transfer Learning</em> as the answer.<br>If it’s about Bedrock &amp; domain-specific → choose <em>Fine-Tuning</em>.</li></ul><hr><h2 id="6-Fine-Tuning-Requirements-in-Amazon-Bedrock"><a href="#6-Fine-Tuning-Requirements-in-Amazon-Bedrock" class="headerlink" title="6. Fine-Tuning Requirements in Amazon Bedrock"></a>6. Fine-Tuning Requirements in Amazon Bedrock</h2><ul><li>Training data <strong>must</strong>:<ul><li>Be in <strong>Amazon S3</strong></li><li>Follow specific formatting</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_15.png" width="100%"></p><ul><li><strong>Provisioned Throughput</strong> is required for:<ul><li>Creating the custom model</li><li>Using the custom model</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_12.png" width="100%"></p><p align="center">  <img src="/images/aws_basic_13.png" width="100%"></p><p align="center">  <img src="/images/aws_basic_14.png" width="100%"></p><ul><li>Not all models can be fine-tuned (usually open-source models are supported).</li></ul><hr><h2 id="7-Common-Use-Cases"><a href="#7-Common-Use-Cases" class="headerlink" title="7. Common Use Cases"></a>7. Common Use Cases</h2><ul><li>Chatbot with specific <strong>persona</strong>, <strong>tone</strong>, or <strong>target audience</strong></li><li>Adding <strong>up-to-date knowledge</strong></li><li>Integrating <strong>exclusive private data</strong> (customer logs, internal documents)</li><li>Improving <strong>categorization</strong>, <strong>accuracy</strong>, or <strong>response style</strong></li></ul><hr><h2 id="8-Exam-Tips"><a href="#8-Exam-Tips" class="headerlink" title="8. Exam Tips"></a>8. Exam Tips</h2><ul><li><strong>Keyword Mapping</strong>:<ul><li>“Labeled data” → <strong>Instruction-based Fine-Tuning</strong></li><li>“Unlabeled data” &#x2F; “Domain adaptation” → <strong>Continued Pre-Training</strong></li><li>“Adapt to a new related task” → <strong>Transfer Learning</strong></li></ul></li><li><strong>Provisioned Throughput</strong> is a must for custom models in Bedrock.</li><li>Fine-tuning changes <strong>weights</strong> of the base model → creates a private version.</li><li>Compare models not just on quality, but also <strong>latency</strong> and <strong>token cost</strong>.</li></ul><h2 id="9-Good-to-know"><a href="#9-Good-to-know" class="headerlink" title="9. Good to know"></a>9. Good to know</h2><ul><li>Re-training an FM requires a higher budget</li><li>Instruction-based fine-tuning is usually cheaper as computations are less intense and the amount of data required usually less</li><li>It also requires experienced ML engineers to perform the task</li><li>You must prepare the data, do the fine-tuning, evaluate the model</li><li>Running a fine-tuned model is also more expensive (provisioned throughput)</li></ul><h2 id="10-Provisioned-Throughput-AWS-Bedrock"><a href="#10-Provisioned-Throughput-AWS-Bedrock" class="headerlink" title="10. Provisioned Throughput (AWS Bedrock)"></a>10. Provisioned Throughput (AWS Bedrock)</h2><p><strong>Definition:</strong><br>Reserving a fixed amount of processing capacity for your custom (fine-tuned) model.</p><h3 id="Why-Needed"><a href="#Why-Needed" class="headerlink" title="Why Needed"></a>Why Needed</h3><ul><li>Fine-tuned models run on <strong>dedicated resources</strong>.</li><li>Ensures <strong>consistent speed</strong>, <strong>low latency</strong>, and <strong>predictable costs</strong>.</li><li>Prevents slowdowns during high demand.</li></ul><h3 id="With-vs-Without"><a href="#With-vs-Without" class="headerlink" title="With vs Without"></a>With vs Without</h3><ul><li><strong>Without:</strong> Performance can drop when traffic spikes.</li><li><strong>With:</strong> Guaranteed performance for the reserved capacity.</li></ul><blockquote><p><strong>Exam Tip:</strong> For custom models in Bedrock, provisioned throughput is <strong>required</strong>.</p></blockquote><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📚-Amazon-Bedrock-Fine-Tuning-Model-Selection&quot;&gt;&lt;a href=&quot;#📚-Amazon-Bedrock-Fine-Tuning-Model-Selection&quot; class=&quot;headerlink&quot; title=&quot;📚</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="AI" scheme="https://kish191919.github.io/categories/Dev/AI/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Certification" scheme="https://kish191919.github.io/tags/Certification/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(3)</title>
    <link href="https://kish191919.github.io/2025/08/14/AWS-Certified-AI-Practitioner-3/"/>
    <id>https://kish191919.github.io/2025/08/14/AWS-Certified-AI-Practitioner-3/</id>
    <published>2025-08-14T23:48:47.000Z</published>
    <updated>2025-08-14T23:55:24.025Z</updated>
    
    <content type="html"><![CDATA[<h1 id="🧠-Generative-AI-Amazon-Bedrock-–-Simple-Summary"><a href="#🧠-Generative-AI-Amazon-Bedrock-–-Simple-Summary" class="headerlink" title="🧠 Generative AI &amp; Amazon Bedrock – Simple Summary"></a>🧠 Generative AI &amp; Amazon Bedrock – Simple Summary</h1><h2 id="1-What-is-Generative-AI"><a href="#1-What-is-Generative-AI" class="headerlink" title="1. What is Generative AI?"></a>1. What is Generative AI?</h2><ul><li><strong>Generative AI (Gen-AI)</strong>: A type of deep learning that <strong>creates new data</strong> similar to what it learned.</li><li>Can generate:<ul><li>Text</li><li>Images</li><li>Audio</li><li>Code</li><li>Video</li></ul></li><li>Example: ChatGPT generating human-like text.</li></ul><hr><h2 id="2-Foundation-Models-FM"><a href="#2-Foundation-Models-FM" class="headerlink" title="2. Foundation Models (FM)"></a>2. Foundation Models (FM)</h2><ul><li>Large AI models trained on diverse datasets.</li><li>Expensive to build (can cost tens of millions of dollars).</li><li>Examples:<ul><li><strong>OpenAI</strong> (GPT-4o)</li><li><strong>Meta</strong> (LLaMA)</li><li><strong>Google</strong> (BERT)</li><li><strong>Amazon</strong> (Titan)</li><li><strong>Anthropic</strong> (Claude)</li></ul></li><li>Some are <strong>open-source</strong> (free), others <strong>commercial</strong> (paid).</li></ul><hr><h2 id="3-Large-Language-Models-LLMs"><a href="#3-Large-Language-Models-LLMs" class="headerlink" title="3. Large Language Models (LLMs)"></a>3. Large Language Models (LLMs)</h2><ul><li>Special AI for <strong>human-like text generation</strong>.</li><li>Trained on huge text datasets (books, websites, articles).</li><li>Billions of parameters.</li><li>Tasks:<ul><li>Translation</li><li>Summarization</li><li>Q&amp;A</li><li>Content creation</li></ul></li></ul><hr><h2 id="4-How-Generative-Language-Models-Work"><a href="#4-How-Generative-Language-Models-Work" class="headerlink" title="4. How Generative Language Models Work"></a>4. How Generative Language Models Work</h2><ol><li><strong>Prompt</strong>: You give an instruction.</li><li><strong>Processing</strong>: The model predicts possible next words.</li><li><strong>Output</strong>: Chooses words based on probability.</li><li><strong>Non-deterministic</strong>: Same prompt → different answers.</li></ol><hr><h2 id="5-Amazon-Bedrock-Overview"><a href="#5-Amazon-Bedrock-Overview" class="headerlink" title="5. Amazon Bedrock Overview"></a>5. Amazon Bedrock Overview</h2><ul><li>AWS service for building Gen-AI apps.</li><li><strong>No server management</strong> – fully managed.</li><li>Pay-per-use.</li><li>Unified API for multiple foundation models.</li><li>Built-in features:<ul><li>RAG (Retrieval-Augmented Generation)</li><li>LLM Agents</li></ul></li><li>Strong focus on security, privacy, and responsible AI.</li></ul><p align="center">  <img src="/images/aws_basic_5.png" width="100%"></p><hr><h2 id="6-Amazon-Bedrock-Foundation-Models"><a href="#6-Amazon-Bedrock-Foundation-Models" class="headerlink" title="6. Amazon Bedrock &amp; Foundation Models"></a>6. Amazon Bedrock &amp; Foundation Models</h2><ul><li>Gives you a <strong>private copy</strong> of the model.</li><li>You can fine-tune it with your data.</li><li>Your data is <strong>not</strong> used to train the public model.</li><li><strong>Amazon Titan</strong>:<ul><li>AWS’s high-performance FM.</li><li>Supports text, image, multimodal.</li><li>Customizable.</li><li>Smaller models &#x3D; more cost-effective.</li></ul></li></ul><hr><h2 id="7-How-to-Use-Amazon-Bedrock"><a href="#7-How-to-Use-Amazon-Bedrock" class="headerlink" title="7. How to Use Amazon Bedrock"></a>7. How to Use Amazon Bedrock</h2><ol><li><strong>Request model access</strong>.</li></ol><p align="center">  <img src="/images/aws_basic_6.png" width="70%"></p><ol start="2"><li>Test with a <strong>single prompt</strong>.</li></ol><p align="center">  <img src="/images/aws_basic_7.png" width="70%"></p><p align="center">  <img src="/images/aws_basic_8.png" width="70%"></p><ol start="3"><li>Try <strong>image generation playground</strong>.</li></ol><p align="center">  <img src="/images/aws_basic_9.png" width="70%"></p><hr><h2 id="8-Example-Models"><a href="#8-Example-Models" class="headerlink" title="8. Example Models"></a>8. Example Models</h2><ul><li><strong>Amazon Titan</strong></li><li><strong>Meta LLaMA</strong></li><li><strong>Anthropic Claude</strong></li><li><strong>Stable Diffusion</strong> (image generation)</li></ul><p align="center">  <img src="/images/aws_basic_10.png" width="70%"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;🧠-Generative-AI-Amazon-Bedrock-–-Simple-Summary&quot;&gt;&lt;a href=&quot;#🧠-Generative-AI-Amazon-Bedrock-–-Simple-Summary&quot; class=&quot;headerlink&quot; tit</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="AI" scheme="https://kish191919.github.io/categories/Dev/AI/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Certification" scheme="https://kish191919.github.io/tags/Certification/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(2)</title>
    <link href="https://kish191919.github.io/2025/08/14/AWS-Certified-AI-Practitioner-2/"/>
    <id>https://kish191919.github.io/2025/08/14/AWS-Certified-AI-Practitioner-2/</id>
    <published>2025-08-14T14:17:53.000Z</published>
    <updated>2025-08-14T14:23:24.934Z</updated>
    
    <content type="html"><![CDATA[<h1 id="💰-AWS-Cost-and-Budget-Setup-Simplified"><a href="#💰-AWS-Cost-and-Budget-Setup-Simplified" class="headerlink" title="💰 AWS Cost and Budget Setup (Simplified)"></a>💰 AWS Cost and Budget Setup (Simplified)</h1><h2 id="1-Access-for-IAM-Users"><a href="#1-Access-for-IAM-Users" class="headerlink" title="1. Access for IAM Users"></a>1. Access for IAM Users</h2><ul><li>To let an <strong>IAM user</strong> view <strong>Billing and Cost Management</strong>,<br>the <strong>administrator</strong> must enable:<br><strong>“IAM user and role access to Billing information”</strong>.</li></ul><p align="center">  <img src="/images/aws_basic_3.png" width="100%"></p>---<h2 id="2-Key-Billing-Tools"><a href="#2-Key-Billing-Tools" class="headerlink" title="2. Key Billing Tools"></a>2. Key Billing Tools</h2><ul><li><strong>Bills</strong>: Shows a detailed breakdown of usage and charges.  </li><li><strong>Free Tier</strong>: Displays remaining Free Tier usage on a dashboard.  </li><li><strong>Budgets</strong>: Sends email alerts if your spending exceeds the set budget.</li></ul><p align="center">  <img src="/images/aws_basic_4.png" width="100%"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;💰-AWS-Cost-and-Budget-Setup-Simplified&quot;&gt;&lt;a href=&quot;#💰-AWS-Cost-and-Budget-Setup-Simplified&quot; class=&quot;headerlink&quot; title=&quot;💰 AWS Cost an</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="AI" scheme="https://kish191919.github.io/categories/Dev/AI/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Certification" scheme="https://kish191919.github.io/tags/Certification/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(1)</title>
    <link href="https://kish191919.github.io/2025/08/14/AWS-Certified-AI-Practitioner-1/"/>
    <id>https://kish191919.github.io/2025/08/14/AWS-Certified-AI-Practitioner-1/</id>
    <published>2025-08-14T11:59:43.000Z</published>
    <updated>2025-08-14T14:22:08.787Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📚-IT-AWS-Basics-Summary"><a href="#📚-IT-AWS-Basics-Summary" class="headerlink" title="📚 IT &amp; AWS Basics Summary"></a>📚 IT &amp; AWS Basics Summary</h1><h2 id="1-Basic-IT-Terms"><a href="#1-Basic-IT-Terms" class="headerlink" title="1. Basic IT Terms"></a>1. Basic IT Terms</h2><ul><li><strong>Network</strong>: A connection of cables, routers, and servers.  </li><li><strong>Router</strong>: A device that decides where to send data packets over the internet.  </li><li><strong>Switch</strong>: Sends a packet to the correct server or client within the network.</li></ul><p align="center">  <img src="/images/aws_basic_1.png" width="60%"></p><hr><h2 id="2-Five-Key-Characteristics-of-Cloud-Computing"><a href="#2-Five-Key-Characteristics-of-Cloud-Computing" class="headerlink" title="2. Five Key Characteristics of Cloud Computing"></a>2. Five Key Characteristics of Cloud Computing</h2><ol><li><strong>On-demand self service</strong> – Instantly get resources without human help.  </li><li><strong>Broad network access</strong> – Access resources from different devices via the internet.  </li><li><strong>Multi-tenancy &amp; Resource pooling</strong> – Multiple users share the same resources securely.  </li><li><strong>Rapid elasticity &amp; Scalability</strong> – Quickly scale up or down when needed.  </li><li><strong>Measured service</strong> – Pay only for the resources you use.</li></ol><hr><h2 id="3-Six-Advantages-of-Cloud-Computing"><a href="#3-Six-Advantages-of-Cloud-Computing" class="headerlink" title="3. Six Advantages of Cloud Computing"></a>3. Six Advantages of Cloud Computing</h2><ul><li>No need to buy hardware; pay only for what you use.  </li><li>Lower costs through large-scale efficiency.  </li><li>Scale based on real usage.  </li><li>Faster development and deployment.  </li><li>No need to run and maintain your own data center.  </li><li>Go global within minutes.</li></ul><hr><h2 id="4-Problems-Solved-by-the-Cloud"><a href="#4-Problems-Solved-by-the-Cloud" class="headerlink" title="4. Problems Solved by the Cloud"></a>4. Problems Solved by the Cloud</h2><ul><li><strong>Flexibility</strong>: Change resource types anytime.  </li><li><strong>Cost-effectiveness</strong>: Pay-as-you-go model.  </li><li><strong>Scalability</strong>: Handle higher loads by adding or upgrading hardware.  </li><li><strong>Elasticity</strong>: Scale in and out when needed.  </li><li><strong>High availability &amp; Fault tolerance</strong>: Spread across multiple data centers.  </li><li><strong>Agility</strong>: Develop and launch quickly.</li></ul><hr><h2 id="5-Cloud-Service-Types-–-Examples"><a href="#5-Cloud-Service-Types-–-Examples" class="headerlink" title="5. Cloud Service Types – Examples"></a>5. Cloud Service Types – Examples</h2><ul><li><strong>IaaS</strong>: AWS EC2, GCP, Azure.  </li><li><strong>PaaS</strong>: AWS Elastic Beanstalk, Heroku.  </li><li><strong>SaaS</strong>: Gmail, Dropbox, Zoom.</li></ul><p align="center">  <img src="/images/aws_basic_2.png" width="60%"></p><hr><h2 id="6-AWS-Pricing-Basics"><a href="#6-AWS-Pricing-Basics" class="headerlink" title="6. AWS Pricing Basics"></a>6. AWS Pricing Basics</h2><ul><li><strong>Compute</strong>: Pay for the time you use computing resources.  </li><li><strong>Storage</strong>: Pay for the data stored in the cloud.  </li><li><strong>Data Transfer</strong>: Pay for data going <strong>out</strong> of the cloud (incoming is free).</li></ul><hr><h2 id="7-AWS-Regions"><a href="#7-AWS-Regions" class="headerlink" title="7. AWS Regions"></a>7. AWS Regions</h2><ul><li>A <strong>region</strong> is a cluster of data centers around the world.  </li><li>Choosing a region depends on:<ul><li>Legal &amp; compliance requirements.  </li><li>Distance to customers (lower latency).  </li><li>Services available in the region.  </li><li>Pricing differences.</li></ul></li></ul><hr><h2 id="8-AWS-Availability-Zones-AZ"><a href="#8-AWS-Availability-Zones-AZ" class="headerlink" title="8. AWS Availability Zones (AZ)"></a>8. AWS Availability Zones (AZ)</h2><ul><li>Each region has 3–6 independent data centers.  </li><li>Redundant power, networking, and connectivity.  </li><li>Separated to avoid disasters and connected with high-speed, low-latency links.</li></ul><hr><h2 id="9-AWS-Edge-Locations-Points-of-Presence"><a href="#9-AWS-Edge-Locations-Points-of-Presence" class="headerlink" title="9. AWS Edge Locations (Points of Presence)"></a>9. AWS Edge Locations (Points of Presence)</h2><ul><li>400+ locations in over 90 cities across 40+ countries.  </li><li>Deliver content to users with lower latency.</li></ul><hr><h2 id="10-AWS-Service-Scope"><a href="#10-AWS-Service-Scope" class="headerlink" title="10. AWS Service Scope"></a>10. AWS Service Scope</h2><ul><li><strong>Global services</strong>: IAM, Route 53, CloudFront, WAF.  </li><li><strong>Region-specific services</strong>: EC2, Elastic Beanstalk, Lambda, Rekognition.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📚-IT-AWS-Basics-Summary&quot;&gt;&lt;a href=&quot;#📚-IT-AWS-Basics-Summary&quot; class=&quot;headerlink&quot; title=&quot;📚 IT &amp;amp; AWS Basics Summary&quot;&gt;&lt;/a&gt;📚 IT &amp;a</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="AI" scheme="https://kish191919.github.io/categories/Dev/AI/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Certification" scheme="https://kish191919.github.io/tags/Certification/"/>
    
  </entry>
  
  <entry>
    <title>Spooky-Author-Identification</title>
    <link href="https://kish191919.github.io/2025/08/13/Spooky-Author-Identification/"/>
    <id>https://kish191919.github.io/2025/08/13/Spooky-Author-Identification/</id>
    <published>2025-08-14T01:16:10.000Z</published>
    <updated>2025-08-14T01:26:36.838Z</updated>
    
    <content type="html"><![CDATA[<h2 id="👻-Spooky-Author-Identification"><a href="#👻-Spooky-Author-Identification" class="headerlink" title="👻 Spooky Author Identification"></a>👻 Spooky Author Identification</h2><p><em>Who wrote this sentence? Classifying authors from a single line of text</em></p><blockquote><p>“Let the words tell you who wrote them.”</p></blockquote><p>📎 <strong>Full Analysis</strong>:<br><a href="https://nbviewer.org/github/kish191919/Spooky_Author_Identification_by_Python/blob/master/Spooky_Author_Identification.ipynb">👉 View Jupyter Notebook on GitHub</a></p><p>📎 <strong>Kaggle Competition</strong>:<br><a href="https://www.kaggle.com/c/spooky-author-identification">👉 Spooky Author Identification (2017 Halloween)</a></p><p align="center">  <img src="/images/portfolio/project6_1.png" alt="Spooky Author Identification" width="30%"></p><hr><h3 id="📌-One-Line-Summary"><a href="#📌-One-Line-Summary" class="headerlink" title="📌 One-Line Summary"></a>📌 One-Line Summary</h3><p>Given a sentence, predict which of <strong>Edgar Allan Poe (EAP)</strong>, <strong>H. P. Lovecraft (HPL)</strong>, or <strong>Mary W. Shelley (MWS)</strong> wrote it.<br>With light preprocessing and <strong>BoW&#x2F;TF‑IDF features + Naive Bayes</strong>, the model achieves strong accuracy and stable generalization.</p><hr><h2 id="1️⃣-Problem-Data"><a href="#1️⃣-Problem-Data" class="headerlink" title="1️⃣ Problem &amp; Data"></a>1️⃣ Problem &amp; Data</h2><ul><li><strong>Task</strong>: Multi-class author classification (EAP&#x2F;HPL&#x2F;MWS) for a single sentence.  </li><li><strong>Metric</strong>: <em>Multi-class Logarithmic Loss</em> (submit probabilities for each author).  </li><li><strong>Files</strong><ul><li><code>train.csv</code>: id, text, author  </li><li><code>test.csv</code>: id, text  </li><li><code>sample_submission.csv</code>: example submission format</li></ul></li><li><strong>Source</strong>: Public-domain fiction, sentence-split with CoreNLP’s MaxEnt tokenizer.</li></ul><hr><h2 id="2️⃣-How-It-Was-Built"><a href="#2️⃣-How-It-Was-Built" class="headerlink" title="2️⃣ How It Was Built"></a>2️⃣ How It Was Built</h2><ol><li><strong>Preprocessing</strong><ul><li>Lowercasing, light cleanup of punctuation&#x2F;numbers, minimal stopword handling.</li></ul></li><li><strong>Feature Extraction</strong><ul><li><strong>Bag-of-Words &#x2F; TF‑IDF</strong> vectors (suited for short sentences).</li></ul></li><li><strong>Modeling</strong><ul><li>Tried <strong>Random Forest</strong>, <strong>AdaBoost</strong>, <strong>SVM</strong>, <strong>Naive Bayes</strong>.</li><li>Evaluated with <strong>10‑fold Cross‑Validation</strong> for robustness.</li></ul></li><li><strong>Final Choice</strong><ul><li><strong>Naive Bayes</strong> selected for best balance of accuracy and stability.</li></ul></li><li><strong>Submission</strong><ul><li>Output calibrated probabilities for each class and submit to Kaggle.</li></ul></li></ol><p><strong>Architecture</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[text] → [cleaning] → [BoW / TF‑IDF] → [Classifier] → P(EAP), P(HPL), P(MWS)</span><br></pre></td></tr></table></figure><hr><h2 id="3️⃣-Results"><a href="#3️⃣-Results" class="headerlink" title="3️⃣ Results"></a>3️⃣ Results</h2><table><thead><tr><th>Model</th><th align="right">Training Score</th><th align="right">10‑Fold CV (avg&#x2F;total F1)</th><th>Notes</th></tr></thead><tbody><tr><td>Random Forest</td><td align="right">0.4311</td><td align="right">0.31</td><td>Struggles with sparse text features</td></tr><tr><td>AdaBoost</td><td align="right">0.6293</td><td align="right">0.65</td><td>Better than RF; still volatile</td></tr><tr><td>SVM</td><td align="right">0.4035</td><td align="right">0.23</td><td>Overfits a single class in this setup</td></tr><tr><td><strong>Naive Bayes (Final)</strong></td><td align="right"><strong>0.8329</strong></td><td align="right"><strong>0.90</strong></td><td>Fast, simple, strong on sparse TF‑IDF ✅</td></tr></tbody></table><p><strong>Kaggle Leaderboard</strong></p><ul><li><strong>LogLoss</strong>: <strong>0.48767</strong>  </li><li><strong>Rank</strong>: <strong>793 &#x2F; 1244 (63.7%)</strong></li></ul><hr><h2 id="4️⃣-Why-Naive-Bayes"><a href="#4️⃣-Why-Naive-Bayes" class="headerlink" title="4️⃣ Why Naive Bayes?"></a>4️⃣ Why Naive Bayes?</h2><ul><li>Excels with <strong>sparse word distributions</strong> and short texts.  </li><li>Few hyperparameters → <strong>stable generalization</strong> and fast iteration.  </li><li>Simple pipeline makes <strong>experimentation</strong> (n‑grams, char‑grams) easy.</li></ul><hr><h2 id="5️⃣-Real‑World-Use"><a href="#5️⃣-Real‑World-Use" class="headerlink" title="5️⃣ Real‑World Use"></a>5️⃣ Real‑World Use</h2><ul><li><strong>Stylometry</strong> (author identification), plagiarism detection, style recommendation.  </li><li>Brand&#x2F;author <strong>tone-of-voice</strong> classification and content routing.</li></ul><hr><h2 id="🛠-Technologies-Used"><a href="#🛠-Technologies-Used" class="headerlink" title="🛠 Technologies Used"></a>🛠 Technologies Used</h2><table><thead><tr><th>Step</th><th>Technology</th></tr></thead><tbody><tr><td>Data &#x2F; EDA</td><td>Python, Pandas, NumPy</td></tr><tr><td>NLP Features</td><td>scikit-learn (Count &#x2F; TF‑IDF)</td></tr><tr><td>Models</td><td>scikit-learn (NB, SVM, RF, AdaBoost)</td></tr><tr><td>Environment</td><td>Jupyter Notebook</td></tr></tbody></table><hr><h2 id="💡-Key-Learnings"><a href="#💡-Key-Learnings" class="headerlink" title="💡 Key Learnings"></a>💡 Key Learnings</h2><ul><li><strong>TF‑IDF + Naive Bayes</strong> remains a strong baseline for short-text classification.  </li><li>Improving leaderboard LogLoss benefits from <strong>probability calibration</strong> and <strong>n‑gram &#x2F; char‑gram</strong> features.  </li><li>For imbalanced, sparse text, simpler models can beat complex ensembles.</li></ul><hr><h2 id="🔗-GitHub-Repository"><a href="#🔗-GitHub-Repository" class="headerlink" title="🔗 GitHub Repository"></a>🔗 GitHub Repository</h2><p>📂 <a href="https://github.com/kish191919/Spooky_Author_Identification_by_Python">View Project on GitHub</a></p><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;👻-Spooky-Author-Identification&quot;&gt;&lt;a href=&quot;#👻-Spooky-Author-Identification&quot; class=&quot;headerlink&quot; title=&quot;👻 Spooky Author Identificatio</summary>
      
    
    
    
    <category term="Showcase" scheme="https://kish191919.github.io/categories/Showcase/"/>
    
    
    <category term="Python" scheme="https://kish191919.github.io/tags/Python/"/>
    
    <category term="NLP" scheme="https://kish191919.github.io/tags/NLP/"/>
    
    <category term="Kaggle" scheme="https://kish191919.github.io/tags/Kaggle/"/>
    
  </entry>
  
  <entry>
    <title>News Keyword Trend Analyzer</title>
    <link href="https://kish191919.github.io/2025/08/13/News-Keyword-Trend-Analyzer/"/>
    <id>https://kish191919.github.io/2025/08/13/News-Keyword-Trend-Analyzer/</id>
    <published>2025-08-14T00:45:31.000Z</published>
    <updated>2025-08-14T01:03:08.689Z</updated>
    
    <content type="html"><![CDATA[<h2 id="📰-Real-Time-News-Keyword-Trend-Analyzer"><a href="#📰-Real-Time-News-Keyword-Trend-Analyzer" class="headerlink" title="📰 Real-Time News Keyword Trend Analyzer"></a>📰 Real-Time News Keyword Trend Analyzer</h2><p><em>Tracking trending keywords in news articles using real-time data<br>pipelines</em></p><blockquote><p>“See the world’s breaking news trends — live.”</p></blockquote><p align="center">  <img src="/images/portfolio/project5_1.png" alt="News Keyword Trend Analyzer" width="80%"></p><hr><h3 id="📌-One-Line-Summary"><a href="#📌-One-Line-Summary" class="headerlink" title="📌 One-Line Summary"></a>📌 One-Line Summary</h3><p>A <strong>real-time news keyword trend analyzer</strong> that collects live news<br>headlines, processes them to extract popular keywords, and visualizes<br>their trends in real time using <strong>Kafka, Apache Flink, Elasticsearch,<br>and Kibana</strong>.</p><hr><h2 id="1️⃣-How-It-Works"><a href="#1️⃣-How-It-Works" class="headerlink" title="1️⃣ How It Works"></a>1️⃣ How It Works</h2><h3 id="1-Data-Collection-—-Kafka-Producer-news-producer-py"><a href="#1-Data-Collection-—-Kafka-Producer-news-producer-py" class="headerlink" title="1. Data Collection — Kafka Producer (news_producer.py)"></a><strong>1. Data Collection — Kafka Producer (<code>news_producer.py</code>)</strong></h3><ul><li>Fetches top news headlines from <strong>NewsAPI.org</strong></li><li>Sends news titles to the Kafka topic <strong><code>news</code></strong> every 30 seconds</li><li>Uses environment variables for API key and EC2 host configuration</li></ul><hr><h3 id="2-Real-Time-Processing-—-Flink-Consumer-keyword-trend-analyzer-py"><a href="#2-Real-Time-Processing-—-Flink-Consumer-keyword-trend-analyzer-py" class="headerlink" title="2. Real-Time Processing — Flink Consumer (keyword_trend_analyzer.py)"></a><strong>2. Real-Time Processing — Flink Consumer (<code>keyword_trend_analyzer.py</code>)</strong></h3><ul><li>Consumes news data from Kafka</li><li>Cleans titles (lowercasing, removing special characters)</li><li>Extracts <strong>keywords</strong> (words with ≥4 letters)</li><li>Counts keyword frequencies in real-time</li><li>Sends processed results to <strong>Elasticsearch</strong></li></ul><hr><h3 id="3-Storage-Visualization-—-Elasticsearch-Kibana"><a href="#3-Storage-Visualization-—-Elasticsearch-Kibana" class="headerlink" title="3. Storage &amp; Visualization — Elasticsearch &amp; Kibana"></a><strong>3. Storage &amp; Visualization — Elasticsearch &amp; Kibana</strong></h3><ul><li>Stores keyword counts in Elasticsearch index <code>news_keywords</code></li><li>Visualizes trends in Kibana dashboards<ul><li><strong>Keyword frequency charts</strong></li><li><strong>Trend over time graphs</strong></li></ul></li></ul><hr><h2 id="2️⃣-System-Architecture"><a href="#2️⃣-System-Architecture" class="headerlink" title="2️⃣ System Architecture"></a>2️⃣ System Architecture</h2><pre><code>[NewsAPI] → [Kafka Producer] → [Kafka Topic: news] → [Flink Consumer] → [Elasticsearch] → [Kibana Dashboard]</code></pre><p align="center">  <img src="/images/portfolio/project5_2.png" alt="News Keyword Trend Analyzer" width="80%"></p><hr><h2 id="🚀-Quick-Start"><a href="#🚀-Quick-Start" class="headerlink" title="🚀 Quick Start"></a>🚀 Quick Start</h2><ol><li><strong>Clone &amp; Install</strong> — Download the repository and install<br>dependencies\</li><li><strong>Start Services</strong> — Launch Kafka, Flink, Elasticsearch, and<br>Kibana\</li><li><strong>Run Scripts</strong> — Start the Kafka producer and Flink consumer\</li><li><strong>Visualize</strong> — Open Kibana to see real-time keyword trends</li></ol><p>📎 <strong>Full setup guide</strong>: <a href="https://github.com/your-username/real-time-news-keyword-trend-analyzer">View on<br>GitHub</a></p><hr><h2 id="4️⃣-Usage"><a href="#4️⃣-Usage" class="headerlink" title="4️⃣ Usage"></a>4️⃣ Usage</h2><ul><li>The Kafka Producer streams news data to Flink.</li><li>Flink processes titles → extracts keywords → counts occurrences.</li><li>Elasticsearch indexes keyword trends.</li><li>Kibana displays <strong>live keyword frequency and trend graphs</strong>.</li></ul><hr><h2 id="🛠-Technologies-Used"><a href="#🛠-Technologies-Used" class="headerlink" title="🛠 Technologies Used"></a>🛠 Technologies Used</h2><p>  Step            Technology</p><hr><p>  Data Source     NewsAPI.org<br>  Streaming       Apache Kafka<br>  Processing      Apache Flink<br>  Storage         Elasticsearch<br>  Visualization   Kibana<br>  Language        Python</p><hr><h2 id="💡-Key-Learnings"><a href="#💡-Key-Learnings" class="headerlink" title="💡 Key Learnings"></a>💡 Key Learnings</h2><ul><li>Apache Flink’s stream processing is powerful for <strong>real-time<br>analytics</strong>.</li><li>Kafka ensures scalable and fault-tolerant data streaming.</li><li>Elasticsearch + Kibana make it easy to explore and visualize trends<br>instantly.</li></ul><hr><h2 id="🔗-GitHub-Repository"><a href="#🔗-GitHub-Repository" class="headerlink" title="🔗 GitHub Repository"></a>🔗 GitHub Repository</h2><p>📂 <a href="https://github.com/kish191919/realTimeNewsKeywordTrendAnalyzer">View Project on<br>GitHub</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;📰-Real-Time-News-Keyword-Trend-Analyzer&quot;&gt;&lt;a href=&quot;#📰-Real-Time-News-Keyword-Trend-Analyzer&quot; class=&quot;headerlink&quot; title=&quot;📰 Real-Time</summary>
      
    
    
    
    <category term="Showcase" scheme="https://kish191919.github.io/categories/Showcase/"/>
    
    
    <category term="Python" scheme="https://kish191919.github.io/tags/Python/"/>
    
    <category term="Kafka" scheme="https://kish191919.github.io/tags/Kafka/"/>
    
    <category term="Apache_Flink" scheme="https://kish191919.github.io/tags/Apache-Flink/"/>
    
    <category term="Elasticsearch" scheme="https://kish191919.github.io/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>House Price Prediction</title>
    <link href="https://kish191919.github.io/2025/08/13/House-Price-Prediction/"/>
    <id>https://kish191919.github.io/2025/08/13/House-Price-Prediction/</id>
    <published>2025-08-14T00:20:03.000Z</published>
    <updated>2025-08-14T00:27:45.889Z</updated>
    
    <content type="html"><![CDATA[<h2 id="🏠-House-Price-Prediction-in-Ames-Iowa"><a href="#🏠-House-Price-Prediction-in-Ames-Iowa" class="headerlink" title="🏠 House Price Prediction in Ames, Iowa"></a>🏠 House Price Prediction in Ames, Iowa</h2><p><em>Predicting real estate prices using advanced regression techniques</em></p><blockquote><p>“Accurate home valuation — powered by data.”</p></blockquote><p>📎 <strong>Full Analysis</strong>:<br><a href="https://nbviewer.org/github/kish191919/House_Price_Project_by_Python/blob/master/House_Prediction_Project_OLS_Model.ipynb">👉 View Jupyter Notebook on GitHub</a></p><p>📎 <strong>Competition Source</strong>:<br><a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques">👉 Kaggle: House Prices - Advanced Regression Techniques</a></p><p align="center">  <img src="/images/portfolio/House_Price.png" alt="House Price Prediction" width="60%"></p><hr><h3 id="📌-One-Line-Summary"><a href="#📌-One-Line-Summary" class="headerlink" title="📌 One-Line Summary"></a>📌 One-Line Summary</h3><p>This project predicts house prices in <strong>Ames, Iowa</strong> using <strong>81 property features</strong> such as area, location, condition, and building type.<br>It applies <strong>data preprocessing</strong>, <strong>feature engineering</strong>, and <strong>regression modeling</strong> to estimate realistic sale prices.</p><hr><h2 id="1️⃣-How-It-Was-Built"><a href="#1️⃣-How-It-Was-Built" class="headerlink" title="1️⃣ How It Was Built"></a>1️⃣ How It Was Built</h2><h3 id="1-Data-Collection"><a href="#1-Data-Collection" class="headerlink" title="1. Data Collection"></a><strong>1. Data Collection</strong></h3><ul><li><strong>Train Data</strong>: 1,460 records, 81 features  </li><li><strong>Test Data</strong>: 1,459 records, 80 features (SalePrice excluded)  </li><li>Total: <strong>2,919 property listings</strong></li><li>Data from Kaggle competition dataset</li></ul><hr><h3 id="2-Data-Preparation"><a href="#2-Data-Preparation" class="headerlink" title="2. Data Preparation"></a><strong>2. Data Preparation</strong></h3><ul><li>Checked missing values (e.g., <code>LotFrontage</code>, <code>MasVnrArea</code>)</li><li>Filled missing values using median or mode depending on the feature type</li><li>Removed outliers (e.g., extreme <code>GrLivArea</code> values)</li><li>Applied <strong>log transformation</strong> to <code>SalePrice</code> to normalize skewed distribution</li><li>Converted categorical features into numerical form using one-hot encoding</li></ul><hr><h3 id="3-Exploratory-Data-Analysis-EDA"><a href="#3-Exploratory-Data-Analysis-EDA" class="headerlink" title="3. Exploratory Data Analysis (EDA)"></a><strong>3. Exploratory Data Analysis (EDA)</strong></h3><ul><li><strong>Numerical features</strong>: Plotted scatter graphs with <code>SalePrice</code> to detect trends<br>→ Found <code>GrLivArea</code> has strong linear correlation with price</li><li><strong>Categorical features</strong>: Compared median prices across categories (e.g., neighborhood)</li><li>Observed that <strong>larger living area</strong> and <strong>better overall quality</strong> strongly increase house price</li></ul><hr><h3 id="4-Feature-Engineering"><a href="#4-Feature-Engineering" class="headerlink" title="4. Feature Engineering"></a><strong>4. Feature Engineering</strong></h3><ul><li>Created new features such as:<ul><li><code>TotalSF</code> &#x3D; Total square footage (basement + 1st floor + 2nd floor)</li><li><code>Age</code> &#x3D; Years since construction</li></ul></li><li>Dropped low-impact or highly correlated redundant features</li></ul><hr><h3 id="5-Model-Training-OLS-Regression"><a href="#5-Model-Training-OLS-Regression" class="headerlink" title="5. Model Training (OLS Regression)"></a><strong>5. Model Training (OLS Regression)</strong></h3><ul><li>Used <strong>Ordinary Least Squares (OLS)</strong> regression to predict prices</li><li>Checked multicollinearity using Variance Inflation Factor (VIF)</li><li>Selected final set of features after removing high-VIF variables</li></ul><p>📊 <strong>Evaluation Metric</strong>:  </p><ul><li><strong>Root Mean Squared Error (RMSE)</strong> used for performance check  </li><li>Final RMSE (log-transformed target): <strong>~0.12</strong> on validation set</li></ul><hr><h3 id="6-Results"><a href="#6-Results" class="headerlink" title="6. Results"></a><strong>6. Results</strong></h3><table><thead><tr><th>Feature</th><th>Impact on Price</th></tr></thead><tbody><tr><td><code>OverallQual</code></td><td>Very High</td></tr><tr><td><code>GrLivArea</code></td><td>High</td></tr><tr><td><code>GarageCars</code></td><td>High</td></tr><tr><td><code>TotalSF</code></td><td>High</td></tr><tr><td><code>Neighborhood</code></td><td>Moderate</td></tr></tbody></table><p>Example Prediction:  </p><ul><li><strong>House</strong>: 2-story, built in 2005, 2,000 sqft, good neighborhood  </li><li><strong>Predicted Price</strong>: ~$197,500</li></ul><hr><h2 id="2️⃣-Real-World-Use"><a href="#2️⃣-Real-World-Use" class="headerlink" title="2️⃣ Real-World Use"></a>2️⃣ Real-World Use</h2><ul><li>The OLS model can be used by real estate agencies to <strong>estimate property prices</strong></li><li>Buyers &amp; sellers can check if a listing is <strong>fairly priced</strong></li><li>Government agencies can use it for <strong>property tax assessment</strong></li></ul><hr><h2 id="🛠-Technologies-Used"><a href="#🛠-Technologies-Used" class="headerlink" title="🛠 Technologies Used"></a>🛠 Technologies Used</h2><table><thead><tr><th>Step</th><th>Technology</th></tr></thead><tbody><tr><td>Data Storage</td><td>CSV (Kaggle Dataset)</td></tr><tr><td>Model Dev</td><td>Python, Pandas, NumPy, statsmodels</td></tr><tr><td>Visualization</td><td>Matplotlib, Seaborn</td></tr><tr><td>Environment</td><td>Jupyter Notebook</td></tr></tbody></table><hr><h2 id="💡-Key-Learnings"><a href="#💡-Key-Learnings" class="headerlink" title="💡 Key Learnings"></a>💡 Key Learnings</h2><ul><li>Log-transforming skewed price data improves model performance</li><li>Removing multicollinear features increases stability of regression coefficients</li><li>Even simple linear models can perform well with good feature engineering</li></ul><hr><h2 id="🔗-GitHub-Repository"><a href="#🔗-GitHub-Repository" class="headerlink" title="🔗 GitHub Repository"></a>🔗 GitHub Repository</h2><p>📂 <a href="https://github.com/kish191919/House_Price_Project_by_Python">View Project on GitHub</a></p><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;🏠-House-Price-Prediction-in-Ames-Iowa&quot;&gt;&lt;a href=&quot;#🏠-House-Price-Prediction-in-Ames-Iowa&quot; class=&quot;headerlink&quot; title=&quot;🏠 House Price P</summary>
      
    
    
    
    <category term="Showcase" scheme="https://kish191919.github.io/categories/Showcase/"/>
    
    
    <category term="Python" scheme="https://kish191919.github.io/tags/Python/"/>
    
    <category term="Machine Learning" scheme="https://kish191919.github.io/tags/Machine-Learning/"/>
    
    <category term="Regression" scheme="https://kish191919.github.io/tags/Regression/"/>
    
  </entry>
  
  <entry>
    <title>AI Stock Analysis App</title>
    <link href="https://kish191919.github.io/2025/08/10/AI-Stock-Analysis-App/"/>
    <id>https://kish191919.github.io/2025/08/10/AI-Stock-Analysis-App/</id>
    <published>2025-08-10T20:25:18.000Z</published>
    <updated>2025-08-12T20:19:34.694Z</updated>
    
    <content type="html"><![CDATA[<h2 id="📈-AI-Stock-Analysis-App"><a href="#📈-AI-Stock-Analysis-App" class="headerlink" title="📈 AI Stock Analysis App"></a>📈 AI Stock Analysis App</h2><p><em>AI-powered iOS app for real-time stock market insights</em></p><blockquote><p>“Real-time stock prices meet AI-powered analysis — in your language.”</p></blockquote><p>📎 <strong>Demo Video</strong>:  </p><p align="center"><video width="40%" autoplay muted playsinline loop>  <source src="/videos/project3.mp4" type="video/mp4">  Your browser does not support the video tag.</video></p><hr><h3 id="📌-One-Line-Summary"><a href="#📌-One-Line-Summary" class="headerlink" title="📌 One-Line Summary"></a>📌 One-Line Summary</h3><p>An iPhone app that collects <strong>real-time stock data</strong> and uses <strong>AI</strong> to provide clear investment insights in multiple languages.<br>It also stores your past analyses so you can track trends over time.</p><hr><h2 id="1️⃣-How-It-Works"><a href="#1️⃣-How-It-Works" class="headerlink" title="1️⃣ How It Works"></a>1️⃣ How It Works</h2><h3 id="1-Live-Stock-Data"><a href="#1-Live-Stock-Data" class="headerlink" title="1. Live Stock Data"></a><strong>1. Live Stock Data</strong></h3><ul><li>Pulls stock prices from <strong>Yahoo Finance API</strong></li><li>Shows:<ul><li><strong>15-minute interval prices</strong> (last 3 days)</li><li><strong>Daily prices</strong> (last month)</li><li>Pre-market, regular, and after-hours prices</li></ul></li><li>Includes related news and market mood indicators (VIX, Fear &amp; Greed Index)</li></ul><hr><h3 id="2-AI-Powered-Analysis"><a href="#2-AI-Powered-Analysis" class="headerlink" title="2. AI-Powered Analysis"></a><strong>2. AI-Powered Analysis</strong></h3><ul><li>Uses <strong>OpenAI GPT-4</strong> to:<ul><li>Predict <strong>BULLISH</strong>, <strong>BEARISH</strong>, or <strong>NEUTRAL</strong> market direction</li><li>Show a confidence percentage</li><li>Explain the reasoning in your chosen language</li><li>Predict tomorrow’s closing price</li></ul></li><li>Tracks AI usage and shows the <strong>cost in real time</strong></li></ul><hr><h3 id="3-Analysis-History"><a href="#3-Analysis-History" class="headerlink" title="3. Analysis History"></a><strong>3. Analysis History</strong></h3><ul><li>Saves past analysis results on your phone:<ul><li>Stock symbol</li><li>Current price</li><li>Prediction &amp; confidence</li><li>Expected price</li><li>Reason for prediction</li><li>Date &amp; time of analysis</li><li>Language used</li></ul></li></ul><hr><h3 id="4-Simple-Navigation"><a href="#4-Simple-Navigation" class="headerlink" title="4. Simple Navigation"></a><strong>4. Simple Navigation</strong></h3><ul><li><strong>Home</strong> → Search and view live prices  </li><li><strong>Analysis</strong> → Run AI prediction  </li><li><strong>History</strong> → Review saved analyses</li></ul><hr><h2 id="2️⃣-Cost-Tracking"><a href="#2️⃣-Cost-Tracking" class="headerlink" title="2️⃣ Cost Tracking"></a>2️⃣ Cost Tracking</h2><ul><li>Uses GPT-4 Turbo pricing (as of 2024):<ul><li><strong>$0.01</strong> per 1,000 prompt tokens</li><li><strong>$0.03</strong> per 1,000 completion tokens</li></ul></li><li>The app logs each request and shows how much you’ve spent</li></ul><hr><h2 id="🛠-Technologies-Used"><a href="#🛠-Technologies-Used" class="headerlink" title="🛠 Technologies Used"></a>🛠 Technologies Used</h2><table><thead><tr><th>Step</th><th>Technology</th></tr></thead><tbody><tr><td>iOS UI</td><td>Swift, SwiftUI</td></tr><tr><td>Data Storage</td><td>Core Data</td></tr><tr><td>API Calls</td><td>URLSession, JSONDecoder</td></tr><tr><td>Data Source</td><td>Yahoo Finance API</td></tr><tr><td>AI Analysis</td><td>OpenAI GPT-4</td></tr></tbody></table><hr><h2 id="💡-Key-Benefits"><a href="#💡-Key-Benefits" class="headerlink" title="💡 Key Benefits"></a>💡 Key Benefits</h2><ul><li>Get instant AI-powered stock insights in your own language</li><li>Track both prices and reasoning over time</li><li>Manage and monitor your AI usage costs</li><li>Clean, mobile-friendly design for quick decisions</li></ul><hr><h2 id="🔗-GitHub-Repository"><a href="#🔗-GitHub-Repository" class="headerlink" title="🔗 GitHub Repository"></a>🔗 GitHub Repository</h2><p>📂 <a href="https://github.com/kish191919/AIStockAnalysis">View Project on GitHub</a></p><hr><div style="display: flex; justify-content: center; gap: 10px; flex-wrap: nowrap;">  <img src="/images/portfolio/project3_1.png" alt="Screen 1" style="width:24%;">  <img src="/images/portfolio/project3_2.png" alt="Screen 2" style="width:24%;">  <img src="/images/portfolio/project3_3.png" alt="Screen 3" style="width:24%;">  <img src="/images/portfolio/project3_4.png" alt="Screen 4" style="width:24%;"></div>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;📈-AI-Stock-Analysis-App&quot;&gt;&lt;a href=&quot;#📈-AI-Stock-Analysis-App&quot; class=&quot;headerlink&quot; title=&quot;📈 AI Stock Analysis App&quot;&gt;&lt;/a&gt;📈 AI Stock An</summary>
      
    
    
    
    <category term="Showcase" scheme="https://kish191919.github.io/categories/Showcase/"/>
    
    
    <category term="OpenAI" scheme="https://kish191919.github.io/tags/OpenAI/"/>
    
    <category term="Swift" scheme="https://kish191919.github.io/tags/Swift/"/>
    
  </entry>
  
  <entry>
    <title>Real Time Crypto Dashboard</title>
    <link href="https://kish191919.github.io/2025/07/24/Real-Time-Crypto-Dashboard/"/>
    <id>https://kish191919.github.io/2025/07/24/Real-Time-Crypto-Dashboard/</id>
    <published>2025-07-24T23:57:22.000Z</published>
    <updated>2025-08-12T20:19:34.694Z</updated>
    
    <content type="html"><![CDATA[<h2 id="💹-Real-Time-Crypto-Dashboard"><a href="#💹-Real-Time-Crypto-Dashboard" class="headerlink" title="💹 Real-Time Crypto Dashboard"></a>💹 Real-Time Crypto Dashboard</h2><p><em>Live Bitcoin &amp; Ethereum tracking with predictions</em></p><blockquote><p>“Watch crypto markets move in real time — and see tomorrow’s trend today.”</p></blockquote><p>📎 <strong>Demo Video</strong>:<br><video width="100%" autoplay muted playsinline loop><br>  <source src="/videos/project2.mp4" type="video/mp4"><br>  Your browser does not support the video tag.<br></video></p><hr><h3 id="📌-One-Line-Summary"><a href="#📌-One-Line-Summary" class="headerlink" title="📌 One-Line Summary"></a>📌 One-Line Summary</h3><p>A live dashboard that tracks <strong>Bitcoin (BTC)</strong> and <strong>Ethereum (ETH)</strong> prices in real time, predicts short-term trends, and displays everything visually.<br>Built entirely with <strong>open-source tools</strong> on AWS.</p><hr><h2 id="1️⃣-How-It-Works"><a href="#1️⃣-How-It-Works" class="headerlink" title="1️⃣ How It Works"></a>1️⃣ How It Works</h2><p><strong>Data Flow:</strong><br>Live Prices → Kafka (data streaming) → PostgreSQL (storage) → Grafana (dashboard)</p><hr><h3 id="1-Live-Price-Collection"><a href="#1-Live-Price-Collection" class="headerlink" title="1. Live Price Collection"></a><strong>1. Live Price Collection</strong></h3><ul><li>Uses the <strong>CryptoCompare API</strong> to fetch BTC and ETH prices</li><li>Updates every <strong>5 seconds</strong></li><li>Includes both current market prices and short-term history</li></ul><hr><h3 id="2-Real-Time-Streaming"><a href="#2-Real-Time-Streaming" class="headerlink" title="2. Real-Time Streaming"></a><strong>2. Real-Time Streaming</strong></h3><ul><li><strong>Apache Kafka</strong> moves live data instantly from the producer (data collector) to the consumer (data inserter)</li><li>Ensures zero delays between data collection and dashboard updates</li></ul><hr><h3 id="3-Database-Storage"><a href="#3-Database-Storage" class="headerlink" title="3. Database Storage"></a><strong>3. Database Storage</strong></h3><ul><li><strong>PostgreSQL</strong> stores:<ul><li>Current prices</li><li>Predicted prices (using a Simple Moving Average)</li></ul></li><li>Keeps historical records for trend analysis</li></ul><hr><h3 id="4-AI-Style-Predictions"><a href="#4-AI-Style-Predictions" class="headerlink" title="4. AI-Style Predictions"></a><strong>4. AI-Style Predictions</strong></h3><ul><li>A <strong>Simple Moving Average (SMA)</strong> model predicts prices 5 minutes ahead</li><li>Predictions are stored alongside actual prices for comparison</li></ul><hr><h3 id="5-Visual-Dashboard"><a href="#5-Visual-Dashboard" class="headerlink" title="5. Visual Dashboard"></a><strong>5. Visual Dashboard</strong></h3><ul><li><strong>Grafana</strong> shows:<ul><li>Real-time price charts</li><li>Overlay of predicted vs. actual prices</li><li>24-hour high&#x2F;low values</li><li>24-hour % change bar charts</li></ul></li></ul><hr><h2 id="🛠-Technologies-Used"><a href="#🛠-Technologies-Used" class="headerlink" title="🛠 Technologies Used"></a>🛠 Technologies Used</h2><table><thead><tr><th>Step</th><th>Technology</th></tr></thead><tbody><tr><td>Data Source</td><td>CryptoCompare API</td></tr><tr><td>Streaming</td><td>Apache Kafka</td></tr><tr><td>Storage</td><td>PostgreSQL</td></tr><tr><td>Prediction</td><td>Python (SMA)</td></tr><tr><td>Visualization</td><td>Grafana</td></tr><tr><td>Environment</td><td>AWS EC2 (Ubuntu 22.04)</td></tr></tbody></table><hr><h2 id="💡-Key-Benefits"><a href="#💡-Key-Benefits" class="headerlink" title="💡 Key Benefits"></a>💡 Key Benefits</h2><ul><li>Watch BTC &amp; ETH prices update instantly</li><li>Compare AI-predicted vs. actual prices in real time</li><li>Access from anywhere via AWS-hosted Grafana</li><li>Fully open-source — no paid tools required</li></ul><hr><h2 id="🔗-GitHub-Repository"><a href="#🔗-GitHub-Repository" class="headerlink" title="🔗 GitHub Repository"></a>🔗 GitHub Repository</h2><p>📂 <a href="https://github.com/kish191919/Crypto">View Project on GitHub</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;💹-Real-Time-Crypto-Dashboard&quot;&gt;&lt;a href=&quot;#💹-Real-Time-Crypto-Dashboard&quot; class=&quot;headerlink&quot; title=&quot;💹 Real-Time Crypto Dashboard&quot;&gt;&lt;/a</summary>
      
    
    
    
    <category term="Showcase" scheme="https://kish191919.github.io/categories/Showcase/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="Python" scheme="https://kish191919.github.io/tags/Python/"/>
    
    <category term="Kafka" scheme="https://kish191919.github.io/tags/Kafka/"/>
    
    <category term="PostgreSQL" scheme="https://kish191919.github.io/tags/PostgreSQL/"/>
    
    <category term="Grafana" scheme="https://kish191919.github.io/tags/Grafana/"/>
    
  </entry>
  
  <entry>
    <title>Used Car Price Prediction</title>
    <link href="https://kish191919.github.io/2025/07/24/Used-Car-Price-Prediction-in-Virginia/"/>
    <id>https://kish191919.github.io/2025/07/24/Used-Car-Price-Prediction-in-Virginia/</id>
    <published>2025-07-24T23:31:06.000Z</published>
    <updated>2025-08-12T20:19:34.694Z</updated>
    
    <content type="html"><![CDATA[<h2 id="🚗-Used-Car-Price-Prediction-in-Virginia"><a href="#🚗-Used-Car-Price-Prediction-in-Virginia" class="headerlink" title="🚗 Used Car Price Prediction in Virginia"></a>🚗 Used Car Price Prediction in Virginia</h2><p><em>Predicting the price of used cars with AI and data analysis</em>  </p><blockquote><p>“Don’t guess the price — let the data tell you.”</p></blockquote><p>📎 <strong>Full Analysis</strong>:<br><a href="https://nbviewer.org/github/yesmanki81/Portfolio_Projects/blob/master/Predict_Used_Car_Price_by_Python/Data_analysis_and_machine_learning_model.ipynb">👉 View Jupyter Notebook on GitHub</a></p><p align="center">  <img src="/images/portfolio/project1_1.png" alt="Web App" width="60%"></p><hr><h3 id="📌-One-Line-Summary"><a href="#📌-One-Line-Summary" class="headerlink" title="📌 One-Line Summary"></a>📌 One-Line Summary</h3><p>This project predicts the prices of used cars in <strong>Virginia</strong> using a dataset of over <strong>46,000 listings</strong>.<br>By analyzing details like <strong>year, mileage, brand, and fuel type</strong>, the AI model can estimate a realistic market price.</p><hr><h2 id="1️⃣-How-It-Was-Built"><a href="#1️⃣-How-It-Was-Built" class="headerlink" title="1️⃣ How It Was Built"></a>1️⃣ How It Was Built</h2><h3 id="1-Data-Collection"><a href="#1-Data-Collection" class="headerlink" title="1. Data Collection"></a><strong>1. Data Collection</strong></h3><ul><li>Collected real car sales data from the web</li><li>Stored in an <strong>AWS cloud MySQL database</strong></li><li>Accessed using <strong>Python</strong> and shared via <strong>Flask API</strong></li></ul><hr><h3 id="2-Data-Preparation"><a href="#2-Data-Preparation" class="headerlink" title="2. Data Preparation"></a><strong>2. Data Preparation</strong></h3><ul><li>Filled missing values (e.g., unknown mileage)</li><li>Removed unrealistic values (e.g., mileage over 1 million km)</li><li>Converted text data (brand, fuel type) into numbers</li><li>Applied <strong>log transformation</strong> to balance skewed data</li></ul><hr><h3 id="3-Data-Analysis-EDA"><a href="#3-Data-Analysis-EDA" class="headerlink" title="3. Data Analysis (EDA)"></a><strong>3. Data Analysis (EDA)</strong></h3><ul><li>Visualized the relationship between price and year&#x2F;mileage</li><li>Found <strong>year</strong> and <strong>mileage</strong> to be the most influential features</li></ul><hr><h3 id="4-AI-Model-Training"><a href="#4-AI-Model-Training" class="headerlink" title="4. AI Model Training"></a><strong>4. AI Model Training</strong></h3><p>Tested several machine learning models:</p><ul><li><strong>Linear Regression</strong></li><li><strong>Decision Tree</strong></li><li><strong>Random Forest</strong></li><li><strong>Support Vector Regression (SVR)</strong></li><li><strong>XGBoost</strong> (winner)</li></ul><p>📊 <strong>Best Model</strong>: <strong>XGBoost</strong></p><ul><li>Accuracy (R²): <strong>0.89</strong></li><li>Average Error (RMSE): <strong>$5,474</strong></li></ul><hr><h3 id="5-Results"><a href="#5-Results" class="headerlink" title="5. Results"></a><strong>5. Results</strong></h3><table><thead><tr><th>Model</th><th>R² Score</th><th>RMSE</th></tr></thead><tbody><tr><td>Linear Regression</td><td>0.58</td><td>14,085</td></tr><tr><td>Decision Tree</td><td>0.73</td><td>9,022</td></tr><tr><td>Random Forest</td><td>0.84</td><td>7,021</td></tr><tr><td>SVR</td><td>0.11</td><td>14,328</td></tr><tr><td><strong>XGBoost</strong></td><td><strong>0.89</strong></td><td><strong>5,474</strong></td></tr></tbody></table><hr><h3 id="6-Real-World-Test"><a href="#6-Real-World-Test" class="headerlink" title="6. Real-World Test"></a><strong>6. Real-World Test</strong></h3><ul><li><strong>2016 Honda Odyssey</strong> → Predicted price: <strong>$18,738</strong><br>Matched closely with actual market data.</li></ul><hr><h2 id="2️⃣-Real-World-Use"><a href="#2️⃣-Real-World-Use" class="headerlink" title="2️⃣ Real-World Use"></a>2️⃣ Real-World Use</h2><ul><li>Final model saved as a <strong>Pickle</strong> file</li><li>Deployed via <strong>Flask API</strong> for real-time predictions</li><li>Created a simplified version (Year, Mileage, Brand, Model) for web app integration</li></ul><hr><h2 id="🛠-Technologies-Used"><a href="#🛠-Technologies-Used" class="headerlink" title="🛠 Technologies Used"></a>🛠 Technologies Used</h2><table><thead><tr><th>Step</th><th>Technology</th></tr></thead><tbody><tr><td>Data Storage</td><td>AWS MySQL</td></tr><tr><td>Model Dev</td><td>Python, scikit-learn, XGBoost</td></tr><tr><td>Deployment</td><td>Flask API, Pickle</td></tr><tr><td>Environment</td><td>AWS EC2 (Ubuntu)</td></tr></tbody></table><hr><h2 id="💡-Key-Learnings"><a href="#💡-Key-Learnings" class="headerlink" title="💡 Key Learnings"></a>💡 Key Learnings</h2><ul><li>Log transformation improves accuracy for skewed data</li><li>Tree-based models handle mixed data types effectively</li><li>Even with only 4 features, accurate real-time predictions are possible</li></ul><hr><h2 id="🔗-GitHub-Repository"><a href="#🔗-GitHub-Repository" class="headerlink" title="🔗 GitHub Repository"></a>🔗 GitHub Repository</h2><p>📂 <a href="https://github.com/kish191919/Predict_Used_Car_Price_by_Python">View Project on GitHub</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;🚗-Used-Car-Price-Prediction-in-Virginia&quot;&gt;&lt;a href=&quot;#🚗-Used-Car-Price-Prediction-in-Virginia&quot; class=&quot;headerlink&quot; title=&quot;🚗 Used Car </summary>
      
    
    
    
    <category term="Showcase" scheme="https://kish191919.github.io/categories/Showcase/"/>
    
    
    <category term="Python" scheme="https://kish191919.github.io/tags/Python/"/>
    
    <category term="Machine Learning" scheme="https://kish191919.github.io/tags/Machine-Learning/"/>
    
    <category term="XGBoost" scheme="https://kish191919.github.io/tags/XGBoost/"/>
    
  </entry>
  
  <entry>
    <title>[Algorithm] Quick Sort — Divide and Conquer!</title>
    <link href="https://kish191919.github.io/2025/07/24/Algorithm-Quick-Sort/"/>
    <id>https://kish191919.github.io/2025/07/24/Algorithm-Quick-Sort/</id>
    <published>2025-07-24T21:34:19.000Z</published>
    <updated>2025-08-12T01:55:33.710Z</updated>
    
    <content type="html"><![CDATA[<h1 id="⚡-Quick-Sort-Divide-and-Conquer"><a href="#⚡-Quick-Sort-Divide-and-Conquer" class="headerlink" title="⚡ Quick Sort: Divide and Conquer!"></a>⚡ Quick Sort: Divide and Conquer!</h1><blockquote><p>“Divide each difficulty into as many parts as is feasible and necessary to resolve it.”<br>— <em>René Descartes</em></p></blockquote><p align="center">  <img src="/images/Quick_Sort.png" alt="René Descartes" width="60%"></p><p>In life, as in sorting algorithms, you don’t have to solve a complex problem all at once.<br>Break it down into smaller pieces, and it becomes much easier to handle.<br><strong>Quick Sort</strong> is an algorithm built exactly on that philosophy.</p><p>Imagine organizing your bookshelf.<br>You pick one book in the middle as a reference point —<br>thinner books go to the left, thicker books to the right.<br>Then, you repeat the same process for each group until the shelf is neatly organized.<br>That’s essentially how Quick Sort works!</p><hr><h2 id="🧠-How-Quick-Sort-Works"><a href="#🧠-How-Quick-Sort-Works" class="headerlink" title="🧠 How Quick Sort Works"></a>🧠 How Quick Sort Works</h2><ol><li>Choose a pivot element from the array.</li><li>Place elements smaller than the pivot to the left, and elements greater than the pivot to the right.</li><li>Recursively apply the same process to both the left and right groups.</li></ol><video width="100%" autoplay muted playsinline loop>  <source src="/videos/Quick_Sort_demo.mp4" type="video/mp4">  Your browser does not support the video tag.</video><hr><h2 id="🧪-Python-Example"><a href="#🧪-Python-Example" class="headerlink" title="🧪 Python Example"></a>🧪 Python Example</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">quick_sort</span>(<span class="params">arr</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(arr) &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> arr</span><br><span class="line">    pivot = arr[<span class="built_in">len</span>(arr) // <span class="number">2</span>]</span><br><span class="line">    left = [x <span class="keyword">for</span> x <span class="keyword">in</span> arr <span class="keyword">if</span> x &lt; pivot]</span><br><span class="line">    middle = [x <span class="keyword">for</span> x <span class="keyword">in</span> arr <span class="keyword">if</span> x == pivot]</span><br><span class="line">    right = [x <span class="keyword">for</span> x <span class="keyword">in</span> arr <span class="keyword">if</span> x &gt; pivot]</span><br><span class="line">    <span class="keyword">return</span> quick_sort(left) + middle + quick_sort(right)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Example usage</span></span><br><span class="line">numbers = [<span class="number">10</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">7</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">9</span>]</span><br><span class="line">sorted_numbers = quick_sort(numbers)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Sorted result:&quot;</span>, sorted_numbers)</span><br></pre></td></tr></table></figure><hr><h2 id="🎯-Wrapping-Up"><a href="#🎯-Wrapping-Up" class="headerlink" title="🎯 Wrapping Up"></a>🎯 Wrapping Up</h2><p>Quick Sort teaches us that <strong>even the biggest problems can be solved beautifully</strong> -<br>if you break them down and tackle them step-by-step.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;⚡-Quick-Sort-Divide-and-Conquer&quot;&gt;&lt;a href=&quot;#⚡-Quick-Sort-Divide-and-Conquer&quot; class=&quot;headerlink&quot; title=&quot;⚡ Quick Sort: Divide and Conqu</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="Algorithm" scheme="https://kish191919.github.io/categories/Dev/Algorithm/"/>
    
    
    <category term="Sorting" scheme="https://kish191919.github.io/tags/Sorting/"/>
    
    <category term="Python" scheme="https://kish191919.github.io/tags/Python/"/>
    
    <category term="Quick Sort" scheme="https://kish191919.github.io/tags/Quick-Sort/"/>
    
  </entry>
  
  <entry>
    <title>[Algorithm] Insertion Sort — Quiet but Steady Growth</title>
    <link href="https://kish191919.github.io/2025/07/22/Algorithm-Insert-Sort/"/>
    <id>https://kish191919.github.io/2025/07/22/Algorithm-Insert-Sort/</id>
    <published>2025-07-22T15:46:26.000Z</published>
    <updated>2025-08-12T01:52:56.420Z</updated>
    
    <content type="html"><![CDATA[<h2 id="🧩-What’s-the-Big-Deal-About-Insertion-Sort"><a href="#🧩-What’s-the-Big-Deal-About-Insertion-Sort" class="headerlink" title="🧩 What’s the Big Deal About Insertion Sort?"></a>🧩 What’s the Big Deal About Insertion Sort?</h2><blockquote><p><strong>“It does not matter how slowly you go as long as you do not stop.” – Confucius</strong></p></blockquote><p align="center">  <img src="/images/insert-sort.png" alt="Confucius" width="60%"></p><p>In life, there are those who don’t seek the spotlight but <strong>quietly find their own place</strong>.<br>In the world of algorithms, there’s a counterpart to such people — <strong>Insertion Sort</strong>.</p><p>As its name suggests, Insertion Sort works by <strong>inserting</strong> each new element<br>into the correct position within an already <strong>sorted portion</strong> of the list.</p><p>It doesn’t sort everything in one flashy move,<br>but instead, compares and shifts elements until each number <strong>finds its rightful place</strong>.</p><p>The process is a lot like <strong>students quietly finding their seats in class</strong>,<br>or <strong>a job seeker moving step-by-step toward their goal</strong> —<br><strong>quiet, but certain progress</strong>.</p><hr><h2 id="📚-How-Does-It-Work"><a href="#📚-How-Does-It-Work" class="headerlink" title="📚 How Does It Work?"></a>📚 How Does It Work?</h2><p>Insertion Sort works like this:</p><ol><li>Assume the first element is already sorted.  </li><li>Starting from the second element, <strong>compare it with the sorted elements on the left</strong>.  </li><li>If there are larger elements, <strong>shift them one position to the right</strong>,<br>then <strong>insert the current element into the empty spot</strong>.  </li><li>Repeat this process until the end of the list.</li></ol><video width="100%" autoplay muted playsinline loop>  <source src="/videos/insert-sort-demo.mp4" type="video/mp4">  Your browser does not support the video tag.</video><blockquote><p>This algorithm seems to say:<br><strong>“I’ll find my place — it may just take a little time.”</strong></p></blockquote><hr><h2 id="🧪-Insertion-Sort-in-Python"><a href="#🧪-Insertion-Sort-in-Python" class="headerlink" title="🧪 Insertion Sort in Python"></a>🧪 Insertion Sort in Python</h2><p>Let’s implement it step-by-step:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">insertion_sort</span>(<span class="params">arr</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(arr)):</span><br><span class="line">        key = arr[i]</span><br><span class="line">        j = i - <span class="number">1</span></span><br><span class="line">        <span class="comment"># Shift elements greater than key one position to the right</span></span><br><span class="line">        <span class="keyword">while</span> j &gt;= <span class="number">0</span> <span class="keyword">and</span> arr[j] &gt; key:</span><br><span class="line">            arr[j + <span class="number">1</span>] = arr[j]</span><br><span class="line">            j -= <span class="number">1</span></span><br><span class="line">        arr[j + <span class="number">1</span>] = key</span><br><span class="line">    <span class="keyword">return</span> arr</span><br><span class="line"></span><br><span class="line"><span class="comment"># Test</span></span><br><span class="line"><span class="built_in">print</span>(insertion_sort([<span class="number">9</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>]))</span><br></pre></td></tr></table></figure><hr><h2 id="🎯-Wrapping-Up"><a href="#🎯-Wrapping-Up" class="headerlink" title="🎯 Wrapping Up"></a>🎯 Wrapping Up</h2><p>While Insertion Sort can be inefficient for large datasets,<br><strong>it’s very efficient for data that is already nearly sorted.</strong></p><p>More than just a sorting method,<br>it resonates with those who value direction and persistence over instant results.</p><blockquote><p>“It’s okay not to be fast.<br>Finding your place step-by-step — that’s the real sorting.” 😊</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;🧩-What’s-the-Big-Deal-About-Insertion-Sort&quot;&gt;&lt;a href=&quot;#🧩-What’s-the-Big-Deal-About-Insertion-Sort&quot; class=&quot;headerlink&quot; title=&quot;🧩 Wha</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="Algorithm" scheme="https://kish191919.github.io/categories/Dev/Algorithm/"/>
    
    
    <category term="Sorting" scheme="https://kish191919.github.io/tags/Sorting/"/>
    
    <category term="Python" scheme="https://kish191919.github.io/tags/Python/"/>
    
    <category term="Insertion Sort" scheme="https://kish191919.github.io/tags/Insertion-Sort/"/>
    
  </entry>
  
  <entry>
    <title>[Algorithm] Dynamic Programming — Trusting Your Past Self</title>
    <link href="https://kish191919.github.io/2025/07/22/Algorithm-Dynamic-Programming/"/>
    <id>https://kish191919.github.io/2025/07/22/Algorithm-Dynamic-Programming/</id>
    <published>2025-07-22T12:13:38.000Z</published>
    <updated>2025-08-11T21:12:06.608Z</updated>
    
    <content type="html"><![CDATA[<h2 id="🔁-What’s-the-Big-Deal-About-Dynamic-Programming"><a href="#🔁-What’s-the-Big-Deal-About-Dynamic-Programming" class="headerlink" title="🔁 What’s the Big Deal About Dynamic Programming?"></a>🔁 What’s the Big Deal About Dynamic Programming?</h2><blockquote><p><strong>“Memory is the treasury and guardian of all things.” – William Shakespeare</strong></p></blockquote><p align="center">  <img src="/images/dp.png" alt="William Shakespeare" width="60%"></p><p>In life, there are moments when we need to <strong>remember and refer to past experiences</strong><br>to avoid making the same mistakes again.  </p><p>Whether in studying, exercising, or love—<br><strong>the ability to remember and use what we’ve learned</strong> shapes our future.  </p><p>There’s an algorithm in programming that reflects this very philosophy:<br><strong>Dynamic Programming (DP)</strong>.</p><hr><h2 id="🧠-The-Philosophy-Behind-It"><a href="#🧠-The-Philosophy-Behind-It" class="headerlink" title="🧠 The Philosophy Behind It"></a>🧠 The Philosophy Behind It</h2><p>Dynamic Programming is a strategy for solving large problems<br>by <strong>breaking them down into smaller subproblems</strong><br>and <strong>remembering the results</strong> of those subproblems.</p><p>Once a problem has been solved,<br>we <strong>reuse the stored result instead of recalculating it</strong>,<br>saving both <strong>time and resources</strong>.</p><blockquote><p>“If my past self worked hard to find an answer,<br>my future self can trust it and keep moving forward.”<br>That’s the essence of Dynamic Programming.</p></blockquote><hr><h2 id="📚-How-It-Works"><a href="#📚-How-It-Works" class="headerlink" title="📚 How It Works"></a>📚 How It Works</h2><p>Dynamic Programming is typically implemented in two main approaches:</p><ul><li><p><strong>Top-Down (Memoization)</strong><br>Break the big problem down recursively,<br>but <strong>remember solutions to subproblems</strong> so they aren’t solved again.</p></li><li><p><strong>Bottom-Up (Tabulation)</strong><br>Start from the smallest problems,<br><strong>store solutions in a table</strong>,<br>and build up to the final solution step-by-step.</p></li></ul><video width="100%" autoplay muted playsinline loop>  <source src="/videos/dp-demo.mp4" type="video/mp4">  Your browser does not support the video tag.</video><hr><h2 id="💡-Example-–-Fibonacci-Sequence"><a href="#💡-Example-–-Fibonacci-Sequence" class="headerlink" title="💡 Example – Fibonacci Sequence"></a>💡 Example – Fibonacci Sequence</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Top-Down approach (Recursion + Memoization)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fib_memo</span>(<span class="params">n, memo=&#123;&#125;</span>):</span><br><span class="line">    <span class="keyword">if</span> n &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> n</span><br><span class="line">    <span class="keyword">if</span> n <span class="keyword">in</span> memo:</span><br><span class="line">        <span class="keyword">return</span> memo[n]</span><br><span class="line">    memo[n] = fib_memo(n-<span class="number">1</span>, memo) + fib_memo(n-<span class="number">2</span>, memo)</span><br><span class="line">    <span class="keyword">return</span> memo[n]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(fib_memo(<span class="number">10</span>))  <span class="comment"># Output: 55</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Bottom-Up approach (Iteration + Tabulation)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fib_tab</span>(<span class="params">n</span>):</span><br><span class="line">    <span class="keyword">if</span> n &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> n</span><br><span class="line">    dp = [<span class="number">0</span>] * (n+<span class="number">1</span>)</span><br><span class="line">    dp[<span class="number">1</span>] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, n+<span class="number">1</span>):</span><br><span class="line">        dp[i] = dp[i-<span class="number">1</span>] + dp[i-<span class="number">2</span>]</span><br><span class="line">    <span class="keyword">return</span> dp[n]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(fib_tab(<span class="number">10</span>))  <span class="comment"># Output: 55</span></span><br></pre></td></tr></table></figure><hr><h2 id="🎯-Wrapping-Up"><a href="#🎯-Wrapping-Up" class="headerlink" title="🎯 Wrapping Up"></a>🎯 Wrapping Up</h2><p>Dynamic Programming is more than just an optimization technique—<br>it teaches us <strong>“how to trust what we already know and reuse it.”</strong></p><p>This algorithm seems to say:</p><blockquote><p>“Don’t try to do everything from scratch.<br>Remember what you’ve already solved,<br>trust that knowledge, and keep moving forward.”</p></blockquote><p>Life works the same way:<br>reducing repeated mistakes,<br>using past lessons to guide future choices—<br>that’s living with a Dynamic Programming mindset 😊</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;🔁-What’s-the-Big-Deal-About-Dynamic-Programming&quot;&gt;&lt;a href=&quot;#🔁-What’s-the-Big-Deal-About-Dynamic-Programming&quot; class=&quot;headerlink&quot; tit</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="Algorithm" scheme="https://kish191919.github.io/categories/Dev/Algorithm/"/>
    
    
    <category term="Python" scheme="https://kish191919.github.io/tags/Python/"/>
    
    <category term="Dynamic Programming" scheme="https://kish191919.github.io/tags/Dynamic-Programming/"/>
    
    <category term="DP" scheme="https://kish191919.github.io/tags/DP/"/>
    
  </entry>
  
  <entry>
    <title>[Algorithm] Selection Sort — The Power of Choosing</title>
    <link href="https://kish191919.github.io/2025/07/22/Algorithm-Selection-Sort/"/>
    <id>https://kish191919.github.io/2025/07/22/Algorithm-Selection-Sort/</id>
    <published>2025-07-22T11:50:00.000Z</published>
    <updated>2025-08-12T01:57:17.134Z</updated>
    
    <content type="html"><![CDATA[<h2 id="🔍-What’s-the-Big-Deal-About-Selection-Sort"><a href="#🔍-What’s-the-Big-Deal-About-Selection-Sort" class="headerlink" title="🔍 What’s the Big Deal About Selection Sort?"></a>🔍 What’s the Big Deal About Selection Sort?</h2><blockquote><p><strong>“Destiny is not a matter of chance, it is a matter of choice.” – William Jennings Bryan</strong></p></blockquote><p align="center">  <img src="/images/selection-sort.png" alt="William Jennings Bryan" width="60%"></p><p>In life, we constantly face <strong>moments of choice</strong>.<br>Who will you walk with? What will you do first?<br>Ultimately, these choices <strong>shape the course of your life</strong>.</p><p>In programming, there’s an algorithm that embodies this same idea —<br><strong>Selection Sort</strong>.</p><p>Selection Sort repeatedly <strong>finds the smallest value in the list</strong>,<br>and <strong>moves it to the front</strong>, step by step, until the entire list is sorted.</p><p>It’s a lot like <strong>setting priorities in life</strong>:<br>finding the most important task right now, and acting on it.<br>That’s the philosophy of Selection Sort.</p><hr><h2 id="📚-How-It-Works"><a href="#📚-How-It-Works" class="headerlink" title="📚 How It Works"></a>📚 How It Works</h2><p>Selection Sort works as follows:</p><ol><li><strong>Find the smallest value</strong> in the list and move it to the first position.  </li><li>From the remaining list, find the smallest value again<br>and move it to the second position.  </li><li>Repeat until the list is fully sorted.</li></ol><video width="100%" autoplay muted playsinline loop>  <source src="/videos/selection-sort-demo.mp4" type="video/mp4">  Your browser does not support the video tag.</video><blockquote><p>This algorithm seems to say:<br><strong>“Choose what matters most right now.”</strong></p></blockquote><hr><h2 id="💻-Selection-Sort-in-Python"><a href="#💻-Selection-Sort-in-Python" class="headerlink" title="💻 Selection Sort in Python"></a>💻 Selection Sort in Python</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">selection_sort</span>(<span class="params">arr</span>):</span><br><span class="line">    n = <span class="built_in">len</span>(arr)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="comment"># Find the index of the minimum value</span></span><br><span class="line">        min_idx = i</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>, n):</span><br><span class="line">            <span class="keyword">if</span> arr[j] &lt; arr[min_idx]:</span><br><span class="line">                min_idx = j</span><br><span class="line">        <span class="comment"># Swap the current element with the minimum</span></span><br><span class="line">        arr[i], arr[min_idx] = arr[min_idx], arr[i]</span><br><span class="line">    <span class="keyword">return</span> arr</span><br><span class="line"></span><br><span class="line"><span class="comment"># Test</span></span><br><span class="line"><span class="built_in">print</span>(selection_sort([<span class="number">29</span>, <span class="number">10</span>, <span class="number">14</span>, <span class="number">37</span>, <span class="number">13</span>]))</span><br></pre></td></tr></table></figure><hr><h2 id="🎯-Wrapping-Up"><a href="#🎯-Wrapping-Up" class="headerlink" title="🎯 Wrapping Up"></a>🎯 Wrapping Up</h2><p>Selection Sort is simple yet follows a clear principle:<br><strong>always choose the smallest at each step and act accordingly.</strong></p><p>While it may not be the fastest algorithm,<br>it teaches us the importance of setting priorities.</p><blockquote><p>“The more complex life gets, the more important it is to choose what matters first.”<br>Selection Sort reminds us to sort life in the same way. 😊</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;🔍-What’s-the-Big-Deal-About-Selection-Sort&quot;&gt;&lt;a href=&quot;#🔍-What’s-the-Big-Deal-About-Selection-Sort&quot; class=&quot;headerlink&quot; title=&quot;🔍 Wha</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="Algorithm" scheme="https://kish191919.github.io/categories/Dev/Algorithm/"/>
    
    
    <category term="Sorting" scheme="https://kish191919.github.io/tags/Sorting/"/>
    
    <category term="Python" scheme="https://kish191919.github.io/tags/Python/"/>
    
    <category term="Selection Sort" scheme="https://kish191919.github.io/tags/Selection-Sort/"/>
    
  </entry>
  
  <entry>
    <title>[Algorithm] Bubble Sort — Can Life Be Sorted Too?</title>
    <link href="https://kish191919.github.io/2025/07/21/Algorithm-Bubble-Sort/"/>
    <id>https://kish191919.github.io/2025/07/21/Algorithm-Bubble-Sort/</id>
    <published>2025-07-21T04:31:35.000Z</published>
    <updated>2025-08-11T21:06:43.916Z</updated>
    
    <content type="html"><![CDATA[<h2 id="🫧-What’s-the-Big-Deal-About-Bubble-Sort"><a href="#🫧-What’s-the-Big-Deal-About-Bubble-Sort" class="headerlink" title="🫧 What’s the Big Deal About Bubble Sort?"></a>🫧 What’s the Big Deal About Bubble Sort?</h2><blockquote><p>“It’s the little differences that make the big difference.” – Napoleon Hill</p></blockquote><p align="center">  <img src="/images/bubble-sort.png" alt="Napoleon Hill" width="60%"></p><p>In the programming world, there are moments when small changes lead to big outcomes—just as Napoleon Hill said.<br>One of the best examples of this is <strong>Bubble Sort</strong>.  </p><p>At first glance, it’s so simple that it’s easy to dismiss. But behind its simplicity lies a surprisingly meaningful lesson.</p><p>Bubble Sort works by scanning a list from start to finish, comparing two neighboring elements, and swapping them if they’re in the wrong order.<br>Once it reaches the end of the list, it starts over, repeating the same process until no swaps are needed.</p><p>This way, the largest elements gradually move to the end of the list—just like bubbles floating to the surface of water.<br>That’s why it’s called “Bubble” Sort!</p><h2 id="👣-Step-by-Step-Through-the-Algorithm"><a href="#👣-Step-by-Step-Through-the-Algorithm" class="headerlink" title="👣 Step by Step Through the Algorithm"></a>👣 Step by Step Through the Algorithm</h2><p>Understanding Bubble Sort isn’t hard. Think back to when you used to organize your desk drawer as a kid—<br>a big pencil, a small eraser, a medium-sized ruler… Didn’t you naturally arrange them by size?</p><p>Bubble Sort works in almost the exact same way:</p><ol><li><strong>Compare two neighboring values.</strong>  </li><li><strong>If they’re in the wrong order, swap them!</strong>  </li><li>Repeat this until you reach the end of the list. That’s one pass.<br>Keep repeating passes until the list is fully sorted.</li></ol><video width="100%" autoplay muted playsinline loop>  <source src="/videos/bubble-sort-demo.mp4" type="video/mp4">  Your browser does not support the video tag.</video><blockquote><p>Bubble Sort says:<br>“Don’t try to be perfect all at once. Change a little at a time—and keep coming back.”</p></blockquote><h2 id="🧪-Bubble-Sort-in-Python"><a href="#🧪-Bubble-Sort-in-Python" class="headerlink" title="🧪 Bubble Sort in Python"></a>🧪 Bubble Sort in Python</h2><p>Let’s put it into code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">bubble_sort</span>(<span class="params">arr</span>):</span><br><span class="line">    n = <span class="built_in">len</span>(arr)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="comment"># The last i elements are already in place</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, n-i-<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> arr[j] &gt; arr[j+<span class="number">1</span>]:</span><br><span class="line">                <span class="comment"># Swap positions</span></span><br><span class="line">                arr[j], arr[j+<span class="number">1</span>] = arr[j+<span class="number">1</span>], arr[j]</span><br><span class="line">    <span class="keyword">return</span> arr</span><br><span class="line"></span><br><span class="line"><span class="comment"># Test</span></span><br><span class="line"><span class="built_in">print</span>(bubble_sort([<span class="number">64</span>, <span class="number">34</span>, <span class="number">25</span>, <span class="number">12</span>, <span class="number">22</span>, <span class="number">11</span>, <span class="number">90</span>]))</span><br></pre></td></tr></table></figure><p>When you run this, you’ll see the larger numbers move toward the back, and the smaller numbers drift to the front—<br>almost like a story where the most dominant character gradually steps back, allowing peace to take over 😄</p><hr><h2 id="🎯-Wrapping-Up"><a href="#🎯-Wrapping-Up" class="headerlink" title="🎯 Wrapping Up"></a>🎯 Wrapping Up</h2><p>Bubble Sort isn’t the most efficient sorting method,<br>but it’s the perfect beginner-friendly algorithm for understanding the basics of sorting.</p><p>Life is a lot like that, too—sometimes small, consistent changes matter more than one big, perfect move.</p><blockquote><p>“Organizing is choosing—what to keep, and what to change.”<br>Bubble Sort has a way of teaching us that about life 😊</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;🫧-What’s-the-Big-Deal-About-Bubble-Sort&quot;&gt;&lt;a href=&quot;#🫧-What’s-the-Big-Deal-About-Bubble-Sort&quot; class=&quot;headerlink&quot; title=&quot;🫧 What’s th</summary>
      
    
    
    
    <category term="Dev" scheme="https://kish191919.github.io/categories/Dev/"/>
    
    <category term="Algorithm" scheme="https://kish191919.github.io/categories/Dev/Algorithm/"/>
    
    
    <category term="Sorting" scheme="https://kish191919.github.io/tags/Sorting/"/>
    
    <category term="Bubble Sort" scheme="https://kish191919.github.io/tags/Bubble-Sort/"/>
    
    <category term="Python" scheme="https://kish191919.github.io/tags/Python/"/>
    
  </entry>
  
</feed>
