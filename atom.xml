<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Danny&#39;s Blog</title>
  
  <subtitle>Data, AI, and Tech Insight</subtitle>
  <link href="https://kish191919.github.io/atom.xml" rel="self"/>
  
  <link href="https://kish191919.github.io/"/>
  <updated>2025-08-27T02:57:51.733Z</updated>
  <id>https://kish191919.github.io/</id>
  
  <author>
    <name>Danny Ki</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>(í•œêµ­ì–´) AWS Certified AI Practitioner (31) - AWS AI ê´€ë¦¬í˜• ì„œë¹„ìŠ¤</title>
    <link href="https://kish191919.github.io/2025/08/26/KO-AWS-Certified-AI-Practitioner-31/"/>
    <id>https://kish191919.github.io/2025/08/26/KO-AWS-Certified-AI-Practitioner-31/</id>
    <published>2025-08-26T19:37:13.000Z</published>
    <updated>2025-08-27T02:57:51.733Z</updated>
    
    <content type="html"><![CDATA[<h1 id="AWS-AI-ê´€ë¦¬í˜•-ì„œë¹„ìŠ¤-AWS-AI-Managed-Services"><a href="#AWS-AI-ê´€ë¦¬í˜•-ì„œë¹„ìŠ¤-AWS-AI-Managed-Services" class="headerlink" title="AWS AI ê´€ë¦¬í˜• ì„œë¹„ìŠ¤ (AWS AI Managed Services)"></a>AWS AI ê´€ë¦¬í˜• ì„œë¹„ìŠ¤ (AWS AI Managed Services)</h1><h2 id="1-ì™œ-AWS-AI-ê´€ë¦¬í˜•-ì„œë¹„ìŠ¤ì¸ê°€"><a href="#1-ì™œ-AWS-AI-ê´€ë¦¬í˜•-ì„œë¹„ìŠ¤ì¸ê°€" class="headerlink" title="1. ì™œ AWS AI ê´€ë¦¬í˜• ì„œë¹„ìŠ¤ì¸ê°€?"></a>1. ì™œ AWS AI ê´€ë¦¬í˜• ì„œë¹„ìŠ¤ì¸ê°€?</h2><ul><li><strong>ì‚¬ì „ í•™ìŠµëœ ML ëª¨ë¸ ì œê³µ</strong> â†’ ë³„ë„ì˜ í›ˆë ¨ í•„ìš” ì—†ìŒ</li><li><strong>ê³ ê°€ìš©ì„± &amp; ë¹ ë¥¸ ì‘ë‹µì„±</strong></li><li><strong>ì¤‘ë³µì„± &amp; ë¦¬ì „ ë°°í¬</strong>: ì—¬ëŸ¬ AZ&#x2F;Region ë°°í¬ë¡œ ì¥ì• ì—ë„ ì•ˆì •ì </li><li><strong>ìµœì í™”ëœ ì„±ëŠ¥</strong>: íŠ¹ìˆ˜ CPU&#x2F;GPU ì‚¬ìš©ìœ¼ë¡œ ë¹„ìš© ì ˆê°</li><li><strong>í† í° ê¸°ë°˜ ê³¼ê¸ˆ</strong>: ì‚¬ìš©í•œ ë§Œí¼ë§Œ ì§€ë¶ˆ (Pay-as-you-go)</li><li><strong>Provisioned Throughput</strong>: ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì›Œí¬ë¡œë“œì— ëŒ€í•´ ì•ˆì •ì  ì„±ëŠ¥ ì œê³µ</li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: AWS AI ì„œë¹„ìŠ¤ëŠ” <strong>Fully Managed, Serverless, Pay-per-use</strong> êµ¬ì¡°ì„</p><p align="center">  <img src="/images/aws_basic_144.png" width="80%"></p> <hr><h1 id="Amazon-Comprehend-ìì—°ì–´-ì²˜ë¦¬-NLP"><a href="#Amazon-Comprehend-ìì—°ì–´-ì²˜ë¦¬-NLP" class="headerlink" title="Amazon Comprehend (ìì—°ì–´ ì²˜ë¦¬, NLP)"></a>Amazon Comprehend (ìì—°ì–´ ì²˜ë¦¬, NLP)</h1><ul><li><strong>ì™„ì „ ê´€ë¦¬í˜•(Serverless) NLP ì„œë¹„ìŠ¤</strong></li><li><strong>ì£¼ìš” ê¸°ëŠ¥</strong>:<ul><li>ì–¸ì–´ ì‹ë³„(Language Detection)</li><li>í‚¤ êµ¬ë¬¸, ì¸ë¬¼, ì¥ì†Œ, ì¡°ì§, ë¸Œëœë“œ, ì´ë²¤íŠ¸ ì¶”ì¶œ</li><li>ê°ì • ë¶„ì„(Sentiment Analysis)</li><li>í’ˆì‚¬ íƒœê¹…(Part-of-Speech)</li><li>í† í”½ ëª¨ë¸ë§(Topic Modeling)</li></ul></li></ul><h3 id="í™œìš©-ì‚¬ë¡€"><a href="#í™œìš©-ì‚¬ë¡€" class="headerlink" title="í™œìš© ì‚¬ë¡€"></a>í™œìš© ì‚¬ë¡€</h3><ul><li>ê³ ê° ì´ë©”ì¼ ë¶„ì„ â†’ ê¸ì •&#x2F;ë¶€ì • ê²½í—˜ ìš”ì¸ íŒŒì•…</li><li>ê¸°ì‚¬&#x2F;ë¬¸ì„œ ìë™ ë¶„ë¥˜</li></ul><hr><h2 id="1-Custom-Classification"><a href="#1-Custom-Classification" class="headerlink" title="1. Custom Classification"></a>1. Custom Classification</h2><ul><li>ì‚¬ìš©ìê°€ ì •ì˜í•œ ì¹´í…Œê³ ë¦¬ë¡œ ë¬¸ì„œ ìë™ ë¶„ë¥˜</li><li>ì˜ˆ: ê³ ê° ì´ë©”ì¼ì„ â€œê²°ì œ&#x2F;ê¸°ìˆ  ì§€ì›&#x2F;ë¶ˆë§Œâ€ìœ¼ë¡œ ë¶„ë¥˜</li><li>ì§€ì› í¬ë§·: Text, PDF, Word, ì´ë¯¸ì§€ ë“±</li><li>ë¶„ì„ ëª¨ë“œ: <strong>ì‹¤ì‹œê°„(Sync)</strong>, <strong>ë¹„ë™ê¸°(Async)</strong></li></ul><p align="center">  <img src="/images/aws_basic_145.png" width="80%"></p> <hr><h2 id="2-Named-Entity-Recognition-NER"><a href="#2-Named-Entity-Recognition-NER" class="headerlink" title="2. Named Entity Recognition (NER)"></a>2. Named Entity Recognition (NER)</h2><ul><li>í…ìŠ¤íŠ¸ì—ì„œ <strong>ì‚¬ëŒ, ì¡°ì§, ì¥ì†Œ, ë‚ ì§œ</strong> ë“± ì¶”ì¶œ</li></ul><p align="center">  <img src="/images/aws_basic_146.png" width="80%"></p> ------------------------------------------------------------------------<h2 id="3-Custom-Entity-Recognition"><a href="#3-Custom-Entity-Recognition" class="headerlink" title="3. Custom Entity Recognition"></a>3. Custom Entity Recognition</h2><ul><li>ë¹„ì¦ˆë‹ˆìŠ¤ ë§ì¶¤ ì—”í„°í‹° ì¶”ì¶œ (ì˜ˆ: ë³´í—˜ë²ˆí˜¸, íŠ¹ì • ì œí’ˆ ì½”ë“œ)</li><li>ì‚¬ìš©ì ë°ì´í„°ë¡œ í›ˆë ¨ â†’ ì‹¤ì‹œê°„&#x2F;ë¹„ë™ê¸° ë¶„ì„ ê°€ëŠ¥</li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>:</p><ul><li>Comprehend &#x3D; <strong>NLP ì„œë¹„ìŠ¤</strong></li><li>í•µì‹¬ ê¸°ëŠ¥: ì–¸ì–´ ì‹ë³„, ê°ì • ë¶„ì„, NER</li><li>ê³ ê¸‰ ê¸°ëŠ¥: <strong>Custom Classification, Custom Entity Recognition</strong></li></ul><p align="center">  <img src="/images/aws_basic_147.png" width="80%"></p> <hr><h1 id="Amazon-Translate-ìë™-ë²ˆì—­"><a href="#Amazon-Translate-ìë™-ë²ˆì—­" class="headerlink" title="Amazon Translate (ìë™ ë²ˆì—­)"></a>Amazon Translate (ìë™ ë²ˆì—­)</h1><ul><li><strong>ì‹ ê²½ë§ ê¸°ë°˜(NMT)</strong> ë²ˆì—­ ì„œë¹„ìŠ¤</li><li>ì›¹&#x2F;ì•± í˜„ì§€í™”(Localization), ëŒ€ê·œëª¨ ë¬¸ì„œ ë²ˆì—­ ì§€ì›</li><li><strong>Custom Terminology</strong>: ë¸Œëœë“œëª…, ë„ë©”ì¸ ìš©ì–´ ë²ˆì—­ ì¼ê´€ì„± ìœ ì§€</li><li><strong>Parallel Data</strong>: ë²ˆì—­ ìŠ¤íƒ€ì¼ ì§€ì • (ê²©ì‹ì²´ vs ë¹„ê²©ì‹ì²´)</li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: TranslateëŠ” <strong>Custom Terminology &amp; Parallel Data</strong> ê¸°ëŠ¥ìœ¼ë¡œ ì°¨ë³„í™”ë¨</p><p align="center">  <img src="/images/aws_basic_148.png" width="80%"></p> ------------------------------------------------------------------------<h1 id="Amazon-Transcribe-ìŒì„±-â†’-í…ìŠ¤íŠ¸"><a href="#Amazon-Transcribe-ìŒì„±-â†’-í…ìŠ¤íŠ¸" class="headerlink" title="Amazon Transcribe (ìŒì„± â†’ í…ìŠ¤íŠ¸)"></a>Amazon Transcribe (ìŒì„± â†’ í…ìŠ¤íŠ¸)</h1><ul><li><strong>ìë™ ìŒì„± ì¸ì‹(ASR)</strong> ê¸°ë°˜</li><li>ìŒì„±ì„ ë¹ ë¥´ê³  ì •í™•í•˜ê²Œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜</li><li><strong>PII Redaction</strong>: ê°œì¸ì •ë³´ ìë™ ì œê±°</li><li><strong>ìë™ ì–¸ì–´ ê°ì§€</strong>: ë‹¤êµ­ì–´ ì˜¤ë””ì˜¤ ì§€ì›</li></ul><h3 id="í™œìš©-ì‚¬ë¡€-1"><a href="#í™œìš©-ì‚¬ë¡€-1" class="headerlink" title="í™œìš© ì‚¬ë¡€"></a>í™œìš© ì‚¬ë¡€</h3><ul><li>ê³ ê°ì„¼í„° í†µí™” ê¸°ë¡ ìë™ ë³€í™˜</li><li>ìë§‰&#x2F;ìº¡ì…˜ ìë™ ìƒì„±</li><li>ë¯¸ë””ì–´ ê²€ìƒ‰ìš© ë©”íƒ€ë°ì´í„° ìƒì„±</li></ul><p align="center">  <img src="/images/aws_basic_149.png" width="80%"></p> ------------------------------------------------------------------------<h2 id="1-Accuracy-í–¥ìƒ-ê¸°ëŠ¥"><a href="#1-Accuracy-í–¥ìƒ-ê¸°ëŠ¥" class="headerlink" title="1. Accuracy í–¥ìƒ ê¸°ëŠ¥"></a>1. Accuracy í–¥ìƒ ê¸°ëŠ¥</h2><ul><li><strong>Custom Vocabularies (ë‹¨ì–´ ë‹¨ìœ„)</strong><ul><li>ë¸Œëœë“œëª…, ì „ë¬¸ ìš©ì–´, ì•½ì–´ ì¸ì‹ë¥  í–¥ìƒ</li></ul></li><li><strong>Custom Language Models (ë¬¸ë§¥ ë‹¨ìœ„)</strong><ul><li>ë„ë©”ì¸ í…ìŠ¤íŠ¸ í•™ìŠµ â†’ ì •í™•ë„ í–¥ìƒ</li></ul></li><li>ë‘ ê¸°ëŠ¥ì„ í•¨ê»˜ ì‚¬ìš© â†’ ìµœê³  ì •í™•ë„ ì œê³µ</li></ul><p align="center">  <img src="/images/aws_basic_151.png" width="80%"></p> <hr><h2 id="2-Toxicity-Detection"><a href="#2-Toxicity-Detection" class="headerlink" title="2. Toxicity Detection"></a>2. Toxicity Detection</h2><ul><li>ìŒì„±ê³¼ í…ìŠ¤íŠ¸ ë¶„ì„ â†’ <strong>í˜ì˜¤ ë°œì–¸, ìš•ì„¤, ì„±í¬ë¡±, í˜‘ë°• ë“± íƒì§€</strong></li><li>ì¹´í…Œê³ ë¦¬: ì„±ì  ê´´ë¡­í˜, ì¦ì˜¤ ë°œì–¸, ìœ„í˜‘, ìš•ì„¤, ëª¨ìš• ë“±</li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>:</p><ul><li>Transcribe &#x3D; <strong>Speech-to-Text ì„œë¹„ìŠ¤</strong></li><li>ìì£¼ ë‚˜ì˜¤ëŠ” ê¸°ëŠ¥: <strong>PII Redaction, Custom Vocabulary, Toxicity Detection</strong></li></ul><p align="center">  <img src="/images/aws_basic_150.png" width="80%"></p> ------------------------------------------------------------------------<h1 id="ì‹œí—˜-ëŒ€ë¹„-í•µì‹¬-ì •ë¦¬"><a href="#ì‹œí—˜-ëŒ€ë¹„-í•µì‹¬-ì •ë¦¬" class="headerlink" title="ì‹œí—˜ ëŒ€ë¹„ í•µì‹¬ ì •ë¦¬"></a>ì‹œí—˜ ëŒ€ë¹„ í•µì‹¬ ì •ë¦¬</h1><ol><li><strong>Comprehend</strong> â†’ NLP (ì–¸ì–´ ì‹ë³„, ê°ì • ë¶„ì„, NER, Custom ê¸°ëŠ¥)</li><li><strong>Translate</strong> â†’ ë²ˆì—­ ì„œë¹„ìŠ¤ (Custom Terminology, Parallel Data)</li><li><strong>Transcribe</strong> â†’ ìŒì„± ì¸ì‹ (PII Redaction, Custom Vocabulary,<br>Toxicity Detection)</li><li>ê³µí†µ íŠ¹ì§•: <strong>Fully Managed, Serverless, Pay-as-you-go</strong></li><li><strong>ì‹œí—˜ì—ì„œ ê°•ì¡°ë˜ëŠ” í¬ì¸íŠ¸</strong>:<ul><li>Comprehend: NLP ì„œë¹„ìŠ¤, Custom ê¸°ëŠ¥</li><li>Translate: Terminology &amp; Parallel Data</li><li>Transcribe: PII Redaction, Custom Language Model, Toxicity<br>Detection</li></ul></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;AWS-AI-ê´€ë¦¬í˜•-ì„œë¹„ìŠ¤-AWS-AI-Managed-Services&quot;&gt;&lt;a href=&quot;#AWS-AI-ê´€ë¦¬í˜•-ì„œë¹„ìŠ¤-AWS-AI-Managed-Services&quot; class=&quot;headerlink&quot; title=&quot;AWS AI ê´€ë¦¬í˜• ì„œë¹„ìŠ¤ (</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(31) - AWS AI Managed Services</title>
    <link href="https://kish191919.github.io/2025/08/26/AWS-Certified-AI-Practitioner-31/"/>
    <id>https://kish191919.github.io/2025/08/26/AWS-Certified-AI-Practitioner-31/</id>
    <published>2025-08-26T19:37:08.000Z</published>
    <updated>2025-08-26T19:47:39.483Z</updated>
    
    <content type="html"><![CDATA[<h1 id="AWS-AI-Managed-Services"><a href="#AWS-AI-Managed-Services" class="headerlink" title="AWS AI Managed Services"></a>AWS AI Managed Services</h1><h2 id="Why-AWS-AI-Managed-Services"><a href="#Why-AWS-AI-Managed-Services" class="headerlink" title="Why AWS AI Managed Services?"></a>Why AWS AI Managed Services?</h2><p>AWS AI Managed Services provide <strong>pre-trained ML models</strong> designed for specific use cases, without requiring you to build or train models from scratch.</p><h3 id="Key-Benefits"><a href="#Key-Benefits" class="headerlink" title="Key Benefits:"></a>Key Benefits:</h3><ul><li><strong>Responsiveness and Availability</strong>: Always accessible, deployed across multiple Availability Zones and AWS Regions.</li><li><strong>Redundancy and Reliability</strong>: Services remain available even if one AZ experiences downtime.</li><li><strong>Performance</strong>: Use of specialized CPUs and GPUs optimized for ML workloads â†’ cost efficiency.</li><li><strong>Token-based Pricing</strong>: Pay only for what you use (no need to over-provision).</li><li><strong>Provisioned Throughput</strong>: Option for predictable workloads to guarantee performance and optimize costs.</li></ul><p>ğŸ‘‰ <strong>Exam Tip</strong>: AWS will test your understanding that these services are <strong>Fully Managed, Serverless, Pay-as-you-go, and globally scalable</strong>.</p><p align="center">  <img src="/images/aws_basic_144.png" width="80%"></p> <hr><h1 id="Amazon-Comprehend-Natural-Language-Processing-â€“-NLP"><a href="#Amazon-Comprehend-Natural-Language-Processing-â€“-NLP" class="headerlink" title="Amazon Comprehend (Natural Language Processing â€“ NLP)"></a>Amazon Comprehend (Natural Language Processing â€“ NLP)</h1><p>Amazon Comprehend is a <strong>fully managed, serverless NLP service</strong>. It uses ML to extract insights and relationships from text.</p><h3 id="Core-Capabilities"><a href="#Core-Capabilities" class="headerlink" title="Core Capabilities:"></a>Core Capabilities:</h3><ul><li>Detects text language</li><li>Extracts key phrases, people, places, brands, and events</li><li>Sentiment analysis â†’ positive, negative, neutral, or mixed</li><li>Tokenization and Part-of-Speech tagging</li><li>Automatically organizes text files by topic</li></ul><h3 id="Common-Use-Cases"><a href="#Common-Use-Cases" class="headerlink" title="Common Use Cases:"></a>Common Use Cases:</h3><ul><li>Analyze customer support emails to identify what leads to positive&#x2F;negative experiences</li><li>Group large document collections (e.g., news articles) by topic</li></ul><hr><h2 id="Custom-Classification"><a href="#Custom-Classification" class="headerlink" title="Custom Classification"></a>Custom Classification</h2><ul><li>Organize documents into <strong>categories you define</strong>.</li><li>Example: Categorize emails into <em>billing, technical support, complaints</em>.</li><li>Supports formats: text, PDF, Word, images.</li><li><strong>Real-time (synchronous)</strong> for single documents, or <strong>batch&#x2F;asynchronous</strong> for larger workloads.</li></ul><p align="center">  <img src="/images/aws_basic_145.png" width="80%"></p> <hr><h2 id="Named-Entity-Recognition-NER"><a href="#Named-Entity-Recognition-NER" class="headerlink" title="Named Entity Recognition (NER)"></a>Named Entity Recognition (NER)</h2><ul><li>Extracts <strong>predefined general entities</strong>: people, organizations, places, dates, etc.</li><li>Example: From â€œJohn works at AnyCompany on July 31st,â€ Comprehend identifies John (Person), AnyCompany (Organization), and July 31st (Date).</li></ul><p align="center">  <img src="/images/aws_basic_146.png" width="80%"></p> ------------------------------------------------------------------------<h2 id="Custom-Entity-Recognition"><a href="#Custom-Entity-Recognition" class="headerlink" title="Custom Entity Recognition"></a>Custom Entity Recognition</h2><ul><li>Allows detection of <strong>business-specific terms</strong>.</li><li>Example: Policy numbers, escalation phrases, custom product codes.</li><li>Requires <strong>training data</strong> (entity list + documents) stored in S3 â†’ Comprehend builds a custom recognizer.</li><li>Works in <strong>real-time</strong> or <strong>batch</strong>.</li></ul><p>ğŸ‘‰ <strong>Exam Tip</strong>:</p><ul><li><strong>NER &#x3D; predefined entities</strong>.</li><li><strong>Custom Entity Recognition &#x3D; business-specific entities trained with your data</strong>.</li></ul><p align="center">  <img src="/images/aws_basic_147.png" width="80%"></p> <hr><h1 id="Amazon-Translate"><a href="#Amazon-Translate" class="headerlink" title="Amazon Translate"></a>Amazon Translate</h1><p>A <strong>neural machine translation (NMT) service</strong> that provides natural and<br>accurate translations.</p><h3 id="Features"><a href="#Features" class="headerlink" title="Features:"></a>Features:</h3><ul><li>Translate text and entire documents (txt, HTML, docx).</li><li><strong>Batch Translation</strong>: Translate large volumes via S3 jobs.</li><li><strong>Custom Terminology</strong>: Maintain brand names or domain-specific terms across translations.</li><li><strong>Parallel Data</strong>: Control translation style (formal vs informal).</li></ul><p>ğŸ‘‰ <strong>Exam Tip</strong>: Custom Terminology and Parallel Data are key differentiators.</p><p align="center">  <img src="/images/aws_basic_148.png" width="80%"></p> <hr><h1 id="Amazon-Transcribe-Speech-to-Text"><a href="#Amazon-Transcribe-Speech-to-Text" class="headerlink" title="Amazon Transcribe (Speech-to-Text)"></a>Amazon Transcribe (Speech-to-Text)</h1><p>A fully managed <strong>Automatic Speech Recognition (ASR)</strong> service that converts speech to text.</p><h3 id="Features-1"><a href="#Features-1" class="headerlink" title="Features:"></a>Features:</h3><ul><li>Converts audio to text quickly and accurately</li><li><strong>PII Redaction</strong>: Removes personally identifiable information (name, SSN, phone number, etc.)</li><li><strong>Automatic Language Identification</strong>: Handles multilingual audio streams</li></ul><h3 id="Use-Cases"><a href="#Use-Cases" class="headerlink" title="Use Cases:"></a>Use Cases:</h3><ul><li>Transcribe customer service calls</li><li>Generate subtitles and closed captions</li><li>Create searchable metadata for media archives</li></ul><p align="center">  <img src="/images/aws_basic_149.png" width="80%"></p> <hr><h2 id="Improving-Accuracy"><a href="#Improving-Accuracy" class="headerlink" title="Improving Accuracy"></a>Improving Accuracy</h2><ul><li><strong>Custom Vocabularies</strong>: Add words, acronyms, brand names â†’ improve recognition.</li><li><strong>Custom Language Models</strong>: Train on domain-specific text to provide context (e.g., distinguishing <em>â€œmicroserviceâ€</em> vs <em>â€œmy crow serviceâ€</em>).</li><li>Best accuracy is achieved when <strong>both are used together</strong>.</li></ul><p align="center">  <img src="/images/aws_basic_151.png" width="80%"></p> <hr><h2 id="Toxicity-Detection"><a href="#Toxicity-Detection" class="headerlink" title="Toxicity Detection"></a>Toxicity Detection</h2><ul><li>Detects <strong>toxic speech content</strong> using both voice cues (tone, pitch) and text cues.</li><li>Categories: sexual harassment, hate speech, threats, abuse, profanity, insults, graphic content.</li></ul><p>ğŸ‘‰ <strong>Exam Tip</strong>:</p><ul><li>Know that Transcribe supports <strong>PII Redaction, Custom Vocabulary, Custom Language Models, and Toxicity Detection</strong>.</li><li>Expect scenario-based exam questions about improving transcription accuracy.</li></ul><p align="center">  <img src="/images/aws_basic_150.png" width="80%"></p> <hr><h1 id="Exam-Focused-Summary"><a href="#Exam-Focused-Summary" class="headerlink" title="Exam-Focused Summary"></a>Exam-Focused Summary</h1><ol><li><strong>Comprehend</strong> â†’ NLP (Sentiment, NER, Custom Classification, Custom Entities).</li><li><strong>Translate</strong> â†’ Language translation (Custom Terminology, Parallel Data).</li><li><strong>Transcribe</strong> â†’ Speech-to-Text (PII Redaction, Custom Vocabulary, Toxicity Detection).</li><li><strong>Shared Traits</strong>: Fully Managed, Serverless, Pay-as-you-go, scalable across regions.</li><li><strong>AWS Exam Hotspots</strong>:<ul><li>When to use Custom Terminology vs Parallel Data in Translate.</li><li>How Comprehend Custom Classification differs from Custom Entity Recognition.</li><li>Improving Transcribe accuracy (Custom Vocabulary + Custom Language Models).</li><li>Toxicity Detection categories in Transcribe.</li></ul></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;AWS-AI-Managed-Services&quot;&gt;&lt;a href=&quot;#AWS-AI-Managed-Services&quot; class=&quot;headerlink&quot; title=&quot;AWS AI Managed Services&quot;&gt;&lt;/a&gt;AWS AI Managed Se</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(30) - Hyperparameter Tuning</title>
    <link href="https://kish191919.github.io/2025/08/26/AWS-Certified-AI-Practitioner-30/"/>
    <id>https://kish191919.github.io/2025/08/26/AWS-Certified-AI-Practitioner-30/</id>
    <published>2025-08-26T19:20:21.000Z</published>
    <updated>2025-08-26T19:27:31.165Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Hyperparameter-Tuning"><a href="#Hyperparameter-Tuning" class="headerlink" title="Hyperparameter Tuning"></a>Hyperparameter Tuning</h1><h2 id="1-What-is-a-Hyperparameter"><a href="#1-What-is-a-Hyperparameter" class="headerlink" title="1. What is a Hyperparameter?"></a>1. What is a Hyperparameter?</h2><ul><li><strong>Definition</strong>: Settings that define how the model is structured and how the learning algorithm works.</li><li><strong>Set before training begins</strong> (they are not learned from the data).</li><li><strong>Examples</strong>:<ul><li><strong>Learning rate</strong></li><li><strong>Batch size</strong></li><li><strong>Number of epochs</strong></li><li><strong>Regularization</strong></li></ul></li></ul><p>ğŸ‘‰ <strong>Exam Tip</strong>: Hyperparameters are <strong>not learned</strong> during training. They are chosen before training and tuned for best performance.</p><hr><h2 id="2-Why-Hyperparameter-Tuning-Matters"><a href="#2-Why-Hyperparameter-Tuning-Matters" class="headerlink" title="2. Why Hyperparameter Tuning Matters"></a>2. Why Hyperparameter Tuning Matters</h2><ul><li><strong>Goal</strong>: Find the best combination of hyperparameters to optimize model performance.</li><li><strong>Benefits</strong>:<ul><li>Improves accuracy</li><li>Reduces overfitting</li><li>Enhances generalization to new data</li></ul></li><li><strong>Methods</strong>:<ul><li><strong>Grid Search</strong>: Tries all possible parameter combinations.</li><li><strong>Random Search</strong>: Tests random parameter values.</li><li><strong>Automated Services</strong>:<ul><li><strong>Amazon SageMaker Automatic Model Tuning (AMT)</strong> runs multiple training jobs and finds the best settings.</li></ul></li></ul></li></ul><hr><h2 id="3-Key-Hyperparameters"><a href="#3-Key-Hyperparameters" class="headerlink" title="3. Key Hyperparameters"></a>3. Key Hyperparameters</h2><h3 id="1-Learning-Rate"><a href="#1-Learning-Rate" class="headerlink" title="(1) Learning Rate"></a>(1) Learning Rate</h3><ul><li>Controls <strong>how big the steps are</strong> when updating model weights.</li><li><strong>High learning rate</strong>: Faster training, but may overshoot the optimal solution.</li><li><strong>Low learning rate</strong>: More stable and precise, but much slower.</li></ul><hr><h3 id="2-Batch-Size"><a href="#2-Batch-Size" class="headerlink" title="(2) Batch Size"></a>(2) Batch Size</h3><ul><li>Number of training examples processed in one iteration.</li><li><strong>Small batches</strong>: More stable, but slower.</li><li><strong>Large batches</strong>: Faster, but may cause less stable updates.</li></ul><hr><h3 id="3-Number-of-Epochs"><a href="#3-Number-of-Epochs" class="headerlink" title="(3) Number of Epochs"></a>(3) Number of Epochs</h3><ul><li>How many times the model goes through the <strong>entire training dataset</strong>.</li><li><strong>Too few</strong>: Underfitting (model doesnâ€™t learn enough).</li><li><strong>Too many</strong>: Overfitting (model memorizes the data, performs poorly on new data).</li></ul><hr><h3 id="4-Regularization"><a href="#4-Regularization" class="headerlink" title="(4) Regularization"></a>(4) Regularization</h3><ul><li>Controls the <strong>balance between a simple and complex model</strong>.</li><li>More regularization â†’ less overfitting.</li></ul><p>ğŸ‘‰ <strong>Exam Tip</strong>: If asked how to reduce overfitting, <strong>increasing regularization</strong> is often the correct answer.</p><hr><h2 id="4-Overfitting"><a href="#4-Overfitting" class="headerlink" title="4. Overfitting"></a>4. Overfitting</h2><h3 id="What-is-it"><a href="#What-is-it" class="headerlink" title="What is it?"></a>What is it?</h3><ul><li>The model performs very well on training data but poorly on new, unseen data.</li></ul><h3 id="Causes"><a href="#Causes" class="headerlink" title="Causes"></a>Causes</h3><ul><li>Too little training data â†’ not representative.</li><li>Training for too many epochs.</li><li>Model too complex â†’ learns noise instead of patterns.</li></ul><h3 id="Solutions"><a href="#Solutions" class="headerlink" title="Solutions"></a>Solutions</h3><ul><li>Increase training data size (best option).</li><li>Use <strong>early stopping</strong> (stop training before overfitting).</li><li>Apply <strong>data augmentation</strong> (add diversity to training data).</li><li>Adjust hyperparameters (e.g., increase regularization, change batch size).</li></ul><p>ğŸ‘‰ <strong>Exam Tip</strong>: If the question is <strong>â€œbest way to prevent overfittingâ€</strong>, the answer is usually <strong>increase training data</strong>.</p><hr><h2 id="5-When-NOT-to-Use-Machine-Learning"><a href="#5-When-NOT-to-Use-Machine-Learning" class="headerlink" title="5. When NOT to Use Machine Learning"></a>5. When NOT to Use Machine Learning</h2><ul><li><strong>Example</strong>:<br>You have a deck of 10 cards (5 red, 3 blue, 2 yellow).<br>Q: What is the probability of drawing a blue card?<br>A: 3&#x2F;10 &#x3D; 0.3</li></ul>   <p align="center">  <img src="/images/aws_basic_143.png" width="80%"></p> <ul><li><p>This is a <strong>deterministic problem</strong>:</p><ul><li>The exact answer can be computed mathematically.</li><li>Writing simple code is the best solution.</li></ul></li><li><p>If we used ML (supervised, unsupervised, or reinforcement learning), weâ€™d only get an <strong>approximation</strong>, not an exact result.</p></li></ul><p>ğŸ‘‰ <strong>Exam Tip</strong>:<br>Machine Learning is <strong>not appropriate</strong> for problems that have a <strong>clear, deterministic answer</strong>. It is designed for problems where patterns must be learned from data.</p><hr><h2 id="6-AWS-Specific-Notes-for-Exams"><a href="#6-AWS-Specific-Notes-for-Exams" class="headerlink" title="6. AWS-Specific Notes for Exams"></a>6. AWS-Specific Notes for Exams</h2><ul><li><strong>Amazon SageMaker Automatic Model Tuning (AMT)</strong>: Automates hyperparameter tuning by running multiple jobs in parallel.</li><li><strong>Common Exam Questions</strong>:<ul><li>How to fix overfitting â†’ Increase data &#x2F; regularization.</li><li>What hyperparameter affects convergence speed â†’ Learning rate.</li><li>Which AWS service automates tuning â†’ SageMaker AMT.</li><li>When NOT to use ML â†’ Deterministic problem with exact answers.</li></ul></li></ul><hr><p>âœ… <strong>Summary</strong> - <strong>Hyperparameters</strong> (learning rate, batch size, epochs regularization) must be tuned for best performance.</p><ul><li><strong>Tuning</strong> improves accuracy, reduces overfitting, and enhances generalization.</li><li><strong>Overfitting</strong> occurs when the model memorizes training data â†’ fix by more data, regularization, early stopping.</li><li><strong>ML is not appropriate</strong> for deterministic problems.</li><li>On AWS, <strong>SageMaker AMT</strong> is the go-to tool for automated hyperparameter tuning.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Hyperparameter-Tuning&quot;&gt;&lt;a href=&quot;#Hyperparameter-Tuning&quot; class=&quot;headerlink&quot; title=&quot;Hyperparameter Tuning&quot;&gt;&lt;/a&gt;Hyperparameter Tuning&lt;/</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(í•œêµ­ì–´) AWS Certified AI Practitioner (30) - í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹</title>
    <link href="https://kish191919.github.io/2025/08/26/KO-AWS-Certified-AI-Practitioner-30/"/>
    <id>https://kish191919.github.io/2025/08/26/KO-AWS-Certified-AI-Practitioner-30/</id>
    <published>2025-08-26T19:20:12.000Z</published>
    <updated>2025-08-27T02:57:51.733Z</updated>
    
    <content type="html"><![CDATA[<h1 id="í•˜ì´í¼íŒŒë¼ë¯¸í„°-íŠœë‹-Hyperparameter-Tuning"><a href="#í•˜ì´í¼íŒŒë¼ë¯¸í„°-íŠœë‹-Hyperparameter-Tuning" class="headerlink" title="í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (Hyperparameter Tuning)"></a>í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (Hyperparameter Tuning)</h1><h2 id="1-í•˜ì´í¼íŒŒë¼ë¯¸í„°ë€"><a href="#1-í•˜ì´í¼íŒŒë¼ë¯¸í„°ë€" class="headerlink" title="1. í•˜ì´í¼íŒŒë¼ë¯¸í„°ë€?"></a>1. í•˜ì´í¼íŒŒë¼ë¯¸í„°ë€?</h2><ul><li><strong>ì •ì˜</strong>: ëª¨ë¸ êµ¬ì¡°ì™€ í•™ìŠµ ë°©ì‹ì„ ê²°ì •í•˜ëŠ” ì„¤ì •ê°’</li><li><strong>íŠ¹ì§•</strong>:<ul><li>í•™ìŠµì´ ì‹œì‘ë˜ê¸° ì „ì— ì •í•´ì§</li><li>ë°ì´í„° ìì²´ê°€ ì•„ë‹ˆë¼, <strong>í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì˜ ë™ì‘ ë°©ì‹</strong>ì— ì˜í–¥ì„ ì¤Œ</li></ul></li><li><strong>ëŒ€í‘œ ì˜ˆì‹œ</strong>:<ul><li>í•™ìŠµë¥ (Learning rate)</li><li>ë°°ì¹˜ í¬ê¸°(Batch size)</li><li>ì—í¬í¬ ìˆ˜(Number of epochs)</li><li>ì •ê·œí™”(Regularization)</li></ul></li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>:<br>í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ëª¨ë¸ í•™ìŠµ ê³¼ì •ì—ì„œ ìë™ìœ¼ë¡œ í•™ìŠµë˜ëŠ” ê°’ì´ ì•„ë‹ˆë¼, <strong>ì‚¬ì „ì— ì„¤ì •í•˜ëŠ” ê°’</strong>ì´ë‹¤.</p><hr><h2 id="2-í•˜ì´í¼íŒŒë¼ë¯¸í„°-íŠœë‹-Hyperparameter-Tuning"><a href="#2-í•˜ì´í¼íŒŒë¼ë¯¸í„°-íŠœë‹-Hyperparameter-Tuning" class="headerlink" title="2. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹(Hyperparameter Tuning)"></a>2. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹(Hyperparameter Tuning)</h2><ul><li><strong>ëª©ì </strong>: ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ì„ ì°¾ì•„ ëª¨ë¸ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”\</li><li><strong>íš¨ê³¼</strong>:<ul><li>ì •í™•ë„ í–¥ìƒ</li><li>ê³¼ì í•©(Overfitting) ê°ì†Œ</li><li>ì¼ë°˜í™” ì„±ëŠ¥ ê°•í™”</li></ul></li><li><strong>ë°©ë²•</strong>:<ul><li><strong>Grid Search</strong>: ê°€ëŠ¥í•œ ëª¨ë“  ì¡°í•© íƒìƒ‰</li><li><strong>Random Search</strong>: ì„ì˜ì˜ ì¡°í•©ì„ íƒìƒ‰</li><li><strong>ìë™í™” ì„œë¹„ìŠ¤</strong>:<ul><li><strong>Amazon SageMaker Automatic Model Tuning (AMT)</strong> í™œìš©</li></ul></li></ul></li></ul><hr><h2 id="3-ì£¼ìš”-í•˜ì´í¼íŒŒë¼ë¯¸í„°"><a href="#3-ì£¼ìš”-í•˜ì´í¼íŒŒë¼ë¯¸í„°" class="headerlink" title="3. ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°"></a>3. ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°</h2><h3 id="1-í•™ìŠµë¥ -Learning-Rate"><a href="#1-í•™ìŠµë¥ -Learning-Rate" class="headerlink" title="(1) í•™ìŠµë¥  (Learning Rate)"></a>(1) í•™ìŠµë¥  (Learning Rate)</h3><ul><li>ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ì–¼ë§ˆë‚˜ í¬ê²Œ&#x2F;ì‘ê²Œ ì—…ë°ì´íŠ¸í• ì§€ ê²°ì •</li><li><strong>ë†’ì€ í•™ìŠµë¥ </strong>: ë¹ ë¥¸ ìˆ˜ë ´ ê°€ëŠ¥, í•˜ì§€ë§Œ ìµœì ê°’ì„ ì§€ë‚˜ì¹  ìœ„í—˜</li><li><strong>ë‚®ì€ í•™ìŠµë¥ </strong>: ë” ì •ë°€í•œ ìˆ˜ë ´ ê°€ëŠ¥, í•˜ì§€ë§Œ ì†ë„ê°€ ëŠë¦¼</li></ul><hr><h3 id="2-ë°°ì¹˜-í¬ê¸°-Batch-Size"><a href="#2-ë°°ì¹˜-í¬ê¸°-Batch-Size" class="headerlink" title="(2) ë°°ì¹˜ í¬ê¸° (Batch Size)"></a>(2) ë°°ì¹˜ í¬ê¸° (Batch Size)</h3><ul><li>í•œ ë²ˆì˜ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ì— ì‚¬ìš©ë˜ëŠ” ë°ì´í„° ìƒ˜í”Œ ê°œìˆ˜</li><li><strong>ì‘ì€ ë°°ì¹˜</strong>: ì•ˆì •ì ì¸ í•™ìŠµ, í•˜ì§€ë§Œ ì—°ì‚° ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼</li><li><strong>í° ë°°ì¹˜</strong>: ë¹ ë¥¸ í•™ìŠµ, í•˜ì§€ë§Œ ë¶ˆì•ˆì •í•œ ì—…ë°ì´íŠ¸ ê°€ëŠ¥</li></ul><hr><h3 id="3-ì—í¬í¬-ìˆ˜-Number-of-Epochs"><a href="#3-ì—í¬í¬-ìˆ˜-Number-of-Epochs" class="headerlink" title="(3) ì—í¬í¬ ìˆ˜ (Number of Epochs)"></a>(3) ì—í¬í¬ ìˆ˜ (Number of Epochs)</h3><ul><li>ì „ì²´ í•™ìŠµ ë°ì´í„°ë¥¼ ëª‡ ë²ˆ ë°˜ë³µí•´ì„œ í•™ìŠµí• ì§€ ê²°ì •</li><li><strong>ë„ˆë¬´ ì ìœ¼ë©´</strong>: í•™ìŠµ ë¶€ì¡±(Underfitting)</li><li><strong>ë„ˆë¬´ ë§ìœ¼ë©´</strong>: ê³¼ì í•©(Overfitting)</li></ul><hr><h3 id="4-ì •ê·œí™”-Regularization"><a href="#4-ì •ê·œí™”-Regularization" class="headerlink" title="(4) ì •ê·œí™” (Regularization)"></a>(4) ì •ê·œí™” (Regularization)</h3><ul><li>ëª¨ë¸ì´ ë„ˆë¬´ ë³µì¡í•´ì ¸ ê³¼ì í•©ë˜ì§€ ì•Šë„ë¡ ì œì–´</li><li>ì •ê·œí™”ë¥¼ ë†’ì´ë©´ ë‹¨ìˆœí•´ì§€ê³ , ê³¼ì í•© ë°©ì§€ íš¨ê³¼</li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>:<br>â€œê³¼ì í•©ì„ ì¤„ì´ê³  ì‹¶ë‹¤â€ë¼ëŠ” ì§ˆë¬¸ â†’ <strong>ì •ê·œí™” ê°•í™”ë¥¼ ì •ë‹µìœ¼ë¡œ ì„ íƒ</strong>í•˜ëŠ” ê²½ìš°ê°€ ë§ìŒ.</p><hr><h2 id="4-ê³¼ì í•©-Overfitting-ê³¼-í•´ê²°-ë°©ë²•"><a href="#4-ê³¼ì í•©-Overfitting-ê³¼-í•´ê²°-ë°©ë²•" class="headerlink" title="4. ê³¼ì í•©(Overfitting)ê³¼ í•´ê²° ë°©ë²•"></a>4. ê³¼ì í•©(Overfitting)ê³¼ í•´ê²° ë°©ë²•</h2><ul><li><strong>ì •ì˜</strong>: í•™ìŠµ ë°ì´í„°ì—ì„œëŠ” ë†’ì€ ì •í™•ë„ë¥¼ ë³´ì´ì§€ë§Œ, ìƒˆë¡œìš´ ë°ì´í„°ì—ì„œëŠ” ì„±ëŠ¥ì´ ê¸‰ê²©íˆ ë–¨ì–´ì§€ëŠ” í˜„ìƒ</li></ul><h3 id="ì›ì¸"><a href="#ì›ì¸" class="headerlink" title="ì›ì¸"></a>ì›ì¸</h3><ul><li>í•™ìŠµ ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŒ â†’ ëŒ€í‘œì„±ì´ ë¶€ì¡±</li><li>ë„ˆë¬´ ë§ì€ ì—í¬í¬ í•™ìŠµ â†’ íŠ¹ì • ë°ì´í„°ì—ë§Œ ë§ì¶°ì§</li><li>ëª¨ë¸ì´ ì§€ë‚˜ì¹˜ê²Œ ë³µì¡ â†’ ë°ì´í„°ì˜ <strong>ë…¸ì´ì¦ˆê¹Œì§€ í•™ìŠµ</strong></li></ul><h3 id="ë°©ì§€-ë°©ë²•"><a href="#ë°©ì§€-ë°©ë²•" class="headerlink" title="ë°©ì§€ ë°©ë²•"></a>ë°©ì§€ ë°©ë²•</h3><ul><li><strong>ë°ì´í„° ì–‘ ëŠ˜ë¦¬ê¸°</strong> (ê°€ì¥ íš¨ê³¼ì )</li><li><strong>Early Stopping</strong> (í•™ìŠµ ì¡°ê¸° ì¢…ë£Œ)</li><li><strong>ë°ì´í„° ì¦ê°•(Data Augmentation)</strong> (ë‹¤ì–‘ì„± í™•ë³´)</li><li><strong>í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •</strong> (í•™ìŠµë¥ , ë°°ì¹˜ í¬ê¸°, ì •ê·œí™” ë“±)</li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>:<br>ê³¼ì í•© ë°©ì§€ì˜ <strong>ê°€ì¥ ì¢‹ì€ ë‹µ</strong>ì€ ë³´í†µ <strong>ë°ì´í„° ì–‘ ëŠ˜ë¦¬ê¸°</strong></p><hr><h2 id="5-ë¨¸ì‹ ëŸ¬ë‹ì´-ì í•©í•˜ì§€-ì•Šì€-ê²½ìš°"><a href="#5-ë¨¸ì‹ ëŸ¬ë‹ì´-ì í•©í•˜ì§€-ì•Šì€-ê²½ìš°" class="headerlink" title="5. ë¨¸ì‹ ëŸ¬ë‹ì´ ì í•©í•˜ì§€ ì•Šì€ ê²½ìš°"></a>5. ë¨¸ì‹ ëŸ¬ë‹ì´ ì í•©í•˜ì§€ ì•Šì€ ê²½ìš°</h2><ul><li><strong>ì˜ˆì‹œ ë¬¸ì œ</strong>:<br>â€œì¹´ë“œ 10ì¥ ì¤‘ ë¹¨ê°• 5ì¥, íŒŒë‘ 3ì¥, ë…¸ë‘ 2ì¥ â†’ íŒŒë‘ ì¹´ë“œë¥¼ ë½‘ì„ í™•ë¥ ì€?â€<ul><li>ë‹µ: <strong>3&#x2F;10 &#x3D; 0.3</strong></li><li>ë‹¨ìˆœ ìˆ˜í•™ì  ê³„ì‚°ìœ¼ë¡œ ì •í™•íˆ í•´ê²° ê°€ëŠ¥</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_143.png" width="80%"></p> <p>ğŸ‘‰ <strong>ê²°ë¡ </strong>:</p><ul><li><strong>ê²°ì •ë¡ ì (Deterministic) ë¬¸ì œ</strong>: ì½”ë“œë¡œ ìˆ˜í•™ì ìœ¼ë¡œ í’€ ìˆ˜ ìˆìŒ â†’ ë¨¸ì‹ ëŸ¬ë‹ ë¶ˆí•„ìš”</li><li>ë¨¸ì‹ ëŸ¬ë‹ì€ í•­ìƒ **ê·¼ì‚¬ê°’(Approximation)**ì„ ë‚´ë¯€ë¡œ, ì´ëŸ° ë¬¸ì œì—ì„œëŠ” <strong>ì ì ˆí•˜ì§€ ì•ŠìŒ</strong></li></ul><hr><h2 id="6-ì‹œí—˜-ëŒ€ë¹„-í•µì‹¬-ìš”ì•½"><a href="#6-ì‹œí—˜-ëŒ€ë¹„-í•µì‹¬-ìš”ì•½" class="headerlink" title="6. ì‹œí—˜ ëŒ€ë¹„ í•µì‹¬ ìš”ì•½"></a>6. ì‹œí—˜ ëŒ€ë¹„ í•µì‹¬ ìš”ì•½</h2><ol><li><strong>í•˜ì´í¼íŒŒë¼ë¯¸í„°</strong> &#x3D; í•™ìŠµ ì „ ì„¤ì • (í•™ìŠµë¥ , ë°°ì¹˜ í¬ê¸°, ì—í¬í¬ ìˆ˜, ì •ê·œí™”)</li><li><strong>íŠœë‹ ëª©ì </strong> &#x3D; ì„±ëŠ¥ í–¥ìƒ, ê³¼ì í•© ë°©ì§€</li><li><strong>ê³¼ì í•© ë°©ì§€ ë°©ë²•</strong> &#x3D; ë°ì´í„° ëŠ˜ë¦¬ê¸°, Early Stopping, ë°ì´í„° ì¦ê°•, ì •ê·œí™”</li><li><strong>AWS ì„œë¹„ìŠ¤</strong> &#x3D; <strong>SageMaker Automatic Model Tuning</strong></li><li><strong>ë¨¸ì‹ ëŸ¬ë‹ì´ í•„ìš” ì—†ëŠ” ê²½ìš°</strong> &#x3D; ë‹µì„ ëª…í™•íˆ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ê²°ì •ë¡ ì  ë¬¸ì œ</li></ol><hr><p>ğŸ‘‰ ìš”ì•½í•˜ë©´, <strong>ì‹œí—˜ì—ì„œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì™€ ê³¼ì í•© ë°©ì§€ ë°©ë²•ì€ ë°˜ë“œì‹œ ë‚˜ì˜¤ëŠ” ë‹¨ê³¨ ì£¼ì œ</strong>ì…ë‹ˆë‹¤.<br>íŠ¹íˆ <strong>SageMaker AMT</strong>ì™€ <strong>ì •ê·œí™”&#x2F;ë°ì´í„° ì¦ê°•</strong> ê´€ë ¨ ë¬¸í•­ì´ ìì£¼ ì¶œì œë©ë‹ˆë‹¤.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;í•˜ì´í¼íŒŒë¼ë¯¸í„°-íŠœë‹-Hyperparameter-Tuning&quot;&gt;&lt;a href=&quot;#í•˜ì´í¼íŒŒë¼ë¯¸í„°-íŠœë‹-Hyperparameter-Tuning&quot; class=&quot;headerlink&quot; title=&quot;í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (Hyperparameter T</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(í•œêµ­ì–´) AWS Certified AI Practitioner (29) - ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ ë‹¨ê³„</title>
    <link href="https://kish191919.github.io/2025/08/25/KO-AWS-Certified-AI-Practitioner-29/"/>
    <id>https://kish191919.github.io/2025/08/25/KO-AWS-Certified-AI-Practitioner-29/</id>
    <published>2025-08-25T17:33:46.000Z</published>
    <updated>2025-08-25T17:44:54.806Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ë¨¸ì‹ ëŸ¬ë‹-í”„ë¡œì íŠ¸-ë‹¨ê³„-Phases-of-Machine-Learning-Project"><a href="#ë¨¸ì‹ ëŸ¬ë‹-í”„ë¡œì íŠ¸-ë‹¨ê³„-Phases-of-Machine-Learning-Project" class="headerlink" title="ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ ë‹¨ê³„ (Phases of Machine Learning Project)"></a>ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ ë‹¨ê³„ (Phases of Machine Learning Project)</h1><h2 id="1-ë¹„ì¦ˆë‹ˆìŠ¤-ëª©í‘œ-ì •ì˜"><a href="#1-ë¹„ì¦ˆë‹ˆìŠ¤-ëª©í‘œ-ì •ì˜" class="headerlink" title="1. ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œ ì •ì˜"></a>1. ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œ ì •ì˜</h2><ul><li><strong>ëª©í‘œ</strong>: ì–´ë–¤ ë¬¸ì œë¥¼ í•´ê²°í• ì§€ ëª…í™•íˆ ì •ì˜</li><li><strong>ì´í•´ê´€ê³„ì(Stakeholders)</strong>: í”„ë¡œì íŠ¸ì˜ <strong>ê°€ì¹˜, ì˜ˆì‚°, ì„±ê³µ ê¸°ì¤€</strong>ì„ ì„¤ì •</li><li><strong>KPI(í•µì‹¬ ì„±ê³¼ ì§€í‘œ)</strong>: ë°˜ë“œì‹œ ì •ì˜í•´ì•¼ í•¨ â†’ ëª¨ë¸ì´ ì‹¤ì œë¡œ ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œì— ê¸°ì—¬í•˜ëŠ”ì§€ íŒë‹¨í•˜ëŠ” ê¸°ì¤€</li></ul><p>ğŸ‘‰ ì‹œí—˜ í¬ì¸íŠ¸:<br>ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ì˜ ì²« ë‹¨ê³„ëŠ” í•­ìƒ <strong>ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì œë¥¼ ì •ì˜</strong>í•˜ëŠ” ê²ƒ. <strong>KPI ì„¤ì •</strong>ì€ AWS ì‹œí—˜ì—ì„œ ìì£¼ ê°•ì¡°ë¨.</p><hr><h2 id="2-ë¬¸ì œ-ì •ì˜ì™€-ML-ë¬¸ì œë¡œ-ì „í™˜-ML-Problem-Framing"><a href="#2-ë¬¸ì œ-ì •ì˜ì™€-ML-ë¬¸ì œë¡œ-ì „í™˜-ML-Problem-Framing" class="headerlink" title="2. ë¬¸ì œ ì •ì˜ì™€ ML ë¬¸ì œë¡œ ì „í™˜ (ML Problem Framing)"></a>2. ë¬¸ì œ ì •ì˜ì™€ ML ë¬¸ì œë¡œ ì „í™˜ (ML Problem Framing)</h2><ul><li><strong>ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì œ â†’ ML ë¬¸ì œë¡œ ë³€í™˜</strong></li><li>ë¨¸ì‹ ëŸ¬ë‹ì´ ì •ë§ í•„ìš”í•œì§€, ë‹¤ë¥¸ í•´ê²°ì±…(ì˜ˆ: ë‹¨ìˆœ ê·œì¹™ ê¸°ë°˜)ì´ ë” ë‚˜ì€ì§€ íŒë‹¨</li><li>ë°ì´í„° ê³¼í•™ì, ë°ì´í„° ì—”ì§€ë‹ˆì–´, ML ì•„í‚¤í…íŠ¸, ë„ë©”ì¸ ì „ë¬¸ê°€ê°€ í•¨ê»˜ í˜‘ì—…</li></ul><hr><h2 id="3-ë°ì´í„°-ì²˜ë¦¬-Data-Processing"><a href="#3-ë°ì´í„°-ì²˜ë¦¬-Data-Processing" class="headerlink" title="3. ë°ì´í„° ì²˜ë¦¬ (Data Processing)"></a>3. ë°ì´í„° ì²˜ë¦¬ (Data Processing)</h2><ul><li><strong>ë°ì´í„° ìˆ˜ì§‘ ë° í†µí•©</strong>: ì¤‘ì•™ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ ì •ë¦¬</li><li><strong>ì „ì²˜ë¦¬ ë° ì‹œê°í™”</strong>: ë°ì´í„° í’ˆì§ˆ í™•ì¸, ì´ìƒì¹˜ ì œê±°, ê²°ì¸¡ê°’ ì²˜ë¦¬</li><li><strong>í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§</strong>: ìƒˆë¡œìš´ ë³€ìˆ˜ë¥¼ ìƒì„±, ë³€í™˜, ì¶”ì¶œí•˜ì—¬ ëª¨ë¸ì´ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ ê°€ê³µ</li></ul><p>ğŸ‘‰ ì‹œí—˜ í¬ì¸íŠ¸:<br>AWS ì„œë¹„ìŠ¤ ì—°ê²°</p><ul><li><strong>AWS Glue</strong>: ë°ì´í„° ìˆ˜ì§‘&#x2F;ì •ë¦¬</li><li><strong>Amazon S3</strong>: ì¤‘ì•™ ì €ì¥ì†Œ</li><li><strong>Amazon QuickSight</strong>: ë°ì´í„° ì‹œê°í™”</li></ul><hr><h2 id="4-íƒìƒ‰ì -ë°ì´í„°-ë¶„ì„-EDA-Exploratory-Data-Analysis"><a href="#4-íƒìƒ‰ì -ë°ì´í„°-ë¶„ì„-EDA-Exploratory-Data-Analysis" class="headerlink" title="4. íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA, Exploratory Data Analysis)"></a>4. íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA, Exploratory Data Analysis)</h2><ul><li><strong>ê·¸ë˜í”„ ì‹œê°í™”</strong>ë¡œ ë°ì´í„° ë¶„í¬ì™€ íŠ¹ì„± ì´í•´</li><li><strong>ìƒê´€í–‰ë ¬(Correlation Matrix)</strong>: í”¼ì²˜ë“¤ ê°„ì˜ ì—°ê´€ì„± íŒŒì•…<ul><li>ì˜ˆ: ê³µë¶€ ì‹œê°„ â†” ì‹œí—˜ ì ìˆ˜ (0.85 ìƒê´€ê´€ê³„ â†’ ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„)</li></ul></li><li>ì–´ë–¤ í”¼ì²˜ê°€ ëª¨ë¸ì— ì¤‘ìš”í•œì§€ íŒë‹¨</li></ul><p align="center">  <img src="/images/aws_basic_142.png" width="80%"></p><hr><h2 id="5-ëª¨ë¸-ê°œë°œ-Model-Development"><a href="#5-ëª¨ë¸-ê°œë°œ-Model-Development" class="headerlink" title="5. ëª¨ë¸ ê°œë°œ (Model Development)"></a>5. ëª¨ë¸ ê°œë°œ (Model Development)</h2><ul><li><strong>ëª¨ë¸ í•™ìŠµ(Training), íŠœë‹(Tuning), í‰ê°€(Evaluation)</strong></li><li><strong>í•˜ì´í¼íŒŒë¼ë¯¸í„°(Hyperparameters)</strong>: ì•Œê³ ë¦¬ì¦˜ ë™ì‘ ë°©ì‹ì„ ì¡°ì •í•˜ëŠ” ê°’ (ì˜ˆ: í•™ìŠµë¥ , íŠ¸ë¦¬ ê°œìˆ˜ ë“±)</li><li>ë°˜ë³µì ì¸ ê³¼ì • (Iterative Process)<ul><li>ì¶”ê°€ì ì¸ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§</li><li>í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹</li></ul></li></ul><p>ğŸ‘‰ ì‹œí—˜ í¬ì¸íŠ¸:</p><ul><li><strong>Amazon SageMaker</strong>ëŠ” í•™ìŠµ, íŠœë‹, í‰ê°€ê¹Œì§€ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì§€ì›í•˜ëŠ” ëŒ€í‘œ ì„œë¹„ìŠ¤.</li><li>SageMaker <strong>Automatic Model Tuning</strong> ê¸°ëŠ¥ë„ ì‹œí—˜ì— ìì£¼ ë‚˜ì˜´.</li></ul><hr><h2 id="6-ì¬í•™ìŠµ-Retraining"><a href="#6-ì¬í•™ìŠµ-Retraining" class="headerlink" title="6. ì¬í•™ìŠµ (Retraining)"></a>6. ì¬í•™ìŠµ (Retraining)</h2><ul><li>ìƒˆë¡œìš´ ë°ì´í„°ê°€ ë“¤ì–´ì˜¬ ë•Œ ëª¨ë¸ì„ ì¬í•™ìŠµ</li><li>í”¼ì²˜ì™€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ì—¬ ì„±ëŠ¥ ê°œì„ </li></ul><hr><h2 id="7-ë°°í¬-Deployment"><a href="#7-ë°°í¬-Deployment" class="headerlink" title="7. ë°°í¬ (Deployment)"></a>7. ë°°í¬ (Deployment)</h2><ul><li>ëª¨ë¸ì„ ì‹¤ì œ í™˜ê²½ì— ë°°í¬í•˜ì—¬ <strong>ì¶”ë¡ (Inferencing)</strong> ì‹œì‘</li><li><strong>ë°°í¬ ì˜µì…˜</strong>:<ul><li><strong>ì‹¤ì‹œê°„ ì¶”ë¡  (Real-Time)</strong></li><li><strong>ë¹„ë™ê¸° ì¶”ë¡  (Asynchronous)</strong></li><li><strong>ë°°ì¹˜ ì¶”ë¡  (Batch)</strong></li><li><strong>ì„œë²„ë¦¬ìŠ¤ (Serverless)</strong></li><li><strong>ì˜¨í”„ë ˆë¯¸ìŠ¤(On-Premises)</strong></li></ul></li></ul><p>ğŸ‘‰ ì‹œí—˜ í¬ì¸íŠ¸:</p><ul><li>SageMakerëŠ” <strong>ì‹¤ì‹œê°„ ì—”ë“œí¬ì¸íŠ¸</strong>, <strong>ë°°ì¹˜ ë³€í™˜(Batch Transform)</strong>, <strong>Serverless Inference</strong> ëª¨ë‘ ì§€ì›</li></ul><hr><h2 id="8-ëª¨ë‹ˆí„°ë§-Monitoring"><a href="#8-ëª¨ë‹ˆí„°ë§-Monitoring" class="headerlink" title="8. ëª¨ë‹ˆí„°ë§ (Monitoring)"></a>8. ëª¨ë‹ˆí„°ë§ (Monitoring)</h2><ul><li>ëª¨ë¸ì´ ì›í•˜ëŠ” ì„±ëŠ¥ì„ ìœ ì§€í•˜ëŠ”ì§€ ì§€ì†ì ìœ¼ë¡œ í™•ì¸</li><li><strong>ë¬¸ì œ ì¡°ê¸° ê°ì§€ ë° ëŒ€ì‘(Early Detection &amp; Mitigation)</strong></li><li><strong>ëª¨ë¸ ë“œë¦¬í”„íŠ¸(Model Drift)</strong>: ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ë°ì´í„° íŒ¨í„´ì´ ë³€í•˜ë©´ì„œ ëª¨ë¸ ì„±ëŠ¥ì´ ì €í•˜ë˜ëŠ” í˜„ìƒ</li></ul><p>ğŸ‘‰ ì‹œí—˜ í¬ì¸íŠ¸:</p><ul><li><strong>Amazon SageMaker Model Monitor</strong> â†’ ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ìë™í™”</li></ul><hr><h2 id="9-ë°˜ë³µ-Iteration-ê³¼-ìœ ì§€ë³´ìˆ˜"><a href="#9-ë°˜ë³µ-Iteration-ê³¼-ìœ ì§€ë³´ìˆ˜" class="headerlink" title="9. ë°˜ë³µ(Iteration)ê³¼ ìœ ì§€ë³´ìˆ˜"></a>9. ë°˜ë³µ(Iteration)ê³¼ ìœ ì§€ë³´ìˆ˜</h2><ul><li><strong>ëª¨ë¸ ì„±ëŠ¥ ê°œì„  ì‚¬ì´í´</strong>:<ul><li>ìƒˆë¡œìš´ ë°ì´í„° â†’ ì¬í•™ìŠµ â†’ ë°°í¬ â†’ ëª¨ë‹ˆí„°ë§</li></ul></li><li>ìš”êµ¬ì‚¬í•­ê³¼ í™˜ê²½ì€ ì‹œê°„ì´ ì§€ë‚˜ë©´ì„œ ë³€í•¨ â†’ ì§€ì†ì  ê°œì„  í•„ìš”</li><li>ì˜ˆì‹œ: ì˜ë¥˜ ì¶”ì²œ ëª¨ë¸ì€ <strong>10ë…„ í›„ íŒ¨ì…˜ íŠ¸ë Œë“œ ë³€í™”</strong>ì— ë”°ë¼ ìƒˆë¡­ê²Œ í•™ìŠµí•´ì•¼ í•¨</li></ul><hr><h2 id="ì „ì²´-ì›Œí¬í”Œë¡œìš°-ìš”ì•½"><a href="#ì „ì²´-ì›Œí¬í”Œë¡œìš°-ìš”ì•½" class="headerlink" title="ì „ì²´ ì›Œí¬í”Œë¡œìš° ìš”ì•½"></a>ì „ì²´ ì›Œí¬í”Œë¡œìš° ìš”ì•½</h2><ol><li><strong>ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œ ì •ì˜ &amp; KPI ì„¤ì •</strong></li><li><strong>ML ë¬¸ì œë¡œ ì „í™˜</strong></li><li><strong>ë°ì´í„° ìˆ˜ì§‘, ì „ì²˜ë¦¬, í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§</strong></li><li><strong>íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)</strong></li><li><strong>ëª¨ë¸ í•™ìŠµ, íŠœë‹, í‰ê°€</strong></li><li><strong>ì¬í•™ìŠµ ë° ë°˜ë³µ ê°œì„ </strong></li><li><strong>ë°°í¬(ì‹¤ì‹œê°„, ë°°ì¹˜, ì„œë²„ë¦¬ìŠ¤ ë“±)</strong></li><li><strong>ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…</strong></li><li><strong>ì§€ì†ì  ê°œì„  &amp; ìš”êµ¬ì‚¬í•­ ë°˜ì˜</strong></li></ol><p align="center">  <img src="/images/aws_basic_141.png" width="80%"></p><hr><p>âœ… <strong>ì‹œí—˜ ëŒ€ë¹„ í•µì‹¬ í¬ì¸íŠ¸</strong>: - KPI ì •ì˜ê°€ ê°€ì¥ ì²« ë‹¨ê³„</p><ul><li>EDA(íƒìƒ‰ì  ë°ì´í„° ë¶„ì„)ê³¼ ìƒê´€í–‰ë ¬ì˜ ì—­í• </li><li>SageMaker ì£¼ìš” ê¸°ëŠ¥: Training, Tuning, Deployment, Monitoring</li><li>ëª¨ë¸ ë°°í¬ ë°©ì‹: Real-time, Batch, Serverless, On-premises</li><li><strong>ëª¨ë¸ ë“œë¦¬í”„íŠ¸ ê°ì§€ &amp; ì¬í•™ìŠµ</strong> ì¤‘ìš”ì„±</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ë¨¸ì‹ ëŸ¬ë‹-í”„ë¡œì íŠ¸-ë‹¨ê³„-Phases-of-Machine-Learning-Project&quot;&gt;&lt;a href=&quot;#ë¨¸ì‹ ëŸ¬ë‹-í”„ë¡œì íŠ¸-ë‹¨ê³„-Phases-of-Machine-Learning-Project&quot; class=&quot;headerlink&quot; title</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(29) - Phases of a Machine Learning Project</title>
    <link href="https://kish191919.github.io/2025/08/25/AWS-Certified-AI-Practitioner-29/"/>
    <id>https://kish191919.github.io/2025/08/25/AWS-Certified-AI-Practitioner-29/</id>
    <published>2025-08-25T17:33:41.000Z</published>
    <updated>2025-08-25T17:44:54.806Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Phases-of-a-Machine-Learning-Project"><a href="#Phases-of-a-Machine-Learning-Project" class="headerlink" title="Phases of a Machine Learning Project"></a>Phases of a Machine Learning Project</h1><h2 id="1-Define-Business-Goals"><a href="#1-Define-Business-Goals" class="headerlink" title="1. Define Business Goals"></a>1. Define Business Goals</h2><ul><li>Every ML project starts with defining the <strong>business objective</strong>.</li><li><strong>Stakeholders</strong> must agree on:<ul><li>The <strong>value</strong> the project will provide</li><li>The <strong>budget</strong></li><li>The <strong>success criteria</strong></li></ul></li><li><strong>KPI (Key Performance Indicators)</strong> are critical to measure whether<br>the ML model actually achieves business goals.</li></ul><p>ğŸ‘‰ <strong>Exam Tip</strong>: AWS often asks about the importance of KPIs in framing an ML project. The first step is always <strong>business problem definition</strong>, not jumping into training a model.</p><hr><h2 id="2-Frame-the-Problem-as-an-ML-Problem"><a href="#2-Frame-the-Problem-as-an-ML-Problem" class="headerlink" title="2. Frame the Problem as an ML Problem"></a>2. Frame the Problem as an ML Problem</h2><ul><li>Convert the <strong>business problem</strong> into a <strong>machine learning problem</strong>.</li><li>Ask: Is machine learning the right tool? Sometimes rules-based systems are more appropriate.</li><li>Collaboration is key: <strong>data scientists, data engineers, ML architects, and subject matter experts (SMEs)</strong> must all contribute.</li></ul><p>ğŸ‘‰ <strong>Example</strong>:</p><ul><li>Business problem: â€œHow can we reduce customer churn?â€</li><li>ML problem: â€œPredict whether a customer will leave in the next 30 days.â€</li></ul><hr><h2 id="3-Data-Processing"><a href="#3-Data-Processing" class="headerlink" title="3. Data Processing"></a>3. Data Processing</h2><ul><li><strong>Data collection and integration</strong>: Centralize data into a usable location (e.g., Amazon S3).</li><li><strong>Data preprocessing</strong>: Clean, normalize, handle missing values.</li><li><strong>Data visualization</strong>: Understand data patterns and spot anomalies.</li><li><strong>Feature engineering</strong>: Create or transform variables that help the model learn.</li></ul><p>ğŸ‘‰ <strong>AWS Services</strong>:</p><ul><li><strong>AWS Glue</strong> for ETL (extract, transform, load)</li><li><strong>Amazon QuickSight</strong> for visualization</li><li><strong>Amazon S3</strong> for data storage</li></ul><hr><h2 id="4-Exploratory-Data-Analysis-EDA"><a href="#4-Exploratory-Data-Analysis-EDA" class="headerlink" title="4. Exploratory Data Analysis (EDA)"></a>4. Exploratory Data Analysis (EDA)</h2><ul><li><strong>Visualize</strong> data distributions and trends using charts.</li><li><strong>Correlation Matrix</strong>: Measures how strongly variables are related.<ul><li>Example: Study hours â†” Test score correlation of 0.85 shows a strong positive relationship.</li></ul></li><li>Helps you decide which features are most valuable for your model.</li></ul><p align="center">  <img src="/images/aws_basic_142.png" width="80%"></p><p>ğŸ‘‰ <strong>Exam Tip</strong>: Feature selection and correlation analysis often appear in ML exam scenarios.</p><hr><h2 id="5-Model-Development"><a href="#5-Model-Development" class="headerlink" title="5. Model Development"></a>5. Model Development</h2><ul><li><strong>Model training</strong>: Fit the model with training data.</li><li><strong>Model tuning</strong>: Adjust <strong>hyperparameters</strong> (e.g., learning rate, number of trees).</li><li><strong>Model evaluation</strong>: Test against validation or test datasets.</li><li>This process is <strong>iterative</strong>:<ul><li>Go back and improve features.</li><li>Try different algorithms.</li><li>Tune hyperparameters repeatedly.</li></ul></li></ul><p>ğŸ‘‰ <strong>AWS Services</strong>:</p><ul><li><strong>Amazon SageMaker</strong> provides: - Model training</li><li>Automatic hyperparameter tuning</li><li>Built-in evaluation metrics</li></ul><hr><h2 id="6-Retraining"><a href="#6-Retraining" class="headerlink" title="6. Retraining"></a>6. Retraining</h2><ul><li>As new data arrives, retrain the model to keep it relevant.</li><li>Adjust features and hyperparameters based on performance.</li></ul><hr><h2 id="7-Deployment"><a href="#7-Deployment" class="headerlink" title="7. Deployment"></a>7. Deployment</h2><ul><li>Once the model meets goals, it is deployed for predictions (inference).</li><li><strong>Deployment options</strong>:<ul><li><strong>Real-time</strong> (low-latency APIs)</li><li><strong>Batch</strong> (large-scale predictions at once)</li><li><strong>Serverless</strong> (cost-efficient, scalable)</li><li><strong>On-premises</strong> (for compliance or offline needs)</li></ul></li></ul><p>ğŸ‘‰ <strong>AWS Services</strong>:</p><ul><li><strong>SageMaker Endpoints</strong>: real-time inference</li><li><strong>Batch Transform</strong>: batch inference</li><li><strong>Serverless Inference</strong>: scalable, cost-optimized</li></ul><hr><h2 id="8-Monitoring"><a href="#8-Monitoring" class="headerlink" title="8. Monitoring"></a>8. Monitoring</h2><ul><li>Ensure the model maintains expected performance.</li><li><strong>Early detection</strong> of problems such as <strong>model drift</strong> (when new data no longer matches training patterns).</li><li><strong>Debugging</strong> and understanding behavior in production.</li></ul><p>ğŸ‘‰ <strong>AWS Service</strong>:</p><ul><li><strong>SageMaker Model Monitor</strong> automatically detects drift, anomalies, and performance degradation.</li></ul><hr><h2 id="9-Iterations-and-Continuous-Improvement"><a href="#9-Iterations-and-Continuous-Improvement" class="headerlink" title="9. Iterations and Continuous Improvement"></a>9. Iterations and Continuous Improvement</h2><ul><li>ML projects are never â€œone-and-done.â€</li><li>As new data becomes available:<ul><li>Retrain</li><li>Deploy again</li><li>Monitor results</li></ul></li><li>Requirements may change over time.</li><li>Example: A clothing recommendation model must be retrained regularly as fashion trends evolve.</li></ul><p>ğŸ‘‰ <strong>Exam Tip</strong>: AWS emphasizes <strong>continuous retraining and monitoring</strong> to keep ML models accurate and relevant.</p><hr><h2 id="Workflow-Summary"><a href="#Workflow-Summary" class="headerlink" title="Workflow Summary"></a>Workflow Summary</h2><ol><li>Define <strong>business goals</strong> &amp; KPIs</li><li>Frame as an <strong>ML problem</strong></li><li>Collect &amp; process data</li><li>Perform <strong>EDA</strong> and <strong>feature engineering</strong></li><li>Train, tune, and evaluate the model</li><li>Retrain when needed</li><li>Deploy (real-time, batch, serverless, on-prem)</li><li>Monitor performance &amp; drift</li><li>Iterate for continuous improvement</li></ol><p align="center">  <img src="/images/aws_basic_141.png" width="80%"></p><hr><p>âœ… <strong>Key Takeaways for Exams</strong>: - The first step &#x3D; <strong>business goals + KPI definition</strong>.</p><ul><li>EDA and correlation matrices help identify key features.</li><li><strong>SageMaker</strong> supports training, tuning, deployment, and monitoring.</li><li>Know the differences between <strong>real-time vs batch vs serverless</strong> inference.</li><li>Monitoring and retraining are critical due to <strong>model drift</strong>.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Phases-of-a-Machine-Learning-Project&quot;&gt;&lt;a href=&quot;#Phases-of-a-Machine-Learning-Project&quot; class=&quot;headerlink&quot; title=&quot;Phases of a Machine </summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(í•œêµ­ì–´) AWS Certified AI Practitioner (28) - ë¨¸ì‹ ëŸ¬ë‹ ì¶”ë¡ </title>
    <link href="https://kish191919.github.io/2025/08/25/KO-AWS-Certified-AI-Practitioner-28/"/>
    <id>https://kish191919.github.io/2025/08/25/KO-AWS-Certified-AI-Practitioner-28/</id>
    <published>2025-08-25T17:11:46.000Z</published>
    <updated>2025-08-25T17:29:46.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ë¨¸ì‹ ëŸ¬ë‹-â€“-ì¶”ë¡ -Inferencing"><a href="#ë¨¸ì‹ ëŸ¬ë‹-â€“-ì¶”ë¡ -Inferencing" class="headerlink" title="ë¨¸ì‹ ëŸ¬ë‹ â€“ ì¶”ë¡ (Inferencing)"></a>ë¨¸ì‹ ëŸ¬ë‹ â€“ ì¶”ë¡ (Inferencing)</h1><h2 id="1-ì¶”ë¡ ì´ë€"><a href="#1-ì¶”ë¡ ì´ë€" class="headerlink" title="1. ì¶”ë¡ ì´ë€?"></a>1. ì¶”ë¡ ì´ë€?</h2><ul><li><strong>ì¶”ë¡ (Inferencing)</strong>: ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ì´ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´<br>ì˜ˆì¸¡ì„ ë‚´ë¦¬ëŠ” ê³¼ì •\</li><li>**í•™ìŠµ(Training)**ì€ ëª¨ë¸ì´ íŒ¨í„´ì„ ë°°ìš°ëŠ” ê³¼ì •ì´ê³ ,<br>**ì¶”ë¡ (Inferencing)**ì€ í•™ìŠµëœ ì§€ì‹ì„ í™œìš©í•˜ëŠ” ë‹¨ê³„</li></ul><hr><h2 id="2-ì¶”ë¡ ì˜-ë‘-ê°€ì§€-ë°©ì‹"><a href="#2-ì¶”ë¡ ì˜-ë‘-ê°€ì§€-ë°©ì‹" class="headerlink" title="2. ì¶”ë¡ ì˜ ë‘ ê°€ì§€ ë°©ì‹"></a>2. ì¶”ë¡ ì˜ ë‘ ê°€ì§€ ë°©ì‹</h2><h3 id="1-ì‹¤ì‹œê°„-ì¶”ë¡ -Real-Time-Inference"><a href="#1-ì‹¤ì‹œê°„-ì¶”ë¡ -Real-Time-Inference" class="headerlink" title="(1) ì‹¤ì‹œê°„ ì¶”ë¡  (Real-Time Inference)"></a>(1) ì‹¤ì‹œê°„ ì¶”ë¡  (Real-Time Inference)</h3><ul><li>ë°ì´í„°ê°€ ë“¤ì–´ì˜¤ëŠ” ì¦‰ì‹œ ì˜ˆì¸¡ì„ ë‚´ë ¤ì•¼ í•˜ëŠ” ê²½ìš°</li><li><strong>íŠ¹ì§•</strong>:<ul><li>ë¹ ë¥¸ ì†ë„ê°€ ì¤‘ìš” (ì •í™•ë„ë³´ë‹¤ëŠ” ì†ë„ ìš°ì„ )</li><li>ê²°ê³¼ë¥¼ ì¦‰ê°ì ìœ¼ë¡œ ì œê³µí•´ì•¼ í•¨</li></ul></li><li><strong>ì˜ˆì‹œ</strong>: ì±—ë´‡, ìŒì„± ë¹„ì„œ(Alexa, Siri), ì˜¨ë¼ì¸ ì¶”ì²œ ì‹œìŠ¤í…œ</li></ul><p>ğŸ‘‰ AWS ìê²©ì¦ì—ì„œ ìì£¼ ë‚˜ì˜¤ëŠ” í¬ì¸íŠ¸:<br>ì‹¤ì‹œê°„ ì¶”ë¡ ì€ <strong>ì§€ì—°(latency) ìµœì†Œí™”</strong>ê°€ í•µì‹¬. ëª¨ë¸ ì •í™•ë„ê°€ ì¡°ê¸ˆ<br>ë‚®ë”ë¼ë„ <strong>ì¦‰ê°ì ì¸ ì‘ë‹µ</strong>ì´ í•„ìš”í•œ ê²½ìš° ì‚¬ìš©ë¨.</p><hr><h3 id="2-ë°°ì¹˜-ì¶”ë¡ -Batch-Inference"><a href="#2-ë°°ì¹˜-ì¶”ë¡ -Batch-Inference" class="headerlink" title="(2) ë°°ì¹˜ ì¶”ë¡  (Batch Inference)"></a>(2) ë°°ì¹˜ ì¶”ë¡  (Batch Inference)</h3><ul><li>ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ ëª¨ì•„ì„œ í•œ ë²ˆì— ì²˜ë¦¬í•˜ëŠ” ë°©ì‹</li><li><strong>íŠ¹ì§•</strong>:<ul><li>ì†ë„ë³´ë‹¤ëŠ” ì •í™•ì„±ì´ ì¤‘ìš”</li><li>ë¶„ì„ìš©ìœ¼ë¡œ ì£¼ë¡œ ì‚¬ìš©</li><li>ê²°ê³¼ë¥¼ ë°›ê¸°ê¹Œì§€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë ¤ë„ ë¬¸ì œ ì—†ìŒ (ë¶„ â†’ ì‹œ â†’ ì¼ ë‹¨ìœ„ ê°€ëŠ¥)</li></ul></li><li><strong>ì˜ˆì‹œ</strong>: ëŒ€ê·œëª¨ ê³ ê° ë°ì´í„° ë¶„ì„, ë¦¬ìŠ¤í¬ í‰ê°€ ëª¨ë¸</li></ul><p>ğŸ‘‰ ì‹œí—˜ì—ì„œ ìì£¼ ë¬»ëŠ” í¬ì¸íŠ¸:</p><ul><li>ì‹¤ì‹œê°„ vs ë°°ì¹˜ ì¶”ë¡ ì˜ ì°¨ì´ì </li><li><strong>ì‹¤ì‹œê°„ &#x3D; ì†ë„ ì¤‘ì‹œ, ë°°ì¹˜ &#x3D; ì •í™•ì„± ì¤‘ì‹œ</strong></li></ul><p align="center">  <img src="/images/aws_basic_139.png" width="80%"></p><hr><h2 id="3-ì—£ì§€-Edge-ì—ì„œì˜-ì¶”ë¡ "><a href="#3-ì—£ì§€-Edge-ì—ì„œì˜-ì¶”ë¡ " class="headerlink" title="3. ì—£ì§€(Edge)ì—ì„œì˜ ì¶”ë¡ "></a>3. ì—£ì§€(Edge)ì—ì„œì˜ ì¶”ë¡ </h2><h3 id="1-ì—£ì§€-ë””ë°”ì´ìŠ¤ë€"><a href="#1-ì—£ì§€-ë””ë°”ì´ìŠ¤ë€" class="headerlink" title="(1) ì—£ì§€ ë””ë°”ì´ìŠ¤ë€?"></a>(1) ì—£ì§€ ë””ë°”ì´ìŠ¤ë€?</h3><ul><li>ë°ì´í„°ê°€ ìƒì„±ë˜ëŠ” ê°€ê¹Œìš´ ìœ„ì¹˜ì— ìˆëŠ” ì¥ì¹˜ë“¤\</li><li>ì¼ë°˜ì ìœ¼ë¡œ <strong>ì»´í“¨íŒ… íŒŒì›Œê°€ ì œí•œì </strong>ì´ê³ , <strong>ì¸í„°ë„· ì—°ê²°ì´ ë¶ˆì•ˆì •</strong>í• <br>ìˆ˜ ìˆìŒ\</li><li>ì˜ˆì‹œ: IoT ì„¼ì„œ, CCTV, ë¼ì¦ˆë² ë¦¬ íŒŒì´, ìŠ¤ë§ˆíŠ¸í°</li></ul><hr><h3 id="2-ì†Œí˜•-ì–¸ì–´-ëª¨ë¸-SLM-Small-Language-Model"><a href="#2-ì†Œí˜•-ì–¸ì–´-ëª¨ë¸-SLM-Small-Language-Model" class="headerlink" title="(2) ì†Œí˜• ì–¸ì–´ ëª¨ë¸ (SLM, Small Language Model)"></a>(2) ì†Œí˜• ì–¸ì–´ ëª¨ë¸ (SLM, Small Language Model)</h3><ul><li><strong>ì—£ì§€ ë””ë°”ì´ìŠ¤ì—ì„œ ì§ì ‘ ì‹¤í–‰ ê°€ëŠ¥</strong>\</li><li><strong>íŠ¹ì§•</strong>:<ul><li><strong>ì§€ì—° ì‹œê°„ì´ ë§¤ìš° ë‚®ìŒ</strong> (ì¸í„°ë„· í†µì‹  ë¶ˆí•„ìš”, ë¡œì»¬ ì‹¤í–‰)\</li><li><strong>ì»´í“¨íŒ… ìì› ì†Œëª¨ ì ìŒ</strong>\</li><li><strong>ì˜¤í”„ë¼ì¸ ìƒíƒœì—ì„œë„ ì¶”ë¡  ê°€ëŠ¥</strong>\</li></ul></li><li><strong>ì˜ˆì‹œ</strong>: ìŠ¤ë§ˆíŠ¸í° ë²ˆì—­ ì•±, ì˜¤í”„ë¼ì¸ ì´ë¯¸ì§€ ì¸ì‹</li></ul><hr><h3 id="3-ëŒ€í˜•-ì–¸ì–´-ëª¨ë¸-LLM-Large-Language-Model"><a href="#3-ëŒ€í˜•-ì–¸ì–´-ëª¨ë¸-LLM-Large-Language-Model" class="headerlink" title="(3) ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ (LLM, Large Language Model)"></a>(3) ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ (LLM, Large Language Model)</h3><ul><li><strong>ì›ê²© ì„œë²„ì—ì„œ ì‹¤í–‰</strong>\</li><li><strong>íŠ¹ì§•</strong>:<ul><li>ë” ê°•ë ¥í•œ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥\</li><li>ë‹¤ë§Œ, <strong>ì¸í„°ë„· ì—°ê²° í•„ìš”</strong>\</li><li><strong>ì§€ì—° ì‹œê°„(ë„¤íŠ¸ì›Œí¬ ì™•ë³µ)</strong> ë°œìƒ\</li></ul></li><li><strong>ì˜ˆì‹œ</strong>: ChatGPT, Amazon Bedrock ê°™ì€ í´ë¼ìš°ë“œ ê¸°ë°˜ AI</li></ul><p>ğŸ‘‰ ì‹œí—˜ í¬ì¸íŠ¸:\</p><ul><li><strong>ì—£ì§€ì—ì„œì˜ ì¶”ë¡ </strong>ì€ <strong>SLM â†’ ì†ë„, ì˜¤í”„ë¼ì¸ ê°€ëŠ¥</strong>\</li><li><strong>í´ë¼ìš°ë“œ LLM â†’ ì„±ëŠ¥ ìš°ìˆ˜í•˜ì§€ë§Œ ì§€ì—°ê³¼ ì¸í„°ë„· ì˜ì¡´ë„ ìˆìŒ</strong>\</li><li>ë¬¸ì œì—ì„œ â€œì¸í„°ë„· ì—°ê²° ë¶ˆì•ˆì •, ì˜¤í”„ë¼ì¸ í™˜ê²½â€ì´ ë‚˜ì˜¤ë©´ <strong>SLM</strong> ì •ë‹µ!\</li><li>â€œê³ ì„±ëŠ¥ ëª¨ë¸, ë³µì¡í•œ ì—°ì‚° í•„ìš”â€ê°€ ë‚˜ì˜¤ë©´ <strong>LLM</strong> ì„ íƒ</li></ul><p align="center">  <img src="/images/aws_basic_140.png" width="80%"></p><hr><h2 id="4-ì‹œí—˜-ëŒ€ë¹„-ì •ë¦¬-Trade-off-ë¹„êµ"><a href="#4-ì‹œí—˜-ëŒ€ë¹„-ì •ë¦¬-Trade-off-ë¹„êµ" class="headerlink" title="4. ì‹œí—˜ ëŒ€ë¹„ ì •ë¦¬ (Trade-off ë¹„êµ)"></a>4. ì‹œí—˜ ëŒ€ë¹„ ì •ë¦¬ (Trade-off ë¹„êµ)</h2><hr><p>  êµ¬ë¶„     ì‹¤ì‹œê°„ ì¶”ë¡        ë°°ì¹˜ ì¶”ë¡       SLM(ì—£ì§€)       LLM(ì„œë²„)</p><hr><p>  ì†ë„     ë§¤ìš° ë¹ ë¦„         ëŠë ¤ë„ OK      ë§¤ìš° ë¹ ë¦„       ì¸í„°ë„· ì§€ì—°<br>                                            (ë¡œì»¬)          ë°œìƒ</p><p>  ì •í™•ë„   ë‹¤ì†Œ ë‚®ì„ ìˆ˜ ìˆìŒ ìµœëŒ€í•œ ë†’ìŒ    ëª¨ë¸ í¬ê¸°       ë†’ìŒ<br>                                            ì œí•œìœ¼ë¡œ ë‚®ìŒ   </p><p>  í™˜ê²½     ì±—ë´‡, ìŒì„±ë¹„ì„œ    ë°ì´í„° ë¶„ì„,   ì˜¤í”„ë¼ì¸ IoT,   í´ë¼ìš°ë“œ AI<br>                             ë¦¬ìŠ¤í¬ ëª¨ë¸    ìŠ¤ë§ˆíŠ¸í°        ì„œë¹„ìŠ¤</p><h2 id="ì¸í„°ë„·-O-O-X-O-í•„ìš”"><a href="#ì¸í„°ë„·-O-O-X-O-í•„ìš”" class="headerlink" title="  ì¸í„°ë„·   O                 O              X               O  í•„ìš”                                                      "></a>  ì¸í„°ë„·   O                 O              X               O<br>  í•„ìš”                                                      </h2><hr><h2 id="5-ì¶”ê°€ë¡œ-ì•Œì•„ë‘ë©´-ì¢‹ì€-ì‹œí—˜-í¬ì¸íŠ¸"><a href="#5-ì¶”ê°€ë¡œ-ì•Œì•„ë‘ë©´-ì¢‹ì€-ì‹œí—˜-í¬ì¸íŠ¸" class="headerlink" title="5. ì¶”ê°€ë¡œ ì•Œì•„ë‘ë©´ ì¢‹ì€ ì‹œí—˜ í¬ì¸íŠ¸"></a>5. ì¶”ê°€ë¡œ ì•Œì•„ë‘ë©´ ì¢‹ì€ ì‹œí—˜ í¬ì¸íŠ¸</h2><ul><li><strong>AWS ê´€ë ¨ ì„œë¹„ìŠ¤ì™€ ì—°ê²°</strong>:<ul><li><strong>Amazon SageMaker</strong>: ì‹¤ì‹œê°„&#x2F;ë°°ì¹˜ ì¶”ë¡  ëª¨ë‘ ì§€ì›</li><li><strong>Amazon Bedrock</strong>: ì„œë²„ ê¸°ë°˜ LLM ì‹¤í–‰</li><li><strong>AWS IoT Greengrass</strong>: ì—£ì§€ ë””ë°”ì´ìŠ¤ì—ì„œ ëª¨ë¸ ì‹¤í–‰ ê°€ëŠ¥</li></ul></li><li><strong>ì‹œí—˜ ë¬¸ì œ ì˜ˆì‹œ</strong>:<ul><li>â€œí•œ ê³µì¥ì—ì„œ ì¸í„°ë„· ì—°ê²°ì´ ìì£¼ ëŠê¸°ëŠ”ë°, ì¥ì¹˜ì—ì„œ ë°ì´í„°ë¥¼<br>ë¶„ì„í•´ì•¼ í•œë‹¤. ì–´ë–¤ ì¶”ë¡  ë°©ì‹ì„ ì„ íƒí• ê¹Œ?â€ â†’ <strong>ì—£ì§€ ì¶”ë¡ , SLM</strong>\</li><li>â€œìˆ˜ë°±ë§Œ ê±´ì˜ ê³ ê° ë¡œê·¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ì„ ì§„í–‰í•˜ê³ , ê²°ê³¼ëŠ” í•˜ë£¨<br>ë’¤ì— ë°›ì•„ë„ ê´œì°®ë‹¤.â€ â†’ <strong>ë°°ì¹˜ ì¶”ë¡ </strong>\</li><li>â€œê³ ê°ì´ ì…ë ¥í•œ ì§ˆë¬¸ì— ì¦‰ê° ë‹µë³€í•´ì•¼ í•œë‹¤.â€ â†’ <strong>ì‹¤ì‹œê°„ ì¶”ë¡ </strong>\</li><li>â€œë” ì •í™•í•œ ê²°ê³¼ê°€ í•„ìš”í•˜ê³ , ì¸í„°ë„· ì—°ê²°ì´ ì•ˆì •ì ì´ë‹¤.â€ â†’ <strong>LLM<br>ì›ê²© ì„œë²„</strong></li></ul></li></ul><hr><p>ğŸ‘‰ ìš”ì•½:\</p><ul><li><strong>ì‹¤ì‹œê°„ ì¶”ë¡  &#x3D; ì†ë„ ìš°ì„ , ì±—ë´‡</strong>\</li><li><strong>ë°°ì¹˜ ì¶”ë¡  &#x3D; ì •í™•ë„ ìš°ì„ , ëŒ€ê·œëª¨ ë¶„ì„</strong>\</li><li><strong>SLM(ì—£ì§€) &#x3D; ë¹ ë¦„ + ì˜¤í”„ë¼ì¸ ê°€ëŠ¥</strong>\</li><li><strong>LLM(ì„œë²„) &#x3D; ê°•ë ¥í•˜ì§€ë§Œ ì¸í„°ë„· í•„ìš”, ì§€ì—° ì¡´ì¬</strong></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ë¨¸ì‹ ëŸ¬ë‹-â€“-ì¶”ë¡ -Inferencing&quot;&gt;&lt;a href=&quot;#ë¨¸ì‹ ëŸ¬ë‹-â€“-ì¶”ë¡ -Inferencing&quot; class=&quot;headerlink&quot; title=&quot;ë¨¸ì‹ ëŸ¬ë‹ â€“ ì¶”ë¡ (Inferencing)&quot;&gt;&lt;/a&gt;ë¨¸ì‹ ëŸ¬ë‹ â€“ ì¶”ë¡ (Inferencing)</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(28) - Machine Learning Inferencing</title>
    <link href="https://kish191919.github.io/2025/08/25/AWS-Certified-AI-Practitioner-28/"/>
    <id>https://kish191919.github.io/2025/08/25/AWS-Certified-AI-Practitioner-28/</id>
    <published>2025-08-25T17:10:35.000Z</published>
    <updated>2025-08-25T17:29:46.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Machine-Learning-â€“-Inferencing"><a href="#Machine-Learning-â€“-Inferencing" class="headerlink" title="Machine Learning â€“ Inferencing"></a>Machine Learning â€“ Inferencing</h1><h2 id="1-What-is-Inferencing"><a href="#1-What-is-Inferencing" class="headerlink" title="1. What is Inferencing?"></a>1. What is Inferencing?</h2><ul><li><strong>Inferencing</strong> is when a trained model makes predictions on <strong>new unseen data</strong>.</li><li>Training &#x3D; teaching the model.</li><li>Inferencing &#x3D; applying what the model has learned to make<br>predictions.</li></ul><hr><h2 id="2-Two-Types-of-Inferencing"><a href="#2-Two-Types-of-Inferencing" class="headerlink" title="2. Two Types of Inferencing"></a>2. Two Types of Inferencing</h2><h3 id="1-Real-Time-Inference"><a href="#1-Real-Time-Inference" class="headerlink" title="(1) Real-Time Inference"></a>(1) Real-Time Inference</h3><ul><li>Predictions are made <strong>instantly</strong> as new data arrives.</li><li><strong>Key Points</strong>:<ul><li><strong>Speed is more important than perfect accuracy</strong>.</li><li>Users expect immediate responses.</li></ul></li><li><strong>Examples</strong>:<ul><li>Chatbots (customer service bots, Alexa, Siri)</li><li>Fraud detection while processing a payment</li></ul></li></ul><p>ğŸ‘‰ <strong>Exam Tip</strong>: Real-time inference is required when <strong>low latency (fast response)</strong> is critical. Accuracy may be slightly lower, but immediate results are necessary.</p><hr><h3 id="2-Batch-Inference"><a href="#2-Batch-Inference" class="headerlink" title="(2) Batch Inference"></a>(2) Batch Inference</h3><ul><li>Predictions are made on <strong>large datasets all at once</strong>.</li><li><strong>Key Points</strong>:<ul><li>Processing can take <strong>minutes, hours, or days</strong>.</li><li><strong>Accuracy is more important than speed</strong>.</li><li>Often used for large-scale analysis.</li></ul></li><li><strong>Examples</strong>:<ul><li>Analyzing millions of customer transactions overnight</li><li>Generating product recommendations for all users at once</li></ul></li></ul><p>ğŸ‘‰ <strong>Exam Tip</strong>: Batch inference is chosen when <strong>speed is not critical</strong>, but <strong>accuracy and completeness</strong> are more important.</p><p align="center">  <img src="/images/aws_basic_139.png" width="80%"></p><hr><h2 id="3-Inferencing-at-the-Edge"><a href="#3-Inferencing-at-the-Edge" class="headerlink" title="3. Inferencing at the Edge"></a>3. Inferencing at the Edge</h2><h3 id="1-What-is-the-Edge"><a href="#1-What-is-the-Edge" class="headerlink" title="(1) What is the Edge?"></a>(1) What is the Edge?</h3><ul><li><strong>Edge devices</strong> are close to where the data is generated.</li><li>Usually have <strong>limited computing power</strong> and may operate with<br><strong>unreliable internet</strong>.</li><li>Examples: IoT sensors, Raspberry Pi, mobile devices, smart cameras.</li></ul><hr><h3 id="2-Small-Language-Models-SLM-on-Edge-Devices"><a href="#2-Small-Language-Models-SLM-on-Edge-Devices" class="headerlink" title="(2) Small Language Models (SLM) on Edge Devices"></a>(2) Small Language Models (SLM) on Edge Devices</h3><ul><li><strong>Run locally on small devices</strong>.</li><li><strong>Key Points</strong>:<ul><li>Very low latency (no internet call required).</li><li>Low compute footprint (uses fewer resources).</li><li>Can work <strong>offline</strong>.</li></ul></li><li><strong>Example</strong>:<ul><li>A smartphone running an offline translation app.</li></ul></li></ul><hr><h3 id="3-Large-Language-Models-LLM-on-Remote-Servers"><a href="#3-Large-Language-Models-LLM-on-Remote-Servers" class="headerlink" title="(3) Large Language Models (LLM) on Remote Servers"></a>(3) Large Language Models (LLM) on Remote Servers</h3><ul><li><strong>Run on powerful cloud servers (not on the device itself)</strong>.</li><li><strong>Key Points</strong>:<ul><li>Can handle <strong>complex tasks</strong> and provide <strong>better accuracy</strong>.</li><li>Requires internet connection.</li><li>Has higher latency (waiting for API response).</li></ul></li><li><strong>Example</strong>:<ul><li>Amazon Bedrock hosting a large model, with the edge device sending API requests.</li></ul></li></ul><p>ğŸ‘‰ <strong>Exam Tip</strong>:\</p><ul><li>Use <strong>SLM on edge</strong> if: - Low latency and offline capability are required.</li><li>The device has limited internet connectivity.</li><li>Use <strong>LLM on the cloud</strong> if: - You need higher accuracy and more powerful computation.</li><li>Internet connectivity is reliable.</li></ul><p align="center">  <img src="/images/aws_basic_140.png" width="80%"></p><hr><h2 id="4-Trade-Off-Comparison"><a href="#4-Trade-Off-Comparison" class="headerlink" title="4. Trade-Off Comparison"></a>4. Trade-Off Comparison</h2><hr><p>  Type           Real-Time Inference    Batch Inference   SLM (Edge)   LLM (Cloud)</p><hr><p>  <strong>Speed</strong>      Instant                Slow              Instant      Slower<br>                                        (minutesâ€“days)   (local)      (network<br>                                                                       latency)</p><p>  <strong>Accuracy</strong>   May be lower           High accuracy     Limited by   High<br>                                                          model size   </p><p>  <strong>Use Case</strong>   Chatbots, fraud        Data analytics,   IoT, mobile  Cloud AI<br>                 detection              reporting         apps         services</p><h2 id="Internet-Yes-Yes-No-Yes-Needed"><a href="#Internet-Yes-Yes-No-Yes-Needed" class="headerlink" title="  Internet     Yes                    Yes               No           Yes  Needed                                                             "></a>  <strong>Internet     Yes                    Yes               No           Yes<br>  Needed</strong>                                                             </h2><hr><h2 id="5-AWS-Services-for-Inferencing"><a href="#5-AWS-Services-for-Inferencing" class="headerlink" title="5. AWS Services for Inferencing"></a>5. AWS Services for Inferencing</h2><ul><li><strong>Amazon SageMaker</strong>:<ul><li>Supports <strong>real-time endpoints</strong> and <strong>batch transform jobs</strong>.</li></ul></li><li><strong>Amazon Bedrock</strong>:<ul><li>Provides <strong>LLMs as a managed service</strong> for inference.</li></ul></li><li><strong>AWS IoT Greengrass</strong>:<ul><li>Runs <strong>models locally</strong> on IoT edge devices.</li></ul></li></ul><p>ğŸ‘‰ <strong>Common Exam Questions</strong>: 1. <em>A factory with unreliable internet wants to analyze data on-site.</em> â†’ <strong>Edge + SLM</strong><br>2. <em>You need to process millions of records overnight for an analytics report.</em> â†’ <strong>Batch inference</strong><br>3. <em>A chatbot must respond instantly to user queries.</em> â†’ <strong>Real-time inference</strong><br>4. <em>You want maximum accuracy and can rely on cloud connectivity.</em> â†’ <strong>LLM on a remote server</strong></p><hr><p>âœ… <strong>Summary</strong>:</p><ul><li><strong>Real-time inference</strong> &#x3D; speed matters (chatbots, fraud detection).</li><li><strong>Batch inference</strong> &#x3D; accuracy matters (large-scale analytics).</li><li><strong>SLM on edge</strong> &#x3D; fast, offline, resource-efficient.</li><li><strong>LLM in cloud</strong> &#x3D; powerful, but requires internet and higher latency.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Machine-Learning-â€“-Inferencing&quot;&gt;&lt;a href=&quot;#Machine-Learning-â€“-Inferencing&quot; class=&quot;headerlink&quot; title=&quot;Machine Learning â€“ Inferencing&quot;&gt;</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(27) - Model Evaluation - Classification &amp; Regression</title>
    <link href="https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-27/"/>
    <id>https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-27/</id>
    <published>2025-08-24T00:55:13.000Z</published>
    <updated>2025-08-24T01:05:14.597Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ“Š-Model-Evaluation-â€“-Classification-Regression"><a href="#ğŸ“Š-Model-Evaluation-â€“-Classification-Regression" class="headerlink" title="ğŸ“Š Model Evaluation â€“ Classification &amp; Regression"></a>ğŸ“Š Model Evaluation â€“ Classification &amp; Regression</h1><p>When building ML models, itâ€™s not enough to just train themâ€”you also<br>need to evaluate how good they are. Different problems (classification<br>vs regression) use different metrics. Letâ€™s break it down.</p><hr><h2 id="ğŸ”¹-Binary-Classification-Example-â€“-Confusion-Matrix"><a href="#ğŸ”¹-Binary-Classification-Example-â€“-Confusion-Matrix" class="headerlink" title="ğŸ”¹ Binary Classification Example â€“ Confusion Matrix"></a>ğŸ”¹ Binary Classification Example â€“ Confusion Matrix</h2><p>A <strong>confusion matrix</strong> compares actual labels (truth) with the modelâ€™s<br>predictions.</p><ul><li><strong>True Positive (TP):</strong> predicted positive, actually positive\</li><li><strong>False Positive (FP):</strong> predicted positive, actually negative\</li><li><strong>True Negative (TN):</strong> predicted negative, actually negative\</li><li><strong>False Negative (FN):</strong> predicted negative, actually positive</li></ul><p>ğŸ‘‰ Goal: maximize TP and TN, minimize FP and FN.</p><p align="center">  <img src="/images/aws_basic_135.png" width="80%"></p><h3 id="Key-Metrics"><a href="#Key-Metrics" class="headerlink" title="Key Metrics"></a>Key Metrics</h3><ul><li><p><strong>Precision &#x3D; TP &#x2F; (TP + FP)</strong><br><em>â€œOf all predicted positives, how many were actually positive?â€</em><br>Best when <strong>false positives are costly</strong> (e.g., diagnosing a healthy<br>person as sick).</p></li><li><p><strong>Recall &#x3D; TP &#x2F; (TP + FN)</strong><br><em>â€œOf all actual positives, how many did we correctly identify?â€</em><br>Best when <strong>false negatives are costly</strong> (e.g., missing a cancer<br>diagnosis).</p></li><li><p><strong>F1 Score &#x3D; 2 Ã— (Precision Ã— Recall) &#x2F; (Precision + Recall)</strong><br>Harmonic mean of precision and recall.<br>Best for <strong>imbalanced datasets</strong> where accuracy alone is misleading.</p></li><li><p><strong>Accuracy &#x3D; (TP + TN) &#x2F; (All predictions)</strong><br>Useful only for <strong>balanced datasets</strong>.<br>Example: If 95% of emails are â€œnot spam,â€ a model that always<br>predicts â€œnot spamâ€ has 95% accuracy but is useless.</p></li></ul><p align="center">  <img src="/images/aws_basic_136.png" width="80%"></p><hr><h2 id="ğŸ”¹-AUC-ROC-Area-Under-the-Curve-â€“-Receiver-Operator-Curve"><a href="#ğŸ”¹-AUC-ROC-Area-Under-the-Curve-â€“-Receiver-Operator-Curve" class="headerlink" title="ğŸ”¹ AUC-ROC (Area Under the Curve â€“ Receiver Operator Curve)"></a>ğŸ”¹ AUC-ROC (Area Under the Curve â€“ Receiver Operator Curve)</h2><ul><li>Plots <strong>True Positive Rate (Sensitivity&#x2F;Recall)</strong> vs <strong>False<br>Positive Rate (1 - Specificity)</strong> at various thresholds.\</li><li><strong>AUC value ranges from 0 to 1.</strong><ul><li><strong>1.0 &#x3D; perfect model</strong>\</li><li><strong>0.5 &#x3D; random guessing</strong></li></ul></li></ul><p>ğŸ‘‰ Business use case: choose a threshold that balances precision and<br>recall for your needs (fraud detection, medical tests, etc.).<br>ğŸ“Œ <strong>Exam Tip:</strong> Remember AUC-ROC helps compare multiple models and find<br>the best threshold.</p><p align="center">  <img src="/images/aws_basic_137.png" width="80%"></p><hr><h2 id="ğŸ”¹-Regression-Model-Metrics"><a href="#ğŸ”¹-Regression-Model-Metrics" class="headerlink" title="ğŸ”¹ Regression Model Metrics"></a>ğŸ”¹ Regression Model Metrics</h2><p>For regression (continuous predictions, e.g., house prices, stock<br>values), we measure <strong>errors</strong>:</p><ul><li><p><strong>MAE (Mean Absolute Error):</strong> average absolute difference between<br>prediction and truth.<br>â†’ Easy to interpret: â€œOn average, the model is off by X units.â€</p></li><li><p><strong>MAPE (Mean Absolute Percentage Error):</strong> average error as a<br>percentage.<br>â†’ Useful when scale of values matters (e.g., sales forecasts).</p></li><li><p><strong>RMSE (Root Mean Squared Error):</strong> penalizes large errors more<br>heavily than MAE.<br>â†’ Common when big mistakes are unacceptable.</p></li><li><p><strong>RÂ² (Coefficient of Determination):</strong> measures how much variance in<br>the target is explained by the model.</p><ul><li>RÂ² &#x3D; 0.8 â†’ 80% of variation is explained by features, 20% by<br>noise&#x2F;other factors.\</li><li>RÂ² close to 1 &#x3D; strong model.</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_138.png" width="80%"></p><hr><h2 id="ğŸ”¹-Example-Regression-Metrics-in-Action"><a href="#ğŸ”¹-Example-Regression-Metrics-in-Action" class="headerlink" title="ğŸ”¹ Example (Regression Metrics in Action)"></a>ğŸ”¹ Example (Regression Metrics in Action)</h2><p>You predict student test scores based on study hours:</p><ul><li><strong>RMSE &#x3D; 5</strong> â†’ model predictions are ~5 points off on average.\</li><li><strong>RÂ² &#x3D; 0.8</strong> â†’ 80% of score differences explained by study hours,<br>20% due to natural ability or luck.</li></ul><hr><h2 id="âœ…-Key-Takeaways-Exam-Perspective"><a href="#âœ…-Key-Takeaways-Exam-Perspective" class="headerlink" title="âœ… Key Takeaways (Exam Perspective)"></a>âœ… Key Takeaways (Exam Perspective)</h2><ul><li><strong>Classification models â†’ Confusion Matrix, Precision, Recall, F1,<br>Accuracy, AUC-ROC</strong>\</li><li><strong>Regression models â†’ MAE, MAPE, RMSE, RÂ²</strong>\</li><li><strong>Choose metrics based on business need:</strong><ul><li>Precision for costly false positives\</li><li>Recall for costly false negatives\</li><li>F1 for imbalanced data\</li><li>Accuracy only for balanced datasets</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ“Š-Model-Evaluation-â€“-Classification-Regression&quot;&gt;&lt;a href=&quot;#ğŸ“Š-Model-Evaluation-â€“-Classification-Regression&quot; class=&quot;headerlink&quot; title</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(í•œêµ­ì–´) AWS Certified AI Practitioner (27) - ì´ì§„ ë¶„ë¥˜ì™€ í˜¼ë™ í–‰ë ¬ (Confusion Matrix)</title>
    <link href="https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-27/"/>
    <id>https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-27/</id>
    <published>2025-08-24T00:55:08.000Z</published>
    <updated>2025-08-25T17:10:15.641Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ“Š-Model-Evaluation-in-Machine-Learning"><a href="#ğŸ“Š-Model-Evaluation-in-Machine-Learning" class="headerlink" title="ğŸ“Š Model Evaluation in Machine Learning"></a>ğŸ“Š Model Evaluation in Machine Learning</h1><p>ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ë§Œë“¤ì—ˆì„ ë•Œ, <strong>ì„±ëŠ¥ì´ ì˜ ë‚˜ì˜¤ëŠ”ì§€</strong>ë¥¼ í™•ì¸í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.<br>ì´ë•Œ <strong>ë¶„ë¥˜(Classification)</strong> ëª¨ë¸ê³¼ <strong>íšŒê·€(Regression)</strong> ëª¨ë¸ì˜ í‰ê°€ ë°©ì‹ì´ ë‹¤ë¥´ë¯€ë¡œ êµ¬ë¶„í•´ì„œ ì•Œì•„ë‘ì–´ì•¼ í•©ë‹ˆë‹¤.</p><hr><h2 id="ğŸ”¹-ì´ì§„-ë¶„ë¥˜-Binary-Classification-ì™€-í˜¼ë™-í–‰ë ¬-Confusion-Matrix"><a href="#ğŸ”¹-ì´ì§„-ë¶„ë¥˜-Binary-Classification-ì™€-í˜¼ë™-í–‰ë ¬-Confusion-Matrix" class="headerlink" title="ğŸ”¹ ì´ì§„ ë¶„ë¥˜ (Binary Classification)ì™€ í˜¼ë™ í–‰ë ¬ (Confusion Matrix)"></a>ğŸ”¹ ì´ì§„ ë¶„ë¥˜ (Binary Classification)ì™€ í˜¼ë™ í–‰ë ¬ (Confusion Matrix)</h2><h3 id="Confusion-Matrixë€"><a href="#Confusion-Matrixë€" class="headerlink" title="Confusion Matrixë€?"></a>Confusion Matrixë€?</h3><ul><li>ì‹¤ì œ ì •ë‹µ(ë¼ë²¨)ê³¼ ëª¨ë¸ ì˜ˆì¸¡ê°’ì„ ë¹„êµí•´ì„œ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë„êµ¬  </li><li>ë„¤ ê°€ì§€ ê°’ìœ¼ë¡œ ë‚˜ë‰©ë‹ˆë‹¤:</li></ul><table><thead><tr><th>êµ¬ë¶„</th><th>ì˜ˆì¸¡ Positive</th><th>ì˜ˆì¸¡ Negative</th></tr></thead><tbody><tr><td>ì‹¤ì œ Positive</td><td><strong>True Positive (TP)</strong></td><td><strong>False Negative (FN)</strong></td></tr><tr><td>ì‹¤ì œ Negative</td><td><strong>False Positive (FP)</strong></td><td><strong>True Negative (TN)</strong></td></tr></tbody></table><p>ğŸ‘‰ ëª©í‘œ: <strong>TPì™€ TNì„ ìµœëŒ€í™”</strong>í•˜ê³ , <strong>FPì™€ FNì„ ìµœì†Œí™”</strong>í•˜ëŠ” ê²ƒ.</p><p align="center">  <img src="/images/aws_basic_135.png" width="80%"></p><hr><h3 id="ì£¼ìš”-í‰ê°€-ì§€í‘œ-Classification-Metrics"><a href="#ì£¼ìš”-í‰ê°€-ì§€í‘œ-Classification-Metrics" class="headerlink" title="ì£¼ìš” í‰ê°€ ì§€í‘œ (Classification Metrics)"></a>ì£¼ìš” í‰ê°€ ì§€í‘œ (Classification Metrics)</h3><ul><li><p><strong>Precision (ì •ë°€ë„)</strong>  </p><ul><li>ê³µì‹: TP &#x2F; (TP + FP)  </li><li>â€œPositiveë¼ê³  ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ì—ì„œ, ì‹¤ì œë¡œ Positiveì¸ ë¹„ìœ¨â€  </li><li>**False Positive(ì˜ëª»ëœ ì–‘ì„± ì˜ˆì¸¡)**ì´ ì¹˜ëª…ì ì¸ ê²½ìš° ì¤‘ìš”  </li><li>ì˜ˆ: ìŠ¤íŒ¸ í•„í„°ì—ì„œ ì •ìƒ ë©”ì¼ì„ ìŠ¤íŒ¸ìœ¼ë¡œ ì˜ëª» ë¶„ë¥˜í•˜ë©´ ì•ˆ ë¨</li></ul></li><li><p><strong>Recall (ì¬í˜„ìœ¨, ë¯¼ê°ë„)</strong>  </p><ul><li>ê³µì‹: TP &#x2F; (TP + FN)  </li><li>â€œì‹¤ì œ Positive ì¤‘ì—ì„œ, ì œëŒ€ë¡œ ë§ì¶˜ ë¹„ìœ¨â€  </li><li>**False Negative(ë†“ì¹œ ì¼€ì´ìŠ¤)**ê°€ ì¹˜ëª…ì ì¸ ê²½ìš° ì¤‘ìš”  </li><li>ì˜ˆ: ì•” ì§„ë‹¨ ëª¨ë¸ì—ì„œ í™˜ìë¥¼ â€œì •ìƒâ€ìœ¼ë¡œ ì˜ëª» ë¶„ë¥˜í•˜ë©´ ì•ˆ ë¨</li></ul></li><li><p><strong>F1 Score</strong>  </p><ul><li>ê³µì‹: 2 Ã— (Precision Ã— Recall) &#x2F; (Precision + Recall)  </li><li>Precisionê³¼ Recallì˜ <strong>ê· í˜•ì„ í‰ê°€</strong>  </li><li>íŠ¹íˆ **ë°ì´í„°ê°€ ë¶ˆê· í˜•(imbalanced dataset)**í•  ë•Œ ìœ ìš©</li></ul></li><li><p><strong>Accuracy (ì •í™•ë„)</strong>  </p><ul><li>ê³µì‹: (TP + TN) &#x2F; ì „ì²´ ë°ì´í„°  </li><li>ë‹¨ìˆœíˆ â€œì–¼ë§ˆë‚˜ ë§ì·„ëŠ”ê°€â€  </li><li>ë°ì´í„°ê°€ <strong>ê· í˜• ì¡íŒ ê²½ìš°</strong>ì—ë§Œ ì˜ë¯¸ ìˆìŒ  </li><li>ì˜ˆ: 95%ê°€ Negativeì¸ ë°ì´í„°ì—ì„œ Accuracy 95% â†’ ì“¸ëª¨ì—†ëŠ” ì§€í‘œ</li></ul></li></ul><p>ğŸ“Œ <strong>ì‹œí—˜ íŒ</strong>:  </p><ul><li><strong>Precision â†’ FPê°€ ë¹„ìŒ€ ë•Œ</strong>  </li><li><strong>Recall â†’ FNì´ ë¹„ìŒ€ ë•Œ</strong>  </li><li><strong>F1 â†’ ë¶ˆê· í˜• ë°ì´í„°ì…‹ì—ì„œ ê· í˜• í‰ê°€</strong>  </li><li><strong>Accuracy â†’ ë°ì´í„°ê°€ ê· í˜•ì¼ ë•Œë§Œ</strong></li></ul><p align="center">  <img src="/images/aws_basic_136.png" width="80%"></p><hr><h2 id="ğŸ”¹-AUC-ROC-Area-Under-the-Curve-Receiver-Operating-Characteristic"><a href="#ğŸ”¹-AUC-ROC-Area-Under-the-Curve-Receiver-Operating-Characteristic" class="headerlink" title="ğŸ”¹ AUC-ROC (Area Under the Curve - Receiver Operating Characteristic)"></a>ğŸ”¹ AUC-ROC (Area Under the Curve - Receiver Operating Characteristic)</h2><ul><li><strong>0 ~ 1 ì‚¬ì´ ê°’</strong>, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì™„ë²½í•œ ëª¨ë¸  </li><li>ì¶•:  <ul><li>Xì¶• â†’ False Positive Rate (1 - Specificity)  </li><li>Yì¶• â†’ True Positive Rate (Sensitivity, Recall)</li></ul></li><li>ì—¬ëŸ¬ Threshold(ì„ê³„ê°’)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ Confusion Matrixë¥¼ ë§Œë“¤ê³  ê³¡ì„ ì„ ê·¸ë¦¼  </li><li>AUC &#x3D; ROC Curve ì•„ë˜ ë©´ì </li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>:  </p><ul><li>AUCê°€ í´ìˆ˜ë¡ ëª¨ë¸ì´ ì¢‹ì€ ê²ƒ  </li><li>ë‹¤ì–‘í•œ ì„ê³„ê°’ì„ ë¹„êµí•  ë•Œ í™œìš©</li></ul><p align="center">  <img src="/images/aws_basic_137.png" width="80%"></p><hr><h2 id="ğŸ”¹-íšŒê·€-ëª¨ë¸-í‰ê°€-ì§€í‘œ-Regression-Metrics"><a href="#ğŸ”¹-íšŒê·€-ëª¨ë¸-í‰ê°€-ì§€í‘œ-Regression-Metrics" class="headerlink" title="ğŸ”¹ íšŒê·€ ëª¨ë¸ í‰ê°€ ì§€í‘œ (Regression Metrics)"></a>ğŸ”¹ íšŒê·€ ëª¨ë¸ í‰ê°€ ì§€í‘œ (Regression Metrics)</h2><p>íšŒê·€ ëª¨ë¸ì€ <strong>ì—°ì†ì ì¸ ê°’</strong>ì„ ì˜ˆì¸¡í•˜ê¸° ë•Œë¬¸ì— í‰ê°€ ë°©ì‹ì´ ë‹¤ë¦…ë‹ˆë‹¤.</p><ul><li><p><strong>MAE (Mean Absolute Error)</strong>  </p><ul><li>ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ì°¨ì´ì˜ ì ˆëŒ“ê°’ í‰ê·   </li><li>ì§ê´€ì ì´ê³  í•´ì„í•˜ê¸° ì‰¬ì›€  </li><li>ì˜ˆ: MAE &#x3D; 5 â†’ í‰ê· ì ìœ¼ë¡œ 5ì  ì°¨ì´ ë°œìƒ</li></ul></li><li><p><strong>MAPE (Mean Absolute Percentage Error)</strong>  </p><ul><li>í¼ì„¼íŠ¸ ê¸°ì¤€ ì˜¤ì°¨ìœ¨  </li><li>ê°’ì˜ í¬ê¸°ê°€ ë‹¤ì–‘í•  ë•Œ ìƒëŒ€ì  ì˜¤ë¥˜ë¥¼ ë³´ë ¤ë©´ ì‚¬ìš©</li></ul></li><li><p><strong>RMSE (Root Mean Squared Error)</strong>  </p><ul><li>ì˜¤ì°¨ë¥¼ ì œê³± í›„ í‰ê·  ë‚´ê³  ì œê³±ê·¼ì„ ì·¨í•¨  </li><li>í° ì˜¤ì°¨ì— ë” ë¯¼ê° â†’ ëª¨ë¸ ì•ˆì •ì„± í‰ê°€ì— ìœ ìš©</li></ul></li><li><p><strong>RÂ² (R-Squared, ê²°ì •ê³„ìˆ˜)</strong>  </p><ul><li>ëª¨ë¸ì´ ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ì„¤ëª…í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ„  </li><li>ê°’ì´ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ì€ ëª¨ë¸  </li><li>ì˜ˆ: RÂ² &#x3D; 0.8 â†’ ëª¨ë¸ì´ 80%ë¥¼ ì„¤ëª…, ë‚˜ë¨¸ì§€ 20%ëŠ” ë‹¤ë¥¸ ìš”ì¸</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_138.png" width="80%"></p><p>ğŸ“Œ <strong>ì‹œí—˜ íŒ</strong>:  </p><ul><li>ë¶„ë¥˜(Classification) â†’ Precision, Recall, F1, Accuracy, AUC-ROC  </li><li>íšŒê·€(Regression) â†’ MAE, MAPE, RMSE, RÂ²</li></ul><hr><h1 id="âœ…-ì •ë¦¬-ì‹œí—˜-ëŒ€ë¹„-í•µì‹¬"><a href="#âœ…-ì •ë¦¬-ì‹œí—˜-ëŒ€ë¹„-í•µì‹¬" class="headerlink" title="âœ… ì •ë¦¬ (ì‹œí—˜ ëŒ€ë¹„ í•µì‹¬)"></a>âœ… ì •ë¦¬ (ì‹œí—˜ ëŒ€ë¹„ í•µì‹¬)</h1><ul><li><strong>Classification í‰ê°€ ì§€í‘œ</strong>: Confusion Matrix, Precision, Recall, F1, Accuracy, AUC-ROC  </li><li><strong>Regression í‰ê°€ ì§€í‘œ</strong>: MAE, MAPE, RMSE, RÂ²  </li><li><strong>Precision â†” Recall Trade-off</strong> ê¸°ì–µí•˜ê¸° (íŠ¹íˆ ì‹œí—˜ì— ìì£¼ ì¶œì œ)</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ“Š-Model-Evaluation-in-Machine-Learning&quot;&gt;&lt;a href=&quot;#ğŸ“Š-Model-Evaluation-in-Machine-Learning&quot; class=&quot;headerlink&quot; title=&quot;ğŸ“Š Model Evalu</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(í•œêµ­ì–´) AWS Certified AI Practitioner (26) - ëª¨ë¸ ì í•©ë„ì™€ í¸í–¥ &amp; ë¶„ì‚°</title>
    <link href="https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-26/"/>
    <id>https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-26/</id>
    <published>2025-08-24T00:39:04.000Z</published>
    <updated>2025-08-24T01:05:14.598Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ¤–-ëª¨ë¸-ì í•©ë„-Model-Fit-ì™€-í¸í–¥-Bias-Â·-ë¶„ì‚°-Variance"><a href="#ğŸ¤–-ëª¨ë¸-ì í•©ë„-Model-Fit-ì™€-í¸í–¥-Bias-Â·-ë¶„ì‚°-Variance" class="headerlink" title="ğŸ¤– ëª¨ë¸ ì í•©ë„(Model Fit)ì™€ í¸í–¥(Bias) Â· ë¶„ì‚°(Variance)"></a>ğŸ¤– ëª¨ë¸ ì í•©ë„(Model Fit)ì™€ í¸í–¥(Bias) Â· ë¶„ì‚°(Variance)</h1><h2 id="1-ëª¨ë¸-ì í•©ë„-Model-Fit"><a href="#1-ëª¨ë¸-ì í•©ë„-Model-Fit" class="headerlink" title="1. ëª¨ë¸ ì í•©ë„(Model Fit)"></a>1. ëª¨ë¸ ì í•©ë„(Model Fit)</h2><p>ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì´ ì œëŒ€ë¡œ ë™ì‘í•˜ì§€ ì•Šì„ ë•ŒëŠ” <strong>ëª¨ë¸ì˜ ì í•©ë„(Fit)</strong> ë¥¼ ì‚´í´ë´ì•¼ í•©ë‹ˆë‹¤.<br>ëª¨ë¸ì´ ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ì„¤ëª…í•˜ëŠ”ì§€ê°€ í•µì‹¬ì…ë‹ˆë‹¤.  </p><ul><li><p><strong>ê³¼ì í•©(Overfitting)</strong>  </p><ul><li>í›ˆë ¨ ë°ì´í„°ì—ì„œëŠ” ì„±ëŠ¥ì´ ë§¤ìš° ì¢‹ìŒ  </li><li>ìƒˆë¡œìš´ ë°ì´í„°(ê²€ì¦&#x2F;í…ŒìŠ¤íŠ¸ ë°ì´í„°)ì—ì„œëŠ” ì„±ëŠ¥ì´ ë‚˜ì¨  </li><li>ì›ì¸: ëª¨ë¸ì´ ë°ì´í„°ì˜ <strong>ë…¸ì´ì¦ˆê¹Œì§€ í•™ìŠµ</strong>í•´ì„œ ì¼ë°˜í™”ê°€ ì•ˆ ë¨  </li><li>ğŸ“Œ ì˜ˆì‹œ: í›ˆë ¨ ë°ì´í„° ì  í•˜ë‚˜í•˜ë‚˜ì— ë§ê²Œ ì„ ì„ êµ¬ë¶€ë ¤ ë§Œë“  ë³µì¡í•œ ê³¡ì„ </li></ul></li><li><p><strong>ê³¼ì†Œì í•©(Underfitting)</strong>  </p><ul><li>í›ˆë ¨ ë°ì´í„°ì—ì„œë„ ì„±ëŠ¥ì´ ë‚˜ì¨  </li><li>ì›ì¸: ëª¨ë¸ì´ ë„ˆë¬´ ë‹¨ìˆœí•˜ê±°ë‚˜, íŠ¹ì§•(Feature)ì´ ë¶€ì¡±í•¨  </li><li>ğŸ“Œ ì˜ˆì‹œ: ë³µì¡í•œ ê³¡ì„  ë°ì´í„°ì— ë‹¨ìˆœ ì§ì„ ì„ ì–µì§€ë¡œ ì ìš©</li></ul></li><li><p><strong>ê· í˜•(Balanced)</strong>  </p><ul><li>ê³¼ì í•©ë„, ê³¼ì†Œì í•©ë„ ì•„ë‹Œ ìƒíƒœ  </li><li>ì–´ëŠ ì •ë„ ì˜¤ì°¨ëŠ” ìˆì§€ë§Œ, ë°ì´í„°ì˜ ì „ì²´ì ì¸ íŒ¨í„´ì„ ì˜ ë”°ë¦„  </li><li>ğŸ“Œ ê°€ì¥ ì´ìƒì ì¸ ìƒí™©</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_129.png" width="80%"></p><hr><h2 id="2-í¸í–¥-Bias-ê³¼-ë¶„ì‚°-Variance"><a href="#2-í¸í–¥-Bias-ê³¼-ë¶„ì‚°-Variance" class="headerlink" title="2. í¸í–¥(Bias)ê³¼ ë¶„ì‚°(Variance)"></a>2. í¸í–¥(Bias)ê³¼ ë¶„ì‚°(Variance)</h2><h3 id="ğŸ“Œ-Bias-í¸í–¥"><a href="#ğŸ“Œ-Bias-í¸í–¥" class="headerlink" title="ğŸ“Œ Bias (í¸í–¥)"></a>ğŸ“Œ Bias (í¸í–¥)</h3><ul><li><strong>ì •ì˜</strong>: ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’ì˜ ì°¨ì´  </li><li><strong>High Bias (í¸í–¥ ë†’ìŒ)</strong>  <ul><li>ëª¨ë¸ì´ ë°ì´í„° íŒ¨í„´ì„ ì˜ ì¡ì§€ ëª»í•¨ â†’ ê³¼ì†Œì í•©  </li><li>ì˜ˆì‹œ: ê³¡ì„  íŒ¨í„´ ë°ì´í„°ë¥¼ ì§ì„ ìœ¼ë¡œ ì˜ˆì¸¡</li></ul></li><li><strong>ì¤„ì´ëŠ” ë°©ë²•</strong>  <ul><li>ë” ë³µì¡í•œ ëª¨ë¸ ì‚¬ìš© (ì˜ˆ: ì„ í˜• â†’ ë¹„ì„ í˜• ëª¨ë¸)  </li><li>ë” ë§ì€ íŠ¹ì§•(Feature) ì¶”ê°€</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_130.png" width="80%"></p><hr><h3 id="ğŸ“Œ-Variance-ë¶„ì‚°"><a href="#ğŸ“Œ-Variance-ë¶„ì‚°" class="headerlink" title="ğŸ“Œ Variance (ë¶„ì‚°)"></a>ğŸ“Œ Variance (ë¶„ì‚°)</h3><ul><li><strong>ì •ì˜</strong>: í›ˆë ¨ ë°ì´í„°ë¥¼ ì¡°ê¸ˆë§Œ ë°”ê¿”ë„ ëª¨ë¸ ì„±ëŠ¥ì´ í¬ê²Œ ë‹¬ë¼ì§€ëŠ” ì •ë„  </li><li><strong>High Variance (ë¶„ì‚° ë†’ìŒ)</strong>  <ul><li>í›ˆë ¨ ë°ì´í„°ì—ì„œëŠ” ì„±ëŠ¥ì´ ë§¤ìš° ì¢‹ì§€ë§Œ, ìƒˆë¡œìš´ ë°ì´í„°ì—ì„œëŠ” ì„±ëŠ¥ì´ ê¸‰ê²©íˆ ë–¨ì–´ì§  </li><li>ì¦‰, ê³¼ì í•© ìƒí™©</li></ul></li><li><strong>ì¤„ì´ëŠ” ë°©ë²•</strong>  <ul><li>ë¶ˆí•„ìš”í•œ íŠ¹ì§• ì œê±° (Feature Selection)  </li><li>ë°ì´í„°ì…‹ì„ ì—¬ëŸ¬ ë²ˆ ë‚˜ëˆ ì„œ êµì°¨ê²€ì¦(Cross Validation) ìˆ˜í–‰  </li><li>ì •ê·œí™”(Regularization, ì˜ˆ: L1&#x2F;L2) ì ìš©</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_131.png" width="80%"></p><hr><h2 id="3-Bias-Variance-Tradeoff-í¸í–¥-ë¶„ì‚°-íŠ¸ë ˆì´ë“œì˜¤í”„"><a href="#3-Bias-Variance-Tradeoff-í¸í–¥-ë¶„ì‚°-íŠ¸ë ˆì´ë“œì˜¤í”„" class="headerlink" title="3. Bias-Variance Tradeoff (í¸í–¥-ë¶„ì‚° íŠ¸ë ˆì´ë“œì˜¤í”„)"></a>3. Bias-Variance Tradeoff (í¸í–¥-ë¶„ì‚° íŠ¸ë ˆì´ë“œì˜¤í”„)</h2><p>ë¨¸ì‹ ëŸ¬ë‹ì—ì„œëŠ” <strong>Bias(í¸í–¥)</strong> ê³¼ <strong>Variance(ë¶„ì‚°)</strong> ì‚¬ì´ì—ì„œ ê· í˜•ì„ ë§ì¶”ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.</p><ul><li><strong>High Bias + Low Variance â†’ ê³¼ì†Œì í•©</strong></li><li><strong>Low Bias + High Variance â†’ ê³¼ì í•©</strong></li><li><strong>Low Bias + Low Variance â†’ ì´ìƒì ì¸ ëª¨ë¸</strong></li><li><strong>High Bias + High Variance â†’ ìµœì•…ì˜ ê²½ìš° (í”¼í•´ì•¼ í•¨)</strong></li></ul><p>ğŸ“Œ ì‹œí—˜ í¬ì¸íŠ¸:  </p><ul><li>ê³¼ì í•© â†” ë¶„ì‚° ë†’ìŒ (Variance High)  </li><li>ê³¼ì†Œì í•© â†” í¸í–¥ ë†’ìŒ (Bias High)  </li><li>ê· í˜• ì¡íŒ ëª¨ë¸ì´ ê°€ì¥ ì¢‹ì€ ìƒíƒœ</li></ul><p align="center">  <img src="/images/aws_basic_132.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_133.png" width="80%"></p><hr><h2 id="4-ì‹œê°ì -ì´í•´-ë‹¤íŠ¸íŒ-ì˜ˆì‹œ-ğŸ¯"><a href="#4-ì‹œê°ì -ì´í•´-ë‹¤íŠ¸íŒ-ì˜ˆì‹œ-ğŸ¯" class="headerlink" title="4. ì‹œê°ì  ì´í•´ (ë‹¤íŠ¸íŒ ì˜ˆì‹œ ğŸ¯)"></a>4. ì‹œê°ì  ì´í•´ (ë‹¤íŠ¸íŒ ì˜ˆì‹œ ğŸ¯)</h2><ul><li><strong>í¸í–¥(Bias)</strong>: ë‹¤íŠ¸ê°€ ê³¼ë…ì˜ ì¤‘ì‹¬ì—ì„œ ì–¼ë§ˆë‚˜ ë–¨ì–´ì ¸ ìˆëŠ”ì§€  </li><li><strong>ë¶„ì‚°(Variance)</strong>: ë‹¤íŠ¸ê°€ í©ì–´ì ¸ ìˆëŠ” ì •ë„</li></ul><table><thead><tr><th>êµ¬ë¶„</th><th>ì„¤ëª…</th><th>ê²°ê³¼</th></tr></thead><tbody><tr><td>High Bias + Low Variance</td><td>ê³„ì† ê°™ì€ ìœ„ì¹˜ì— ë§ì¶”ì§€ë§Œ ì¤‘ì‹¬ì—ì„œ ë©‚</td><td>Underfitting</td></tr><tr><td>Low Bias + High Variance</td><td>ì¤‘ì‹¬ ê·¼ì²˜ì— ë§ì¶”ì§€ë§Œ í©ì–´ì ¸ ìˆìŒ</td><td>Overfitting</td></tr><tr><td>Low Bias + Low Variance</td><td>ì¤‘ì‹¬ì— ê°€ê¹ê³  ëª¨ì—¬ ìˆìŒ</td><td>Best Model</td></tr><tr><td>High Bias + High Variance</td><td>ë©€ë¦¬ ìˆê³  í©ì–´ì ¸ ìˆìŒ</td><td>Worst Model</td></tr></tbody></table><hr><h2 id="âœ…-ì‹œí—˜-ëŒ€ë¹„-Key-Takeaways"><a href="#âœ…-ì‹œí—˜-ëŒ€ë¹„-Key-Takeaways" class="headerlink" title="âœ… ì‹œí—˜ ëŒ€ë¹„ Key Takeaways"></a>âœ… ì‹œí—˜ ëŒ€ë¹„ Key Takeaways</h2><ol><li><strong>Overfitting</strong> â†’ í›ˆë ¨ ë°ì´í„° ì˜ ë§ì¶¤, í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„±ëŠ¥ ë‚˜ì¨ â†’ Variance â†‘  </li><li><strong>Underfitting</strong> â†’ í›ˆë ¨ ë°ì´í„°ì¡°ì°¨ ì„±ëŠ¥ ë‚˜ì¨ â†’ Bias â†‘  </li><li><strong>Balanced Fit</strong> â†’ Biasì™€ Variance ëª¨ë‘ ë‚®ì•„ì•¼ í•¨  </li><li><strong>Bias-Variance Tradeoff</strong> ê°œë… ìˆ™ì§€ í•„ìˆ˜  </li><li>AWS ìê²©ì¦ ì‹œí—˜ì—ì„œëŠ” <strong>ê³¼ì í•© &#x2F; ê³¼ì†Œì í•©ì„ ì–´ë–»ê²Œ í•´ê²°í• ì§€</strong>ë¥¼ ë¬¼ì„ ìˆ˜ ìˆìŒ  <ul><li>ê³¼ì í•© í•´ê²°: Regularization, Feature Selection, Cross Validation  </li><li>ê³¼ì†Œì í•© í•´ê²°: ë” ë³µì¡í•œ ëª¨ë¸, Feature ì¶”ê°€</li></ul></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ¤–-ëª¨ë¸-ì í•©ë„-Model-Fit-ì™€-í¸í–¥-Bias-Â·-ë¶„ì‚°-Variance&quot;&gt;&lt;a href=&quot;#ğŸ¤–-ëª¨ë¸-ì í•©ë„-Model-Fit-ì™€-í¸í–¥-Bias-Â·-ë¶„ì‚°-Variance&quot; class=&quot;headerlink&quot; title=&quot;ğŸ¤– ëª¨ë¸ </summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(26) - Model Fit, Bias, and Variance</title>
    <link href="https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-26/"/>
    <id>https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-26/</id>
    <published>2025-08-24T00:39:00.000Z</published>
    <updated>2025-08-24T01:02:42.203Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ“Š-Model-Fit-Bias-and-Variance"><a href="#ğŸ“Š-Model-Fit-Bias-and-Variance" class="headerlink" title="ğŸ“Š Model Fit, Bias, and Variance"></a>ğŸ“Š Model Fit, Bias, and Variance</h1><p>When a machine learning model performs poorly, one of the first things<br>to check is whether itâ€™s a <strong>good fit</strong> for the data. This is often<br>discussed in terms of <strong>overfitting</strong>, <strong>underfitting</strong>, and<br><strong>balance</strong>.</p><hr><h2 id="âœ…-Model-Fit"><a href="#âœ…-Model-Fit" class="headerlink" title="âœ… Model Fit"></a>âœ… Model Fit</h2><h3 id="ğŸ”¹-Overfitting"><a href="#ğŸ”¹-Overfitting" class="headerlink" title="ğŸ”¹ Overfitting"></a>ğŸ”¹ Overfitting</h3><ul><li>The model performs <strong>very well</strong> on training data.\</li><li>But performs <strong>poorly</strong> on evaluation or unseen test data.\</li><li>Example: A line that connects every single training point perfectly<br>â€” great for training, useless for new data.\</li><li>Common when the model is <strong>too complex</strong> and â€œmemorizesâ€ instead of<br>generalizing.</li></ul><h3 id="ğŸ”¹-Underfitting"><a href="#ğŸ”¹-Underfitting" class="headerlink" title="ğŸ”¹ Underfitting"></a>ğŸ”¹ Underfitting</h3><ul><li>The model performs poorly even on training data.\</li><li>Often happens when the model is <strong>too simple</strong> (e.g., a straight<br>line for data that is clearly non-linear).\</li><li>Can also be caused by <strong>poor features</strong>.</li></ul><h3 id="ğŸ”¹-Balanced-Fit"><a href="#ğŸ”¹-Balanced-Fit" class="headerlink" title="ğŸ”¹ Balanced Fit"></a>ğŸ”¹ Balanced Fit</h3><ul><li>Neither overfitting nor underfitting.\</li><li>The model generalizes well: some error is expected, but predictions<br>follow the data trend.\</li><li><strong>Goal: Low training error + low test error.</strong></li></ul><p>ğŸ‘‰ <strong>AWS Exam Tip</strong>: You might get questions asking which situation<br>describes <em>overfitting vs.Â underfitting</em>. Remember:\</p><ul><li><strong>Overfitting â†’ High variance problem.</strong>\</li><li><strong>Underfitting â†’ High bias problem.</strong></li></ul><p align="center">  <img src="/images/aws_basic_129.png" width="80%"></p><hr><h2 id="âš–ï¸-Bias-and-Variance"><a href="#âš–ï¸-Bias-and-Variance" class="headerlink" title="âš–ï¸ Bias and Variance"></a>âš–ï¸ Bias and Variance</h2><p>Bias and variance help explain why models underfit or overfit.</p><h3 id="ğŸ”¹-Bias"><a href="#ğŸ”¹-Bias" class="headerlink" title="ğŸ”¹ Bias"></a>ğŸ”¹ Bias</h3><ul><li>Difference between <strong>predicted values</strong> and <strong>actual values</strong>.\</li><li>High Bias &#x3D; model is too simple â†’ canâ€™t capture the pattern.\</li><li>Example: Using linear regression on a clearly curved dataset.\</li><li>Considered <strong>underfitting</strong>.</li></ul><p><strong>How to reduce bias:</strong> - Use a <strong>more complex model</strong> (e.g., move from<br>linear regression to decision trees or neural networks).\</p><ul><li>Add more <strong>features</strong> (better input data).</li></ul><p align="center">  <img src="/images/aws_basic_130.png" width="80%"></p><hr><h3 id="ğŸ”¹-Variance"><a href="#ğŸ”¹-Variance" class="headerlink" title="ğŸ”¹ Variance"></a>ğŸ”¹ Variance</h3><ul><li>Describes how much the modelâ€™s predictions change if trained on<br>different (but similar) datasets.\</li><li>High Variance &#x3D; model is <strong>too sensitive</strong> to training data<br>changes.\</li><li>Typical in <strong>overfitting</strong> cases.</li></ul><p><strong>How to reduce variance:</strong> - Feature selection (keep fewer, more<br>important features).\</p><ul><li>Use <strong>cross-validation</strong> (split data into train&#x2F;test multiple times).\</li><li>Regularization techniques (e.g., L1&#x2F;L2 penalties).</li></ul><p align="center">  <img src="/images/aws_basic_131.png" width="80%"></p><hr><h2 id="ğŸ¯-Putting-It-All-Together"><a href="#ğŸ¯-Putting-It-All-Together" class="headerlink" title="ğŸ¯ Putting It All Together"></a>ğŸ¯ Putting It All Together</h2><ul><li><strong>High Bias, Low Variance</strong> â†’ Underfitting (too simple).\</li><li><strong>Low Bias, High Variance</strong> â†’ Overfitting (too complex).\</li><li><strong>High Bias, High Variance</strong> â†’ Bad model (donâ€™t use it).\</li><li><strong>Low Bias, Low Variance</strong> â†’ Balanced (ideal).</li></ul><h3 id="ğŸ¯-Visual-Analogy-â€“-Dartboard-ğŸ¯"><a href="#ğŸ¯-Visual-Analogy-â€“-Dartboard-ğŸ¯" class="headerlink" title="ğŸ¯ Visual Analogy â€“ Dartboard ğŸ¯"></a>ğŸ¯ Visual Analogy â€“ Dartboard ğŸ¯</h3><ul><li><strong>High Bias</strong>: All darts clustered far from the bullseye<br>(consistently wrong).\</li><li><strong>High Variance</strong>: Darts scattered everywhere (inconsistent).\</li><li><strong>Balanced</strong>: Darts tightly grouped near the bullseye.</li></ul><p align="center">  <img src="/images/aws_basic_132.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_133.png" width="80%"></p><hr><h2 id="ğŸ”‘-Key-Takeaways-Exam-Focused"><a href="#ğŸ”‘-Key-Takeaways-Exam-Focused" class="headerlink" title="ğŸ”‘ Key Takeaways (Exam-Focused)"></a>ğŸ”‘ Key Takeaways (Exam-Focused)</h2><ul><li><strong>Overfitting</strong> &#x3D; High variance problem â†’ fix with simpler models or<br>regularization.\</li><li><strong>Underfitting</strong> &#x3D; High bias problem â†’ fix with more complex models<br>or better features.\</li><li><strong>Balanced models</strong> generalize well.\</li><li>AWS exams often test your understanding of these tradeoffs when<br>evaluating ML models.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ“Š-Model-Fit-Bias-and-Variance&quot;&gt;&lt;a href=&quot;#ğŸ“Š-Model-Fit-Bias-and-Variance&quot; class=&quot;headerlink&quot; title=&quot;ğŸ“Š Model Fit, Bias, and Variance</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(25) - Reinforcement Learning</title>
    <link href="https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-25/"/>
    <id>https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-25/</id>
    <published>2025-08-24T00:17:27.000Z</published>
    <updated>2025-08-24T00:33:26.299Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ§ -Reinforcement-Learning-RL-RLHF"><a href="#ğŸ§ -Reinforcement-Learning-RL-RLHF" class="headerlink" title="ğŸ§  Reinforcement Learning (RL) &amp; RLHF"></a>ğŸ§  Reinforcement Learning (RL) &amp; RLHF</h1><h2 id="1-What-is-Reinforcement-Learning-RL"><a href="#1-What-is-Reinforcement-Learning-RL" class="headerlink" title="1. What is Reinforcement Learning (RL)?"></a>1. What is Reinforcement Learning (RL)?</h2><p>Reinforcement Learning is a type of machine learning where an <strong>agent</strong><br>learns to make decisions by interacting with an <strong>environment</strong> and<br>maximizing rewards.</p><ul><li><strong>Agent</strong> â†’ the learner or decision-maker (e.g., a robot, software<br>bot).\</li><li><strong>Environment</strong> â†’ the external system the agent interacts with<br>(e.g., a maze, stock market).\</li><li><strong>State</strong> â†’ the current situation of the environment.\</li><li><strong>Action</strong> â†’ the choice the agent makes.\</li><li><strong>Reward</strong> â†’ feedback (positive or negative) from the environment.\</li><li><strong>Policy</strong> â†’ the strategy the agent follows to decide its next<br>action.</li></ul><p>ğŸ‘‰ <strong>Exam Tip:</strong> RL is less common in AWS certification questions, but<br>you may see it in contexts like <strong>robotics, gaming, or reinforcement<br>learning from human feedback (RLHF)</strong> in generative AI.</p><p align="center">  <img src="/images/aws_basic_123.png" width="80%"></p><hr><h2 id="2-How-Does-RL-Work"><a href="#2-How-Does-RL-Work" class="headerlink" title="2. How Does RL Work?"></a>2. How Does RL Work?</h2><ol><li>The agent observes the <strong>current state</strong>.\</li><li>It selects an <strong>action</strong> based on its <strong>policy</strong>.\</li><li>The environment transitions to a <strong>new state</strong> and gives a<br><strong>reward</strong>.\</li><li>The agent updates its <strong>policy</strong> to improve future actions.</li></ol><p>ğŸ¯ Goal: <strong>Maximize cumulative rewards over time.</strong></p><p align="center">  <img src="/images/aws_basic_124.png" width="80%"></p><hr><h2 id="3-Example-Robot-in-a-Maze"><a href="#3-Example-Robot-in-a-Maze" class="headerlink" title="3. Example: Robot in a Maze"></a>3. Example: Robot in a Maze</h2><ul><li><strong>Agent:</strong> Robot\</li><li><strong>Environment:</strong> Maze\</li><li><strong>Actions:</strong> Move up, down, left, right\</li><li><strong>Rewards:</strong><ul><li><code>-1</code> for taking a step\</li><li><code>-10</code> for hitting a wall\</li><li><code>+100</code> for reaching the exit</li></ul></li></ul><p>ğŸ‘‰ Over time, the robot learns the best path to the exit by trial and<br>error.</p><p align="center">  <img src="/images/aws_basic_125.png" width="80%"></p><p>ğŸ‘‰ Click the image or link to watch the video: <a href="https://youtu.be/2tamH76Tjvw">AI Learns to Escape</a></p><hr><h2 id="4-Applications-of-Reinforcement-Learning"><a href="#4-Applications-of-Reinforcement-Learning" class="headerlink" title="4. Applications of Reinforcement Learning"></a>4. Applications of Reinforcement Learning</h2><ul><li><strong>Gaming</strong> â†’ Chess, Go, StarCraft\</li><li><strong>Robotics</strong> â†’ navigation, object manipulation\</li><li><strong>Finance</strong> â†’ portfolio management, trading strategies\</li><li><strong>Healthcare</strong> â†’ personalized treatment recommendations\</li><li><strong>Autonomous Vehicles</strong> â†’ path planning and decision-making</li></ul><p>ğŸ‘‰ <strong>Exam Tip:</strong> AWS exams might frame RL in <strong>autonomous systems</strong> or<br><strong>AI training optimization</strong> contexts.</p><hr><h2 id="5-What-is-RLHF-Reinforcement-Learning-from-Human-Feedback"><a href="#5-What-is-RLHF-Reinforcement-Learning-from-Human-Feedback" class="headerlink" title="5. What is RLHF? (Reinforcement Learning from Human Feedback)"></a>5. What is RLHF? (Reinforcement Learning from Human Feedback)</h2><p>RLHF is widely used in <strong>Generative AI</strong> (like GPT models).<br>It combines <strong>reinforcement learning</strong> with <strong>human feedback</strong> to better<br>align AI with human goals.</p><ul><li>In standard RL, rewards are fixed (e.g., +100 for reaching the<br>exit).\</li><li>In RLHF, <strong>humans help define the reward function</strong> by ranking<br>outputs.</li></ul><p>Example:\</p><ul><li>Machine translation â†’ â€œtechnically correctâ€ vs.Â â€œnatural-soundingâ€<br>translation.\</li><li>Humans score the responses â†’ model learns to prefer human-preferred<br>outputs.</li></ul><hr><h2 id="6-How-Does-RLHF-Work"><a href="#6-How-Does-RLHF-Work" class="headerlink" title="6. How Does RLHF Work?"></a>6. How Does RLHF Work?</h2><ol><li><strong>Data Collection</strong> â†’ Create human prompts + responses.<ul><li>Example: â€œWhere is the HR department in Boston?â€\</li></ul></li><li><strong>Supervised Fine-Tuning</strong> â†’ Train a base model with labeled<br>responses.\</li><li><strong>Reward Model Creation</strong> â†’ Humans rank multiple responses â†’ AI<br>learns a <strong>reward model</strong>.\</li><li><strong>Optimization</strong> â†’ Use the reward model to further train the base<br>model with reinforcement learning.</li></ol><p>ğŸ”„ This process can be repeated and eventually <strong>automated</strong>.</p><p align="center">  <img src="/images/aws_basic_128.png" width="80%"></p><hr><h2 id="7-Why-is-RLHF-Important"><a href="#7-Why-is-RLHF-Important" class="headerlink" title="7. Why is RLHF Important?"></a>7. Why is RLHF Important?</h2><ul><li>Aligns AI systems with <strong>human preferences</strong>.\</li><li>Used in <strong>LLMs (Large Language Models)</strong> like ChatGPT, Anthropic<br>Claude, and others.\</li><li>Improves quality, safety, and usefulness of responses.</li></ul><p>ğŸ‘‰ <strong>Exam Tip:</strong><br>If you see <strong>â€œhuman feedbackâ€</strong> or <strong>â€œreward modelâ€</strong>, the answer is<br>likely <strong>RLHF</strong>.</p><hr><h2 id="âœ…-Key-Takeaways"><a href="#âœ…-Key-Takeaways" class="headerlink" title="âœ… Key Takeaways"></a>âœ… Key Takeaways</h2><ul><li><strong>Reinforcement Learning (RL):</strong> Agent learns via trial and error to<br>maximize cumulative reward.\</li><li><strong>Applications:</strong> Games, robotics, finance, healthcare, autonomous<br>vehicles.\</li><li><strong>RLHF:</strong> Human feedback is added to the reward function â†’ critical<br>in modern LLMs.\</li><li><strong>Exam Strategy:</strong> Focus less on math and more on <strong>concepts +<br>applications</strong>.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ§ -Reinforcement-Learning-RL-RLHF&quot;&gt;&lt;a href=&quot;#ğŸ§ -Reinforcement-Learning-RL-RLHF&quot; class=&quot;headerlink&quot; title=&quot;ğŸ§  Reinforcement Learning </summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(í•œêµ­ì–´) AWS Certified AI Practitioner (25) - ê°•í™”í•™ìŠµ</title>
    <link href="https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-25/"/>
    <id>https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-25/</id>
    <published>2025-08-24T00:17:22.000Z</published>
    <updated>2025-08-25T15:50:22.993Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ§ -ê°•í™”í•™ìŠµ-Reinforcement-Learning-RL-ê³¼-RLHF-ì‰½ê²Œ-ì´í•´í•˜ê¸°"><a href="#ğŸ§ -ê°•í™”í•™ìŠµ-Reinforcement-Learning-RL-ê³¼-RLHF-ì‰½ê²Œ-ì´í•´í•˜ê¸°" class="headerlink" title="ğŸ§  ê°•í™”í•™ìŠµ(Reinforcement Learning, RL)ê³¼ RLHF ì‰½ê²Œ ì´í•´í•˜ê¸°"></a>ğŸ§  ê°•í™”í•™ìŠµ(Reinforcement Learning, RL)ê³¼ RLHF ì‰½ê²Œ ì´í•´í•˜ê¸°</h1><h2 id="1-ê°•í™”í•™ìŠµì´ë€"><a href="#1-ê°•í™”í•™ìŠµì´ë€" class="headerlink" title="1. ê°•í™”í•™ìŠµì´ë€?"></a>1. ê°•í™”í•™ìŠµì´ë€?</h2><p>ê°•í™”í•™ìŠµ(RL)ì€ <strong>í™˜ê²½(Environment)</strong> ì†ì—ì„œ **ì—ì´ì „íŠ¸(Agent)**ê°€<br>í–‰ë™(Action)ì„ ìˆ˜í–‰í•˜ë©´ì„œ ë³´ìƒ(Reward)ì„ ì–»ê³ , ì¥ê¸°ì ìœ¼ë¡œ ëˆ„ì  ë³´ìƒì„<br>ê·¹ëŒ€í™”í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë²•ì…ë‹ˆë‹¤.</p><ul><li><strong>í•µì‹¬ ê°œë…</strong><ul><li><strong>Agent</strong>: í•™ìŠµì ë˜ëŠ” ì˜ì‚¬ê²°ì •ì (ì˜ˆ: ë¡œë´‡)</li><li><strong>Environment</strong>: ì—ì´ì „íŠ¸ê°€ ìƒí˜¸ì‘ìš©í•˜ëŠ” ì™¸ë¶€ ì‹œìŠ¤í…œ (ì˜ˆ: ë¯¸ë¡œ)</li><li><strong>Action</strong>: ì—ì´ì „íŠ¸ê°€ ì„ íƒí•  ìˆ˜ ìˆëŠ” í–‰ë™ (ì˜ˆ: ìœ„, ì•„ë˜, ì™¼ìª½,ì˜¤ë¥¸ìª½ ì´ë™)</li><li><strong>Reward</strong>: í–‰ë™ì˜ ê²°ê³¼ì— ë”°ë¥¸ í”¼ë“œë°± (ì˜ˆ: +100 ì  &#x3D; ì„±ê³µ, -10ì  &#x3D; ë²½ ì¶©ëŒ)</li><li><strong>State</strong>: í™˜ê²½ì˜ í˜„ì¬ ìƒíƒœ (ì˜ˆ: ë¡œë´‡ì˜ ìœ„ì¹˜)\</li><li><strong>Policy</strong>: ìƒíƒœì— ë”°ë¼ ì–´ë–¤ í–‰ë™ì„ í• ì§€ ì •í•˜ëŠ” ì „ëµ</li></ul></li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: RLì€ <strong>ë³´ìƒ(Reward) ê¸°ë°˜ í•™ìŠµ</strong>ì´ë¼ëŠ” ì ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.</p><p align="center">  <img src="/images/aws_basic_123.png" width="80%"></p><hr><h2 id="2-ê°•í™”í•™ìŠµ-ë™ì‘-ë°©ì‹"><a href="#2-ê°•í™”í•™ìŠµ-ë™ì‘-ë°©ì‹" class="headerlink" title="2. ê°•í™”í•™ìŠµ ë™ì‘ ë°©ì‹"></a>2. ê°•í™”í•™ìŠµ ë™ì‘ ë°©ì‹</h2><ol><li>ì—ì´ì „íŠ¸ê°€ í™˜ê²½ì˜ í˜„ì¬ <strong>State</strong>ë¥¼ ê´€ì°°</li><li><strong>Policy</strong>ì— ë”°ë¼ <strong>Action</strong> ì„ íƒ</li><li>í™˜ê²½ì´ ìƒˆë¡œìš´ <strong>State</strong>ë¡œ ì „í™˜ë˜ê³  <strong>Reward</strong> ì œê³µ</li><li>ì—ì´ì „íŠ¸ëŠ” ë³´ìƒ í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ <strong>Policy</strong>ë¥¼ ì—…ë°ì´íŠ¸</li><li>ë°˜ë³µì„ í†µí•´ ìµœì ì˜ ì „ëµ í•™ìŠµ â†’ <strong>ëˆ„ì  ë³´ìƒ ìµœëŒ€í™”</strong></li></ol><p align="center">  <img src="/images/aws_basic_124.png" width="80%"></p><hr><h2 id="3-ì˜ˆì‹œ-â€“-ë¡œë´‡-ë¯¸ë¡œ-íƒìƒ‰"><a href="#3-ì˜ˆì‹œ-â€“-ë¡œë´‡-ë¯¸ë¡œ-íƒìƒ‰" class="headerlink" title="3. ì˜ˆì‹œ â€“ ë¡œë´‡ ë¯¸ë¡œ íƒìƒ‰"></a>3. ì˜ˆì‹œ â€“ ë¡œë´‡ ë¯¸ë¡œ íƒìƒ‰</h2><ul><li><strong>ì‹œë‚˜ë¦¬ì˜¤</strong>: ë¡œë´‡ì´ ë¯¸ë¡œë¥¼ íƒˆì¶œí•˜ë„ë¡ í•™ìŠµ</li><li><strong>ë³´ìƒ ì„¤ê³„</strong>:<ul><li>í•œ ê±¸ìŒ ì´ë™: -1</li><li>ë²½ ì¶©ëŒ: -10</li><li>ì¶œêµ¬ ë„ì°©: +100</li></ul></li></ul><p>ğŸ“Œ ê²°ê³¼: ì²˜ìŒì—ëŠ” ëœë¤í•˜ê²Œ ì›€ì§ì´ì§€ë§Œ, ìˆ˜ë§ì€ ì‹œë®¬ë ˆì´ì…˜ì„ ë°˜ë³µí•˜ë©´ì„œ <strong>ì§§ê³  íš¨ìœ¨ì ì¸ ê²½ë¡œ</strong>ë¥¼ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ê²Œ ë©ë‹ˆë‹¤.</p><p align="center">  <img src="/images/aws_basic_125.png" width="80%"></p><p>Hereâ€™s a great visual demonstration of <strong>Reinforcement Learning in action</strong>:</p><p>ğŸ‘‰ Click the image or link to watch the video: <a href="https://youtu.be/2tamH76Tjvw">AI Learns to Escape</a></p><hr><h2 id="4-RL-í™œìš©-ì‚¬ë¡€"><a href="#4-RL-í™œìš©-ì‚¬ë¡€" class="headerlink" title="4. RL í™œìš© ì‚¬ë¡€"></a>4. RL í™œìš© ì‚¬ë¡€</h2><ul><li><strong>ê²Œì„</strong>: ì²´ìŠ¤, ë°”ë‘‘ ê°™ì€ ë³µì¡í•œ ê²Œì„ í•™ìŠµ</li><li><strong>ë¡œë³´í‹±ìŠ¤</strong>: ë¬¼ì²´ ì¡°ì‘, ê²½ë¡œ íƒìƒ‰</li><li><strong>ê¸ˆìœµ</strong>: í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”, ìë™ ë§¤ë§¤ ì „ëµ</li><li><strong>í—¬ìŠ¤ì¼€ì–´</strong>: ì¹˜ë£Œ ê³„íš ìµœì í™”</li><li><strong>ììœ¨ì£¼í–‰ì°¨</strong>: ê²½ë¡œ ê³„íš ë° ì‹¤ì‹œê°„ ì˜ì‚¬ê²°ì •</li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ ëŒ€ë¹„</strong>: RLì€ <strong>ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½</strong>ì—ì„œ ë§ì´ í™œìš©ëœë‹¤ëŠ” ì ì„<br>ê¸°ì–µí•˜ì„¸ìš”.</p><hr><h2 id="5-RLHF-Reinforcement-Learning-from-Human-Feedback"><a href="#5-RLHF-Reinforcement-Learning-from-Human-Feedback" class="headerlink" title="5. RLHF (Reinforcement Learning from Human Feedback)"></a>5. RLHF (Reinforcement Learning from Human Feedback)</h2><p>RLHFëŠ” <strong>ê°•í™”í•™ìŠµì— ì¸ê°„ì˜ í”¼ë“œë°±ì„ ë³´ìƒ í•¨ìˆ˜ì— í†µí•©</strong>í•˜ì—¬ ëª¨ë¸ì„ ì‚¬ëŒì´<br>ì›í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµì‹œí‚¤ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.</p><ul><li><strong>ê³¼ì •</strong><ol><li><strong>ë°ì´í„° ìˆ˜ì§‘</strong>: ì‚¬ëŒì´ ë§Œë“  ì§ˆë¬¸ &amp; ë‹µë³€ ì„¸íŠ¸ ì¤€ë¹„</li><li><strong>Supervised Fine-Tuning</strong>: ê¸°ì¡´ ì–¸ì–´ëª¨ë¸ì„ ë‚´ë¶€ ì§€ì‹ì— ë§ê²Œ ë¯¸ì„¸ì¡°ì •</li><li><strong>Reward Model êµ¬ì¶•</strong>: ê°™ì€ ì§ˆë¬¸ì— ëŒ€í•´ ì—¬ëŸ¬ ë‹µë³€ì„ ì œì‹œ â†’ ì‚¬ëŒì´ ë” ì„ í˜¸í•˜ëŠ” ë‹µë³€ì„ ì„ íƒ</li><li><strong>ìµœì í™”</strong>: Reward Modelì„ RL ë³´ìƒ í•¨ìˆ˜ë¡œ í™œìš©í•˜ì—¬ ëª¨ë¸ ê°œì„ </li></ol></li><li><strong>ì˜ˆì‹œ</strong><ul><li>ê¸°ê³„ ë²ˆì—­ ëª¨ë¸ì´ â€œê¸°ìˆ ì ìœ¼ë¡œ ë§ëŠ” ë²ˆì—­â€ì„ í•˜ë”ë¼ë„ <strong>ì‚¬ëŒì´ ì½ê¸°ì— ì–´ìƒ‰í•˜ë‹¤ë©´ ë‚®ì€ ì ìˆ˜</strong>ë¥¼ ì£¼ê³ , <strong>ìì—°ìŠ¤ëŸ¬ìš´ ë²ˆì—­</strong>ì—ëŠ” ë†’ì€ ì ìˆ˜ë¥¼ ì¤Œ</li><li>ì´ëŸ° í”¼ë“œë°±ì„ í†µí•´ ëª¨ë¸ì€ ë” ì¸ê°„ì ì¸ ë‹µë³€ì„ í•™ìŠµ</li></ul></li></ul><p>ğŸ“Œ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: RLHFëŠ” <strong>ChatGPT, Bard, Claude</strong> ê°™ì€ ìµœì‹  LLMì— ë°˜ë“œì‹œ ë“±ì¥í•˜ëŠ” ê°œë…ì´ë¯€ë¡œ, <strong>ë°ì´í„° ìˆ˜ì§‘ â†’ íŒŒì¸íŠœë‹ â†’ ë³´ìƒëª¨ë¸ â†’ ìµœì í™”</strong> ë‹¨ê³„ë¥¼ ê¸°ì–µí•˜ì„¸ìš”.</p><p align="center">  <img src="/images/aws_basic_128.png" width="80%"></p><hr><h2 id="6-Key-Takeaways"><a href="#6-Key-Takeaways" class="headerlink" title="6. Key Takeaways"></a>6. Key Takeaways</h2><ul><li><strong>Reinforcement Learning (RL)</strong>: ë³´ìƒ ê¸°ë°˜ í•™ìŠµ, ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ì—ì„œ ìµœì ì˜ ì •ì±…ì„ í•™ìŠµ</li><li><strong>í™œìš© ë¶„ì•¼</strong>: ê²Œì„, ë¡œë³´í‹±ìŠ¤, ê¸ˆìœµ, í—¬ìŠ¤ì¼€ì–´, ììœ¨ì£¼í–‰</li><li><strong>RLHF</strong>: ì¸ê°„ì˜ í”¼ë“œë°±ì„ ë³´ìƒ í•¨ìˆ˜ì— í†µí•©í•˜ì—¬ <strong>ì‚¬ëŒ ì¹œí™”ì  ëª¨ë¸</strong>ì„ í•™ìŠµ</li><li><strong>ì‹œí—˜ ëŒ€ë¹„ í•µì‹¬</strong>:<ul><li>RLì€ <strong>ë³´ìƒ ìµœëŒ€í™” í•™ìŠµ</strong></li><li>RLHFëŠ” <strong>Human-in-the-loop</strong> ë°©ì‹</li><li>RLHF &#x3D; LLM ì„±ëŠ¥ í–¥ìƒì˜ í•µì‹¬ ê¸°ë²•</li></ul></li></ul><hr><p>âœï¸ ì°¸ê³ : ì‹¤ì œ ì‹œí—˜ì—ì„œëŠ” RL ìì²´ì˜ ìˆ˜í•™ì  ì„¸ë¶€ì‚¬í•­ë³´ë‹¤ëŠ”, <strong>ê°œë…ê³¼ í™œìš©ì‚¬ë¡€, RLHFì˜ ë‹¨ê³„</strong>ë¥¼ ë¬»ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ§ -ê°•í™”í•™ìŠµ-Reinforcement-Learning-RL-ê³¼-RLHF-ì‰½ê²Œ-ì´í•´í•˜ê¸°&quot;&gt;&lt;a href=&quot;#ğŸ§ -ê°•í™”í•™ìŠµ-Reinforcement-Learning-RL-ê³¼-RLHF-ì‰½ê²Œ-ì´í•´í•˜ê¸°&quot; class=&quot;headerlink&quot; tit</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(í•œêµ­ì–´) AWS Certified AI Practitioner (24) - ë¹„ì§€ë„ í•™ìŠµ &amp; ìê¸° ì§€ë„ í•™ìŠµ</title>
    <link href="https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-24/"/>
    <id>https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-24/</id>
    <published>2025-08-23T22:19:50.000Z</published>
    <updated>2025-08-24T00:33:26.299Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ¤–-ë¨¸ì‹ ëŸ¬ë‹-ì•Œê³ ë¦¬ì¦˜-â€“-ë¹„ì§€ë„-í•™ìŠµ-Unsupervised-Learning-ìê¸°-ì§€ë„-í•™ìŠµ-Self-Supervised-Learning"><a href="#ğŸ¤–-ë¨¸ì‹ ëŸ¬ë‹-ì•Œê³ ë¦¬ì¦˜-â€“-ë¹„ì§€ë„-í•™ìŠµ-Unsupervised-Learning-ìê¸°-ì§€ë„-í•™ìŠµ-Self-Supervised-Learning" class="headerlink" title="ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ â€“ ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning) &amp; ìê¸° ì§€ë„ í•™ìŠµ(Self-Supervised Learning)"></a>ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ â€“ ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning) &amp; ìê¸° ì§€ë„ í•™ìŠµ(Self-Supervised Learning)</h1><h2 id="1-ë¹„ì§€ë„-í•™ìŠµ-Unsupervised-Learning"><a href="#1-ë¹„ì§€ë„-í•™ìŠµ-Unsupervised-Learning" class="headerlink" title="1. ë¹„ì§€ë„ í•™ìŠµ (Unsupervised Learning)"></a>1. ë¹„ì§€ë„ í•™ìŠµ (Unsupervised Learning)</h2><ul><li><strong>ë¼ë²¨(ì •ë‹µ)ì´ ì—†ëŠ” ë°ì´í„°</strong>ì—ì„œ íŒ¨í„´, êµ¬ì¡°, ê´€ê³„ë¥¼ ìŠ¤ìŠ¤ë¡œ ë°œê²¬í•˜ëŠ” í•™ìŠµ ë°©ì‹  </li><li>ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì´ ë°ì´í„° ê·¸ë£¹ì„ ë§Œë“¤ê³ , <strong>ì‚¬ëŒì´ ê·¸ ê²°ê³¼ì— ì˜ë¯¸(ë¼ë²¨)ë¥¼ ë¶€ì—¬</strong>  </li><li>ëŒ€í‘œ ê¸°ë²•:<ul><li><strong>í´ëŸ¬ìŠ¤í„°ë§(Clustering)</strong></li><li><strong>ì—°ê´€ ê·œì¹™ í•™ìŠµ(Association Rule Learning)</strong></li><li><strong>ì´ìƒì¹˜ íƒì§€(Anomaly Detection)</strong></li></ul></li><li><strong>í™œìš© ì‚¬ë¡€</strong><ul><li>ê³ ê° ì„¸ë¶„í™” (ë§ˆì¼€íŒ…)</li><li>ì¶”ì²œ ì‹œìŠ¤í…œ</li><li>ì‚¬ê¸° íƒì§€</li></ul></li><li>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: ë¹„ì§€ë„ í•™ìŠµì€ <strong>ë¼ë²¨ì´ ì—†ëŠ” ë°ì´í„°</strong>ë¥¼ í™œìš©í•œë‹¤ëŠ” ì  ê¸°ì–µí•˜ê¸°</li></ul><p align="center">  <img src="/images/aws_basic_116.png" width="80%"></p><hr><h2 id="2-í´ëŸ¬ìŠ¤í„°ë§-Clustering"><a href="#2-í´ëŸ¬ìŠ¤í„°ë§-Clustering" class="headerlink" title="2. í´ëŸ¬ìŠ¤í„°ë§ (Clustering)"></a>2. í´ëŸ¬ìŠ¤í„°ë§ (Clustering)</h2><ul><li><strong>ì •ì˜</strong>: ìœ ì‚¬í•œ íŠ¹ì§•ì„ ê°€ì§„ ë°ì´í„°ë¥¼ ë¬¶ì–´ ê·¸ë£¹(cluster)ìœ¼ë¡œ ë‚˜ëˆ”  </li><li><strong>ì‚¬ë¡€: ê³ ê° ì„¸ë¶„í™”(Customer Segmentation)</strong>  <ul><li>ìƒí™©: e-commerce ê¸°ì—…ì´ ê³ ê°ì„ êµ¬ë§¤ íŒ¨í„´ì— ë”°ë¼ êµ¬ë¶„  </li><li>ë°ì´í„°: êµ¬ë§¤ ë¹ˆë„, í‰ê·  ì£¼ë¬¸ ê¸ˆì•¡ ë“±  </li><li>ì•Œê³ ë¦¬ì¦˜: <strong>K-means Clustering</strong>  </li><li>ê²°ê³¼:  <ul><li>ê·¸ë£¹ 1 â†’ í•™ìƒì¸µ (í”¼ì, ê³¼ì, ë§¥ì£¼ êµ¬ë§¤)  </li><li>ê·¸ë£¹ 2 â†’ ì‹ ìƒì•„ ë¶€ëª¨ (ê¸°ì €ê·€, ë² ì´ë¹„ ì œí’ˆ êµ¬ë§¤)  </li><li>ê·¸ë£¹ 3 â†’ ê±´ê°• ê´€ì‹¬ì¸µ (ê³¼ì¼, ì±„ì†Œ êµ¬ë§¤)</li></ul></li><li>í™œìš©: ê·¸ë£¹ë³„ <strong>ë§ì¶¤í˜• ë§ˆì¼€íŒ… ì „ëµ</strong> ê°€ëŠ¥</li></ul></li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: K-meansëŠ” ë¹„ì§€ë„ í•™ìŠµ ëŒ€í‘œ ì•Œê³ ë¦¬ì¦˜, ê³ ê° ì„¸ë¶„í™” ì‚¬ë¡€ë¡œ ìì£¼ ì¶œì œë¨.  </p><p align="center">  <img src="/images/aws_basic_117.png" width="80%"></p><hr><h2 id="3-ì—°ê´€-ê·œì¹™-í•™ìŠµ-Association-Rule-Learning"><a href="#3-ì—°ê´€-ê·œì¹™-í•™ìŠµ-Association-Rule-Learning" class="headerlink" title="3. ì—°ê´€ ê·œì¹™ í•™ìŠµ (Association Rule Learning)"></a>3. ì—°ê´€ ê·œì¹™ í•™ìŠµ (Association Rule Learning)</h2><ul><li><strong>ì •ì˜</strong>: ì–´ë–¤ ìƒí’ˆì´ <strong>ìì£¼ í•¨ê»˜ êµ¬ë§¤ë˜ëŠ”ì§€</strong>ë¥¼ ì°¾ì•„ë‚´ëŠ” ë°©ë²•  </li><li><strong>ì‚¬ë¡€: ì¥ë°”êµ¬ë‹ˆ ë¶„ì„(Market Basket Analysis)</strong>  <ul><li>ìƒí™©: ìŠˆí¼ë§ˆì¼“ì´ ìƒí’ˆ ì§„ì—´ ìµœì í™”  </li><li>ë°ì´í„°: ê³ ê° êµ¬ë§¤ ì´ë ¥  </li><li>ì•Œê³ ë¦¬ì¦˜: <strong>Apriori ì•Œê³ ë¦¬ì¦˜</strong>  </li><li>ê²°ê³¼:  <ul><li>â€œë¹µì„ ì‚¬ë©´ ë²„í„°ë„ í•¨ê»˜ êµ¬ë§¤â€ â†’ ë¹µê³¼ ë²„í„°ë¥¼ ê°€ê¹Œì´ ì§„ì—´ â†’ ë§¤ì¶œ ì¦ê°€</li></ul></li></ul></li></ul><p align="center">  <img src="/images/aws_basic_118.png" width="60%"></p><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: Apriori &#x3D; ëŒ€í‘œì ì¸ ì—°ê´€ ê·œì¹™ ì•Œê³ ë¦¬ì¦˜  </p><hr><h2 id="4-ì´ìƒì¹˜-íƒì§€-Anomaly-Detection"><a href="#4-ì´ìƒì¹˜-íƒì§€-Anomaly-Detection" class="headerlink" title="4. ì´ìƒì¹˜ íƒì§€ (Anomaly Detection)"></a>4. ì´ìƒì¹˜ íƒì§€ (Anomaly Detection)</h2><ul><li><strong>ì •ì˜</strong>: ì •ìƒ íŒ¨í„´ê³¼ ë‹¤ë¥¸ <strong>ì´ìƒí•œ ë°ì´í„°(Outlier)</strong> íƒì§€  </li><li><strong>ì‚¬ë¡€: ì‹ ìš©ì¹´ë“œ ì‚¬ê¸° íƒì§€(Fraud Detection)</strong>  <ul><li>ë°ì´í„°: ê²°ì œ ê¸ˆì•¡, ì‹œê°„, ìœ„ì¹˜  </li><li>ì•Œê³ ë¦¬ì¦˜: <strong>Isolation Forest</strong>  </li><li>ê²°ê³¼: ì •ìƒ ê±°ë˜ íŒ¨í„´ê³¼ í¬ê²Œ ë‹¤ë¥¸ íŠ¸ëœì­ì…˜ì„ <strong>ì‚¬ê¸° ì˜ì‹¬ ê±°ë˜ë¡œ í‘œì‹œ</strong></li></ul></li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: ë¹„ì§€ë„ í•™ìŠµì˜ ëŒ€í‘œì ì¸ ì‹¤ì œ í™œìš© &#x3D; <strong>ì‚¬ê¸° íƒì§€</strong>  </p><p align="center">  <img src="/images/aws_basic_119.png" width="80%"></p><hr><h2 id="5-ì¤€ì§€ë„-í•™ìŠµ-Semi-Supervised-Learning"><a href="#5-ì¤€ì§€ë„-í•™ìŠµ-Semi-Supervised-Learning" class="headerlink" title="5. ì¤€ì§€ë„ í•™ìŠµ (Semi-Supervised Learning)"></a>5. ì¤€ì§€ë„ í•™ìŠµ (Semi-Supervised Learning)</h2><ul><li><strong>ì •ì˜</strong>: ì†ŒëŸ‰ì˜ ë¼ë²¨ ë°ì´í„° + ëŒ€ëŸ‰ì˜ ë¹„ë¼ë²¨ ë°ì´í„°ë¥¼ í•¨ê»˜ í•™ìŠµ  </li><li><strong>ë°©ë²•</strong>:<ol><li>ë¼ë²¨ ë°ì´í„°ë¡œ ì´ˆê¸° í•™ìŠµ  </li><li>í•™ìŠµëœ ëª¨ë¸ì´ ë¹„ë¼ë²¨ ë°ì´í„°ì— <strong>ê°€ì§œ ë¼ë²¨(Pseudo-label)</strong> ìƒì„±  </li><li>ì „ì²´ ë°ì´í„°(ë¼ë²¨ + ê°€ì§œ ë¼ë²¨)ë¡œ ì¬í•™ìŠµ</li></ol></li><li>ğŸ‘‰ ë°ì´í„° ë¼ë²¨ë§ ë¹„ìš©ì´ ë†’ì„ ë•Œ íš¨ê³¼ì </li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: Semi-supervised learning &#x3D; <strong>pseudo-labeling</strong> í•µì‹¬ í‚¤ì›Œë“œ  </p><p align="center">  <img src="/images/aws_basic_120.png" width="80%"></p><hr><h2 id="6-ìê¸°-ì§€ë„-í•™ìŠµ-Self-Supervised-Learning"><a href="#6-ìê¸°-ì§€ë„-í•™ìŠµ-Self-Supervised-Learning" class="headerlink" title="6. ìê¸° ì§€ë„ í•™ìŠµ (Self-Supervised Learning)"></a>6. ìê¸° ì§€ë„ í•™ìŠµ (Self-Supervised Learning)</h2><ul><li><strong>ì •ì˜</strong>: ì‚¬ëŒì´ ì§ì ‘ ë¼ë²¨ë§í•˜ì§€ ì•Šê³ , <strong>ëª¨ë¸ì´ ìŠ¤ìŠ¤ë¡œ ê°€ì§œ ë¼ë²¨(pseudo-labels)ì„ ìƒì„±</strong>í•˜ì—¬ í•™ìŠµ  </li><li><strong>í™œìš© ì‚¬ë¡€</strong>:<ul><li>NLP â†’ BERT, GPT ê°™ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸  </li><li>ì´ë¯¸ì§€ ì¸ì‹ â†’ ë§ˆìŠ¤í‚¹ëœ ë¶€ë¶„ ì˜ˆì¸¡ ë“±</li></ul></li><li><strong>ë°©ë²•: Pre-text Task í™œìš©</strong><ul><li>ë¬¸ì¥ì—ì„œ ë‹¤ìŒ ë‹¨ì–´ ë§ì¶”ê¸°  </li><li>ë¬¸ì¥ì˜ ì¼ë¶€ë¥¼ ê°€ë ¤ë†“ê³  ì±„ìš°ê¸° (Masked Language Modeling)  </li><li>ì´ë¯¸ì§€ì—ì„œ ê°€ë ¤ì§„ ë¶€ë¶„ ì˜ˆì¸¡í•˜ê¸°</li></ul></li></ul><p>ğŸ‘‰ ì´ë ‡ê²Œ í•™ìŠµëœ ëª¨ë¸ì€ ì´í›„ <strong>ìš”ì•½, ë²ˆì—­, ë¶„ë¥˜</strong> ê°™ì€ <strong>ë‹¤ìš´ìŠ¤íŠ¸ë¦¼(ì‹¤ì œ) ê³¼ì œ</strong>ì— í™œìš© ê°€ëŠ¥  </p><p align="center">  <img src="/images/aws_basic_121.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_122.png" width="80%"></p><hr><h1 id="ğŸ“Œ-ìµœì¢…-ìš”ì•½"><a href="#ğŸ“Œ-ìµœì¢…-ìš”ì•½" class="headerlink" title="ğŸ“Œ ìµœì¢… ìš”ì•½"></a>ğŸ“Œ ìµœì¢… ìš”ì•½</h1><ul><li><strong>ë¹„ì§€ë„ í•™ìŠµ</strong>: ë¼ë²¨ ì—†ìŒ â†’ íŒ¨í„´&#x2F;ê·¸ë£¹ ì°¾ê¸°  <ul><li>K-means (í´ëŸ¬ìŠ¤í„°ë§) â†’ ê³ ê° ì„¸ë¶„í™”  </li><li>Apriori (ì—°ê´€ ê·œì¹™) â†’ ì¥ë°”êµ¬ë‹ˆ ë¶„ì„  </li><li>Isolation Forest (ì´ìƒì¹˜ íƒì§€) â†’ ì‚¬ê¸° íƒì§€</li></ul></li><li><strong>ì¤€ì§€ë„ í•™ìŠµ</strong>: ì†ŒëŸ‰ ë¼ë²¨ + ëŒ€ëŸ‰ ë¹„ë¼ë²¨ â†’ Pseudo-labeling  </li><li><strong>ìê¸° ì§€ë„ í•™ìŠµ</strong>: ëª¨ë¸ì´ ìì²´ì ìœ¼ë¡œ ë¼ë²¨ ìƒì„± (GPT, BERT ê¸°ë°˜)</li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ ëŒ€ë¹„ í‚¤ì›Œë“œ</strong>  </p><ul><li>ë¹„ì§€ë„ í•™ìŠµ &#x3D; ë¼ë²¨ ì—†ìŒ  </li><li>K-means &#x3D; ê³ ê° ì„¸ë¶„í™”  </li><li>Apriori &#x3D; ì¥ë°”êµ¬ë‹ˆ ë¶„ì„  </li><li>ì´ìƒì¹˜ íƒì§€ &#x3D; ì‚¬ê¸° íƒì§€  </li><li>Semi-supervised &#x3D; Pseudo-labeling  </li><li>Self-supervised &#x3D; GPT&#x2F;BERT ê¸°ë°˜ í•™ìŠµ</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ¤–-ë¨¸ì‹ ëŸ¬ë‹-ì•Œê³ ë¦¬ì¦˜-â€“-ë¹„ì§€ë„-í•™ìŠµ-Unsupervised-Learning-ìê¸°-ì§€ë„-í•™ìŠµ-Self-Supervised-Learning&quot;&gt;&lt;a href=&quot;#ğŸ¤–-ë¨¸ì‹ ëŸ¬ë‹-ì•Œê³ ë¦¬ì¦˜-â€“-ë¹„ì§€ë„-í•™ìŠµ-Unsupervised-Learning</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(24) - Unsupervised &amp; Semi/Self-Supervised Learning</title>
    <link href="https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-24/"/>
    <id>https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-24/</id>
    <published>2025-08-23T22:19:44.000Z</published>
    <updated>2025-08-24T00:31:01.851Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ§ -Machine-Learning-Algorithms-â€“-Unsupervised-Semi-Self-Supervised-Learning"><a href="#ğŸ§ -Machine-Learning-Algorithms-â€“-Unsupervised-Semi-Self-Supervised-Learning" class="headerlink" title="ğŸ§  Machine Learning Algorithms â€“ Unsupervised &amp; Semi&#x2F;Self-Supervised Learning"></a>ğŸ§  Machine Learning Algorithms â€“ Unsupervised &amp; Semi&#x2F;Self-Supervised Learning</h1><h2 id="1-What-is-Unsupervised-Learning"><a href="#1-What-is-Unsupervised-Learning" class="headerlink" title="1. What is Unsupervised Learning?"></a>1. What is Unsupervised Learning?</h2><ul><li><strong>Definition</strong>: Machine learning on unlabeled data (no predefined outputs).  </li><li><strong>Goal</strong>: Discover hidden patterns, structures, or relationships in the data.  </li><li><strong>Key point</strong>: The algorithm finds groups or rules by itself, while humans later assign meaning (labels) to those groups.</li></ul><p><strong>Common techniques</strong>:</p><ul><li><strong>Clustering</strong> â†’ finding groups of similar data (e.g., customer segmentation)  </li><li><strong>Association Rule Learning</strong> â†’ discovering relationships between items (e.g., â€œbread + butterâ€)  </li><li><strong>Anomaly Detection</strong> â†’ spotting unusual behaviors (e.g., fraud detection)</li></ul><p>ğŸ‘‰ <strong>Exam Tip</strong>: You donâ€™t need deep math for the exam, but know what each technique is used for.  </p><p align="center">  <img src="/images/aws_basic_116.png" width="80%"></p><hr><h2 id="2-Clustering-Example-â€“-Customer-Segmentation"><a href="#2-Clustering-Example-â€“-Customer-Segmentation" class="headerlink" title="2. Clustering Example â€“ Customer Segmentation"></a>2. Clustering Example â€“ Customer Segmentation</h2><ul><li><strong>Scenario</strong>: An e-commerce company wants to understand customer purchase behavior.  </li><li><strong>Data</strong>: Purchase history (e.g., average order size, purchase frequency).  </li><li><strong>Technique</strong>: <strong>K-Means Clustering</strong>  </li><li><strong>Goal</strong>: Group customers into segments based on behavior.</li></ul><p><strong>Outcome</strong>:</p><ul><li>Segment A: Students (buy pizza, chips, beer)  </li><li>Segment B: New parents (buy baby shampoo, wipes)  </li><li>Segment C: Health-conscious customers (buy fruits, vegetables)</li></ul><p>ğŸ’¡ The company can now target each group with tailored marketing campaigns.  </p><p align="center">  <img src="/images/aws_basic_117.png" width="80%"></p><hr><h2 id="3-Association-Rule-Learning-â€“-Market-Basket-Analysis"><a href="#3-Association-Rule-Learning-â€“-Market-Basket-Analysis" class="headerlink" title="3. Association Rule Learning â€“ Market Basket Analysis"></a>3. Association Rule Learning â€“ Market Basket Analysis</h2><ul><li><strong>Scenario</strong>: A supermarket wants to know which products are often bought together.  </li><li><strong>Data</strong>: Transaction histories.  </li><li><strong>Technique</strong>: <strong>Apriori Algorithm</strong>  </li><li><strong>Goal</strong>: Find product associations.</li></ul><p><strong>Outcome</strong>:</p><ul><li>â€œBread â†’ Butterâ€  </li><li>â€œChips â†’ Sodaâ€</li></ul><p>ğŸ“Œ <strong>Business Value</strong>: Place associated items together on shelves or bundle promotions to increase sales.  </p><p align="center">  <img src="/images/aws_basic_118.png" width="60%"></p><hr><h2 id="4-Anomaly-Detection-â€“-Fraud-Detection"><a href="#4-Anomaly-Detection-â€“-Fraud-Detection" class="headerlink" title="4. Anomaly Detection â€“ Fraud Detection"></a>4. Anomaly Detection â€“ Fraud Detection</h2><ul><li><strong>Scenario</strong>: Detect fraudulent credit card transactions.  </li><li><strong>Data</strong>: Amount, time, location of transactions.  </li><li><strong>Technique</strong>: <strong>Isolation Forest</strong> (or other anomaly detection methods).  </li><li><strong>Goal</strong>: Identify transactions that deviate significantly from normal behavior.</li></ul><p><strong>Outcome</strong>: The system flags suspicious transactions for manual review.  </p><p>ğŸ‘‰ <strong>Exam Insight</strong>: Anomaly detection is commonly tied to fraud detection, intrusion detection, or system monitoring.  </p><p align="center">  <img src="/images/aws_basic_119.png" width="80%"></p><hr><h2 id="5-Semi-Supervised-Learning"><a href="#5-Semi-Supervised-Learning" class="headerlink" title="5. Semi-Supervised Learning"></a>5. Semi-Supervised Learning</h2><ul><li><p><strong>Definition</strong>: Uses a small amount of labeled data + a large amount of unlabeled data.  </p></li><li><p><strong>Process</strong>:</p><ol><li>Train model on labeled data.  </li><li>Model assigns labels to unlabeled data (<strong>pseudo-labeling</strong>).  </li><li>Retrain model on the now-larger dataset.</li></ol></li><li><p><strong>Use case</strong>: Medical imaging (expensive to label every scan).</p></li></ul><p>ğŸ“Œ <strong>Exam Tip</strong>: Remember <strong>semi-supervised &#x3D; mix of supervised + unsupervised.</strong>  </p><p align="center">  <img src="/images/aws_basic_120.png" width="80%"></p><hr><h2 id="6-Self-Supervised-Learning"><a href="#6-Self-Supervised-Learning" class="headerlink" title="6. Self-Supervised Learning"></a>6. Self-Supervised Learning</h2><ul><li><strong>Definition</strong>: Model creates its own pseudo-labels without human labeling.</li></ul><p><strong>How it works</strong>:</p><ul><li>Use â€œpretext tasksâ€ â†’ simple prediction challenges that force the model to learn patterns.  </li><li>Examples:  <ul><li>Predict the next word in a sentence (language models).  </li><li>Predict a missing part of an image (vision tasks).</li></ul></li></ul><p><strong>Outcome</strong>: Model builds internal representations of data, which can then be used for downstream tasks like translation, summarization, or classification.  </p><p>ğŸ’¡ <strong>Real-world use</strong>:  </p><ul><li><strong>NLP</strong>: Training BERT and GPT models.  </li><li><strong>Computer Vision</strong>: Pretraining models for image recognition.</li></ul><p>ğŸ‘‰ <strong>Exam Tip</strong>: If you see <strong>BERT, GPT, or modern NLP models</strong>, think <strong>Self-Supervised Learning.</strong>  </p><p align="center">  <img src="/images/aws_basic_121.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_122.png" width="80%"></p><hr><h2 id="âœ…-Key-Takeaways-for-Exams"><a href="#âœ…-Key-Takeaways-for-Exams" class="headerlink" title="âœ… Key Takeaways for Exams"></a>âœ… Key Takeaways for Exams</h2><ul><li><strong>Unsupervised Learning</strong> &#x3D; find hidden patterns in unlabeled data.  <ul><li>Clustering â†’ segmentation  </li><li>Association Rule â†’ product relationships  </li><li>Anomaly Detection â†’ fraud &#x2F; unusual behavior</li></ul></li><li><strong>Semi-Supervised Learning</strong> &#x3D; small labeled + large unlabeled (pseudo-labeling).  </li><li><strong>Self-Supervised Learning</strong> &#x3D; model labels itself using pretext tasks (foundation for GPT&#x2F;BERT).  </li><li><strong>Feature Engineering</strong> still helps improve results in all cases.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ§ -Machine-Learning-Algorithms-â€“-Unsupervised-Semi-Self-Supervised-Learning&quot;&gt;&lt;a href=&quot;#ğŸ§ -Machine-Learning-Algorithms-â€“-Unsupervised</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(23) - Training Data &amp; Feature Engineering</title>
    <link href="https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-23/"/>
    <id>https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-23/</id>
    <published>2025-08-23T13:50:14.000Z</published>
    <updated>2025-08-23T14:08:31.634Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ“˜-Training-Data-Feature-Engineering"><a href="#ğŸ“˜-Training-Data-Feature-Engineering" class="headerlink" title="ğŸ“˜ Training Data &amp; Feature Engineering"></a>ğŸ“˜ Training Data &amp; Feature Engineering</h1><h2 id="Why-Training-Data-Matters"><a href="#Why-Training-Data-Matters" class="headerlink" title="Why Training Data Matters"></a>Why Training Data Matters</h2><ul><li>To build a reliable ML model, you need <strong>good quality data</strong>.\</li><li>Principle: <strong>Garbage In â†’ Garbage Out</strong>. If your input data is messy<br>or incorrect, your model will produce poor predictions.\</li><li>Data preparation is the <strong>most critical stage</strong> of ML.\</li><li>The way you model your data (e.g., labeled&#x2F;unlabeled,<br>structured&#x2F;unstructured) directly impacts which algorithms you can<br>use.</li></ul><p>ğŸ‘‰ <strong>Exam Tip</strong>: Expect questions about <em>labeled vs.Â unlabeled</em> and<br><em>structured vs.Â unstructured data</em>.</p><hr><h2 id="Labeled-vs-Unlabeled-Data"><a href="#Labeled-vs-Unlabeled-Data" class="headerlink" title="Labeled vs.Â Unlabeled Data"></a>Labeled vs.Â Unlabeled Data</h2><h3 id="ğŸ”¹-Labeled-Data"><a href="#ğŸ”¹-Labeled-Data" class="headerlink" title="ğŸ”¹ Labeled Data"></a>ğŸ”¹ Labeled Data</h3><ul><li>Contains <strong>both input features</strong> and <strong>output labels</strong>.\</li><li>Example: Animal images labeled as â€œcatâ€ or â€œdog.â€\</li><li>Used in <strong>Supervised Learning</strong> â†’ the model learns to map inputs to<br>outputs.\</li><li>Strong but expensive â†’ requires manual labeling.</li></ul><p align="center">  <img src="/images/aws_basic_107.png" width="80%"></p><h3 id="ğŸ”¹-Unlabeled-Data"><a href="#ğŸ”¹-Unlabeled-Data" class="headerlink" title="ğŸ”¹ Unlabeled Data"></a>ğŸ”¹ Unlabeled Data</h3><ul><li>Contains <strong>only input features</strong>, with no labels.\</li><li>Example: A folder of animal pictures with no tags.\</li><li>Used in <strong>Unsupervised Learning</strong> â†’ the model finds hidden patterns<br>or clusters.\</li><li>Cheaper and more abundant, but harder to interpret.</li></ul><p align="center">  <img src="/images/aws_basic_108.png" width="80%"></p><hr><h2 id="Structured-vs-Unstructured-Data"><a href="#Structured-vs-Unstructured-Data" class="headerlink" title="Structured vs.Â Unstructured Data"></a>Structured vs.Â Unstructured Data</h2><h3 id="ğŸ”¹-Structured-Data"><a href="#ğŸ”¹-Structured-Data" class="headerlink" title="ğŸ”¹ Structured Data"></a>ğŸ”¹ Structured Data</h3><p>Organized into rows&#x2F;columns (like Excel or databases).\</p><ul><li><strong>Tabular Data</strong>: Customer DB (Name, Age, Purchase Amount).\</li></ul><p align="center">  <img src="/images/aws_basic_109.png" width="80%"></p><ul><li><strong>Time Series Data</strong>: Stock prices collected daily.</li></ul><p align="center">  <img src="/images/aws_basic_110.png" width="80%"></p><h3 id="ğŸ”¹-Unstructured-Data"><a href="#ğŸ”¹-Unstructured-Data" class="headerlink" title="ğŸ”¹ Unstructured Data"></a>ğŸ”¹ Unstructured Data</h3><p>Doesnâ€™t follow a set format, often text-heavy or media-rich.\</p><ul><li><strong>Text Data</strong>: Articles, social posts, product reviews.\</li><li><strong>Image Data</strong>: Photos, medical scans, etc.</li></ul><p>ğŸ‘‰ <strong>Exam Tip</strong>: AWS might test you on which algorithm handles<br><strong>structured (tabular, time-series)</strong> vs.Â <strong>unstructured (text, image)</strong><br>data.</p><hr><h2 id="Supervised-Learning"><a href="#Supervised-Learning" class="headerlink" title="Supervised Learning"></a>Supervised Learning</h2><ul><li>Learns a <strong>mapping function</strong>: predicts output for unseen inputs.\</li><li>Requires <strong>labeled data</strong>.\</li><li>Types: <strong>Regression</strong> (continuous values) and <strong>Classification</strong><br>(categories).</li></ul><h3 id="ğŸ”¹-Regression"><a href="#ğŸ”¹-Regression" class="headerlink" title="ğŸ”¹ Regression"></a>ğŸ”¹ Regression</h3><ul><li>Predicts numeric values.\</li><li>Examples:<ul><li>House prices (based on size, location).\</li><li>Stock price forecasting.\</li><li>Weather prediction (temperature).\</li></ul></li><li>Output &#x3D; continuous (any real value).</li></ul><p align="center">  <img src="/images/aws_basic_112.png" width="80%"></p><h3 id="ğŸ”¹-Classification"><a href="#ğŸ”¹-Classification" class="headerlink" title="ğŸ”¹ Classification"></a>ğŸ”¹ Classification</h3><ul><li>Predicts discrete categories.\</li><li>Examples:<ul><li>Binary: Spam vs.Â Not Spam.\</li><li>Multi-class: Mammal, Bird, Reptile.\</li><li>Multi-label: A movie labeled as <em>Action + Comedy</em>.\</li></ul></li><li>Common Algorithm: <strong>k-NN (k-Nearest Neighbors)</strong>.</li></ul><p align="center">  <img src="/images/aws_basic_113.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_111.png" width="80%"></p>------------------------------------------------------------------------<h2 id="Splitting-the-Dataset"><a href="#Splitting-the-Dataset" class="headerlink" title="Splitting the Dataset"></a>Splitting the Dataset</h2><ul><li><strong>Training Set</strong>: 60â€“80% (used to train).\</li><li><strong>Validation Set</strong>: 10â€“20% (used to tune hyperparameters).\</li><li><strong>Test Set</strong>: 10â€“20% (used to evaluate final performance).</li></ul><p>ğŸ‘‰ <strong>Exam Tip</strong>:\</p><ul><li>Training &#x3D; learning.\</li><li>Validation &#x3D; tuning.\</li><li>Test &#x3D; evaluation.</li></ul><p align="center">  <img src="/images/aws_basic_114.png" width="80%"></p><hr><h2 id="Feature-Engineering"><a href="#Feature-Engineering" class="headerlink" title="Feature Engineering"></a>Feature Engineering</h2><p>Transforming raw data into useful features â†’ improves model accuracy.</p><h3 id="Techniques"><a href="#Techniques" class="headerlink" title="Techniques"></a>Techniques</h3><ul><li><strong>Feature Extraction</strong>: Convert raw values into meaningful ones.<ul><li>Example: From birth date â†’ calculate age.\</li></ul></li><li><strong>Feature Selection</strong>: Keep only the most relevant features.<ul><li>Example: House price prediction â†’ keep location &amp; size, drop<br>irrelevant columns.\</li></ul></li><li><strong>Feature Transformation</strong>: Normalize or scale data to improve<br>convergence.</li></ul><p align="center">  <img src="/images/aws_basic_115.png" width="80%"></p><hr><h2 id="Feature-Engineering-Examples"><a href="#Feature-Engineering-Examples" class="headerlink" title="Feature Engineering Examples"></a>Feature Engineering Examples</h2><h3 id="ğŸ”¹-On-Structured-Data"><a href="#ğŸ”¹-On-Structured-Data" class="headerlink" title="ğŸ”¹ On Structured Data"></a>ğŸ”¹ On Structured Data</h3><ul><li>Predicting house prices:<ul><li>Create <em>price per square foot</em>.\</li><li>Normalize features like size and income.</li></ul></li></ul><h3 id="ğŸ”¹-On-Unstructured-Data"><a href="#ğŸ”¹-On-Unstructured-Data" class="headerlink" title="ğŸ”¹ On Unstructured Data"></a>ğŸ”¹ On Unstructured Data</h3><ul><li><strong>Text</strong>: Convert reviews into numbers using TF-IDF or word<br>embeddings.\</li><li><strong>Images</strong>: Use CNNs to extract edges, shapes, or textures.</li></ul><p>ğŸ‘‰ <strong>Exam Tip</strong>: Know that <strong>feature engineering &#x3D; boosting model<br>performance by transforming data.</strong></p><hr><h1 id="âœ…-Quick-Recap-for-Exam"><a href="#âœ…-Quick-Recap-for-Exam" class="headerlink" title="âœ… Quick Recap for Exam"></a>âœ… Quick Recap for Exam</h1><ol><li><strong>Good data is critical</strong> â€“ Garbage In, Garbage Out.\</li><li><strong>Labeled â†’ Supervised | Unlabeled â†’ Unsupervised.</strong>\</li><li><strong>Structured vs.Â Unstructured</strong>: Tables vs.Â Text&#x2F;Images.\</li><li><strong>Regression</strong> &#x3D; numeric predictions, <strong>Classification</strong> &#x3D;<br>categories.\</li><li><strong>Data split</strong>: Train (learn), Validate (tune), Test (evaluate).\</li><li><strong>Feature Engineering</strong> improves accuracy through extraction,<br>selection, transformation.</li></ol><hr><p>ğŸ‘‰ <strong>One-Liner Exam Tip</strong>:<br>Most AWS exam questions on ML basics test whether you can correctly<br><strong>match the data type with the ML method</strong> (e.g., <em>time-series â†’<br>supervised regression</em>, <em>unlabeled images â†’ unsupervised clustering</em>).</p><h2 id="Additional-ğŸ“Œ-What-is-TF-IDF"><a href="#Additional-ğŸ“Œ-What-is-TF-IDF" class="headerlink" title="(Additional) ğŸ“Œ What is TF-IDF?"></a>(Additional) ğŸ“Œ What is TF-IDF?</h2><p>TF-IDF is a statistical method used in <strong>Natural Language Processing (NLP)</strong> to evaluate how important a word is within a document relative to a collection of documents (called a corpus).<br>It is widely used in <strong>search engines, information retrieval, and text mining</strong>.</p><hr><h2 id="Additional-âš¡-How-It-Works"><a href="#Additional-âš¡-How-It-Works" class="headerlink" title="(Additional)  âš¡ How It Works"></a>(Additional)  âš¡ How It Works</h2><h3 id="1-Term-Frequency-TF"><a href="#1-Term-Frequency-TF" class="headerlink" title="1. Term Frequency (TF)"></a>1. Term Frequency (TF)</h3><ul><li>Measures how often a word appears in a document.</li><li>Formula:<br>( TF(t, d) &#x3D; \frac{\text{Number of times term t appears in document d}}{\text{Total terms in document d}} )</li></ul><p>ğŸ‘‰ Example: If the word <strong>â€œAIâ€</strong> appears 5 times in a 100-word document,<br>( TF(AI) &#x3D; 5 &#x2F; 100 &#x3D; 0.05 ).</p><hr><h3 id="2-Inverse-Document-Frequency-IDF"><a href="#2-Inverse-Document-Frequency-IDF" class="headerlink" title="2. Inverse Document Frequency (IDF)"></a>2. Inverse Document Frequency (IDF)</h3><ul><li>Measures how important a word is across all documents in the corpus.</li><li>Common words (like â€œtheâ€, â€œisâ€, â€œandâ€) get lower scores, while rare words get higher scores.</li><li>Formula:<br>( IDF(t) &#x3D; \log\frac{N}{1 + df(t)} )<br>where:  <ul><li>(N) &#x3D; total number of documents  </li><li>(df(t)) &#x3D; number of documents containing the term t</li></ul></li></ul><p>ğŸ‘‰ Example: If the word <strong>â€œAIâ€</strong> appears in 2 out of 10 documents,<br>( IDF(AI) &#x3D; \log(10 &#x2F; (1+2)) â‰ˆ 1.20 ).</p><hr><h3 id="3-TF-IDF-Score"><a href="#3-TF-IDF-Score" class="headerlink" title="3. TF-IDF Score"></a>3. TF-IDF Score</h3><ul><li>Combines TF and IDF to measure the importance of a term in a document relative to the whole corpus.</li><li>Formula:<br>( TF\text{-}IDF(t, d) &#x3D; TF(t, d) \times IDF(t) )</li></ul><p>ğŸ‘‰ Example:<br>Using the previous numbers, ( TF(AI) &#x3D; 0.05 ) and ( IDF(AI) &#x3D; 1.20 ).<br>So, ( TF\text{-}IDF(AI) &#x3D; 0.05 \times 1.20 &#x3D; 0.06 ).</p><hr><h2 id="ğŸ¯-Why-Is-TF-IDF-Useful"><a href="#ğŸ¯-Why-Is-TF-IDF-Useful" class="headerlink" title="ğŸ¯ Why Is TF-IDF Useful?"></a>ğŸ¯ Why Is TF-IDF Useful?</h2><ul><li><strong>Search Engines</strong>: Helps rank documents by relevance to a query.  </li><li><strong>Text Mining</strong>: Identifies key terms in large text datasets.  </li><li><strong>Spam Filtering</strong>: Detects suspicious terms often used in spam messages.  </li><li><strong>Recommendation Systems</strong>: Finds similarities between documents or user profiles.</li></ul><hr><h2 id="ğŸ“-Summary"><a href="#ğŸ“-Summary" class="headerlink" title="ğŸ“ Summary"></a>ğŸ“ Summary</h2><ul><li><strong>TF</strong> â†’ Frequency of a word in a document.  </li><li><strong>IDF</strong> â†’ Importance of a word across all documents.  </li><li><strong>TF-IDF</strong> â†’ Highlights words that are frequent in one document but rare across the corpus.</li></ul><p>ğŸ‘‰ In AWS or AI-related exams, TF-IDF often comes up as a <strong>classic feature extraction technique</strong> for text data before applying ML algorithms.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ“˜-Training-Data-Feature-Engineering&quot;&gt;&lt;a href=&quot;#ğŸ“˜-Training-Data-Feature-Engineering&quot; class=&quot;headerlink&quot; title=&quot;ğŸ“˜ Training Data &amp;am</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(í•œêµ­ì–´) AWS Certified AI Practitioner (23) - ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ë°ì´í„° ì •ë¦¬</title>
    <link href="https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-23/"/>
    <id>https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-23/</id>
    <published>2025-08-23T13:50:09.000Z</published>
    <updated>2025-08-23T22:13:40.546Z</updated>
    
    <content type="html"><![CDATA[<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id="MathJax-script" async  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><h1 id="ğŸ“Š-ë¨¸ì‹ ëŸ¬ë‹-í•™ìŠµ-ë°ì´í„°-ì •ë¦¬"><a href="#ğŸ“Š-ë¨¸ì‹ ëŸ¬ë‹-í•™ìŠµ-ë°ì´í„°-ì •ë¦¬" class="headerlink" title="ğŸ“Š ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ë°ì´í„° ì •ë¦¬"></a>ğŸ“Š ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ë°ì´í„° ì •ë¦¬</h1><h2 id="1-í•™ìŠµ-ë°ì´í„°-Training-Data-ì˜-ì¤‘ìš”ì„±"><a href="#1-í•™ìŠµ-ë°ì´í„°-Training-Data-ì˜-ì¤‘ìš”ì„±" class="headerlink" title="1. í•™ìŠµ ë°ì´í„°(Training Data)ì˜ ì¤‘ìš”ì„±"></a>1. í•™ìŠµ ë°ì´í„°(Training Data)ì˜ ì¤‘ìš”ì„±</h2><ul><li>ì¢‹ì€ ë°ì´í„°ë¥¼ ê°€ì ¸ì•¼ ì¢‹ì€ ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆìŒ  </li><li><strong>Garbage In â†’ Garbage Out</strong> : ì˜ëª»ëœ ë°ì´í„°ë¥¼ ë„£ìœ¼ë©´ ê²°ê³¼ë„ ì˜ëª»ë¨  </li><li>ê°€ì¥ ì¤‘ìš”í•œ ë‹¨ê³„ &#x3D; ë°ì´í„°ë¥¼ ê¹¨ë—í•˜ê²Œ ì¤€ë¹„í•˜ëŠ” ê²ƒ  </li><li>ë°ì´í„°ì˜ ì¢…ë¥˜ì— ë”°ë¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì•Œê³ ë¦¬ì¦˜ë„ ë‹¬ë¼ì§</li></ul><hr><h2 id="2-ë¼ë²¨ë§-ë°ì´í„°-vs-ë¹„ë¼ë²¨ë§-ë°ì´í„°"><a href="#2-ë¼ë²¨ë§-ë°ì´í„°-vs-ë¹„ë¼ë²¨ë§-ë°ì´í„°" class="headerlink" title="2. ë¼ë²¨ë§ ë°ì´í„° vs ë¹„ë¼ë²¨ë§ ë°ì´í„°"></a>2. ë¼ë²¨ë§ ë°ì´í„° vs ë¹„ë¼ë²¨ë§ ë°ì´í„°</h2><h3 id="ğŸ”¹-ë¼ë²¨ë§-ë°ì´í„°-Labeled-Data"><a href="#ğŸ”¹-ë¼ë²¨ë§-ë°ì´í„°-Labeled-Data" class="headerlink" title="ğŸ”¹ ë¼ë²¨ë§ ë°ì´í„° (Labeled Data)"></a>ğŸ”¹ ë¼ë²¨ë§ ë°ì´í„° (Labeled Data)</h3><ul><li>ì…ë ¥ê°’(Input) + ì •ë‹µ(Output Label)ì´ í•¨ê»˜ ìˆëŠ” ë°ì´í„°  </li><li>ì˜ˆ: ê³ ì–‘ì´, ê°•ì•„ì§€ ì´ë¯¸ì§€ì™€ ê°ê°ì˜ ë¼ë²¨ì´ í•¨ê»˜ ìˆìŒ  </li><li><strong>ì‚¬ìš© ì‚¬ë¡€</strong>: ì§€ë„í•™ìŠµ(Supervised Learning)</li></ul><p align="center">  <img src="/images/aws_basic_107.png" width="80%"></p><h3 id="ğŸ”¹-ë¹„ë¼ë²¨ë§-ë°ì´í„°-Unlabeled-Data"><a href="#ğŸ”¹-ë¹„ë¼ë²¨ë§-ë°ì´í„°-Unlabeled-Data" class="headerlink" title="ğŸ”¹ ë¹„ë¼ë²¨ë§ ë°ì´í„° (Unlabeled Data)"></a>ğŸ”¹ ë¹„ë¼ë²¨ë§ ë°ì´í„° (Unlabeled Data)</h3><ul><li>ì…ë ¥ê°’ë§Œ ìˆê³  ì •ë‹µ ë¼ë²¨ì´ ì—†ìŒ  </li><li>ì˜ˆ: ê³ ì–‘ì´&#x2F;ê°•ì•„ì§€ ì‚¬ì§„ë§Œ ìˆê³  ë¼ë²¨ì´ ì—†ëŠ” ê²½ìš°  </li><li><strong>ì‚¬ìš© ì‚¬ë¡€</strong>: ë¹„ì§€ë„í•™ìŠµ(Unsupervised Learning) â†’ íŒ¨í„´ì´ë‚˜ êµ°ì§‘ ì°¾ê¸°</li></ul><p>ğŸ‘‰ ì‹œí—˜ í¬ì¸íŠ¸: <strong>ë¼ë²¨ë§ ë°ì´í„° â†’ ì§€ë„í•™ìŠµ &#x2F; ë¹„ë¼ë²¨ë§ ë°ì´í„° â†’ ë¹„ì§€ë„í•™ìŠµ</strong></p><p align="center">  <img src="/images/aws_basic_108.png" width="80%"></p>---<h2 id="3-êµ¬ì¡°í™”-ë°ì´í„°-vs-ë¹„êµ¬ì¡°í™”-ë°ì´í„°"><a href="#3-êµ¬ì¡°í™”-ë°ì´í„°-vs-ë¹„êµ¬ì¡°í™”-ë°ì´í„°" class="headerlink" title="3. êµ¬ì¡°í™” ë°ì´í„° vs ë¹„êµ¬ì¡°í™” ë°ì´í„°"></a>3. êµ¬ì¡°í™” ë°ì´í„° vs ë¹„êµ¬ì¡°í™” ë°ì´í„°</h2><h3 id="ğŸ”¹-êµ¬ì¡°í™”-ë°ì´í„°-Structured-Data"><a href="#ğŸ”¹-êµ¬ì¡°í™”-ë°ì´í„°-Structured-Data" class="headerlink" title="ğŸ”¹ êµ¬ì¡°í™” ë°ì´í„° (Structured Data)"></a>ğŸ”¹ êµ¬ì¡°í™” ë°ì´í„° (Structured Data)</h3><ul><li>í–‰(Row)ê³¼ ì—´(Column)ë¡œ ì •ë¦¬ëœ ë°ì´í„° (ì˜ˆ: ì—‘ì…€, DB)</li><li><strong>ì˜ˆì‹œ</strong><ul><li>í‘œ í˜•íƒœ(Tabular): ê³ ê° ID, ì´ë¦„, ë‚˜ì´, êµ¬ë§¤ ê¸ˆì•¡</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_109.png" width="80%"></p><ul><li>ì‹œê³„ì—´ ë°ì´í„°(Time Series): ì£¼ì‹ ê°€ê²©, ì„¼ì„œ ë°ì´í„°</li></ul><p align="center">  <img src="/images/aws_basic_110.png" width="80%"></p><h3 id="ğŸ”¹-ë¹„êµ¬ì¡°í™”-ë°ì´í„°-Unstructured-Data"><a href="#ğŸ”¹-ë¹„êµ¬ì¡°í™”-ë°ì´í„°-Unstructured-Data" class="headerlink" title="ğŸ”¹ ë¹„êµ¬ì¡°í™” ë°ì´í„° (Unstructured Data)"></a>ğŸ”¹ ë¹„êµ¬ì¡°í™” ë°ì´í„° (Unstructured Data)</h3><ul><li>ì¼ì •í•œ í˜•ì‹ì´ ì—†ëŠ” ë°ì´í„° (í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤ ë“±)</li><li><strong>ì˜ˆì‹œ</strong><ul><li>í…ìŠ¤íŠ¸ ë°ì´í„°: ë¦¬ë·°, SNS ê¸€</li><li>ì´ë¯¸ì§€ ë°ì´í„°: ê°ì²´ ì¸ì‹ìš© ì´ë¯¸ì§€</li></ul></li></ul><hr><h2 id="4-ì§€ë„í•™ìŠµ-Supervised-Learning"><a href="#4-ì§€ë„í•™ìŠµ-Supervised-Learning" class="headerlink" title="4. ì§€ë„í•™ìŠµ (Supervised Learning)"></a>4. ì§€ë„í•™ìŠµ (Supervised Learning)</h2><ul><li>ì •ë‹µ(ë¼ë²¨)ì´ ìˆëŠ” ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµ  </li><li><strong>ëª©í‘œ</strong>: ì…ë ¥ê°’ â†’ ì¶œë ¥ê°’ ì˜ˆì¸¡</li></ul><h3 id="ğŸ“ˆ-íšŒê·€-Regression"><a href="#ğŸ“ˆ-íšŒê·€-Regression" class="headerlink" title="ğŸ“ˆ íšŒê·€(Regression)"></a>ğŸ“ˆ íšŒê·€(Regression)</h3><ul><li>ì—°ì†ì ì¸ ìˆ«ì ê°’ ì˜ˆì¸¡  </li><li>ì˜ˆì‹œ:<ul><li>ì§‘ê°’ ì˜ˆì¸¡ (ë©´ì , ìœ„ì¹˜, ë°© ê°œìˆ˜ ê¸°ë°˜)</li><li>ì£¼ì‹ ê°€ê²© ì˜ˆì¸¡</li><li>ë‚ ì”¨(ì˜¨ë„) ì˜ˆì¸¡</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_112.png" width="80%"></p><h3 id="ğŸ·ï¸-ë¶„ë¥˜-Classification"><a href="#ğŸ·ï¸-ë¶„ë¥˜-Classification" class="headerlink" title="ğŸ·ï¸ ë¶„ë¥˜(Classification)"></a>ğŸ·ï¸ ë¶„ë¥˜(Classification)</h3><ul><li>ì¹´í…Œê³ ë¦¬ ì˜ˆì¸¡ (ì´ì‚°í˜• ë°ì´í„°)  </li><li>ì˜ˆì‹œ:<ul><li>ì´ì§„ ë¶„ë¥˜(Binary): ìŠ¤íŒ¸ë©”ì¼ &#x2F; ì •ìƒë©”ì¼</li><li>ë‹¤ì¤‘ ë¶„ë¥˜(Multi-class): ë™ë¬¼ â†’ í¬ìœ ë¥˜, ì¡°ë¥˜, íŒŒì¶©ë¥˜</li><li>ë‹¤ì¤‘ ë¼ë²¨(Multi-label): ì˜í™” â†’ ì•¡ì…˜ + ì½”ë¯¸ë””</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_113.png" width="80%"></p><p>ğŸ‘‰ ì‹œí—˜ í¬ì¸íŠ¸: <strong>Regression &#x3D; ìˆ«ì ì˜ˆì¸¡ &#x2F; Classification &#x3D; ì¹´í…Œê³ ë¦¬ ì˜ˆì¸¡</strong></p><p align="center">  <img src="/images/aws_basic_111.png" width="80%"></p><hr><h2 id="5-ë°ì´í„°ì…‹-ë¶„ë¦¬"><a href="#5-ë°ì´í„°ì…‹-ë¶„ë¦¬" class="headerlink" title="5. ë°ì´í„°ì…‹ ë¶„ë¦¬"></a>5. ë°ì´í„°ì…‹ ë¶„ë¦¬</h2><ul><li>í•™ìŠµ ë°ì´í„°ì…‹(Training), ê²€ì¦ ë°ì´í„°ì…‹(Validation), í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹(Test)ìœ¼ë¡œ ë‚˜ëˆ”</li></ul><table><thead><tr><th>ë°ì´í„°ì…‹</th><th>ë¹„ìœ¨</th><th>ì—­í• </th></tr></thead><tbody><tr><td>Training</td><td>60~80%</td><td>ëª¨ë¸ í•™ìŠµ</td></tr><tr><td>Validation</td><td>10~20%</td><td>í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹</td></tr><tr><td>Test</td><td>10~20%</td><td>ìµœì¢… ì„±ëŠ¥ í‰ê°€</td></tr></tbody></table><p>ğŸ‘‰ ì‹œí—˜ í¬ì¸íŠ¸: <strong>Validationì€ ëª¨ë¸ ì¡°ì •ìš©, TestëŠ” ìµœì¢… ì„±ëŠ¥ í™•ì¸ìš©</strong></p><p align="center">  <img src="/images/aws_basic_114.png" width="80%"></p><hr><h2 id="6-íŠ¹ì§•-ê³µí•™-Feature-Engineering"><a href="#6-íŠ¹ì§•-ê³µí•™-Feature-Engineering" class="headerlink" title="6. íŠ¹ì§• ê³µí•™ (Feature Engineering)"></a>6. íŠ¹ì§• ê³µí•™ (Feature Engineering)</h2><ul><li>ì›ì‹œ(raw) ë°ì´í„°ë¥¼ ìœ ìš©í•œ íŠ¹ì§•(Feature)ìœ¼ë¡œ ê°€ê³µí•˜ëŠ” ê³¼ì •  </li><li>ì„±ëŠ¥ í–¥ìƒì— ë§¤ìš° ì¤‘ìš”í•œ ë‹¨ê³„</li></ul><h3 id="ğŸ”¹-ì£¼ìš”-ê¸°ë²•"><a href="#ğŸ”¹-ì£¼ìš”-ê¸°ë²•" class="headerlink" title="ğŸ”¹ ì£¼ìš” ê¸°ë²•"></a>ğŸ”¹ ì£¼ìš” ê¸°ë²•</h3><ol><li><strong>íŠ¹ì§• ì¶”ì¶œ (Feature Extraction)</strong>  <ul><li>ì˜ˆ: ìƒë…„ì›”ì¼ â†’ ë‚˜ì´(age) ê³„ì‚°</li></ul></li></ol><p align="center">  <img src="/images/aws_basic_115.png" width="80%"></p><ol start="2"><li><strong>íŠ¹ì§• ì„ íƒ (Feature Selection)</strong>  <ul><li>ì¤‘ìš”í•œ íŠ¹ì§•ë§Œ ì„ íƒ (ì˜ˆ: ì§‘ê°’ ì˜ˆì¸¡ì—ì„œ ìœ„ì¹˜, í‰ìˆ˜ë§Œ ì„ íƒ)</li></ul></li><li><strong>íŠ¹ì§• ë³€í™˜ (Feature Transformation)</strong>  <ul><li>ë°ì´í„° ì •ê·œí™”(Normalization) ë“±ìœ¼ë¡œ ëª¨ë¸ í•™ìŠµì„ ë¹ ë¥´ê³  ì•ˆì •ì ìœ¼ë¡œ ìˆ˜í–‰</li></ul></li></ol><h3 id="ğŸ”¹-êµ¬ì¡°í™”-ë°ì´í„°ì—ì„œì˜-íŠ¹ì§•-ê³µí•™"><a href="#ğŸ”¹-êµ¬ì¡°í™”-ë°ì´í„°ì—ì„œì˜-íŠ¹ì§•-ê³µí•™" class="headerlink" title="ğŸ”¹ êµ¬ì¡°í™” ë°ì´í„°ì—ì„œì˜ íŠ¹ì§• ê³µí•™"></a>ğŸ”¹ êµ¬ì¡°í™” ë°ì´í„°ì—ì„œì˜ íŠ¹ì§• ê³µí•™</h3><ul><li>ì˜ˆ: ì§‘ê°’ ì˜ˆì¸¡<ul><li>ìƒˆë¡œìš´ íŠ¹ì§• ìƒì„±: â€œí‰ë‹¹ ê°€ê²©â€</li><li>ì¤‘ìš” íŠ¹ì§• ì„ íƒ: ìœ„ì¹˜, ë°© ê°œìˆ˜</li><li>ì •ê·œí™”: ëª¨ë“  ìˆ˜ì¹˜ë¥¼ ë¹„ìŠ·í•œ ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜</li></ul></li></ul><h3 id="ğŸ”¹-ë¹„êµ¬ì¡°í™”-ë°ì´í„°ì—ì„œì˜-íŠ¹ì§•-ê³µí•™"><a href="#ğŸ”¹-ë¹„êµ¬ì¡°í™”-ë°ì´í„°ì—ì„œì˜-íŠ¹ì§•-ê³µí•™" class="headerlink" title="ğŸ”¹ ë¹„êµ¬ì¡°í™” ë°ì´í„°ì—ì„œì˜ íŠ¹ì§• ê³µí•™"></a>ğŸ”¹ ë¹„êµ¬ì¡°í™” ë°ì´í„°ì—ì„œì˜ íŠ¹ì§• ê³µí•™</h3><ul><li><strong>í…ìŠ¤íŠ¸ ë°ì´í„°</strong>: TF-IDF, ì›Œë“œ ì„ë² ë”©  </li><li><strong>ì´ë¯¸ì§€ ë°ì´í„°</strong>: CNNìœ¼ë¡œ ì—£ì§€, íŒ¨í„´, ìƒ‰ìƒ íŠ¹ì§• ì¶”ì¶œ</li></ul><p>ğŸ‘‰ ì‹œí—˜ í¬ì¸íŠ¸: <strong>Feature Engineeringì€ ëª¨ë¸ ì„±ëŠ¥ ìµœì í™”ì˜ í•µì‹¬ ê³¼ì •</strong></p><hr><h2 id="âœ…-ìš”ì•½"><a href="#âœ…-ìš”ì•½" class="headerlink" title="âœ… ìš”ì•½"></a>âœ… ìš”ì•½</h2><ul><li><strong>ì¢‹ì€ ë°ì´í„° í™•ë³´</strong>ê°€ ê°€ì¥ ì¤‘ìš” (Garbage In â†’ Garbage Out)  </li><li><strong>ë¼ë²¨ë§ ì—¬ë¶€</strong> â†’ ì§€ë„í•™ìŠµ vs ë¹„ì§€ë„í•™ìŠµ  </li><li><strong>ë°ì´í„° êµ¬ì¡°</strong> â†’ êµ¬ì¡°í™” vs ë¹„êµ¬ì¡°í™”  </li><li><strong>ì§€ë„í•™ìŠµ ìœ í˜•</strong> â†’ íšŒê·€(ìˆ«ì ì˜ˆì¸¡), ë¶„ë¥˜(ì¹´í…Œê³ ë¦¬ ì˜ˆì¸¡)  </li><li><strong>ë°ì´í„°ì…‹ ë¶„ë¦¬</strong> â†’ Training &#x2F; Validation &#x2F; Test  </li><li><strong>íŠ¹ì§• ê³µí•™</strong> â†’ ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ë°ì´í„° ê°€ê³µ</li></ul><p>ğŸ‘‰ AWS ìê²©ì¦ ì‹œí—˜ ëŒ€ë¹„:</p><ul><li>ì§€ë„&#x2F;ë¹„ì§€ë„ í•™ìŠµ ê°œë…</li><li>ë°ì´í„°ì…‹ ë¶„ë¦¬ ë¹„ìœ¨</li><li>Feature Engineering ê¸°ë²•<br>ì„ í™•ì‹¤íˆ ê¸°ì–µí•´ ë‘ë©´ ì‹œí—˜ì— ìœ ìš©í•¨ ğŸš€</li></ul><h2 id="ì¶”ê°€ë‚´ìš©-1-TF-IDFë€"><a href="#ì¶”ê°€ë‚´ìš©-1-TF-IDFë€" class="headerlink" title="(ì¶”ê°€ë‚´ìš©) 1. TF-IDFë€?"></a>(ì¶”ê°€ë‚´ìš©) 1. TF-IDFë€?</h2><p>TF-IDFëŠ” <strong>ë¬¸ì„œ(Text)</strong> ì•ˆì—ì„œ ë‹¨ì–´ì˜ ì¤‘ìš”ë„ë¥¼ ìˆ˜ì¹˜ë¡œ ë‚˜íƒ€ë‚´ëŠ” ë°©ë²•ì´ì—ìš”.<br>ê²€ìƒ‰ ì—”ì§„, ë¬¸ì„œ ë¶„ë¥˜, ìì—°ì–´ ì²˜ë¦¬(NLP)ì—ì„œ ìì£¼ ì‚¬ìš©ë©ë‹ˆë‹¤.  </p><p>ğŸ‘‰ í•µì‹¬ ì•„ì´ë””ì–´:  </p><ul><li>íŠ¹ì • ë¬¸ì„œì—ì„œ <strong>ë§ì´ ë“±ì¥í•˜ëŠ” ë‹¨ì–´</strong>ì¼ìˆ˜ë¡ ì¤‘ìš”í•˜ë‹¤ (<strong>TF</strong>)  </li><li>í•˜ì§€ë§Œ <strong>ëª¨ë“  ë¬¸ì„œì— í”íˆ ë“±ì¥í•˜ëŠ” ë‹¨ì–´</strong>ëŠ” ì¤‘ìš”í•˜ì§€ ì•Šë‹¤ (<strong>IDF</strong>)</li></ul><hr><h2 id="ì¶”ê°€ë‚´ìš©-2-TF-Term-Frequency-ë‹¨ì–´-ë¹ˆë„"><a href="#ì¶”ê°€ë‚´ìš©-2-TF-Term-Frequency-ë‹¨ì–´-ë¹ˆë„" class="headerlink" title="(ì¶”ê°€ë‚´ìš©) 2. TF (Term Frequency, ë‹¨ì–´ ë¹ˆë„)"></a>(ì¶”ê°€ë‚´ìš©) 2. TF (Term Frequency, ë‹¨ì–´ ë¹ˆë„)</h2><ul><li>ì–´ë–¤ ë¬¸ì„œ ì•ˆì—ì„œ íŠ¹ì • ë‹¨ì–´ê°€ ì–¼ë§ˆë‚˜ ìì£¼ ë“±ì¥í–ˆëŠ”ì§€ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.  </li><li>ê³„ì‚°ì‹:</li></ul><p>$$<br>TF(t, d) &#x3D; \frac{\text{ë‹¨ì–´ tì˜ ë“±ì¥ íšŸìˆ˜}}{\text{ë¬¸ì„œ dì˜ ì „ì²´ ë‹¨ì–´ ìˆ˜}}<br>$$</p><p>ğŸ“Œ ì˜ˆì‹œ:<br>ë¬¸ì„œì— ë‹¨ì–´ê°€ 100ê°œ ìˆê³ , ê·¸ ì¤‘ <strong>â€œdogâ€</strong> ê°€ 5ë²ˆ ë‚˜ì™”ë‹¤ë©´:  </p><p>$$<br>TF(dog) &#x3D; \frac{5}{100} &#x3D; 0.05<br>$$</p><hr><h2 id="ì¶”ê°€ë‚´ìš©-3-IDF-Inverse-Document-Frequency-ì—­ë¬¸ì„œ-ë¹ˆë„"><a href="#ì¶”ê°€ë‚´ìš©-3-IDF-Inverse-Document-Frequency-ì—­ë¬¸ì„œ-ë¹ˆë„" class="headerlink" title="(ì¶”ê°€ë‚´ìš©) 3. IDF (Inverse Document Frequency, ì—­ë¬¸ì„œ ë¹ˆë„)"></a>(ì¶”ê°€ë‚´ìš©) 3. IDF (Inverse Document Frequency, ì—­ë¬¸ì„œ ë¹ˆë„)</h2><ul><li>í”í•œ ë‹¨ì–´(ì˜ˆ: â€œtheâ€, â€œandâ€)ëŠ” ì¤‘ìš”í•˜ì§€ ì•Šë‹¤ê³  ë³´ê³ , ë“œë¬¼ê²Œ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ì— ê°€ì¤‘ì¹˜ë¥¼ ë” ì¤ë‹ˆë‹¤.  </li><li>ê³„ì‚°ì‹:</li></ul><p>$$<br>IDF(t) &#x3D; \log \frac{\text{ì „ì²´ ë¬¸ì„œ ìˆ˜}}{\text{ë‹¨ì–´ tê°€ ë“±ì¥í•œ ë¬¸ì„œ ìˆ˜}}<br>$$</p><p>ğŸ“Œ ì˜ˆì‹œ:  </p><ul><li>ë¬¸ì„œ 1000ê°œ ì¤‘ â€œdogâ€ì´ 10ê°œ ë¬¸ì„œì—ë§Œ ë“±ì¥ â†’</li></ul><p>$$<br>IDF(dog) &#x3D; \log \frac{1000}{10} &#x3D; \log(100) \approx 2<br>$$  </p><ul><li>â€œtheâ€ê°€ 1000ê°œ ë¬¸ì„œ ëª¨ë‘ì— ë“±ì¥ â†’</li></ul><p>$$<br>IDF(the) &#x3D; \log \frac{1000}{1000} &#x3D; \log(1) &#x3D; 0<br>$$  </p><p>ì¦‰, í”í•œ ë‹¨ì–´ëŠ” ì¤‘ìš”ë„ê°€ ê±°ì˜ 0ì´ ë©ë‹ˆë‹¤.</p><hr><h2 id="ì¶”ê°€ë‚´ìš©-4-TF-IDF-ìµœì¢…-ê³„ì‚°"><a href="#ì¶”ê°€ë‚´ìš©-4-TF-IDF-ìµœì¢…-ê³„ì‚°" class="headerlink" title="(ì¶”ê°€ë‚´ìš©) 4. TF-IDF ìµœì¢… ê³„ì‚°"></a>(ì¶”ê°€ë‚´ìš©) 4. TF-IDF ìµœì¢… ê³„ì‚°</h2><p>$$<br>TF\text{-}IDF(t, d) &#x3D; TF(t, d) \times IDF(t)<br>$$</p><p>ğŸ‘‰ ë‹¨ì–´ê°€ <strong>íŠ¹ì • ë¬¸ì„œì—ì„œ ìì£¼ ë‚˜ì˜¤ê³ </strong>, ë‹¤ë¥¸ ë¬¸ì„œì—ì„œëŠ” ì˜ ì•ˆ ë‚˜ì˜¤ë©´ â†’ <strong>ì¤‘ìš” ë‹¨ì–´!</strong></p><hr><h2 id="ì¶”ê°€ë‚´ìš©-5-ì˜ˆì‹œë¡œ-ì´í•´í•˜ê¸°"><a href="#ì¶”ê°€ë‚´ìš©-5-ì˜ˆì‹œë¡œ-ì´í•´í•˜ê¸°" class="headerlink" title="(ì¶”ê°€ë‚´ìš©) 5. ì˜ˆì‹œë¡œ ì´í•´í•˜ê¸°"></a>(ì¶”ê°€ë‚´ìš©) 5. ì˜ˆì‹œë¡œ ì´í•´í•˜ê¸°</h2><p>ë¬¸ì„œ 3ê°œê°€ ìˆë‹¤ê³  ê°€ì •í•´ ë´…ì‹œë‹¤.</p><ul><li>ë¬¸ì„œ1: â€œdog likes playingâ€  </li><li>ë¬¸ì„œ2: â€œdog and cat are friendsâ€  </li><li>ë¬¸ì„œ3: â€œdog runs fastâ€</li></ul><p>ğŸ“Œ â€œdogâ€ì€ ëª¨ë“  ë¬¸ì„œì— ë“±ì¥ â†’ IDF ê°’ì´ ë‚®ìŒ (ì¤‘ìš”ë„ â†“)<br>ğŸ“Œ â€œplayingâ€ì€ ë¬¸ì„œ1ì—ë§Œ ë“±ì¥ â†’ IDF ê°’ì´ ë†’ìŒ (ì¤‘ìš”ë„ â†‘)  </p><p>ë”°ë¼ì„œ ë¬¸ì„œ1ì—ì„œ â€œplayingâ€ì˜ TF-IDF ì ìˆ˜ëŠ” ë†’ê²Œ ë‚˜ì˜¤ê³ , ê²€ìƒ‰ ì—”ì§„ì€ ì´ ë‹¨ì–´ë¥¼ ë¬¸ì„œ1ì˜ <strong>í•µì‹¬ í‚¤ì›Œë“œ</strong>ë¡œ ì¸ì‹í•©ë‹ˆë‹¤.</p><hr><h2 id="ì¶”ê°€ë‚´ìš©-6-ì‹œí—˜-ëŒ€ë¹„-í•µì‹¬-í¬ì¸íŠ¸"><a href="#ì¶”ê°€ë‚´ìš©-6-ì‹œí—˜-ëŒ€ë¹„-í•µì‹¬-í¬ì¸íŠ¸" class="headerlink" title="(ì¶”ê°€ë‚´ìš©) 6. ì‹œí—˜ ëŒ€ë¹„ í•µì‹¬ í¬ì¸íŠ¸"></a>(ì¶”ê°€ë‚´ìš©) 6. ì‹œí—˜ ëŒ€ë¹„ í•µì‹¬ í¬ì¸íŠ¸</h2><ul><li>TF &#x3D; íŠ¹ì • ë¬¸ì„œ ë‚´ ë‹¨ì–´ ë¹ˆë„  </li><li>IDF &#x3D; ì „ì²´ ë¬¸ì„œì—ì„œ ì–¼ë§ˆë‚˜ ë“œë¬¸ ë‹¨ì–´ì¸ì§€  </li><li>TF-IDF &#x3D; <strong>íŠ¹ì • ë¬¸ì„œì—ì„œ ì¤‘ìš”í•œ ë‹¨ì–´ë¥¼ ì°¾ëŠ” ì ìˆ˜</strong>  </li><li>ìì£¼ ë‚˜ì˜¤ëŠ” í”í•œ ë‹¨ì–´ëŠ” ë¬´ì‹œ, ë“œë¬¼ê²Œ ë‚˜ì˜¤ì§€ë§Œ íŠ¹ì • ë¬¸ì„œì— ì§‘ì¤‘ëœ ë‹¨ì–´ëŠ” ê°•ì¡°</li></ul><hr><p>ğŸ‘‰ í•œ ì¤„ ìš”ì•½:<br><strong>TF-IDFëŠ” ë¬¸ì„œì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ë½‘ì•„ë‚´ëŠ” ê°€ì¥ ê¸°ë³¸ì ì´ê³  ì¤‘ìš”í•œ ë°©ë²•ì´ë‹¤.</strong><br>AWS ìê²©ì¦ ì‹œí—˜ì—ì„œë„ <strong>í…ìŠ¤íŠ¸ ì²˜ë¦¬ë‚˜ NLP ê´€ë ¨ ë¬¸ì œ</strong>ì—ì„œ ë“±ì¥í•  ìˆ˜ ìˆìœ¼ë‹ˆ ê¼­ ê¸°ì–µí•˜ì„¸ìš” âœ…  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;script src=&quot;https://polyfill.io/v3/polyfill.min.js?features=es6&quot;&gt;&lt;/script&gt;
&lt;script id=&quot;MathJax-script&quot; async
  src=&quot;https://cdn.jsdelivr.ne</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(í•œêµ­ì–´) AWS Certified AI Practitioner (22) - ê³µì§€ëŠ¥(AI), ë¨¸ì‹ ëŸ¬ë‹(ML), ë”¥ëŸ¬ë‹(DL), ìƒì„±í˜• AI (GenAI) ì •ë¦¬</title>
    <link href="https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-22/"/>
    <id>https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-22/</id>
    <published>2025-08-23T13:01:55.000Z</published>
    <updated>2025-08-23T22:13:40.551Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ¤–-ì¸ê³µì§€ëŠ¥-AI-ë¨¸ì‹ ëŸ¬ë‹-ML-ë”¥ëŸ¬ë‹-DL-ìƒì„±í˜•-AI-GenAI-ì •ë¦¬"><a href="#ğŸ¤–-ì¸ê³µì§€ëŠ¥-AI-ë¨¸ì‹ ëŸ¬ë‹-ML-ë”¥ëŸ¬ë‹-DL-ìƒì„±í˜•-AI-GenAI-ì •ë¦¬" class="headerlink" title="ğŸ¤– ì¸ê³µì§€ëŠ¥(AI), ë¨¸ì‹ ëŸ¬ë‹(ML), ë”¥ëŸ¬ë‹(DL), ìƒì„±í˜• AI (GenAI) ì •ë¦¬"></a>ğŸ¤– ì¸ê³µì§€ëŠ¥(AI), ë¨¸ì‹ ëŸ¬ë‹(ML), ë”¥ëŸ¬ë‹(DL), ìƒì„±í˜• AI (GenAI) ì •ë¦¬</h1><h2 id="1-ì¸ê³µì§€ëŠ¥-AI-ë€"><a href="#1-ì¸ê³µì§€ëŠ¥-AI-ë€" class="headerlink" title="1. ì¸ê³µì§€ëŠ¥(AI)ë€?"></a>1. ì¸ê³µì§€ëŠ¥(AI)ë€?</h2><ul><li>AIëŠ” <strong>ì¸ê°„ì˜ ì§€ëŠ¥ì´ í•„ìš”í•œ ì¼ì„ ëŒ€ì‹  ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œ</strong>ì„ ë§Œë“œëŠ” ê´‘ë²”ìœ„í•œ ê¸°ìˆ  ë¶„ì•¼ì…ë‹ˆë‹¤.  </li><li>ì£¼ìš” ê¸°ëŠ¥:<ul><li>ì¸ì‹(Perception)</li><li>ì¶”ë¡ (Reasoning)</li><li>í•™ìŠµ(Learning)</li><li>ë¬¸ì œ í•´ê²°(Problem Solving)</li><li>ì˜ì‚¬ê²°ì •(Decision Making)</li></ul></li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: AIëŠ” í° ê°œë…(ìš°ì‚°)ì´ê³ , ê·¸ ì•ˆì— <strong>ML â†’ DL â†’ GenAI</strong> ìˆœì„œë¡œ ì„¸ë¶€ ê¸°ìˆ ì´ í¬í•¨ë©ë‹ˆë‹¤.  </p><p align="center">  <img src="/images/aws_basic_96.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_97.png" width="80%"></p>---<h2 id="2-AIì˜-êµ¬ì„±-ìš”ì†Œ"><a href="#2-AIì˜-êµ¬ì„±-ìš”ì†Œ" class="headerlink" title="2. AIì˜ êµ¬ì„± ìš”ì†Œ"></a>2. AIì˜ êµ¬ì„± ìš”ì†Œ</h2><ul><li><strong>ë°ì´í„° ê³„ì¸µ</strong>: ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘  </li><li><strong>ML í”„ë ˆì„ì›Œí¬ ë° ì•Œê³ ë¦¬ì¦˜ ê³„ì¸µ</strong>: ë°ì´í„° ê³¼í•™ìì™€ ì—”ì§€ë‹ˆì–´ê°€ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” ì•Œê³ ë¦¬ì¦˜ ì„¤ê³„  </li><li><strong>ëª¨ë¸ ê³„ì¸µ</strong>: ëª¨ë¸ êµ¬ì¡° ì„¤ê³„, íŒŒë¼ë¯¸í„° ë° ìµœì í™” í•¨ìˆ˜ ì ìš© â†’ í•™ìŠµ ìˆ˜í–‰  </li><li><strong>ì• í”Œë¦¬ì¼€ì´ì…˜ ê³„ì¸µ</strong>: í•™ìŠµëœ ëª¨ë¸ì„ ì‹¤ì œ ì‚¬ìš©ìì—ê²Œ ì„œë¹„ìŠ¤</li></ul><p align="center">  <img src="/images/aws_basic_98.png" width="80%"></p><hr><h2 id="3-ë¨¸ì‹ ëŸ¬ë‹-ML-ë€"><a href="#3-ë¨¸ì‹ ëŸ¬ë‹-ML-ë€" class="headerlink" title="3. ë¨¸ì‹ ëŸ¬ë‹(ML)ë€?"></a>3. ë¨¸ì‹ ëŸ¬ë‹(ML)ë€?</h2><ul><li>AIì˜ í•œ ë¶„ì•¼ë¡œ, ë°ì´í„°ë¥¼ ì´ìš©í•´ <strong>ê¸°ê³„ê°€ í•™ìŠµ</strong>í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê¸°ìˆ   </li><li>ê·œì¹™ì„ ì§ì ‘ í”„ë¡œê·¸ë˜ë°í•˜ì§€ ì•Šê³ , ë°ì´í„°ë¥¼ í†µí•´ <strong>ì˜ˆì¸¡ ëª¨ë¸</strong>ì„ ë§Œë“¦  </li><li>ì˜ˆì‹œ:<ul><li><strong>íšŒê·€(Regression)</strong>: ì—°ì†ì ì¸ ê°’ ì˜ˆì¸¡ (ì˜ˆ: ì§‘ê°’ ì˜ˆì¸¡)  </li><li><strong>ë¶„ë¥˜(Classification)</strong>: ê·¸ë£¹ êµ¬ë¶„ (ì˜ˆ: ê³ ì–‘ì´ vs ê°œ ì´ë¯¸ì§€ ë¶„ë¥˜)</li></ul></li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: MLì€ ë°ì´í„°ë¥¼ í†µí•´ í•™ìŠµí•˜ì§€ë§Œ, <strong>ëª…ì‹œì  ê·œì¹™(If&#x2F;Then)ì„ ì§ì ‘ ì‘ì„±í•˜ì§€ ì•ŠëŠ”ë‹¤</strong>.  </p><p align="center">  <img src="/images/aws_basic_99.png" width="80%"></p><hr><h2 id="4-AI-â‰ -ML-ê³ ì „-AI-ì˜ˆì‹œ"><a href="#4-AI-â‰ -ML-ê³ ì „-AI-ì˜ˆì‹œ" class="headerlink" title="4. AI â‰  ML (ê³ ì „ AI ì˜ˆì‹œ)"></a>4. AI â‰  ML (ê³ ì „ AI ì˜ˆì‹œ)</h2><ul><li><strong>MYCIN ì „ë¬¸ê°€ ì‹œìŠ¤í…œ (1970ë…„ëŒ€)</strong>  <ul><li>ì¦ìƒ&#x2F;ê²€ì‚¬ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í™˜ì ì§„ë‹¨  </li><li>500ê°œ ì´ìƒì˜ ê·œì¹™(If-Then Rule)ë¡œ ì‘ë™  </li><li>í™•ë¥  ê¸°ë°˜ìœ¼ë¡œ ì›ì¸ê·  ì¶”ì • ë° ì¹˜ë£Œ ì œì•ˆ  </li><li>ë‹¹ì‹œì—ëŠ” ê°œì¸ìš© ì»´í“¨í„°ê°€ ì—†ì–´ ì‹¤ì œ ë„ì…ì€ ì œí•œì </li></ul></li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: ì˜›ë‚  AIëŠ” ê·œì¹™ ê¸°ë°˜(Expert System)ì´ì—ˆì§€ë§Œ, í˜„ëŒ€ AIëŠ” MLì„ ì¤‘ì‹¬ìœ¼ë¡œ ë°œì „.  </p><p align="center">  <img src="/images/aws_basic_100.png" width="80%"></p><hr><h2 id="5-ë”¥ëŸ¬ë‹-Deep-Learning-DL"><a href="#5-ë”¥ëŸ¬ë‹-Deep-Learning-DL" class="headerlink" title="5. ë”¥ëŸ¬ë‹(Deep Learning, DL)"></a>5. ë”¥ëŸ¬ë‹(Deep Learning, DL)</h2><ul><li><p>MLì˜ í•˜ìœ„ ë¶„ì•¼  </p></li><li><p>ë‡Œì˜ <strong>ë‰´ëŸ°(Neuron)ê³¼ ì‹œëƒ…ìŠ¤(Synapse)</strong> êµ¬ì¡°ë¥¼ ëª¨ë°©í•œ <strong>ì‹ ê²½ë§(Neural Network)</strong> ê¸°ë°˜  </p></li><li><p>íŠ¹ì§•:</p><ul><li>ë‹¤ì¸µ(hidden layers)ì„ í™œìš© â†’ ë” ë³µì¡í•œ íŒ¨í„´ í•™ìŠµ  </li><li><strong>ëŒ€ëŸ‰ì˜ ë°ì´í„°</strong> í•„ìš”  </li><li><strong>GPU</strong> í•„ìš” (ë³‘ë ¬ ì—°ì‚°ì„ ë¹ ë¥´ê²Œ ì²˜ë¦¬)</li></ul></li><li><p>ì£¼ìš” í™œìš©:</p><ul><li><strong>ì»´í“¨í„° ë¹„ì „</strong>: ì´ë¯¸ì§€ ë¶„ë¥˜, ê°ì²´ íƒì§€, ì˜ìƒ ì¸ì‹  </li><li><strong>ìì—°ì–´ ì²˜ë¦¬(NLP)</strong>: ë²ˆì—­, ê°ì • ë¶„ì„, í…ìŠ¤íŠ¸ ìš”ì•½</li></ul></li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: DL &#x3D; MLë³´ë‹¤ ë³µì¡í•œ ë¬¸ì œ í•´ê²° ê°€ëŠ¥, <strong>GPU í™œìš©</strong>ì´ ìì£¼ ì–¸ê¸‰ë¨.  </p><p align="center">  <img src="/images/aws_basic_101.png" width="80%"></p><hr><h2 id="6-ì‹ ê²½ë§-Neural-Networks-ë™ì‘-ë°©ì‹"><a href="#6-ì‹ ê²½ë§-Neural-Networks-ë™ì‘-ë°©ì‹" class="headerlink" title="6. ì‹ ê²½ë§(Neural Networks) ë™ì‘ ë°©ì‹"></a>6. ì‹ ê²½ë§(Neural Networks) ë™ì‘ ë°©ì‹</h2><ul><li>ì…ë ¥ ë°ì´í„°ê°€ <strong>ë…¸ë“œ(Node)</strong> ë¥¼ í†µí•´ ì—¬ëŸ¬ ì¸µì„ ê±°ì¹˜ë©° ì „ë‹¬  </li><li>ê° ì¸µì—ì„œ íŒ¨í„´ì„ í•™ìŠµ â†’ ìƒˆë¡œìš´ ì—°ê²° ìƒì„± ë˜ëŠ” ë¶ˆí•„ìš”í•œ ì—°ê²° ì œê±°  </li><li>ìˆ˜ì‹­ì–µ ê°œì˜ ë…¸ë“œì™€ ìˆ˜ë°±~ìˆ˜ì²œ ê°œì˜ ì¸µìœ¼ë¡œ êµ¬ì„± ê°€ëŠ¥</li></ul><p>ì˜ˆ: <strong>ì†ê¸€ì”¨ ìˆ«ì ì¸ì‹</strong>  </p><ul><li>í•œ ì¸µì€ â€œì„¸ë¡œ ì„ â€ì„ ê°ì§€ (1, 4, 7)  </li><li>ë˜ ë‹¤ë¥¸ ì¸µì€ â€œê³¡ì„ â€ì„ ê°ì§€ (6, 8, 0)  </li><li>ì—¬ëŸ¬ ì¸µì´ ê²°í•©ë˜ë©´ì„œ ìˆ«ì ì¸ì‹ ê°€ëŠ¥</li></ul><p align="center">  <img src="/images/aws_basic_102.png" width="80%"></p>---<h2 id="7-ìƒì„±í˜•-AI-Generative-AI-GenAI"><a href="#7-ìƒì„±í˜•-AI-Generative-AI-GenAI" class="headerlink" title="7. ìƒì„±í˜• AI (Generative AI, GenAI)"></a>7. ìƒì„±í˜• AI (Generative AI, GenAI)</h2><ul><li>ë”¥ëŸ¬ë‹ì˜ í•˜ìœ„ ë¶„ì•¼  </li><li>**ì‚¬ì „ í•™ìŠµëœ ëŒ€ê·œëª¨ ëª¨ë¸(Foundation Model)**ì„ í™œìš©  </li><li>ìƒˆë¡œìš´ í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ìŒì„±, ì˜ìƒ ë“±ì„ ìƒì„± ê°€ëŠ¥  </li><li>í•„ìš”í•˜ë©´ **íŒŒì¸íŠœë‹(Fine-tuning)**ìœ¼ë¡œ ê¸°ì—… ë§ì¶¤í˜• ëª¨ë¸ ì œì‘</li></ul><p align="center">  <img src="/images/aws_basic_103.png" width="80%"></p><hr><h2 id="8-íŠ¸ëœìŠ¤í¬ë¨¸-ëª¨ë¸-Transformer-LLM"><a href="#8-íŠ¸ëœìŠ¤í¬ë¨¸-ëª¨ë¸-Transformer-LLM" class="headerlink" title="8. íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸(Transformer, LLM)"></a>8. íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸(Transformer, LLM)</h2><ul><li>ê¸°ì¡´ RNN&#x2F;LSTMê³¼ ë‹¬ë¦¬, ë¬¸ì¥ì„ ë‹¨ì–´ ë‹¨ìœ„ê°€ ì•„ë‹Œ <strong>ì „ì²´ ë¬¸ë§¥</strong>ìœ¼ë¡œ ì²˜ë¦¬  </li><li><strong>Self-Attention ë©”ì»¤ë‹ˆì¦˜</strong>ìœ¼ë¡œ ë‹¨ì–´ ê°„ ì¤‘ìš”ë„ë¥¼ ê³„ì‚° â†’ ë” ì¼ê´€ì„± ìˆê³  ë¹ ë¥¸ í•™ìŠµ ê°€ëŠ¥  </li><li>ëŒ€í‘œ ì‚¬ë¡€:<ul><li><strong>Google BERT</strong></li><li><strong>OpenAI ChatGPT</strong> (<em>Chat Generative Pre-trained Transformer</em>)</li></ul></li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>:  </p><ul><li>íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” <strong>LLM(ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸)ì˜ í•µì‹¬ ì•„í‚¤í…ì²˜</strong>  </li><li><strong>ChatGPT &#x3D; íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ëª¨ë¸</strong></li></ul><p align="center">  <img src="/images/aws_basic_104.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_105.png" width="80%"></p><hr><h2 id="9-ë©€í‹°ëª¨ë‹¬-Multimodal-ëª¨ë¸"><a href="#9-ë©€í‹°ëª¨ë‹¬-Multimodal-ëª¨ë¸" class="headerlink" title="9. ë©€í‹°ëª¨ë‹¬(Multimodal) ëª¨ë¸"></a>9. ë©€í‹°ëª¨ë‹¬(Multimodal) ëª¨ë¸</h2><ul><li>í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤ ë“± <strong>ë‹¤ì–‘í•œ ì…ë ¥</strong>ì„ ë™ì‹œì— ë°›ì•„ì„œ, ë³µí•©ì ì¸ ì¶œë ¥ ìƒì„± ê°€ëŠ¥  </li><li>ì˜ˆ: ê³ ì–‘ì´ ì‚¬ì§„ + ìŒì„± ì…ë ¥ â†’ ê³ ì–‘ì´ê°€ ë§í•˜ëŠ” ì˜ìƒ ìƒì„±</li></ul><p>ğŸ‘‰ <strong>ì‹œí—˜ í¬ì¸íŠ¸</strong>: ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ &#x3D; <strong>ì—¬ëŸ¬ í˜•ì‹ì˜ ì…ë ¥ê³¼ ì¶œë ¥ ì²˜ë¦¬ ê°€ëŠ¥</strong>  </p><p align="center">  <img src="/images/aws_basic_106.png" width="80%"></p><hr><h2 id="ğŸ”‘-ì¸ê°„ê³¼-AIì˜-ë¹„êµ"><a href="#ğŸ”‘-ì¸ê°„ê³¼-AIì˜-ë¹„êµ" class="headerlink" title="ğŸ”‘ ì¸ê°„ê³¼ AIì˜ ë¹„êµ"></a>ğŸ”‘ ì¸ê°„ê³¼ AIì˜ ë¹„êµ</h2><ul><li><strong>AI(ê·œì¹™ ê¸°ë°˜)</strong>: â€œë§Œì•½ ë¶ˆì´ ë‚˜ë©´ ë¬¼ì„ ë¿Œë ¤ë¼â€ â†’ ëª…ì‹œì  ê·œì¹™  </li><li><strong>ML</strong>: ë§ì´ ë³¸ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ë¶„ë¥˜ (â€œì´ê±´ ê°•ì•„ì§€ì¼ í™•ë¥ ì´ ë†’ë‹¤â€)  </li><li><strong>DL</strong>: ë³¸ ì  ì—†ëŠ” ìƒˆë¡œìš´ ë°ì´í„°ë„ ìœ ì‚¬ íŒ¨í„´ í•™ìŠµìœ¼ë¡œ ì¸ì‹ (â€œì²˜ìŒ ë³¸ ë™ë¬¼ë„ â€˜ë™ë¬¼â€™ì„ì„ ì•Œ ìˆ˜ ìˆìŒâ€)  </li><li><strong>GenAI</strong>: í•™ìŠµí•œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ ì°½ì‘ (â€œìƒˆë¡œìš´ ì‹œë‚˜ ê·¸ë¦¼ì„ ë§Œë“¤ì–´ëƒ„â€)</li></ul><hr><h2 id="ğŸ“-ì‹œí—˜-ëŒ€ë¹„-ìš”ì•½"><a href="#ğŸ“-ì‹œí—˜-ëŒ€ë¹„-ìš”ì•½" class="headerlink" title="ğŸ“ ì‹œí—˜ ëŒ€ë¹„ ìš”ì•½"></a>ğŸ“ ì‹œí—˜ ëŒ€ë¹„ ìš”ì•½</h2><ul><li><strong>AI</strong>: í° ê°œë… (ì§€ëŠ¥ì  ì‹œìŠ¤í…œ ì „ë°˜)  </li><li><strong>ML</strong>: ë°ì´í„°ë¥¼ ì´ìš©í•œ í•™ìŠµ (ê·œì¹™ ì§ì ‘ ì½”ë”© X)  </li><li><strong>DL</strong>: ë‹¤ì¸µ ì‹ ê²½ë§ + GPU í•„ìš” â†’ ì´ë¯¸ì§€&#x2F;í…ìŠ¤íŠ¸ ì²˜ë¦¬ ê°•ë ¥  </li><li><strong>GenAI</strong>: ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ë¡œ ìƒˆë¡œìš´ ì½˜í…ì¸  ìƒì„±  </li><li><strong>Transformer</strong>: LLMì˜ í•µì‹¬ êµ¬ì¡°, ChatGPT ê¸°ë°˜  </li><li><strong>Multimodal</strong>: í…ìŠ¤íŠ¸+ì´ë¯¸ì§€+ìŒì„± ë“± ë‹¤ì–‘í•œ ì…ë ¥&#x2F;ì¶œë ¥ ê°€ëŠ¥</li></ul><p>ğŸ‘‰ <strong>í•œ ì¤„ ì •ë¦¬</strong>:<br>AWS ì‹œí—˜ì—ì„œëŠ” <strong>AI â†’ ML â†’ DL â†’ GenAI â†’ Transformer(LLM)</strong> ìˆœì„œì™€ ê°ê°ì˜ íŠ¹ì§•, GPU í•„ìš” ì—¬ë¶€, íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ LLM(ì˜ˆ: ChatGPT)ì´ ìì£¼ ì¶œì œë©ë‹ˆë‹¤.  </p><h2 id="ğŸ“Œ-ì£¼ìš”-ìš©ì–´-ì •ë¦¬"><a href="#ğŸ“Œ-ì£¼ìš”-ìš©ì–´-ì •ë¦¬" class="headerlink" title="ğŸ“Œ ì£¼ìš” ìš©ì–´ ì •ë¦¬"></a>ğŸ“Œ ì£¼ìš” ìš©ì–´ ì •ë¦¬</h2><h3 id="1-GPT-Generative-Pre-trained-Transformer"><a href="#1-GPT-Generative-Pre-trained-Transformer" class="headerlink" title="1. GPT (Generative Pre-trained Transformer)"></a>1. GPT (Generative Pre-trained Transformer)</h3><ul><li>ì…ë ¥ í”„ë¡¬í”„íŠ¸(ë¬¸ì¥)ì— ë”°ë¼ <strong>ì‚¬ëŒ ê°™ì€ í…ìŠ¤íŠ¸ë‚˜ ì½”ë“œ</strong>ë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë¸  </li><li>ëŒ€í‘œ ì˜ˆ: ChatGPT  </li><li>ğŸ‘‰ ì‹œí—˜ í¬ì¸íŠ¸: í…ìŠ¤íŠ¸ ìƒì„±, ì½”ë“œ ìƒì„± &#x3D; GPT</li></ul><hr><h3 id="2-BERT-Bidirectional-Encoder-Representations-from-Transformers"><a href="#2-BERT-Bidirectional-Encoder-Representations-from-Transformers" class="headerlink" title="2. BERT (Bidirectional Encoder Representations from Transformers)"></a>2. BERT (Bidirectional Encoder Representations from Transformers)</h3><ul><li>í…ìŠ¤íŠ¸ë¥¼ <strong>ì–‘ë°©í–¥(ì•ë’¤ ëª¨ë‘)</strong> ìœ¼ë¡œ ì½ëŠ” ì–¸ì–´ ëª¨ë¸  </li><li>ë¬¸ë§¥ ì´í•´ì— ê°•í•¨ â†’ ë²ˆì—­, ë¬¸ì„œ ìš”ì•½ ë“±ì— ë§ì´ ì‚¬ìš©  </li><li>ğŸ‘‰ ì‹œí—˜ í¬ì¸íŠ¸: <strong>ë¬¸ë§¥ ê¸°ë°˜ ì´í•´ &#x3D; BERT</strong></li></ul><hr><h3 id="3-RNN-Recurrent-Neural-Network"><a href="#3-RNN-Recurrent-Neural-Network" class="headerlink" title="3. RNN (Recurrent Neural Network)"></a>3. RNN (Recurrent Neural Network)</h3><ul><li><strong>ìˆœì°¨ì  ë°ì´í„°(Sequential Data)</strong> ë¥¼ ë‹¤ë£¨ëŠ” ì‹ ê²½ë§  </li><li>ì˜ˆì‹œ: ì‹œê³„ì—´ ë°ì´í„°, í…ìŠ¤íŠ¸, ìŒì„±  </li><li>ì‚¬ìš©ì²˜: ìŒì„± ì¸ì‹, ì‹œê³„ì—´ ì˜ˆì¸¡  </li><li>ğŸ‘‰ ì‹œí—˜ í¬ì¸íŠ¸: <strong>ìˆœì„œê°€ ì¤‘ìš”í•œ ë°ì´í„° ì²˜ë¦¬ &#x3D; RNN</strong></li></ul><hr><h3 id="4-ResNet-Residual-Network"><a href="#4-ResNet-Residual-Network" class="headerlink" title="4. ResNet (Residual Network)"></a>4. ResNet (Residual Network)</h3><ul><li>ì´ë¯¸ì§€ ì²˜ë¦¬ìš© <strong>ë”¥ëŸ¬ë‹ CNN(Convolutional Neural Network)</strong>  </li><li>ì´ë¯¸ì§€ ì¸ì‹, ê°ì²´ íƒì§€, ì–¼êµ´ ì¸ì‹ ë“±ì— ì‚¬ìš©  </li><li>ğŸ‘‰ ì‹œí—˜ í¬ì¸íŠ¸: <strong>ì´ë¯¸ì§€ ì²˜ë¦¬ &#x3D; ResNet</strong></li></ul><hr><h3 id="5-SVM-Support-Vector-Machine"><a href="#5-SVM-Support-Vector-Machine" class="headerlink" title="5. SVM (Support Vector Machine)"></a>5. SVM (Support Vector Machine)</h3><ul><li>ë¶„ë¥˜(Classification)ì™€ íšŒê·€(Regression)ì— ëª¨ë‘ ì‚¬ìš©ë˜ëŠ” ML ì•Œê³ ë¦¬ì¦˜  </li><li>ğŸ‘‰ ì‹œí—˜ í¬ì¸íŠ¸: ì „í†µì  ML ì•Œê³ ë¦¬ì¦˜ (ë¹„ì‹ ê²½ë§ ê¸°ë°˜)</li></ul><hr><h3 id="6-WaveNet"><a href="#6-WaveNet" class="headerlink" title="6. WaveNet"></a>6. WaveNet</h3><ul><li><strong>ì›ì‹œ ì˜¤ë””ì˜¤ íŒŒí˜•(raw audio waveform)</strong> ì„ ìƒì„±í•˜ëŠ” ëª¨ë¸  </li><li>ìŒì„± í•©ì„±(Text-to-Speech, TTS)ì— í™œìš© (ì˜ˆ: Google Assistant ìŒì„±)  </li><li>ğŸ‘‰ ì‹œí—˜ í¬ì¸íŠ¸: <strong>ìŒì„± í•©ì„± &#x3D; WaveNet</strong></li></ul><hr><h3 id="7-GAN-Generative-Adversarial-Network"><a href="#7-GAN-Generative-Adversarial-Network" class="headerlink" title="7. GAN (Generative Adversarial Network)"></a>7. GAN (Generative Adversarial Network)</h3><ul><li>ë‘ ê°œì˜ ë„¤íŠ¸ì›Œí¬(ìƒì„±ì vs íŒë³„ì)ê°€ ê²½ìŸí•˜ë©° í•™ìŠµ  </li><li><strong>ê°€ì§œ ë°ì´í„°(ì´ë¯¸ì§€, ì˜ìƒ, ìŒì„± ë“±)</strong> ë¥¼ ì§„ì§œì²˜ëŸ¼ ìƒì„±  </li><li>ë°ì´í„° ì¦ê°•(Data Augmentation)ì— í™œìš©  </li><li>ğŸ‘‰ ì‹œí—˜ í¬ì¸íŠ¸: <strong>í•©ì„± ë°ì´í„° ìƒì„±, ë°ì´í„° ë¶€ì¡± ë³´ì™„ &#x3D; GAN</strong></li></ul><hr><h3 id="8-XGBoost-Extreme-Gradient-Boosting"><a href="#8-XGBoost-Extreme-Gradient-Boosting" class="headerlink" title="8. XGBoost (Extreme Gradient Boosting)"></a>8. XGBoost (Extreme Gradient Boosting)</h3><ul><li><strong>Gradient Boosting ì•Œê³ ë¦¬ì¦˜ì˜ ê³ ì„±ëŠ¥ êµ¬í˜„ì²´</strong>  </li><li>ë¶„ë¥˜(Classification)ì™€ íšŒê·€(Regression) ë¬¸ì œì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥  </li><li>Kaggle ë“± ë°ì´í„° ê²½ì§„ëŒ€íšŒì—ì„œ ìì£¼ ì‚¬ìš©  </li><li>ğŸ‘‰ ì‹œí—˜ í¬ì¸íŠ¸: <strong>íŠ¸ë¦¬ ê¸°ë°˜, ê³ ì„±ëŠ¥ ML &#x3D; XGBoost</strong></li></ul><hr><h2 id="âœ…-ì‹œí—˜-ëŒ€ë¹„-í•µì‹¬-ìš”ì•½"><a href="#âœ…-ì‹œí—˜-ëŒ€ë¹„-í•µì‹¬-ìš”ì•½" class="headerlink" title="âœ… ì‹œí—˜ ëŒ€ë¹„ í•µì‹¬ ìš”ì•½"></a>âœ… ì‹œí—˜ ëŒ€ë¹„ í•µì‹¬ ìš”ì•½</h2><ul><li><strong>GPT, BERT</strong> â†’ ìì—°ì–´ ì²˜ë¦¬ (ì–¸ì–´ ëª¨ë¸)  </li><li><strong>RNN</strong> â†’ ìˆœì°¨ì  ë°ì´í„° (ì‹œê³„ì—´, ìŒì„±)  </li><li><strong>ResNet</strong> â†’ ì´ë¯¸ì§€ ì²˜ë¦¬  </li><li><strong>WaveNet</strong> â†’ ìŒì„± í•©ì„±  </li><li><strong>GAN</strong> â†’ í•©ì„± ë°ì´í„° ìƒì„± &#x2F; ë°ì´í„° ì¦ê°•  </li><li><strong>XGBoost, SVM</strong> â†’ ì „í†µ ML ì•Œê³ ë¦¬ì¦˜</li></ul><p>ğŸ‘‰ ì‹¤ì œ ì‹œí—˜ì—ì„œëŠ” ìš©ì–´ì˜ ìƒì„¸ ë™ì‘ë³´ë‹¤ëŠ” <strong>ë¬´ì—‡ì„ ìœ„í•œ ëª¨ë¸ì¸ì§€, ì–´ë–¤ ë°ì´í„° ìœ í˜•ì— ì“°ì´ëŠ”ì§€</strong> ì •ë„ë§Œ êµ¬ë¶„í•  ìˆ˜ ìˆìœ¼ë©´ ì¶©ë¶„í•©ë‹ˆë‹¤.</p><hr><p>ğŸ“Œ <strong>ì¶”ê°€ ì‹œí—˜ í¬ì¸íŠ¸</strong></p><ul><li>AWS ìê²©ì¦ì—ì„œëŠ” <strong>GenAI, LLM(ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸), Transformer</strong> ì™€ì˜ ì—°ê³„ì„±ì„ ê°•ì¡°í•  ìˆ˜ ìˆìŒ  </li><li>â€œì–´ë–¤ ëª¨ë¸ì´ ì´ë¯¸ì§€ì— ì“°ì´ëŠ”ê°€?â€ â†’ ResNet  </li><li>â€œì–¸ì–´ ëª¨ë¸ ê´€ë ¨ ìš©ì–´ëŠ”?â€ â†’ GPT, BERT  </li><li>â€œí•©ì„± ë°ì´í„° ìƒì„±?â€ â†’ GAN</li></ul><h2 id="ì¶”ê°€ì •ë³´-ğŸ§ -Self-Attentionì´ë€"><a href="#ì¶”ê°€ì •ë³´-ğŸ§ -Self-Attentionì´ë€" class="headerlink" title="(ì¶”ê°€ì •ë³´) ğŸ§  Self-Attentionì´ë€?"></a>(ì¶”ê°€ì •ë³´) ğŸ§  Self-Attentionì´ë€?</h2><p>Self-Attentionì€ ë¬¸ì¥ ì•ˆì˜ <strong>ëª¨ë“  ë‹¨ì–´ê°€ ì„œë¡œë¥¼ ë°”ë¼ë³´ë©° ì¤‘ìš”ë„ë¥¼ ê³„ì‚°</strong>í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜ì´ì—ìš”.<br>ì´ë¥¼ í†µí•´ GPT, BERT ê°™ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì€ ë¬¸ë§¥ì  ê´€ê³„ë¥¼ ë” ì˜ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p><hr><h2 id="âš™ï¸-ë™ì‘-ë°©ì‹-ê°„ë‹¨íˆ"><a href="#âš™ï¸-ë™ì‘-ë°©ì‹-ê°„ë‹¨íˆ" class="headerlink" title="âš™ï¸ ë™ì‘ ë°©ì‹ (ê°„ë‹¨íˆ)"></a>âš™ï¸ ë™ì‘ ë°©ì‹ (ê°„ë‹¨íˆ)</h2><p>ê° ë‹¨ì–´ëŠ” ì„¸ ê°€ì§€ ë²¡í„°ë¡œ ë³€í™˜ë©ë‹ˆë‹¤: </p><ol><li><strong>Query (Q)</strong> â€“ â€œë‚´ê°€ ë‹¤ë¥¸ ë‹¨ì–´ë“¤ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ì´ ìˆëŠ”ì§€ ì•Œê³  ì‹¶ì–´.â€ </li><li><strong>Key (K)</strong> â€“ â€œë‚˜ëŠ” ì´ëŸ° ì˜ë¯¸ë¥¼ ê°€ì§€ê³  ìˆì–´.â€ </li><li><strong>Value (V)</strong> â€“ â€œë‚´ ì •ë³´ëŠ” ì´ê±°ì•¼.â€</li></ol><p>ì‘ë™ ë‹¨ê³„: </p><ol><li>Query(Q)ì™€ ë‹¤ë¥¸ ëª¨ë“  Key(K)ì˜ ë‚´ì  â†’ <strong>ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°</strong></li><li>Softmax ì ìš© â†’ **ê°€ì¤‘ì¹˜(Attention Score)**ë¡œ ë³€í™˜ </li><li>ê° Value(V)ì— ê°€ì¤‘ì¹˜ë¥¼ ê³±í•˜ê³  í•©ì‚° â†’ ë¬¸ë§¥ì´ ë°˜ì˜ëœ ìƒˆë¡œìš´ ë‹¨ì–´ í‘œí˜„ ìƒì„±</li></ol><hr><h2 id="âœ¨-Self-Attentionì˜-ì¥ì "><a href="#âœ¨-Self-Attentionì˜-ì¥ì " class="headerlink" title="âœ¨ Self-Attentionì˜ ì¥ì "></a>âœ¨ Self-Attentionì˜ ì¥ì </h2><ol><li><strong>ë¬¸ë§¥ ì´í•´ ê°•í™”</strong> â€“ ë©€ë¦¬ ë–¨ì–´ì§„ ë‹¨ì–´ë„ ê´€ê³„ë¥¼ ì—°ê²°<br>(ì˜ˆ: <em>â€œê³µì€ ë¹¨ê°°ë‹¤. ê·¸ê²ƒì€ êµ´ëŸ¬ê°”ë‹¤.â€</em> â†’ â€œê·¸ê²ƒâ€ &#x3D; â€œê³µâ€)</li><li><strong>ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥</strong> â€“ RNNì²˜ëŸ¼ ìˆœì°¨ì ì´ ì•„ë‹ˆë¼, ëª¨ë“  ë‹¨ì–´ë¥¼ ë™ì‹œì— ì²˜ë¦¬ â†’ í•™ìŠµ ì†ë„ ë¹ ë¦„</li><li><strong>ì¥ê±°ë¦¬ ì˜ì¡´ì„± í•´ê²°</strong> â€“ ë¬¸ì¥ì´ ê¸¸ì–´ë„ ì•ë’¤ ë¬¸ë§¥ì„ ì˜ ì—°ê²° ê°€ëŠ¥</li></ol><hr><h2 id="ğŸ“Œ-ìš”ì•½"><a href="#ğŸ“Œ-ìš”ì•½" class="headerlink" title="ğŸ“Œ ìš”ì•½"></a>ğŸ“Œ ìš”ì•½</h2><p>Self-Attention &#x3D; <strong>â€œë¬¸ì¥ ì•ˆì˜ ëª¨ë“  ë‹¨ì–´ê°€ ì„œë¡œë¥¼ ë°”ë¼ë³´ë©° ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•˜ê³ , ê·¸ ì •ë³´ë¥¼ í•©ì³ ìƒˆë¡œìš´ ì˜ë¯¸ ìˆëŠ” í‘œí˜„ì„ ë§Œë“œëŠ” ë°©ë²•â€</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ¤–-ì¸ê³µì§€ëŠ¥-AI-ë¨¸ì‹ ëŸ¬ë‹-ML-ë”¥ëŸ¬ë‹-DL-ìƒì„±í˜•-AI-GenAI-ì •ë¦¬&quot;&gt;&lt;a href=&quot;#ğŸ¤–-ì¸ê³µì§€ëŠ¥-AI-ë¨¸ì‹ ëŸ¬ë‹-ML-ë”¥ëŸ¬ë‹-DL-ìƒì„±í˜•-AI-GenAI-ì •ë¦¬&quot; class=&quot;headerlink&quot; title=&quot;ğŸ¤– ì¸ê³µì§€ëŠ¥(AI</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(22) - Understanding AI, ML, DL, and GenAI</title>
    <link href="https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-22/"/>
    <id>https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-22/</id>
    <published>2025-08-23T13:01:51.000Z</published>
    <updated>2025-08-23T22:13:40.551Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ğŸ¤–-Understanding-AI-ML-DL-and-GenAI"><a href="#ğŸ¤–-Understanding-AI-ML-DL-and-GenAI" class="headerlink" title="ğŸ¤– Understanding AI, ML, DL, and GenAI"></a>ğŸ¤– Understanding AI, ML, DL, and GenAI</h1><h2 id="1-What-is-Artificial-Intelligence-AI"><a href="#1-What-is-Artificial-Intelligence-AI" class="headerlink" title="1. What is Artificial Intelligence (AI)?"></a>1. What is Artificial Intelligence (AI)?</h2><p>Artificial Intelligence (AI) is a broad field focused on building intelligent systems capable of tasks that usually require human intelligence, such as:</p><ul><li>Perception  </li><li>Reasoning  </li><li>Learning  </li><li>Problem solving  </li><li>Decision making</li></ul><p>ğŸ‘‰ AI is an <strong>umbrella term</strong> covering multiple techniques.</p><p align="center">  <img src="/images/aws_basic_96.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_97.png" width="80%"></p><hr><h2 id="2-AI-Components"><a href="#2-AI-Components" class="headerlink" title="2. AI Components"></a>2. AI Components</h2><ul><li><strong>Data Layer</strong>: Collects large amounts of data.  </li><li><strong>ML Framework &amp; Algorithm Layer</strong>: Data scientists and engineers design use cases and frameworks to solve them.  </li><li><strong>Model Layer</strong>: Implements and trains models (structure, parameters, optimizer functions).  </li><li><strong>Application Layer</strong>: How the model is served to users.</li></ul><p align="center">  <img src="/images/aws_basic_98.png" width="80%"></p><hr><h2 id="3-What-is-Machine-Learning-ML"><a href="#3-What-is-Machine-Learning-ML" class="headerlink" title="3. What is Machine Learning (ML)?"></a>3. What is Machine Learning (ML)?</h2><ul><li>ML is a <strong>subset of AI</strong> focused on building methods that allow machines to <strong>learn from data</strong>.  </li><li>Improves performance by finding patterns and making predictions.  </li><li>No need for explicitly programmed rules.</li></ul><p><strong>Examples of ML tasks</strong>:  </p><ul><li>Regression (predicting trends).  </li><li>Classification (distinguishing categories).</li></ul><p align="center">  <img src="/images/aws_basic_99.png" width="80%"></p><hr><h2 id="4-AI-â‰ -ML-Historical-Example"><a href="#4-AI-â‰ -ML-Historical-Example" class="headerlink" title="4. AI â‰  ML (Historical Example)"></a>4. AI â‰  ML (Historical Example)</h2><p><strong>MYCIN Expert System (1970s)</strong>  </p><ul><li>Used 500+ rules to diagnose patients.  </li><li>Asked yes&#x2F;no questions and suggested possible bacteria and treatments.  </li><li>Never widely used (computing power was too limited).</li></ul><p>ğŸ‘‰ Shows that AI existed before ML became mainstream.</p><p align="center">  <img src="/images/aws_basic_100.png" width="80%"></p><hr><h2 id="5-What-is-Deep-Learning-DL"><a href="#5-What-is-Deep-Learning-DL" class="headerlink" title="5. What is Deep Learning (DL)?"></a>5. What is Deep Learning (DL)?</h2><ul><li>Subset of ML that uses <strong>artificial neural networks</strong> inspired by the human brain.  </li><li>Handles complex patterns using multiple hidden layers.  </li><li>Requires <strong>large datasets</strong> and <strong>GPUs</strong> for processing.</li></ul><p><strong>Examples</strong>:  </p><ul><li><strong>Computer Vision</strong>: Image classification, object detection, segmentation.  </li><li><strong>NLP (Natural Language Processing)</strong>: Text classification, sentiment analysis, machine translation, language generation.</li></ul><p align="center">  <img src="/images/aws_basic_101.png" width="80%"></p><hr><h2 id="6-Neural-Networks-â€“-How-They-Work"><a href="#6-Neural-Networks-â€“-How-They-Work" class="headerlink" title="6. Neural Networks â€“ How They Work"></a>6. Neural Networks â€“ How They Work</h2><ul><li>Nodes (neurons) are connected in layers.  </li><li>Input data flows through layers, adjusting connections (weights).  </li><li>Networks may contain <strong>billions of nodes</strong> and many hidden layers.  </li><li>The system â€œlearnsâ€ patterns automatically â€” not manually programmed.</li></ul><p><strong>Example</strong>: Handwritten digit recognition  </p><ul><li>Early layers detect <strong>lines&#x2F;curves</strong>.  </li><li>Deeper layers combine these to recognize complete numbers.</li></ul><p align="center">  <img src="/images/aws_basic_102.png" width="80%"></p><hr><h2 id="7-What-is-Generative-AI-GenAI"><a href="#7-What-is-Generative-AI-GenAI" class="headerlink" title="7. What is Generative AI (GenAI)?"></a>7. What is Generative AI (GenAI)?</h2><ul><li>Subset of Deep Learning.  </li><li>Uses <strong>foundation models</strong> (trained on massive datasets) that can generate text, images, audio, or code.  </li><li>Can be <strong>fine-tuned</strong> with your own data for specific use cases.</li></ul><p align="center">  <img src="/images/aws_basic_103.png" width="80%"></p><hr><h2 id="8-What-is-the-Transformer-Model-LLM"><a href="#8-What-is-the-Transformer-Model-LLM" class="headerlink" title="8. What is the Transformer Model? (LLM)"></a>8. What is the Transformer Model? (LLM)</h2><ul><li>Processes entire sentences at once (not word by word).  </li><li>Assigns <strong>relative importance</strong> to words (attention mechanism).  </li><li>More efficient and coherent than older models.</li></ul><p><strong>Transformer-based LLMs</strong>:  </p><ul><li>Trained on vast amounts of internet, books, and documents.  </li><li>Examples: <strong>Google BERT</strong>, <strong>OpenAI ChatGPT</strong> (Chat Generative Pre-trained Transformer).</li></ul><p>ğŸ‘‰ Key foundation of modern GenAI.</p><p align="center">  <img src="/images/aws_basic_104.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_105.png" width="80%"></p><hr><h2 id="9-Humans-as-a-Mix-of-AI"><a href="#9-Humans-as-a-Mix-of-AI" class="headerlink" title="9. Humans as a Mix of AI"></a>9. Humans as a Mix of AI</h2><ul><li><strong>AI (Rules-based)</strong>: â€œIf this happens, then do that.â€  </li><li><strong>ML</strong>: Learn patterns from past examples.  </li><li><strong>DL</strong>: Generalize from similar concepts (recognize new things by analogy).  </li><li><strong>GenAI</strong>: Go beyond recognition â†’ generate creative, new content.</li></ul><p align="center">  <img src="/images/aws_basic_106.png" width="80%"></p><hr><h2 id="âœ…-Exam-Tips"><a href="#âœ…-Exam-Tips" class="headerlink" title="âœ… Exam Tips"></a>âœ… Exam Tips</h2><ul><li>AI &#x3D; umbrella field, ML &#x3D; subset, DL &#x3D; deeper subset, GenAI &#x3D; specialized subset of DL.  </li><li>ML does <strong>not require explicit rules</strong> (learns from data).  </li><li>DL requires <strong>big data + GPUs</strong>.  </li><li>Transformer &#x3D; key architecture behind LLMs like ChatGPT.  </li><li>Remember the order: <strong>AI â†’ ML â†’ DL â†’ GenAI (â†’ Transformers&#x2F;LLMs)</strong>.</li></ul><h2 id="ğŸ§ -Key-Terms"><a href="#ğŸ§ -Key-Terms" class="headerlink" title="ğŸ§  Key Terms"></a>ğŸ§  Key Terms</h2><ul><li><p><strong>GPT (Generative Pre-trained Transformer)</strong>  </p><ul><li>Foundation model that generates human-like text or computer code from prompts.  </li><li><strong>Exam Tip:</strong> Remember itâ€™s focused on <strong>text&#x2F;code generation</strong>.</li></ul></li><li><p><strong>BERT (Bidirectional Encoder Representations from Transformers)</strong>  </p><ul><li>Reads text <strong>both left-to-right and right-to-left</strong> to understand context.  </li><li>Very strong for <strong>language understanding and translation</strong>.  </li><li><strong>Exam Tip:</strong> GPT &#x3D; generation, BERT &#x3D; understanding.</li></ul></li><li><p><strong>RNN (Recurrent Neural Network)</strong>  </p><ul><li>Designed for <strong>sequential data</strong> (time-series, text, speech).  </li><li>Commonly used in <strong>speech recognition</strong> and <strong>time-series forecasting</strong>.  </li><li><strong>Exam Tip:</strong> Think <strong>R &#x3D; Recurrent &#x3D; Sequence</strong>.</li></ul></li><li><p><strong>ResNet (Residual Network)</strong>  </p><ul><li>A type of <strong>Deep Convolutional Neural Network (CNN)</strong>.  </li><li>Used for <strong>image recognition, object detection, and facial recognition</strong>.  </li><li><strong>Exam Tip:</strong> If itâ€™s <strong>image-related</strong>, ResNet is a strong candidate.</li></ul></li><li><p><strong>SVM (Support Vector Machine)</strong>  </p><ul><li>Traditional ML algorithm for <strong>classification and regression</strong>.  </li><li>Finds a boundary (hyperplane) between categories.  </li><li><strong>Exam Tip:</strong> If you see â€œclassification with small datasets,â€ think SVM.</li></ul></li><li><p><strong>WaveNet</strong>  </p><ul><li>Model that generates <strong>raw audio waveforms</strong>.  </li><li>Used in <strong>speech synthesis (text-to-speech)</strong>.  </li><li><strong>Exam Tip:</strong> â€œWaveâ€ &#x3D; audio.</li></ul></li><li><p><strong>GAN (Generative Adversarial Network)</strong>  </p><ul><li>Two models compete (generator vs discriminator) to create <strong>synthetic data</strong>.  </li><li>Generates images, videos, or sounds that look real.  </li><li>Helpful for <strong>data augmentation</strong> when training data is limited.  </li><li><strong>Exam Tip:</strong> GAN &#x3D; â€œFake but realistic data.â€</li></ul></li><li><p><strong>XGBoost (Extreme Gradient Boosting)</strong>  </p><ul><li>Optimized implementation of gradient boosting.  </li><li>Commonly used in <strong>classification and regression</strong> tasks.  </li><li>Frequently wins Kaggle competitions due to efficiency.  </li><li><strong>Exam Tip:</strong> If you see â€œgradient boostingâ€ in the exam, XGBoost is likely the answer.</li></ul></li></ul><hr><h2 id="âœ…-Quick-Exam-Memory-Aid"><a href="#âœ…-Quick-Exam-Memory-Aid" class="headerlink" title="âœ… Quick Exam Memory Aid"></a>âœ… Quick Exam Memory Aid</h2><ul><li><strong>GPT &amp; BERT</strong> â†’ Language (Generation vs Understanding)  </li><li><strong>RNN</strong> â†’ Sequences (speech, time-series)  </li><li><strong>ResNet</strong> â†’ Images (recognition&#x2F;detection)  </li><li><strong>SVM</strong> â†’ Classification (small datasets, traditional ML)  </li><li><strong>WaveNet</strong> â†’ Audio (speech synthesis)  </li><li><strong>GAN</strong> â†’ Synthetic data (augmentation, fake-but-realistic images&#x2F;videos)  </li><li><strong>XGBoost</strong> â†’ Gradient boosting (fast, efficient, tabular data)</li></ul><hr><p>ğŸ‘‰ <strong>Bottom line for the exam:</strong><br>Know which domain each term belongs to (text, image, audio, data augmentation, etc.) and you can eliminate wrong answers quickly. </p><h2 id="Additional-ğŸ§ -What-is-Self-Attention"><a href="#Additional-ğŸ§ -What-is-Self-Attention" class="headerlink" title="(Additional) ğŸ§  What is Self-Attention?"></a>(Additional) ğŸ§  What is Self-Attention?</h2><p>Self-Attention is a mechanism that allows <strong>each word in a sentence to<br>look at every other word</strong> and determine how much attention it should<br>pay to them.<br>It helps LLMs (Large Language Models) like GPT or BERT capture<br><strong>contextual relationships</strong> within a sentence.</p><hr><h2 id="âš™ï¸-How-it-Works"><a href="#âš™ï¸-How-it-Works" class="headerlink" title="âš™ï¸ How it Works"></a>âš™ï¸ How it Works</h2><p>Each token (word) is transformed into three vectors: 1. <strong>Query (Q)</strong> â€“<br>â€œI want to know how related I am to others.â€ 2. <strong>Key (K)</strong> â€“ â€œThis is<br>what I represent.â€ 3. <strong>Value (V)</strong> â€“ â€œThis is my actual information.â€</p><p>Steps: 1. Compute the dot product of Query (Q) and Key (K) of all words<br>â†’ <strong>similarity score</strong> 2. Apply <strong>Softmax</strong> â†’ turns similarity into<br>attention weights 3. Multiply each Value (V) by its weight and sum them<br>â†’ new context-aware representation of the word</p><hr><h2 id="âœ¨-Why-it-Matters"><a href="#âœ¨-Why-it-Matters" class="headerlink" title="âœ¨ Why it Matters"></a>âœ¨ Why it Matters</h2><ol><li><strong>Captures context</strong> â€“ Even long-distance dependencies are<br>recognized<br>(e.g., <em>â€œThe ball was red. It rolled away.â€</em> â†’ â€œItâ€ refers to<br>â€œballâ€)\</li><li><strong>Parallel computation</strong> â€“ Unlike RNNs, attention processes all<br>words at once, making training faster\</li><li><strong>Handles long sequences</strong> â€“ No degradation like RNN&#x2F;LSTM with long<br>sentences</li></ol><hr><h2 id="ğŸ“Œ-Summary"><a href="#ğŸ“Œ-Summary" class="headerlink" title="ğŸ“Œ Summary"></a>ğŸ“Œ Summary</h2><p>Self-Attention &#x3D;<br><em>â€œEvery word looks at every other word, assigns importance, and builds a<br>new meaning-aware representation.â€</em></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ğŸ¤–-Understanding-AI-ML-DL-and-GenAI&quot;&gt;&lt;a href=&quot;#ğŸ¤–-Understanding-AI-ML-DL-and-GenAI&quot; class=&quot;headerlink&quot; title=&quot;ğŸ¤– Understanding AI, M</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
</feed>
