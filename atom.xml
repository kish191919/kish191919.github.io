<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Danny&#39;s Blog</title>
  
  <subtitle>Data, AI, and Tech Insight</subtitle>
  <link href="https://kish191919.github.io/atom.xml" rel="self"/>
  
  <link href="https://kish191919.github.io/"/>
  <updated>2025-09-02T17:13:50.786Z</updated>
  <id>https://kish191919.github.io/</id>
  
  <author>
    <name>Danny Ki</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (35) - EC2</title>
    <link href="https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-35/"/>
    <id>https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-35/</id>
    <published>2025-09-02T17:05:35.000Z</published>
    <updated>2025-09-02T17:13:50.786Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Amazon-EC2-Elastic-Compute-Cloud"><a href="#Amazon-EC2-Elastic-Compute-Cloud" class="headerlink" title="Amazon EC2 (Elastic Compute Cloud)"></a>Amazon EC2 (Elastic Compute Cloud)</h1><h3 id="기본-개념"><a href="#기본-개념" class="headerlink" title="기본 개념"></a>기본 개념</h3><ul><li><strong>EC2 &#x3D; Elastic Compute Cloud</strong> → AWS의 대표적인 <strong>IaaS (Infrastructure as a Service)</strong> 서비스.</li><li>클라우드에서 <strong>가상 서버(인스턴스)를 임대</strong>하는 개념.</li><li>EC2를 이해하는 것은 클라우드 기본 개념을 이해하는 데 핵심.</li></ul><h3 id="주요-기능"><a href="#주요-기능" class="headerlink" title="주요 기능"></a>주요 기능</h3><ul><li><strong>가상 서버 임대 (EC2 Instance)</strong></li><li><strong>스토리지 연결</strong>: EBS(Elastic Block Store), EFS, 또는 인스턴스 스토어(하드웨어 기반).</li><li><strong>로드 밸런싱 (ELB)</strong>: 여러 서버에 트래픽 분산.</li><li><strong>오토 스케일링 (ASG)</strong>: 트래픽 변화에 따라 서버 자동 확장&#x2F;축소.</li></ul><hr><h1 id="EC2-인스턴스-설정-옵션"><a href="#EC2-인스턴스-설정-옵션" class="headerlink" title="EC2 인스턴스 설정 옵션"></a>EC2 인스턴스 설정 옵션</h1><ul><li><strong>운영체제 (OS)</strong>: Linux, Windows, macOS 지원.</li><li><strong>CPU</strong>: 코어 수와 연산 성능 선택 가능.</li><li><strong>메모리 (RAM)</strong>: 애플리케이션 요구사항에 맞게 조정.</li><li><strong>스토리지</strong>:<ul><li><strong>네트워크 연결 스토리지</strong> → EBS, EFS</li><li><strong>하드웨어 스토리지</strong> → EC2 Instance Store</li></ul></li><li><strong>네트워크 설정</strong>: 네트워크 카드 속도, 퍼블릭 IP 할당 여부.</li><li><strong>보안</strong>: Security Group(방화벽 역할).</li><li><strong>부트스트랩 스크립트</strong>: 인스턴스 최초 실행 시 자동 실행되는 <strong>User Data</strong> 스크립트.</li></ul><p>👉 <strong>시험 포인트</strong></p><ul><li>“EC2 User Data &#x3D; 인스턴스 최초 실행 시 자동 설정 스크립트”</li><li>“Security Group &#x3D; 인스턴스 방화벽 규칙”</li></ul><hr><h1 id="Amazon-EC2와-AI-관련-하드웨어"><a href="#Amazon-EC2와-AI-관련-하드웨어" class="headerlink" title="Amazon EC2와 AI 관련 하드웨어"></a>Amazon EC2와 AI 관련 하드웨어</h1><p>AI&#x2F;ML 워크로드에서는 일반 CPU보다 <strong>GPU&#x2F;전용 칩</strong>을 활용해야 효율적입니다.</p><h3 id="GPU-기반-인스턴스"><a href="#GPU-기반-인스턴스" class="headerlink" title="GPU 기반 인스턴스"></a>GPU 기반 인스턴스</h3><ul><li><strong>P 시리즈</strong> (P3, P4, P5): 고성능 머신러닝&#x2F;딥러닝 학습용.</li><li><strong>G 시리즈</strong> (G3~G6): 그래픽 처리, 딥러닝 추론, VDI(가상 데스크톱)용.</li></ul><h3 id="AWS-전용-AI-칩"><a href="#AWS-전용-AI-칩" class="headerlink" title="AWS 전용 AI 칩"></a>AWS 전용 AI 칩</h3><ol><li><strong>AWS Trainium (학습 전용)</strong><ul><li>대규모 딥러닝 모델(1000억+ 파라미터) 학습 최적화.</li><li><strong>Trn1 인스턴스</strong>: Trainium 칩 16개 포함.</li><li>GPU 대비 <strong>최대 50% 비용 절감</strong>.</li></ul></li><li><strong>AWS Inferentia (추론 전용)</strong><ul><li>고성능&#x2F;저비용 <strong>추론(Inference)</strong> 가속기.</li><li><strong>Inf1, Inf2 인스턴스</strong>에서 사용.</li><li>최대 <strong>4배 처리량, 70% 비용 절감</strong>.</li></ul></li></ol><p>👉 <strong>시험 포인트</strong></p><ul><li>“모델 학습 최적화, 비용 절감” → <strong>Trainium (Trn1)</strong></li><li>“추론 최적화, 비용 절감” → <strong>Inferentia (Inf1&#x2F;Inf2)</strong></li><li><strong>Trainium&#x2F;Inferentia &#x3D; AWS 자체 칩, 가장 친환경적(환경 발자국 최소화)</strong></li></ul><p align="center">  <img src="/images/aws_basic_165.png" width="80%"></p> ------------------------------------------------------------------------<h1 id="정리-시험-대비"><a href="#정리-시험-대비" class="headerlink" title="정리 (시험 대비)"></a>정리 (시험 대비)</h1><ul><li><strong>EC2 &#x3D; 클라우드 가상 서버</strong> (IaaS).</li><li><strong>EBS&#x2F;EFS</strong>: 네트워크 스토리지, <strong>Instance Store</strong>: 로컬 하드웨어 스토리지.</li><li><strong>ELB</strong>: 로드밸런싱, <strong>ASG</strong>: 자동 확장&#x2F;축소.</li><li><strong>Security Group</strong>: 방화벽, <strong>User Data</strong>: 초기 설정 스크립트.</li><li><strong>GPU 기반 인스턴스</strong>: P, G 시리즈 (ML 학습&#x2F;추론용).</li><li><strong>Trainium (Trn1)</strong>: 학습 전용 칩, 비용 절감.</li><li><strong>Inferentia (Inf1&#x2F;Inf2)</strong>: 추론 전용 칩, 성능+비용 효율.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Amazon-EC2-Elastic-Compute-Cloud&quot;&gt;&lt;a href=&quot;#Amazon-EC2-Elastic-Compute-Cloud&quot; class=&quot;headerlink&quot; title=&quot;Amazon EC2 (Elastic Compute </summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(35) - EC2</title>
    <link href="https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-35/"/>
    <id>https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-35/</id>
    <published>2025-09-02T17:05:29.000Z</published>
    <updated>2025-09-02T17:13:50.788Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Amazon-EC2-Elastic-Compute-Cloud"><a href="#Amazon-EC2-Elastic-Compute-Cloud" class="headerlink" title="Amazon EC2 (Elastic Compute Cloud)"></a>Amazon EC2 (Elastic Compute Cloud)</h1><h3 id="What-it-is"><a href="#What-it-is" class="headerlink" title="What it is"></a>What it is</h3><ul><li><strong>EC2 &#x3D; Elastic Compute Cloud</strong> → AWS’s most popular <strong>IaaS (Infrastructure as a Service)</strong> offering.</li><li>With EC2, you can:<ul><li><strong>Rent virtual machines</strong> (instances).</li><li><strong>Attach storage</strong> with EBS (Elastic Block Store) or EFS.</li><li><strong>Distribute traffic</strong> with ELB (Elastic Load Balancing).</li><li><strong>Scale automatically</strong> with Auto Scaling Groups (ASG).</li></ul></li><li><strong>Why it matters:</strong> Understanding EC2 is fundamental to understanding the AWS Cloud.</li></ul><hr><h1 id="EC2-Sizing-Configuration-Options"><a href="#EC2-Sizing-Configuration-Options" class="headerlink" title="EC2 Sizing &amp; Configuration Options"></a>EC2 Sizing &amp; Configuration Options</h1><p>When launching an EC2 instance, you configure:</p><ul><li><strong>Operating System (OS):</strong> Linux, Windows, or macOS.</li><li><strong>CPU:</strong> Number of vCPUs and compute power.</li><li><strong>Memory (RAM):</strong> Amount of memory allocated.</li><li><strong>Storage Options:</strong><ul><li><strong>Network-attached storage:</strong> EBS or EFS.</li><li><strong>Instance Store (local hardware):</strong> Temporary but very fast.</li></ul></li><li><strong>Networking:</strong> Network card bandwidth, public IP address.</li><li><strong>Firewall:</strong> Security Groups control inbound&#x2F;outbound traffic.</li><li><strong>Bootstrap Scripts:</strong> EC2 <strong>User Data</strong> can configure the instance at first launch (e.g., install packages, run setup commands).</li></ul><p>💡 <strong>Exam Tip:</strong></p><ul><li><em>Security Groups &#x3D; virtual firewalls.</em></li><li><em>EC2 User Data &#x3D; automation at first boot.</em></li></ul><hr><h1 id="Amazon’s-Hardware-for-AI-ML"><a href="#Amazon’s-Hardware-for-AI-ML" class="headerlink" title="Amazon’s Hardware for AI &amp; ML"></a>Amazon’s Hardware for AI &amp; ML</h1><p>For <strong>machine learning workloads</strong>, AWS offers specialized EC2 families and custom silicon:</p><h3 id="GPU-Instances"><a href="#GPU-Instances" class="headerlink" title="GPU Instances"></a>GPU Instances</h3><ul><li><strong>P-series (P3, P4, P5):</strong> Optimized for deep learning training.</li><li><strong>G-series (G3–G6):</strong> Graphics, inference, and virtual desktops.</li></ul><h3 id="AWS-Trainium"><a href="#AWS-Trainium" class="headerlink" title="AWS Trainium"></a>AWS Trainium</h3><ul><li>Custom <strong>ML training chip</strong> designed for <strong>deep learning models with 100B+ parameters</strong>.</li><li><strong>Trn1 instances</strong> have up to <strong>16 Trainium accelerators</strong>.</li><li><strong>50% lower training cost</strong> compared to GPU-based instances.</li></ul><h3 id="AWS-Inferentia"><a href="#AWS-Inferentia" class="headerlink" title="AWS Inferentia"></a>AWS Inferentia</h3><ul><li>Custom <strong>inference chip</strong> optimized for performance and cost.</li><li>Powers <strong>Inf1 and Inf2 instances</strong>.</li><li>Provides <strong>up to 4x throughput</strong> and <strong>70% cost savings</strong> over GPUs.</li></ul><p>👉 <strong>Exam Tip:</strong></p><ul><li><strong>Trainium (Trn1) &#x3D; Training at scale, lower cost.</strong></li><li><strong>Inferentia (Inf1&#x2F;Inf2) &#x3D; High-performance, low-cost inference.</strong></li><li>Both have <strong>lowest environmental footprint</strong> → “green AI hardware.”</li></ul><hr><h1 id="Key-Takeaways-for-the-Exam"><a href="#Key-Takeaways-for-the-Exam" class="headerlink" title="Key Takeaways for the Exam"></a>Key Takeaways for the Exam</h1><ul><li><strong>EC2 &#x3D; Virtual servers in the cloud</strong>.</li><li><strong>Storage</strong>: EBS&#x2F;EFS for persistent storage, Instance Store for temporary high-speed storage.</li><li><strong>ELB &amp; ASG</strong>: Scaling and load balancing.</li><li><strong>Security Group</strong>: Acts as firewall.</li><li><strong>User Data</strong>: Automates setup at instance launch.</li><li><strong>AI Workloads</strong>:<ul><li><strong>GPU Instances (P, G series)</strong> for ML&#x2F;DL.</li><li><strong>Trainium (Trn1)</strong> for training.</li><li><strong>Inferentia (Inf1&#x2F;Inf2)</strong> for inference.</li></ul></li></ul><p>💡 <strong>Common Exam Question Patterns:</strong></p><ul><li><em>“Which instance type is best for large-scale ML model training?” → Trn1 (Trainium).</em></li><li><em>“Which service provides cost-effective inference at scale?” → Inferentia.</em></li><li><em>“Where do you configure startup scripts for EC2?” → EC2 User Data.</em></li></ul><p align="center">  <img src="/images/aws_basic_165.png" width="80%"></p> ]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Amazon-EC2-Elastic-Compute-Cloud&quot;&gt;&lt;a href=&quot;#Amazon-EC2-Elastic-Compute-Cloud&quot; class=&quot;headerlink&quot; title=&quot;Amazon EC2 (Elastic Compute </summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (34) - Mechanical Turk, Augmented AI, Transcribe Medical, Comprehend Medical</title>
    <link href="https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-34/"/>
    <id>https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-34/</id>
    <published>2025-09-02T16:49:39.000Z</published>
    <updated>2025-09-02T17:04:54.722Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Amazon-Mechanical-Turk-MTurk"><a href="#Amazon-Mechanical-Turk-MTurk" class="headerlink" title="Amazon Mechanical Turk (MTurk)"></a>Amazon Mechanical Turk (MTurk)</h1><h3 id="개요"><a href="#개요" class="headerlink" title="개요"></a>개요</h3><ul><li><strong>Amazon Mechanical Turk</strong>은 <strong>크라우드소싱 기반 인력 마켓플레이스</strong>입니다.</li><li>전 세계에 분산된 가상 인력을 통해 간단한 작업(HIT, Human Intelligence Task)을 저렴하게 처리할 수 있습니다.</li><li>이름은 18세기 체스 자동인형 *”Mechanical Turk”*에서 유래되었는데, 사실 안에 사람이 들어가 체스를 두던 일종의 착시였음.</li></ul><p align="center">  <img src="/images/aws_basic_161.png" width="80%"></p> <h3 id="사용-예시"><a href="#사용-예시" class="headerlink" title="사용 예시"></a>사용 예시</h3><ul><li>이미지 라벨링: 1천만 장의 이미지를 태깅해야 한다면, 작업을 MTurk에 배포 → 전 세계 작업자가 참여해 태깅 수행.</li><li>보상 예: 이미지당 $0.10 지급 → 1천만 장 처리 시 약 $100만 비용 발생.</li><li>단순 업무(데이터 분류, 수집, 설문조사, 콘텐츠 검토 등)에 최적.</li></ul><h3 id="통합"><a href="#통합" class="headerlink" title="통합"></a>통합</h3><ul><li><strong>Amazon A2I (Augmented AI)</strong>, <strong>SageMaker Ground Truth</strong>와 연동되어 <strong>AI 학습용 데이터 라벨링</strong>에 활용 가능.</li></ul><p>👉 <strong>시험 포인트</strong></p><ul><li>“대규모 데이터 라벨링&#x2F;간단 반복 작업을 인력에 의존” → <strong>MTurk</strong>.</li><li>Ground Truth, A2I와 함께 자주 출제됨.</li></ul><hr><h1 id="Amazon-Augmented-AI-A2I"><a href="#Amazon-Augmented-AI-A2I" class="headerlink" title="Amazon Augmented AI (A2I)"></a>Amazon Augmented AI (A2I)</h1><h3 id="개요-1"><a href="#개요-1" class="headerlink" title="개요"></a>개요</h3><ul><li><strong>Amazon A2I</strong>는 **머신러닝 예측 결과에 대한 인간 검토(Human-in-the-loop)**를 제공하는 서비스입니다.</li><li>모델 예측 결과가 <strong>신뢰도가 낮거나 모호할 때</strong>, 자동으로 사람에게 검토를 요청.</li><li>결과는 <strong>Amazon S3에 저장</strong>되고, 다시 모델 학습에 피드백되어 품질 개선에 기여.</li></ul><p align="center">  <img src="/images/aws_basic_162.png" width="80%"></p> <h3 id="검토-인력"><a href="#검토-인력" class="headerlink" title="검토 인력"></a>검토 인력</h3><ul><li>옵션 ① 사내 직원</li><li>옵션 ② <strong>AWS 계약자(500,000명 이상)</strong></li><li>옵션 ③ <strong>MTurk 인력</strong></li><li>옵션 ④ <strong>AWS Marketplace 벤더</strong> (보안&#x2F;비밀 유지 검증 완료된 업체)</li></ul><h3 id="주요-활용"><a href="#주요-활용" class="headerlink" title="주요 활용"></a>주요 활용</h3><ul><li><strong>Rekognition</strong>: 이미지&#x2F;비디오 콘텐츠 모더레이션 결과 검토.</li><li><strong>Textract</strong>: 문서에서 추출된 키-값 쌍 검증.</li><li><strong>Custom ML 모델</strong>: 신뢰도 기준에 따라 인간 검토 파이프라인 적용.</li></ul><p>👉 <strong>시험 포인트</strong></p><ul><li>“AI 예측 결과 검토 필요” → <strong>A2I</strong>.</li><li>Rekognition&#x2F;Textract와 함께 등장할 확률 높음.</li><li>Human-in-the-loop 키워드가 나오면 A2I.</li></ul><hr><h1 id="Amazon-Transcribe-Medical"><a href="#Amazon-Transcribe-Medical" class="headerlink" title="Amazon Transcribe Medical"></a>Amazon Transcribe Medical</h1><h3 id="개요-2"><a href="#개요-2" class="headerlink" title="개요"></a>개요</h3><ul><li><strong>의료 분야 전용 음성-텍스트 변환 서비스</strong>.</li><li><strong>HIPAA 규정 준수</strong>, 의료 환경에서 안전하게 사용 가능.</li><li>의료 전문 용어(약물명, 질환명, 시술명 등)에 최적화.</li></ul><p align="center">  <img src="/images/aws_basic_163.png" width="80%"></p> <h3 id="기능"><a href="#기능" class="headerlink" title="기능"></a>기능</h3><ul><li><strong>실시간 전사</strong> (마이크 입력).</li><li><strong>배치 전사</strong> (녹음 파일 업로드).</li></ul><h3 id="활용-사례"><a href="#활용-사례" class="headerlink" title="활용 사례"></a>활용 사례</h3><ul><li>의사가 진료 중 음성으로 메모 → 자동으로 환자 기록 생성.</li><li>제약사 콜센터 통화 기록을 전사하여 <strong>부작용&#x2F;안전성 보고</strong>에 활용.</li></ul><p>👉 <strong>시험 포인트</strong></p><ul><li>“의료 음성을 HIPAA 준수 환경에서 전사” → <strong>Transcribe Medical</strong>.</li></ul><hr><h1 id="Amazon-Comprehend-Medical"><a href="#Amazon-Comprehend-Medical" class="headerlink" title="Amazon Comprehend Medical"></a>Amazon Comprehend Medical</h1><h3 id="개요-3"><a href="#개요-3" class="headerlink" title="개요"></a>개요</h3><ul><li><strong>비정형 임상 텍스트</strong>(의사 메모, 퇴원 요약, 검사 결과, 환자 케이스 노트 등)에서 <strong>의미 있는 정보 추출</strong>.</li><li>자연어처리(NLP) 기반으로 <strong>의학 개체(Entity) 인식</strong> 및 <strong>관계 파악</strong> 가능.</li><li><strong>PHI (Protected Health Information)</strong> 탐지 API 제공 → 개인정보 보호.</li></ul><h3 id="기능-1"><a href="#기능-1" class="headerlink" title="기능"></a>기능</h3><ul><li>약물명, 투약량, 투여 방식 등 식별.</li><li>증상, 질환, 환자 특성(나이, 성별 등) 인식.</li><li>의학 용어 간 관계 분석 (예: 특정 약물이 특정 증상과 연관됨).</li></ul><p align="center">  <img src="/images/aws_basic_164.png" width="80%"></p> <h3 id="통합-1"><a href="#통합-1" class="headerlink" title="통합"></a>통합</h3><ul><li>데이터 저장: <strong>Amazon S3</strong></li><li>실시간 분석: <strong>Kinesis Data Firehose</strong></li><li>전사 입력: <strong>Transcribe Medical</strong>과 결합 → 음성 → 텍스트 → Comprehend Medical 분석</li></ul><p>👉 <strong>시험 포인트</strong></p><ul><li>“의료 문서&#x2F;음성 분석, PHI 탐지” → <strong>Comprehend Medical</strong>.</li><li>Transcribe Medical과 함께 등장하는 시나리오 문제 많음.</li></ul><hr><h1 id="요약-시험-대비"><a href="#요약-시험-대비" class="headerlink" title="요약 (시험 대비)"></a>요약 (시험 대비)</h1><ul><li><strong>MTurk</strong>: 크라우드소싱 인력 마켓플레이스 → 대규모 라벨링&#x2F;간단 작업.</li><li><strong>A2I</strong>: AI 예측 결과에 대한 인간 검토(Human-in-the-loop).</li><li><strong>Transcribe Medical</strong>: 의료 음성 전사 (HIPAA 준수, 의료 용어 지원).</li><li><strong>Comprehend Medical</strong>: 의료 텍스트 분석, 개체&#x2F;관계 인식, PHI 탐지.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Amazon-Mechanical-Turk-MTurk&quot;&gt;&lt;a href=&quot;#Amazon-Mechanical-Turk-MTurk&quot; class=&quot;headerlink&quot; title=&quot;Amazon Mechanical Turk (MTurk)&quot;&gt;&lt;/a&gt;</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(34) - Mechanical Turk, Augmented AI, Transcribe Medical, Comprehend Medical</title>
    <link href="https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-34/"/>
    <id>https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-34/</id>
    <published>2025-09-02T16:49:34.000Z</published>
    <updated>2025-09-02T17:13:50.788Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Amazon-Mechanical-Turk-MTurk"><a href="#Amazon-Mechanical-Turk-MTurk" class="headerlink" title="Amazon Mechanical Turk (MTurk)"></a>Amazon Mechanical Turk (MTurk)</h1><h3 id="What-it-is"><a href="#What-it-is" class="headerlink" title="What it is"></a>What it is</h3><ul><li><strong>Amazon Mechanical Turk (MTurk)</strong> is a <strong>crowdsourcing marketplace</strong> for simple human tasks (HITs, or Human Intelligence Tasks).</li><li>It provides a <strong>distributed virtual workforce</strong>—humans across the globe who can complete small tasks for pay.</li><li>The name comes from an 18th-century chess-playing automaton called <em>“The Mechanical Turk”</em>, which was actually secretly operated by a human.</li></ul><p align="center">  <img src="/images/aws_basic_161.png" width="80%"></p> <h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><ul><li>You have <strong>10 million images</strong> and need labels.</li><li>Instead of hiring a full-time workforce, you post this job on MTurk.</li><li>Workers tag the images, and you set a reward (e.g., <strong>$0.10 per image</strong> → $1M total cost).</li></ul><h3 id="Use-cases"><a href="#Use-cases" class="headerlink" title="Use cases"></a>Use cases</h3><ul><li>Image classification</li><li>Data collection</li><li>Simple business processes (like surveys, data entry, content review)</li></ul><h3 id="Integration"><a href="#Integration" class="headerlink" title="Integration"></a>Integration</h3><ul><li>Works with <strong>Amazon A2I (Augmented AI)</strong> and <strong>SageMaker Ground Truth</strong> for large-scale <strong>data labeling for ML models</strong>.</li></ul><p>💡 <strong>Exam Tip:</strong><br>When you see “large dataset labeling with human workforce” → <strong>MTurk</strong>. Often paired with <strong>A2I</strong> or <strong>Ground Truth</strong> in exam scenarios.</p><hr><h1 id="Amazon-Augmented-AI-A2I"><a href="#Amazon-Augmented-AI-A2I" class="headerlink" title="Amazon Augmented AI (A2I)"></a>Amazon Augmented AI (A2I)</h1><h3 id="What-it-is-1"><a href="#What-it-is-1" class="headerlink" title="What it is"></a>What it is</h3><ul><li><strong>Amazon A2I</strong> adds <strong>human oversight (Human-in-the-Loop, HITL)</strong> to ML predictions.</li><li>Even the best ML models can be uncertain. A2I lets you send <strong>low-confidence predictions</strong> to humans for review.</li><li>Humans can be:<ul><li>Your own employees</li><li>AWS’s network of 500,000+ contractors</li><li>MTurk workers</li><li>Pre-screened third-party vendors (via AWS Marketplace)</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_162.png" width="80%"></p> <h3 id="How-it-works"><a href="#How-it-works" class="headerlink" title="How it works"></a>How it works</h3><ol><li>Input → ML model makes a prediction.</li><li>If <strong>confidence is high</strong> → result is returned immediately.</li><li>If <strong>confidence is low</strong> → sent to <strong>A2I for human review</strong>.</li><li>Reviewed outputs are stored (e.g., in S3) and can be fed back into training to improve the model.</li></ol><h3 id="Use-cases-1"><a href="#Use-cases-1" class="headerlink" title="Use cases"></a>Use cases</h3><ul><li><strong>Content moderation</strong> (Rekognition) → humans review flagged images&#x2F;videos.</li><li><strong>Text extraction</strong> (Textract) → humans validate extracted key-value pairs.</li><li><strong>Custom ML</strong> → define your own review workflow.</li></ul><p>💡 <strong>Exam Tip:</strong><br>Key phrase <strong>“Human-in-the-Loop”</strong> &#x3D; <strong>A2I</strong>. Often combined with Rekognition or Textract.</p><hr><h1 id="Amazon-Transcribe-Medical"><a href="#Amazon-Transcribe-Medical" class="headerlink" title="Amazon Transcribe Medical"></a>Amazon Transcribe Medical</h1><h3 id="What-it-is-2"><a href="#What-it-is-2" class="headerlink" title="What it is"></a>What it is</h3><ul><li>A version of <strong>Amazon Transcribe</strong> built specifically for the <strong>medical domain</strong>.</li><li><strong>HIPAA compliant</strong>, so safe for healthcare environments.</li><li>Recognizes <strong>medical terminology</strong>: drug names, conditions, procedures, diseases.</li></ul><p align="center">  <img src="/images/aws_basic_163.png" width="80%"></p> <h3 id="Capabilities"><a href="#Capabilities" class="headerlink" title="Capabilities"></a>Capabilities</h3><ul><li><strong>Real-time transcription</strong> (via microphone input).</li><li><strong>Batch transcription</strong> (upload audio files).</li></ul><h3 id="Use-cases-2"><a href="#Use-cases-2" class="headerlink" title="Use cases"></a>Use cases</h3><ul><li>Doctors dictating patient notes directly into medical systems.</li><li>Transcribing drug safety calls and adverse event reports.</li></ul><p>💡 <strong>Exam Tip:</strong><br>If the scenario involves <strong>medical speech-to-text with HIPAA compliance</strong> → <strong>Transcribe Medical</strong>.</p><hr><h1 id="Amazon-Comprehend-Medical"><a href="#Amazon-Comprehend-Medical" class="headerlink" title="Amazon Comprehend Medical"></a>Amazon Comprehend Medical</h1><h3 id="What-it-is-3"><a href="#What-it-is-3" class="headerlink" title="What it is"></a>What it is</h3><ul><li>A specialized version of <strong>Amazon Comprehend</strong> for <strong>healthcare data</strong>.</li><li>Extracts structured information from <strong>unstructured clinical text</strong><br>like:<ul><li>Doctor’s notes</li><li>Discharge summaries</li><li>Lab&#x2F;test results</li><li>Case notes</li></ul></li></ul><h3 id="Features"><a href="#Features" class="headerlink" title="Features"></a>Features</h3><ul><li><strong>Entity detection</strong>: meds, dosage, frequency, conditions, symptoms.</li><li><strong>Relationship extraction</strong>: links between medications, dosages, and conditions.</li><li><strong>PHI detection (DetectPHI API)</strong>: identifies sensitive patient info for compliance.</li></ul><h3 id="Integration-1"><a href="#Integration-1" class="headerlink" title="Integration"></a>Integration</h3><ul><li>Documents stored in <strong>Amazon S3</strong>.</li><li>Real-time data via <strong>Kinesis Data Firehose</strong>.</li><li>Often used together with <strong>Transcribe Medical</strong>:<br>Speech → Text (Transcribe) → Text Analysis (Comprehend Medical).</li></ul><p>💡 <strong>Exam Tip:</strong><br>When you see <strong>clinical text, PHI detection, or structured medical insights</strong> → <strong>Comprehend Medical</strong>. Frequently paired with <strong>Transcribe Medical</strong> in exam questions.</p><p align="center">  <img src="/images/aws_basic_164.png" width="80%"></p> <hr><h1 id="Summary-for-AWS-Exam"><a href="#Summary-for-AWS-Exam" class="headerlink" title="Summary (for AWS Exam)"></a>Summary (for AWS Exam)</h1><ul><li><strong>MTurk</strong>: Crowdsourced workforce for labeling and simple tasks.</li><li><strong>A2I</strong>: Human review for ML predictions (Human-in-the-Loop).</li><li><strong>Transcribe Medical</strong>: Medical speech-to-text, HIPAA compliant.</li><li><strong>Comprehend Medical</strong>: Extract medical insights &amp; PHI detection from text.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Amazon-Mechanical-Turk-MTurk&quot;&gt;&lt;a href=&quot;#Amazon-Mechanical-Turk-MTurk&quot; class=&quot;headerlink&quot; title=&quot;Amazon Mechanical Turk (MTurk)&quot;&gt;&lt;/a&gt;</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(33) - Lex, Personalize, Textract, Kendra</title>
    <link href="https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-33/"/>
    <id>https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-33/</id>
    <published>2025-09-02T16:33:22.000Z</published>
    <updated>2025-09-02T16:49:18.056Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Amazon-Lex"><a href="#Amazon-Lex" class="headerlink" title="Amazon Lex"></a>Amazon Lex</h1><h2 id="What-it-is"><a href="#What-it-is" class="headerlink" title="What it is"></a>What it is</h2><p><strong>Amazon Lex</strong> lets you build conversational chatbots quickly using <strong>voice or text</strong>. Think pizza-ordering bots, hotel-booking bots, or customer support assistants. It supports <strong>multiple languages</strong> and integrates tightly with <strong>AWS Lambda, Amazon Connect, Comprehend, and<br>Kendra</strong>.</p><h2 id="How-it-works-simple-flow"><a href="#How-it-works-simple-flow" class="headerlink" title="How it works (simple flow)"></a>How it works (simple flow)</h2><ol><li><strong>User utterance</strong>: “I want to book a hotel.”</li><li><strong>Intent detection</strong>: Lex matches this to the <strong>BookHotel</strong> intent.</li><li><strong>Slot collection</strong>: Lex asks for required <strong>slots</strong> (city, check-in date, nights, room type).</li><li><strong>Fulfillment</strong>: When all slots are filled, Lex triggers a <strong>Lambda</strong> function to complete the action (e.g., create a reservation).</li><li><strong>Response</strong>: “Your reservation is confirmed.”</li></ol><h2 id="Key-terms-exam-ready"><a href="#Key-terms-exam-ready" class="headerlink" title="Key terms (exam-ready)"></a>Key terms (exam-ready)</h2><ul><li><strong>Intent</strong>: What the user wants (e.g., BookHotel).</li><li><strong>Utterances</strong>: Example phrases that trigger an intent.</li><li><strong>Slots</strong>: Input parameters Lex must collect to fulfill an intent.</li><li><strong>Fulfillment</strong>: Often a <strong>Lambda</strong> function that performs the action.</li><li><strong>Connect integration</strong>: Use Lex in contact centers for IVR and agent assist.</li><li><strong>Generative builder</strong> (with Bedrock): Option to bootstrap bots using GenAI.</li></ul><p><strong>Exam tips</strong> - When you see <strong>chatbot + intents&#x2F;slots + Lambda</strong>, think <strong>Lex</strong>.</p><ul><li>For <strong>call center</strong>&#x2F;IVR use cases → <strong>Lex + Amazon Connect</strong>.</li><li>Entity extraction&#x2F;semantic understanding in the conversation → consider <strong>Comprehend</strong> with Lex.</li></ul><p align="center">  <img src="/images/aws_basic_157.png" width="80%"></p> <hr><h1 id="Amazon-Personalize"><a href="#Amazon-Personalize" class="headerlink" title="Amazon Personalize"></a>Amazon Personalize</h1><h2 id="What-it-is-1"><a href="#What-it-is-1" class="headerlink" title="What it is"></a>What it is</h2><p><strong>Amazon Personalize</strong> is a fully managed ML service for <strong>real-time, personalized recommendations</strong> (no need to build&#x2F;train&#x2F;deploy models yourself). It’s the same tech used on <strong>Amazon.com</strong> and can be integrated into <strong>websites, apps, email, SMS</strong>, and more—<strong>in days, not months</strong>.</p><p align="center">  <img src="/images/aws_basic_158.png" width="80%"></p> <h2 id="Typical-use-cases"><a href="#Typical-use-cases" class="headerlink" title="Typical use cases"></a>Typical use cases</h2><ul><li>Personalized product recommendations</li><li>Re-ranking lists for each user</li><li>Targeted campaigns (email&#x2F;SMS&#x2F;push)</li><li>Media&#x2F;content suggestions</li></ul><h2 id="Data-integration"><a href="#Data-integration" class="headerlink" title="Data &amp; integration"></a>Data &amp; integration</h2><ul><li>Historical&#x2F;real-time interaction data via <strong>Amazon S3</strong> and <strong>Personalize APIs</strong>.</li><li>The service exposes <strong>real-time inference APIs</strong> for your app to call.</li></ul><h2 id="Recipes-algorithm-templates"><a href="#Recipes-algorithm-templates" class="headerlink" title="Recipes (algorithm templates)"></a>Recipes (algorithm templates)</h2><ul><li><strong>USER_PERSONALIZATION</strong> → <em>User-Personalization-v2</em>: Personalized item recommendations.</li><li><strong>PERSONALIZED_RANKING</strong> → <em>Personalized-Ranking-v2</em>: Re-rank a given list for a user.</li><li><strong>POPULAR_ITEMS</strong> → <em>Trending-Now</em>, <em>Popularity-Count</em>: Popular or trending content.</li><li><strong>RELATED_ITEMS</strong> → <em>Similar-Items</em>: “Because you watched&#x2F;bought…”.</li><li><strong>PERSONALIZED_ACTIONS</strong> → <em>Next-Best-Action</em>: Suggest the next optimal step.</li><li><strong>USER_SEGMENTATION</strong> → <em>Item-Affinity</em>: Build user segments by affinity.</li></ul><p><strong>Exam tips</strong> - “We need <strong>recommendations</strong>“ → <strong>Personalize</strong>.</p><ul><li>Recipes are <strong>for recommendation use cases</strong> (not forecasting).</li><li><strong>Real-time personalization</strong> and <strong>re-ranking</strong> are strong signals for Personalize.</li></ul><hr><h1 id="Amazon-Textract"><a href="#Amazon-Textract" class="headerlink" title="Amazon Textract"></a>Amazon Textract</h1><h2 id="What-it-is-2"><a href="#What-it-is-2" class="headerlink" title="What it is"></a>What it is</h2><p><strong>Amazon Textract</strong> extracts <strong>text, handwriting, and structured data</strong> from scanned documents, PDFs, and images—<strong>beyond basic OCR</strong>. It understands <strong>forms (key–value pairs)</strong> and <strong>tables</strong>.</p><p align="center">  <img src="/images/aws_basic_159.png" width="80%"></p> <h2 id="Capabilities"><a href="#Capabilities" class="headerlink" title="Capabilities"></a>Capabilities</h2><ul><li><strong>Text extraction</strong> from images&#x2F;PDFs</li><li><strong>Form extraction</strong>: Detects keys&#x2F;values (e.g., “DOB → 2008-07-18”)</li><li><strong>Table extraction</strong>: Preserves rows&#x2F;columns&#x2F;headers</li><li><strong>Queries</strong>: Ask targeted questions (“What is YTD gross pay?”)</li><li><strong>ID&#x2F;receipt parsing</strong>: Extracts standardized fields</li></ul><h2 id="Use-cases"><a href="#Use-cases" class="headerlink" title="Use cases"></a>Use cases</h2><ul><li><strong>Financial services</strong>: Invoices, statements</li><li><strong>Healthcare</strong>: Medical records, insurance claims</li><li><strong>Public sector</strong>: Tax forms, IDs, passports</li></ul><p><strong>Exam tips</strong> - “Extract text and <strong>structured</strong> fields from documents” → <strong>Textract</strong>.</p><ul><li>If the question is about <strong>document layout</strong> (tables&#x2F;forms), Textract is the right fit (not just simple OCR).</li></ul><hr><h1 id="Amazon-Kendra"><a href="#Amazon-Kendra" class="headerlink" title="Amazon Kendra"></a>Amazon Kendra</h1><h2 id="What-it-is-3"><a href="#What-it-is-3" class="headerlink" title="What it is"></a>What it is</h2><p><strong>Amazon Kendra</strong> is a fully managed, <strong>ML-powered enterprise search</strong> service. It supports <strong>natural language queries</strong> and returns <strong>relevant passages&#x2F;answers from documents</strong> (PDF, Word, HTML, PPT, FAQs, etc.).</p><p align="center">  <img src="/images/aws_basic_160.png" width="80%"></p> <h2 id="Why-it’s-useful"><a href="#Why-it’s-useful" class="headerlink" title="Why it’s useful"></a>Why it’s useful</h2><ul><li>Users can ask <strong>natural language</strong> questions (“Where is the IT support desk?”) and get direct answers (“1st floor”).</li><li>Learns from clicks&#x2F;feedback (<strong>incremental learning</strong>) to improve ranking.</li><li>Admins can <strong>manually tune relevance</strong> (boost freshness, source, metadata).</li></ul><p><strong>Exam tips</strong> - “We need to <strong>search</strong> across many document types and return answers” → <strong>Kendra</strong>.</p><ul><li><strong>Kendra vs Textract</strong>: Kendra is for <strong>search and Q&amp;A</strong>; Textract is for <strong>data extraction</strong> from documents.</li></ul><hr><h2 id="Quick-Certification-Checkpoints"><a href="#Quick-Certification-Checkpoints" class="headerlink" title="Quick Certification Checkpoints"></a>Quick Certification Checkpoints</h2><ul><li><strong>Lex</strong>: Conversational AI with <strong>intents&#x2F;slots</strong> and <strong>Lambda</strong> fulfillment; integrates with <strong>Connect</strong> (IVR) and <strong>Comprehend</strong> (NLP).</li><li><strong>Personalize</strong>: <strong>Recommendations</strong> service; choose a <strong>recipe</strong> matching the use case; supports <strong>real-time</strong> inference and <strong>re-ranking</strong>.</li><li><strong>Textract</strong>: OCR <strong>plus</strong> structure—<strong>forms, tables, queries</strong>, ID&#x2F;receipt extraction.</li><li><strong>Kendra</strong>: Enterprise <strong>search</strong> with <strong>natural language</strong> Q&amp;A and tunable relevance.</li></ul><hr><h2 id="Architecture-Selection-Hints-good-for-scenario-questions"><a href="#Architecture-Selection-Hints-good-for-scenario-questions" class="headerlink" title="Architecture &amp; Selection Hints (good for scenario questions)"></a>Architecture &amp; Selection Hints (good for scenario questions)</h2><ul><li><strong>Need a voice&#x2F;text bot that collects parameters and acts?</strong> → <strong>Lex + Lambda</strong> (maybe Connect for phone).</li><li><strong>Need to recommend products&#x2F;content in real time?</strong> → <strong>Personalize</strong> (pick the right <strong>recipe</strong>).</li><li><strong>Need to parse scanned documents into structured fields?</strong> → <strong>Textract</strong>.</li><li><strong>Need to search across knowledge bases and return direct answers?</strong> → <strong>Kendra</strong>.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Amazon-Lex&quot;&gt;&lt;a href=&quot;#Amazon-Lex&quot; class=&quot;headerlink&quot; title=&quot;Amazon Lex&quot;&gt;&lt;/a&gt;Amazon Lex&lt;/h1&gt;&lt;h2 id=&quot;What-it-is&quot;&gt;&lt;a href=&quot;#What-it-is&quot;</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (33) - Lex, Personalize, Textract, Kendra</title>
    <link href="https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-33/"/>
    <id>https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-33/</id>
    <published>2025-09-02T16:33:16.000Z</published>
    <updated>2025-09-02T16:49:18.057Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Amazon-Lex"><a href="#Amazon-Lex" class="headerlink" title="Amazon Lex"></a>Amazon Lex</h1><h3 id="기본-개념"><a href="#기본-개념" class="headerlink" title="기본 개념"></a>기본 개념</h3><ul><li><strong>Amazon Lex</strong>는 음성이나 텍스트로 대화형 챗봇을 빠르게 만들 수 있는 서비스입니다.</li><li>예시: 고객이 호텔 예약을 하거나 피자를 주문할 수 있는 챗봇.</li><li>여러 언어를 지원하며, <strong>AWS Lambda, Amazon Connect, Comprehend, Kendra</strong>와 통합됩니다.</li><li>사용자의 의도(Intent)를 자동으로 파악해 알맞은 Lambda 함수를 호출하여 요청을 처리합니다.</li><li>필요한 경우 챗봇이 사용자에게 추가 정보를 요청하는데, 이를 **Slot(입력 매개변수)**라고 부릅니다.</li></ul><h3 id="동작-방식"><a href="#동작-방식" class="headerlink" title="동작 방식"></a>동작 방식</h3><ol><li>사용자가 “호텔 예약하고 싶어요”라고 입력.</li><li>Lex는 미리 정의된 **Intent(호텔 예약)**를 인식.</li><li>필요한 Slot(도시, 체크인 날짜, 숙박일수 등)을 질문하여 채움.</li><li>모든 Slot이 채워지면 Lambda 함수를 호출해 예약 처리.</li><li>결과를 사용자에게 응답 (“예약이 완료되었습니다”).</li></ol><h3 id="시험-포인트"><a href="#시험-포인트" class="headerlink" title="시험 포인트"></a>시험 포인트</h3><ul><li><strong>Intent</strong>: 사용자가 원하는 목적(예: 호텔 예약).</li><li><strong>Utterance</strong>: Intent를 유발하는 사용자 입력(“호텔 예약해줘”).</li><li><strong>Slot</strong>: 작업 수행에 필요한 입력값(날짜, 장소 등).</li><li><strong>Lambda 연계</strong>: Intent를 Fulfillment(실행)할 때 Lambda를 호출.</li><li><strong>생성형 AI 기반 챗봇</strong>도 지원 (Amazon Bedrock과 통합).</li></ul><p>👉 <strong>자격증 시험에서는</strong> “대화형 챗봇”, “Slot 기반 파라미터”, “Lambda 연계” 키워드 나오면 → Amazon Lex.</p><p align="center">  <img src="/images/aws_basic_157.png" width="80%"></p> <hr><h1 id="Amazon-Personalize"><a href="#Amazon-Personalize" class="headerlink" title="Amazon Personalize"></a>Amazon Personalize</h1><h3 id="기본-개념-1"><a href="#기본-개념-1" class="headerlink" title="기본 개념"></a>기본 개념</h3><ul><li><strong>Amazon Personalize</strong>는 실시간 개인화 추천 시스템을 구축할 수 있는 완전 관리형 ML 서비스입니다.</li><li>예시: 상품 추천, 개인화된 마케팅, 사용자가 본 영화와 유사한 영화 추천.</li><li>Amazon.com이 사용하는 동일한 기술 기반.</li><li>웹사이트, 앱, 이메일, SMS 등에 통합 가능.</li><li>직접 ML 모델을 구축·훈련할 필요 없이 <strong>며칠 만에 구현 가능</strong>.</li></ul><p align="center">  <img src="/images/aws_basic_158.png" width="80%"></p> <h3 id="활용-사례"><a href="#활용-사례" class="headerlink" title="활용 사례"></a>활용 사례</h3><ul><li>소매업: 고객 구매 패턴 기반 상품 추천.</li><li>미디어&#x2F;엔터테인먼트: 시청 이력 기반 영화&#x2F;음악 추천.</li></ul><h3 id="Recipes-알고리즘-템플릿"><a href="#Recipes-알고리즘-템플릿" class="headerlink" title="Recipes (알고리즘 템플릿)"></a>Recipes (알고리즘 템플릿)</h3><ul><li><strong>USER_PERSONALIZATION</strong>: 사용자 맞춤형 추천 (예: User-Personalization-v2).</li><li><strong>PERSONALIZED_RANKING</strong>: 특정 사용자에 맞춰 아이템 순위 재정렬.</li><li><strong>POPULAR_ITEMS</strong>: 인기 상품&#x2F;트렌드 추천 (Trending-Now, Popularity-Count).</li><li><strong>RELATED_ITEMS</strong>: 유사 아이템 추천 (Similar-Items).</li><li><strong>PERSONALIZED_ACTIONS</strong>: 다음 행동 추천 (Next-Best-Action).</li><li><strong>USER_SEGMENTATION</strong>: 사용자 그룹 세분화 (Item-Affinity).</li></ul><p>👉 <strong>시험 포인트</strong></p><ul><li>“추천 시스템” &#x3D; Personalize.</li><li>Recipes는 <strong>추천(Recommendation)</strong> 전용임 → <strong>예측&#x2F;Forecasting 아님</strong>.</li></ul><hr><h1 id="Amazon-Textract"><a href="#Amazon-Textract" class="headerlink" title="Amazon Textract"></a>Amazon Textract</h1><h3 id="기본-개념-2"><a href="#기본-개념-2" class="headerlink" title="기본 개념"></a>기본 개념</h3><ul><li><strong>Amazon Textract</strong>는 스캔된 문서, PDF, 이미지에서 <strong>텍스트·필기·데이터를 자동 추출</strong>하는 서비스.</li><li>단순 OCR을 넘어 **문서 구조(테이블, 양식, 키-값 쌍)**까지 인식.</li></ul><p align="center">  <img src="/images/aws_basic_159.png" width="80%"></p> <h3 id="활용-사례-1"><a href="#활용-사례-1" class="headerlink" title="활용 사례"></a>활용 사례</h3><ul><li><strong>금융</strong>: 인보이스, 금융 보고서 처리.</li><li><strong>헬스케어</strong>: 진료 기록, 보험 청구서.</li><li><strong>공공기관</strong>: 세금 신고서, 여권, 신분증.</li></ul><h3 id="주요-기능"><a href="#주요-기능" class="headerlink" title="주요 기능"></a>주요 기능</h3><ul><li><strong>텍스트 추출</strong>: 이미지에서 모든 텍스트 인식.</li><li><strong>양식(Form) 인식</strong>: 키-값 쌍 자동 추출 (예: “생년월일 → 2008&#x2F;07&#x2F;18”).</li><li><strong>테이블 인식</strong>: 표 구조 분석 후 행&#x2F;열 단위로 데이터 추출.</li><li><strong>질의(Query)</strong>: 문서에 질문 던져 원하는 값만 추출 (예: “연간 총급여는 얼마?”).</li><li><strong>ID&#x2F;영수증 분석</strong>: 신분증·청구서에서 표준 필드 인식.</li></ul><p>👉 <strong>시험 포인트</strong></p><ul><li>“문서에서 텍스트, 표, 양식 데이터 추출” &#x3D; Textract.</li><li><strong>OCR 그 이상</strong> → 문서 레이아웃과 구조 이해 가능.</li></ul><hr><h1 id="Amazon-Kendra"><a href="#Amazon-Kendra" class="headerlink" title="Amazon Kendra"></a>Amazon Kendra</h1><h3 id="기본-개념-3"><a href="#기본-개념-3" class="headerlink" title="기본 개념"></a>기본 개념</h3><ul><li><strong>Amazon Kendra</strong>는 머신러닝 기반 <strong>지능형 문서 검색 서비스</strong>입니다.</li><li>문서 내에서 <strong>정확한 답변 추출</strong> 가능 (PDF, Word, HTML, FAQ 등).</li><li><strong>자연어 검색 지원</strong> (“IT 지원팀은 어디 있나요?” → “1층에 있습니다”).</li><li>사용자 피드백 기반 <strong>Incremental Learning</strong> → 자주 선택되는 답변이 상위 노출.</li><li>관리자가 <strong>중요도, 최신성, 사용자 정의 필터</strong>를 통해 검색 결과 조정 가능.</li></ul><p align="center">  <img src="/images/aws_basic_160.png" width="80%"></p> <h3 id="시험-포인트-1"><a href="#시험-포인트-1" class="headerlink" title="시험 포인트"></a>시험 포인트</h3><ul><li>“문서 검색&#x2F;FAQ 검색 서비스” → Amazon Kendra.</li><li>Kendra는 <strong>검색(Search)</strong>, Textract는 <strong>텍스트 추출(Extract)</strong>.</li></ul><hr><h1 id="요약-시험-대비"><a href="#요약-시험-대비" class="headerlink" title="요약 (시험 대비)"></a>요약 (시험 대비)</h1><ul><li><strong>Lex</strong>: 대화형 챗봇, Intent&#x2F;Slot, Lambda 연계.</li><li><strong>Personalize</strong>: 개인화 추천 시스템, Recipes 사용.</li><li><strong>Textract</strong>: 문서에서 텍스트·양식·테이블 추출.</li><li><strong>Kendra</strong>: 지능형 문서 검색 서비스, 자연어 질의 지원.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Amazon-Lex&quot;&gt;&lt;a href=&quot;#Amazon-Lex&quot; class=&quot;headerlink&quot; title=&quot;Amazon Lex&quot;&gt;&lt;/a&gt;Amazon Lex&lt;/h1&gt;&lt;h3 id=&quot;기본-개념&quot;&gt;&lt;a href=&quot;#기본-개념&quot; class=&quot;he</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(32) - Amazon Polly &amp; Rekognition</title>
    <link href="https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-32/"/>
    <id>https://kish191919.github.io/2025/09/02/AWS-Certified-AI-Practitioner-32/</id>
    <published>2025-09-02T16:13:59.000Z</published>
    <updated>2025-09-02T16:28:05.745Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Amazon-Polly"><a href="#Amazon-Polly" class="headerlink" title="Amazon Polly"></a>Amazon Polly</h1><h3 id="What-It-Does"><a href="#What-It-Does" class="headerlink" title="What It Does"></a>What It Does</h3><ul><li><strong>Amazon Polly</strong> is a Text-to-Speech (TTS) service that converts written text into lifelike speech using <strong>deep learning</strong>.</li><li>With Polly, you can create applications that actually <strong>speak</strong> to users—for example, an audiobook generator, a voice-enabled chatbot, or accessibility tools for visually impaired users.</li></ul><p align="center">  <img src="/images/aws_basic_153.png" width="80%"></p> <h3 id="Key-Features-Exam-Focus"><a href="#Key-Features-Exam-Focus" class="headerlink" title="Key Features (Exam Focus)"></a>Key Features (Exam Focus)</h3><ol><li><strong>Lexicons (Custom Pronunciation Dictionary)</strong><ul><li>You can define how certain words should be pronounced.</li><li>Example: <code>AWS</code> → <em>Amazon Web Services</em>, <code>W3C</code> → <em>World Wide Web Consortium</em>.</li><li><strong>Exam Tip:</strong> If a question asks how to control the way Polly pronounces abbreviations → the answer is <strong>Lexicons</strong>.</li></ul></li><li><strong>SSML (Speech Synthesis Markup Language)</strong><ul><li><p>Markup language to fine-tune speech output: pauses, emphasis, pitch, volume, rate, etc.</p></li><li><p>Example:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">speak</span>&gt;</span>Hello, <span class="tag">&lt;<span class="name">break</span> <span class="attr">time</span>=<span class="string">&quot;1s&quot;</span>/&gt;</span> how are you?<span class="tag">&lt;/<span class="name">speak</span>&gt;</span></span><br></pre></td></tr></table></figure><p>→ Polly will say “Hello,” pause for 1 second, then continue with “how are you?”</p></li></ul></li><li><strong>Voice Engines</strong><ul><li><strong>Standard:</strong> Older, robotic-sounding voices.</li><li><strong>Neural:</strong> More human-like and natural.</li><li><strong>Long-form:</strong> Designed for extended audio like podcasts or audiobooks.</li><li><strong>Generative:</strong> Latest engine using GenAI, capable of expressive, adaptive voices.</li><li><strong>Exam Tip:</strong> Know the difference between <strong>Standard vs Neural</strong> voices.</li></ul></li><li><strong>Speech Marks</strong><ul><li>Metadata showing where words and sentences start&#x2F;end in the audio stream.</li><li>Useful for <strong>lip-syncing</strong> or <strong>highlighting words in real-time transcripts</strong>.</li></ul></li></ol><h3 id="Important-Comparison"><a href="#Important-Comparison" class="headerlink" title="Important Comparison"></a>Important Comparison</h3><ul><li><strong>Amazon Polly &#x3D; Text → Speech</strong></li><li><strong>Amazon Transcribe &#x3D; Speech → Text</strong></li></ul><hr><h1 id="Amazon-Rekognition"><a href="#Amazon-Rekognition" class="headerlink" title="Amazon Rekognition"></a>Amazon Rekognition</h1><h3 id="What-It-Does-1"><a href="#What-It-Does-1" class="headerlink" title="What It Does"></a>What It Does</h3><ul><li><strong>Amazon Rekognition</strong> analyzes <strong>images and videos</strong> with machine learning.</li><li>It can identify <strong>objects, text, people, and activities</strong>, and it supports <strong>facial recognition and verification</strong>.</li></ul><p align="center">  <img src="/images/aws_basic_154.png" width="80%"></p> <h3 id="Core-Use-Cases-High-Exam-Relevance"><a href="#Core-Use-Cases-High-Exam-Relevance" class="headerlink" title="Core Use Cases (High Exam Relevance)"></a>Core Use Cases (High Exam Relevance)</h3><ol><li><strong>Labeling</strong> – Automatically detect and categorize objects and scenes (e.g., “car,” “dog,” “mountain”).</li><li><strong>Text Detection</strong> – Extract text from images (e.g., license plates, signs).</li><li><strong>Face Detection &amp; Analysis</strong> – Determine gender, age range, and emotions (e.g., smiling, eyes open).</li><li><strong>Face Search &amp; Verification</strong> – Match against a database of known faces (e.g., for access control).</li><li><strong>Celebrity Recognition</strong> – Identify famous people.</li><li><strong>Pathing &#x2F; Tracking</strong> – Track movement (e.g., following a ball in a sports game).</li><li><strong>PPE Detection</strong> – Detect personal protective equipment like helmets, gloves, and masks.</li></ol><hr><h3 id="Advanced-Features"><a href="#Advanced-Features" class="headerlink" title="Advanced Features"></a>Advanced Features</h3><ol><li><p><strong>Custom Labels</strong></p><ul><li>Train Rekognition to detect your <strong>own objects or logos</strong>.</li><li>Example: The NFL uses Rekognition to automatically find its logo in social media photos.</li><li>Only a few hundred training images are needed.</li><li>Images are stored in <strong>Amazon S3</strong>, then Rekognition trains a <strong>custom model</strong>.</li></ul><p><strong>Exam Tip:</strong><br>If you see “identify your company logo in images” → answer is <strong>Rekognition Custom Labels</strong>.</p></li><li><p><strong>Content Moderation</strong></p><ul><li>Automatically detect <strong>inappropriate or unsafe content</strong> (e.g., for social media platforms, ad campaigns, broadcasting).</li><li>Reduces human review workload to about <strong>1–5%</strong>.</li><li>Integrated with <strong>Amazon Augmented AI (A2I)</strong> so humans can review edge cases.</li><li>Supports <strong>Custom Moderation Adapters</strong> → you can supply your own labeled datasets to improve accuracy.</li></ul><p><strong>Exam Tip:</strong><br>If a question asks about automatically filtering harmful content while still allowing human review when needed → the answer involves <strong>Rekognition Content Moderation + A2I</strong>.</p></li></ol><p align="center">  <img src="/images/aws_basic_155.png" width="80%"></p> <p align="center">  <img src="/images/aws_basic_156.png" width="80%"></p> <hr><h3 id="Extra-Details-That-Might-Show-Up-on-Exams"><a href="#Extra-Details-That-Might-Show-Up-on-Exams" class="headerlink" title="Extra Details That Might Show Up on Exams"></a>Extra Details That Might Show Up on Exams</h3><ul><li><strong>Face Liveness Detection</strong>: Ensures the detected face is real (not a photo or video spoof).</li><li><strong>Image Properties</strong>: Extract dominant colors, foreground&#x2F;background quality.</li><li><strong>Integration with Other AWS Services</strong>:<ul><li>Works well with <strong>Amazon S3</strong> (for image storage).</li><li>Results can be sent to <strong>Amazon SNS&#x2F;SQS</strong> for event handling.</li><li>Human-in-the-loop moderation integrates with <strong>Amazon A2I</strong>.</li></ul></li></ul><hr><h1 id="Quick-Exam-Summary"><a href="#Quick-Exam-Summary" class="headerlink" title="Quick Exam Summary"></a>Quick Exam Summary</h1><ul><li><strong>Polly vs Transcribe</strong> → Polly &#x3D; TTS, Transcribe &#x3D; STT.</li><li><strong>Polly Key Features</strong> → Lexicons, SSML, Neural&#x2F;Generative Voices, Speech Marks.</li><li><strong>Rekognition Key Features</strong> → Labeling, Text Detection, Face Analysis, Celebrity Recognition, PPE Detection.</li><li><strong>Rekognition Advanced</strong> → Custom Labels, Content Moderation (+ A2I integration).</li><li><strong>Remember:</strong> Rekognition &#x3D; image&#x2F;video analysis, Polly &#x3D; text-to-speech.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Amazon-Polly&quot;&gt;&lt;a href=&quot;#Amazon-Polly&quot; class=&quot;headerlink&quot; title=&quot;Amazon Polly&quot;&gt;&lt;/a&gt;Amazon Polly&lt;/h1&gt;&lt;h3 id=&quot;What-It-Does&quot;&gt;&lt;a href=&quot;#W</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (32) - Amazon Polly &amp; Rekognition</title>
    <link href="https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-32/"/>
    <id>https://kish191919.github.io/2025/09/02/KO-AWS-Certified-AI-Practitioner-32/</id>
    <published>2025-09-02T16:13:52.000Z</published>
    <updated>2025-09-02T16:28:04.169Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Amazon-Polly"><a href="#Amazon-Polly" class="headerlink" title="Amazon Polly"></a>Amazon Polly</h1><h3 id="기본-개념"><a href="#기본-개념" class="headerlink" title="기본 개념"></a>기본 개념</h3><ul><li><strong>Amazon Polly</strong>는 텍스트를 사람처럼 자연스러운 음성으로 바꿔주는 서비스입니다.</li><li><strong>딥러닝 기반 음성 합성(TTS, Text-to-Speech)</strong> 기술을 사용해 실제 사람 목소리처럼 들리게 합니다.</li><li>이 기능을 활용하면 “말하는 애플리케이션”을 만들 수 있습니다. 예: 뉴스 읽기 앱, 시각장애인용 리더, 고객센터 챗봇 등.</li></ul><p align="center">  <img src="/images/aws_basic_153.png" width="80%"></p> <h3 id="주요-기능"><a href="#주요-기능" class="headerlink" title="주요 기능"></a>주요 기능</h3><ol><li><strong>Lexicon (발음 사전)</strong><ul><li>특정 단어를 원하는 방식으로 읽도록 설정 가능.</li><li>예: <code>AWS</code> → <em>Amazon Web Services</em>, <code>W3C</code> → <em>World Wide Web Consortium</em>.</li></ul></li><li><strong>SSML (Speech Synthesis Markup Language)</strong><ul><li>발음·억양·속도·강세 등을 조정하는 마크업 언어.</li><li>예: <code>&quot;Hello, &lt;break time=&#39;1s&#39;/&gt; how are you?&quot;</code> → “헬로” 후 1초 쉬고 “하우 아 유?”</li><li>시험 포인트: <strong>Polly에서 발음을 제어하려면 SSML 사용</strong>.</li></ul></li><li><strong>Voice Engine 종류</strong><ul><li><strong>Standard</strong>: 기본 엔진, 가장 오래됨.</li><li><strong>Neural</strong>: 사람 목소리에 더 가까운 고품질 엔진.</li><li><strong>Long-form</strong>: 긴 콘텐츠(예: 오디오북)에 최적화.</li><li><strong>Generative</strong>: 최신 Gen AI 기반, 가장 자연스럽고 감정 표현 가능.</li></ul></li><li><strong>Speech Marks</strong><ul><li>오디오에서 단어·문장이 시작&#x2F;끝나는 위치를 표시.</li><li><strong>활용 사례</strong>: 입 모양과 싱크 맞추기(lip-sync), 자막이나 단어 하이라이팅.</li></ul></li></ol><p>👉 <strong>시험에 자주 나오는 포인트</strong></p><ul><li>Polly &#x3D; TTS(Text-to-Speech), Transcribe &#x3D; STT(Speech-to-Text).</li><li>발음을 제어하는 방법 → <strong>Lexicon &#x2F; SSML</strong>.</li><li>음성 엔진 종류 차이 (Standard vs Neural vs Generative).</li></ul><hr><h1 id="Amazon-Rekognition"><a href="#Amazon-Rekognition" class="headerlink" title="Amazon Rekognition"></a>Amazon Rekognition</h1><h3 id="기본-개념-1"><a href="#기본-개념-1" class="headerlink" title="기본 개념"></a>기본 개념</h3><ul><li>이미지와 동영상을 분석하는 서비스.</li><li><strong>머신러닝 기반</strong>으로 객체, 사람, 텍스트, 장면 등을 인식합니다.</li><li>얼굴 분석(성별, 나이대, 감정), 얼굴 검색(유사 인물 찾기), 셀러브리티 인식 등이 가능.</li></ul><p align="center">  <img src="/images/aws_basic_154.png" width="80%"></p> <h3 id="주요-기능-시험에서-잘-나옴"><a href="#주요-기능-시험에서-잘-나옴" class="headerlink" title="주요 기능 (시험에서 잘 나옴)"></a>주요 기능 (시험에서 잘 나옴)</h3><ol><li><strong>라벨링(Labeling)</strong><ul><li>사진·영상에서 객체나 장면을 자동 인식 (예: 사람, 자동차, 건물).</li></ul></li><li><strong>텍스트 탐지(Text Detection)</strong><ul><li>이미지 안의 글자 추출 (예: 차량 번호판, 간판 텍스트).</li></ul></li><li><strong>얼굴 분석(Face Analysis)</strong><ul><li>나이대, 성별, 감정(웃음, 눈뜸 여부 등).</li></ul></li><li><strong>얼굴 검색&#x2F;비교(Face Search &amp; Verification)</strong><ul><li>데이터베이스에 있는 얼굴과 비교 → 본인 인증이나 중복 인식에 활용.</li></ul></li><li><strong>셀러브리티 인식(Celebrity Recognition)</strong><ul><li>유명인 얼굴을 자동으로 인식 (예: Jeff Bezos, Andy Jassy).</li></ul></li><li><strong>경로 추적(Pathing)</strong><ul><li>스포츠 경기에서 선수·공의 움직임 추적.</li></ul></li><li><strong>PPE(개인 보호 장비) 감지</strong><ul><li>마스크, 안전모, 장갑 착용 여부 확인 → 산업&#x2F;보안 환경에서 사용.</li></ul></li></ol><hr><h3 id="고급-기능"><a href="#고급-기능" class="headerlink" title="고급 기능"></a>고급 기능</h3><ol><li><strong>Custom Labels (맞춤 라벨링)</strong><ul><li>기본 제공 라벨 외에, 기업이 직접 원하는 객체&#x2F;로고 인식 가능.</li><li>예: NFL → 경기 사진에서 NFL 로고 자동 탐지.</li><li>방법:<ul><li>학습용 이미지(S3에 저장) 업로드 → Rekognition이 맞춤 모델 생성.</li><li>수백 장 이하의 이미지로도 가능.</li></ul></li></ul></li><li><strong>Content Moderation (콘텐츠 필터링)</strong><ul><li>부적절하거나 유해한 이미지·영상 자동 탐지.</li><li>예: SNS, 광고, 방송 콘텐츠에서 유해 콘텐츠 필터링.</li><li><strong>사람이 직접 검토해야 하는 양을 1~5% 수준으로 줄임.</strong></li><li>**Amazon A2I(Augmented AI)**와 통합 → AI가 불확실할 때 사람에게 검토 요청.</li><li><strong>Custom Moderation Adapter</strong> 사용 → 기업 맞춤형 콘텐츠 필터링 가능.</li></ul></li></ol><p align="center">  <img src="/images/aws_basic_155.png" width="80%"></p> <p align="center">  <img src="/images/aws_basic_156.png" width="80%"></p> <hr><h3 id="시험-포인트-정리"><a href="#시험-포인트-정리" class="headerlink" title="시험 포인트 정리"></a>시험 포인트 정리</h3><ul><li><strong>Polly vs Transcribe</strong> → Polly는 TTS, Transcribe는 STT.</li><li><strong>Polly 주요 기능</strong> → Lexicon, SSML, Speech Marks, Neural&#x2F;Standard 엔진.</li><li><strong>Rekognition 주요 기능</strong> → 라벨링, 얼굴 분석&#x2F;검색, 텍스트 탐지, 콘텐츠 필터링, Custom Labels.</li><li><strong>Rekognition Content Moderation</strong> → 부적절 콘텐츠 자동 감지, A2I와 연계.</li><li><strong>Custom Labels</strong> → 소수의 이미지 데이터만으로 기업 맞춤형 객체 인식 가능.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Amazon-Polly&quot;&gt;&lt;a href=&quot;#Amazon-Polly&quot; class=&quot;headerlink&quot; title=&quot;Amazon Polly&quot;&gt;&lt;/a&gt;Amazon Polly&lt;/h1&gt;&lt;h3 id=&quot;기본-개념&quot;&gt;&lt;a href=&quot;#기본-개념&quot; c</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (31) - AWS AI 관리형 서비스</title>
    <link href="https://kish191919.github.io/2025/08/26/KO-AWS-Certified-AI-Practitioner-31/"/>
    <id>https://kish191919.github.io/2025/08/26/KO-AWS-Certified-AI-Practitioner-31/</id>
    <published>2025-08-26T19:37:13.000Z</published>
    <updated>2025-08-27T02:57:51.733Z</updated>
    
    <content type="html"><![CDATA[<h1 id="AWS-AI-관리형-서비스-AWS-AI-Managed-Services"><a href="#AWS-AI-관리형-서비스-AWS-AI-Managed-Services" class="headerlink" title="AWS AI 관리형 서비스 (AWS AI Managed Services)"></a>AWS AI 관리형 서비스 (AWS AI Managed Services)</h1><h2 id="1-왜-AWS-AI-관리형-서비스인가"><a href="#1-왜-AWS-AI-관리형-서비스인가" class="headerlink" title="1. 왜 AWS AI 관리형 서비스인가?"></a>1. 왜 AWS AI 관리형 서비스인가?</h2><ul><li><strong>사전 학습된 ML 모델 제공</strong> → 별도의 훈련 필요 없음</li><li><strong>고가용성 &amp; 빠른 응답성</strong></li><li><strong>중복성 &amp; 리전 배포</strong>: 여러 AZ&#x2F;Region 배포로 장애에도 안정적</li><li><strong>최적화된 성능</strong>: 특수 CPU&#x2F;GPU 사용으로 비용 절감</li><li><strong>토큰 기반 과금</strong>: 사용한 만큼만 지불 (Pay-as-you-go)</li><li><strong>Provisioned Throughput</strong>: 예측 가능한 워크로드에 대해 안정적 성능 제공</li></ul><p>👉 <strong>시험 포인트</strong>: AWS AI 서비스는 <strong>Fully Managed, Serverless, Pay-per-use</strong> 구조임</p><p align="center">  <img src="/images/aws_basic_144.png" width="80%"></p> <hr><h1 id="Amazon-Comprehend-자연어-처리-NLP"><a href="#Amazon-Comprehend-자연어-처리-NLP" class="headerlink" title="Amazon Comprehend (자연어 처리, NLP)"></a>Amazon Comprehend (자연어 처리, NLP)</h1><ul><li><strong>완전 관리형(Serverless) NLP 서비스</strong></li><li><strong>주요 기능</strong>:<ul><li>언어 식별(Language Detection)</li><li>키 구문, 인물, 장소, 조직, 브랜드, 이벤트 추출</li><li>감정 분석(Sentiment Analysis)</li><li>품사 태깅(Part-of-Speech)</li><li>토픽 모델링(Topic Modeling)</li></ul></li></ul><h3 id="활용-사례"><a href="#활용-사례" class="headerlink" title="활용 사례"></a>활용 사례</h3><ul><li>고객 이메일 분석 → 긍정&#x2F;부정 경험 요인 파악</li><li>기사&#x2F;문서 자동 분류</li></ul><hr><h2 id="1-Custom-Classification"><a href="#1-Custom-Classification" class="headerlink" title="1. Custom Classification"></a>1. Custom Classification</h2><ul><li>사용자가 정의한 카테고리로 문서 자동 분류</li><li>예: 고객 이메일을 “결제&#x2F;기술 지원&#x2F;불만”으로 분류</li><li>지원 포맷: Text, PDF, Word, 이미지 등</li><li>분석 모드: <strong>실시간(Sync)</strong>, <strong>비동기(Async)</strong></li></ul><p align="center">  <img src="/images/aws_basic_145.png" width="80%"></p> <hr><h2 id="2-Named-Entity-Recognition-NER"><a href="#2-Named-Entity-Recognition-NER" class="headerlink" title="2. Named Entity Recognition (NER)"></a>2. Named Entity Recognition (NER)</h2><ul><li>텍스트에서 <strong>사람, 조직, 장소, 날짜</strong> 등 추출</li></ul><p align="center">  <img src="/images/aws_basic_146.png" width="80%"></p> ------------------------------------------------------------------------<h2 id="3-Custom-Entity-Recognition"><a href="#3-Custom-Entity-Recognition" class="headerlink" title="3. Custom Entity Recognition"></a>3. Custom Entity Recognition</h2><ul><li>비즈니스 맞춤 엔터티 추출 (예: 보험번호, 특정 제품 코드)</li><li>사용자 데이터로 훈련 → 실시간&#x2F;비동기 분석 가능</li></ul><p>👉 <strong>시험 포인트</strong>:</p><ul><li>Comprehend &#x3D; <strong>NLP 서비스</strong></li><li>핵심 기능: 언어 식별, 감정 분석, NER</li><li>고급 기능: <strong>Custom Classification, Custom Entity Recognition</strong></li></ul><p align="center">  <img src="/images/aws_basic_147.png" width="80%"></p> <hr><h1 id="Amazon-Translate-자동-번역"><a href="#Amazon-Translate-자동-번역" class="headerlink" title="Amazon Translate (자동 번역)"></a>Amazon Translate (자동 번역)</h1><ul><li><strong>신경망 기반(NMT)</strong> 번역 서비스</li><li>웹&#x2F;앱 현지화(Localization), 대규모 문서 번역 지원</li><li><strong>Custom Terminology</strong>: 브랜드명, 도메인 용어 번역 일관성 유지</li><li><strong>Parallel Data</strong>: 번역 스타일 지정 (격식체 vs 비격식체)</li></ul><p>👉 <strong>시험 포인트</strong>: Translate는 <strong>Custom Terminology &amp; Parallel Data</strong> 기능으로 차별화됨</p><p align="center">  <img src="/images/aws_basic_148.png" width="80%"></p> ------------------------------------------------------------------------<h1 id="Amazon-Transcribe-음성-→-텍스트"><a href="#Amazon-Transcribe-음성-→-텍스트" class="headerlink" title="Amazon Transcribe (음성 → 텍스트)"></a>Amazon Transcribe (음성 → 텍스트)</h1><ul><li><strong>자동 음성 인식(ASR)</strong> 기반</li><li>음성을 빠르고 정확하게 텍스트로 변환</li><li><strong>PII Redaction</strong>: 개인정보 자동 제거</li><li><strong>자동 언어 감지</strong>: 다국어 오디오 지원</li></ul><h3 id="활용-사례-1"><a href="#활용-사례-1" class="headerlink" title="활용 사례"></a>활용 사례</h3><ul><li>고객센터 통화 기록 자동 변환</li><li>자막&#x2F;캡션 자동 생성</li><li>미디어 검색용 메타데이터 생성</li></ul><p align="center">  <img src="/images/aws_basic_149.png" width="80%"></p> ------------------------------------------------------------------------<h2 id="1-Accuracy-향상-기능"><a href="#1-Accuracy-향상-기능" class="headerlink" title="1. Accuracy 향상 기능"></a>1. Accuracy 향상 기능</h2><ul><li><strong>Custom Vocabularies (단어 단위)</strong><ul><li>브랜드명, 전문 용어, 약어 인식률 향상</li></ul></li><li><strong>Custom Language Models (문맥 단위)</strong><ul><li>도메인 텍스트 학습 → 정확도 향상</li></ul></li><li>두 기능을 함께 사용 → 최고 정확도 제공</li></ul><p align="center">  <img src="/images/aws_basic_151.png" width="80%"></p> <hr><h2 id="2-Toxicity-Detection"><a href="#2-Toxicity-Detection" class="headerlink" title="2. Toxicity Detection"></a>2. Toxicity Detection</h2><ul><li>음성과 텍스트 분석 → <strong>혐오 발언, 욕설, 성희롱, 협박 등 탐지</strong></li><li>카테고리: 성적 괴롭힘, 증오 발언, 위협, 욕설, 모욕 등</li></ul><p>👉 <strong>시험 포인트</strong>:</p><ul><li>Transcribe &#x3D; <strong>Speech-to-Text 서비스</strong></li><li>자주 나오는 기능: <strong>PII Redaction, Custom Vocabulary, Toxicity Detection</strong></li></ul><p align="center">  <img src="/images/aws_basic_150.png" width="80%"></p> ------------------------------------------------------------------------<h1 id="시험-대비-핵심-정리"><a href="#시험-대비-핵심-정리" class="headerlink" title="시험 대비 핵심 정리"></a>시험 대비 핵심 정리</h1><ol><li><strong>Comprehend</strong> → NLP (언어 식별, 감정 분석, NER, Custom 기능)</li><li><strong>Translate</strong> → 번역 서비스 (Custom Terminology, Parallel Data)</li><li><strong>Transcribe</strong> → 음성 인식 (PII Redaction, Custom Vocabulary,<br>Toxicity Detection)</li><li>공통 특징: <strong>Fully Managed, Serverless, Pay-as-you-go</strong></li><li><strong>시험에서 강조되는 포인트</strong>:<ul><li>Comprehend: NLP 서비스, Custom 기능</li><li>Translate: Terminology &amp; Parallel Data</li><li>Transcribe: PII Redaction, Custom Language Model, Toxicity<br>Detection</li></ul></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;AWS-AI-관리형-서비스-AWS-AI-Managed-Services&quot;&gt;&lt;a href=&quot;#AWS-AI-관리형-서비스-AWS-AI-Managed-Services&quot; class=&quot;headerlink&quot; title=&quot;AWS AI 관리형 서비스 (</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(31) - AWS AI Managed Services</title>
    <link href="https://kish191919.github.io/2025/08/26/AWS-Certified-AI-Practitioner-31/"/>
    <id>https://kish191919.github.io/2025/08/26/AWS-Certified-AI-Practitioner-31/</id>
    <published>2025-08-26T19:37:08.000Z</published>
    <updated>2025-08-26T19:47:39.483Z</updated>
    
    <content type="html"><![CDATA[<h1 id="AWS-AI-Managed-Services"><a href="#AWS-AI-Managed-Services" class="headerlink" title="AWS AI Managed Services"></a>AWS AI Managed Services</h1><h2 id="Why-AWS-AI-Managed-Services"><a href="#Why-AWS-AI-Managed-Services" class="headerlink" title="Why AWS AI Managed Services?"></a>Why AWS AI Managed Services?</h2><p>AWS AI Managed Services provide <strong>pre-trained ML models</strong> designed for specific use cases, without requiring you to build or train models from scratch.</p><h3 id="Key-Benefits"><a href="#Key-Benefits" class="headerlink" title="Key Benefits:"></a>Key Benefits:</h3><ul><li><strong>Responsiveness and Availability</strong>: Always accessible, deployed across multiple Availability Zones and AWS Regions.</li><li><strong>Redundancy and Reliability</strong>: Services remain available even if one AZ experiences downtime.</li><li><strong>Performance</strong>: Use of specialized CPUs and GPUs optimized for ML workloads → cost efficiency.</li><li><strong>Token-based Pricing</strong>: Pay only for what you use (no need to over-provision).</li><li><strong>Provisioned Throughput</strong>: Option for predictable workloads to guarantee performance and optimize costs.</li></ul><p>👉 <strong>Exam Tip</strong>: AWS will test your understanding that these services are <strong>Fully Managed, Serverless, Pay-as-you-go, and globally scalable</strong>.</p><p align="center">  <img src="/images/aws_basic_144.png" width="80%"></p> <hr><h1 id="Amazon-Comprehend-Natural-Language-Processing-–-NLP"><a href="#Amazon-Comprehend-Natural-Language-Processing-–-NLP" class="headerlink" title="Amazon Comprehend (Natural Language Processing – NLP)"></a>Amazon Comprehend (Natural Language Processing – NLP)</h1><p>Amazon Comprehend is a <strong>fully managed, serverless NLP service</strong>. It uses ML to extract insights and relationships from text.</p><h3 id="Core-Capabilities"><a href="#Core-Capabilities" class="headerlink" title="Core Capabilities:"></a>Core Capabilities:</h3><ul><li>Detects text language</li><li>Extracts key phrases, people, places, brands, and events</li><li>Sentiment analysis → positive, negative, neutral, or mixed</li><li>Tokenization and Part-of-Speech tagging</li><li>Automatically organizes text files by topic</li></ul><h3 id="Common-Use-Cases"><a href="#Common-Use-Cases" class="headerlink" title="Common Use Cases:"></a>Common Use Cases:</h3><ul><li>Analyze customer support emails to identify what leads to positive&#x2F;negative experiences</li><li>Group large document collections (e.g., news articles) by topic</li></ul><hr><h2 id="Custom-Classification"><a href="#Custom-Classification" class="headerlink" title="Custom Classification"></a>Custom Classification</h2><ul><li>Organize documents into <strong>categories you define</strong>.</li><li>Example: Categorize emails into <em>billing, technical support, complaints</em>.</li><li>Supports formats: text, PDF, Word, images.</li><li><strong>Real-time (synchronous)</strong> for single documents, or <strong>batch&#x2F;asynchronous</strong> for larger workloads.</li></ul><p align="center">  <img src="/images/aws_basic_145.png" width="80%"></p> <hr><h2 id="Named-Entity-Recognition-NER"><a href="#Named-Entity-Recognition-NER" class="headerlink" title="Named Entity Recognition (NER)"></a>Named Entity Recognition (NER)</h2><ul><li>Extracts <strong>predefined general entities</strong>: people, organizations, places, dates, etc.</li><li>Example: From “John works at AnyCompany on July 31st,” Comprehend identifies John (Person), AnyCompany (Organization), and July 31st (Date).</li></ul><p align="center">  <img src="/images/aws_basic_146.png" width="80%"></p> ------------------------------------------------------------------------<h2 id="Custom-Entity-Recognition"><a href="#Custom-Entity-Recognition" class="headerlink" title="Custom Entity Recognition"></a>Custom Entity Recognition</h2><ul><li>Allows detection of <strong>business-specific terms</strong>.</li><li>Example: Policy numbers, escalation phrases, custom product codes.</li><li>Requires <strong>training data</strong> (entity list + documents) stored in S3 → Comprehend builds a custom recognizer.</li><li>Works in <strong>real-time</strong> or <strong>batch</strong>.</li></ul><p>👉 <strong>Exam Tip</strong>:</p><ul><li><strong>NER &#x3D; predefined entities</strong>.</li><li><strong>Custom Entity Recognition &#x3D; business-specific entities trained with your data</strong>.</li></ul><p align="center">  <img src="/images/aws_basic_147.png" width="80%"></p> <hr><h1 id="Amazon-Translate"><a href="#Amazon-Translate" class="headerlink" title="Amazon Translate"></a>Amazon Translate</h1><p>A <strong>neural machine translation (NMT) service</strong> that provides natural and<br>accurate translations.</p><h3 id="Features"><a href="#Features" class="headerlink" title="Features:"></a>Features:</h3><ul><li>Translate text and entire documents (txt, HTML, docx).</li><li><strong>Batch Translation</strong>: Translate large volumes via S3 jobs.</li><li><strong>Custom Terminology</strong>: Maintain brand names or domain-specific terms across translations.</li><li><strong>Parallel Data</strong>: Control translation style (formal vs informal).</li></ul><p>👉 <strong>Exam Tip</strong>: Custom Terminology and Parallel Data are key differentiators.</p><p align="center">  <img src="/images/aws_basic_148.png" width="80%"></p> <hr><h1 id="Amazon-Transcribe-Speech-to-Text"><a href="#Amazon-Transcribe-Speech-to-Text" class="headerlink" title="Amazon Transcribe (Speech-to-Text)"></a>Amazon Transcribe (Speech-to-Text)</h1><p>A fully managed <strong>Automatic Speech Recognition (ASR)</strong> service that converts speech to text.</p><h3 id="Features-1"><a href="#Features-1" class="headerlink" title="Features:"></a>Features:</h3><ul><li>Converts audio to text quickly and accurately</li><li><strong>PII Redaction</strong>: Removes personally identifiable information (name, SSN, phone number, etc.)</li><li><strong>Automatic Language Identification</strong>: Handles multilingual audio streams</li></ul><h3 id="Use-Cases"><a href="#Use-Cases" class="headerlink" title="Use Cases:"></a>Use Cases:</h3><ul><li>Transcribe customer service calls</li><li>Generate subtitles and closed captions</li><li>Create searchable metadata for media archives</li></ul><p align="center">  <img src="/images/aws_basic_149.png" width="80%"></p> <hr><h2 id="Improving-Accuracy"><a href="#Improving-Accuracy" class="headerlink" title="Improving Accuracy"></a>Improving Accuracy</h2><ul><li><strong>Custom Vocabularies</strong>: Add words, acronyms, brand names → improve recognition.</li><li><strong>Custom Language Models</strong>: Train on domain-specific text to provide context (e.g., distinguishing <em>“microservice”</em> vs <em>“my crow service”</em>).</li><li>Best accuracy is achieved when <strong>both are used together</strong>.</li></ul><p align="center">  <img src="/images/aws_basic_151.png" width="80%"></p> <hr><h2 id="Toxicity-Detection"><a href="#Toxicity-Detection" class="headerlink" title="Toxicity Detection"></a>Toxicity Detection</h2><ul><li>Detects <strong>toxic speech content</strong> using both voice cues (tone, pitch) and text cues.</li><li>Categories: sexual harassment, hate speech, threats, abuse, profanity, insults, graphic content.</li></ul><p>👉 <strong>Exam Tip</strong>:</p><ul><li>Know that Transcribe supports <strong>PII Redaction, Custom Vocabulary, Custom Language Models, and Toxicity Detection</strong>.</li><li>Expect scenario-based exam questions about improving transcription accuracy.</li></ul><p align="center">  <img src="/images/aws_basic_150.png" width="80%"></p> <hr><h1 id="Exam-Focused-Summary"><a href="#Exam-Focused-Summary" class="headerlink" title="Exam-Focused Summary"></a>Exam-Focused Summary</h1><ol><li><strong>Comprehend</strong> → NLP (Sentiment, NER, Custom Classification, Custom Entities).</li><li><strong>Translate</strong> → Language translation (Custom Terminology, Parallel Data).</li><li><strong>Transcribe</strong> → Speech-to-Text (PII Redaction, Custom Vocabulary, Toxicity Detection).</li><li><strong>Shared Traits</strong>: Fully Managed, Serverless, Pay-as-you-go, scalable across regions.</li><li><strong>AWS Exam Hotspots</strong>:<ul><li>When to use Custom Terminology vs Parallel Data in Translate.</li><li>How Comprehend Custom Classification differs from Custom Entity Recognition.</li><li>Improving Transcribe accuracy (Custom Vocabulary + Custom Language Models).</li><li>Toxicity Detection categories in Transcribe.</li></ul></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;AWS-AI-Managed-Services&quot;&gt;&lt;a href=&quot;#AWS-AI-Managed-Services&quot; class=&quot;headerlink&quot; title=&quot;AWS AI Managed Services&quot;&gt;&lt;/a&gt;AWS AI Managed Se</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(30) - Hyperparameter Tuning</title>
    <link href="https://kish191919.github.io/2025/08/26/AWS-Certified-AI-Practitioner-30/"/>
    <id>https://kish191919.github.io/2025/08/26/AWS-Certified-AI-Practitioner-30/</id>
    <published>2025-08-26T19:20:21.000Z</published>
    <updated>2025-08-26T19:27:31.165Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Hyperparameter-Tuning"><a href="#Hyperparameter-Tuning" class="headerlink" title="Hyperparameter Tuning"></a>Hyperparameter Tuning</h1><h2 id="1-What-is-a-Hyperparameter"><a href="#1-What-is-a-Hyperparameter" class="headerlink" title="1. What is a Hyperparameter?"></a>1. What is a Hyperparameter?</h2><ul><li><strong>Definition</strong>: Settings that define how the model is structured and how the learning algorithm works.</li><li><strong>Set before training begins</strong> (they are not learned from the data).</li><li><strong>Examples</strong>:<ul><li><strong>Learning rate</strong></li><li><strong>Batch size</strong></li><li><strong>Number of epochs</strong></li><li><strong>Regularization</strong></li></ul></li></ul><p>👉 <strong>Exam Tip</strong>: Hyperparameters are <strong>not learned</strong> during training. They are chosen before training and tuned for best performance.</p><hr><h2 id="2-Why-Hyperparameter-Tuning-Matters"><a href="#2-Why-Hyperparameter-Tuning-Matters" class="headerlink" title="2. Why Hyperparameter Tuning Matters"></a>2. Why Hyperparameter Tuning Matters</h2><ul><li><strong>Goal</strong>: Find the best combination of hyperparameters to optimize model performance.</li><li><strong>Benefits</strong>:<ul><li>Improves accuracy</li><li>Reduces overfitting</li><li>Enhances generalization to new data</li></ul></li><li><strong>Methods</strong>:<ul><li><strong>Grid Search</strong>: Tries all possible parameter combinations.</li><li><strong>Random Search</strong>: Tests random parameter values.</li><li><strong>Automated Services</strong>:<ul><li><strong>Amazon SageMaker Automatic Model Tuning (AMT)</strong> runs multiple training jobs and finds the best settings.</li></ul></li></ul></li></ul><hr><h2 id="3-Key-Hyperparameters"><a href="#3-Key-Hyperparameters" class="headerlink" title="3. Key Hyperparameters"></a>3. Key Hyperparameters</h2><h3 id="1-Learning-Rate"><a href="#1-Learning-Rate" class="headerlink" title="(1) Learning Rate"></a>(1) Learning Rate</h3><ul><li>Controls <strong>how big the steps are</strong> when updating model weights.</li><li><strong>High learning rate</strong>: Faster training, but may overshoot the optimal solution.</li><li><strong>Low learning rate</strong>: More stable and precise, but much slower.</li></ul><hr><h3 id="2-Batch-Size"><a href="#2-Batch-Size" class="headerlink" title="(2) Batch Size"></a>(2) Batch Size</h3><ul><li>Number of training examples processed in one iteration.</li><li><strong>Small batches</strong>: More stable, but slower.</li><li><strong>Large batches</strong>: Faster, but may cause less stable updates.</li></ul><hr><h3 id="3-Number-of-Epochs"><a href="#3-Number-of-Epochs" class="headerlink" title="(3) Number of Epochs"></a>(3) Number of Epochs</h3><ul><li>How many times the model goes through the <strong>entire training dataset</strong>.</li><li><strong>Too few</strong>: Underfitting (model doesn’t learn enough).</li><li><strong>Too many</strong>: Overfitting (model memorizes the data, performs poorly on new data).</li></ul><hr><h3 id="4-Regularization"><a href="#4-Regularization" class="headerlink" title="(4) Regularization"></a>(4) Regularization</h3><ul><li>Controls the <strong>balance between a simple and complex model</strong>.</li><li>More regularization → less overfitting.</li></ul><p>👉 <strong>Exam Tip</strong>: If asked how to reduce overfitting, <strong>increasing regularization</strong> is often the correct answer.</p><hr><h2 id="4-Overfitting"><a href="#4-Overfitting" class="headerlink" title="4. Overfitting"></a>4. Overfitting</h2><h3 id="What-is-it"><a href="#What-is-it" class="headerlink" title="What is it?"></a>What is it?</h3><ul><li>The model performs very well on training data but poorly on new, unseen data.</li></ul><h3 id="Causes"><a href="#Causes" class="headerlink" title="Causes"></a>Causes</h3><ul><li>Too little training data → not representative.</li><li>Training for too many epochs.</li><li>Model too complex → learns noise instead of patterns.</li></ul><h3 id="Solutions"><a href="#Solutions" class="headerlink" title="Solutions"></a>Solutions</h3><ul><li>Increase training data size (best option).</li><li>Use <strong>early stopping</strong> (stop training before overfitting).</li><li>Apply <strong>data augmentation</strong> (add diversity to training data).</li><li>Adjust hyperparameters (e.g., increase regularization, change batch size).</li></ul><p>👉 <strong>Exam Tip</strong>: If the question is <strong>“best way to prevent overfitting”</strong>, the answer is usually <strong>increase training data</strong>.</p><hr><h2 id="5-When-NOT-to-Use-Machine-Learning"><a href="#5-When-NOT-to-Use-Machine-Learning" class="headerlink" title="5. When NOT to Use Machine Learning"></a>5. When NOT to Use Machine Learning</h2><ul><li><strong>Example</strong>:<br>You have a deck of 10 cards (5 red, 3 blue, 2 yellow).<br>Q: What is the probability of drawing a blue card?<br>A: 3&#x2F;10 &#x3D; 0.3</li></ul>   <p align="center">  <img src="/images/aws_basic_143.png" width="80%"></p> <ul><li><p>This is a <strong>deterministic problem</strong>:</p><ul><li>The exact answer can be computed mathematically.</li><li>Writing simple code is the best solution.</li></ul></li><li><p>If we used ML (supervised, unsupervised, or reinforcement learning), we’d only get an <strong>approximation</strong>, not an exact result.</p></li></ul><p>👉 <strong>Exam Tip</strong>:<br>Machine Learning is <strong>not appropriate</strong> for problems that have a <strong>clear, deterministic answer</strong>. It is designed for problems where patterns must be learned from data.</p><hr><h2 id="6-AWS-Specific-Notes-for-Exams"><a href="#6-AWS-Specific-Notes-for-Exams" class="headerlink" title="6. AWS-Specific Notes for Exams"></a>6. AWS-Specific Notes for Exams</h2><ul><li><strong>Amazon SageMaker Automatic Model Tuning (AMT)</strong>: Automates hyperparameter tuning by running multiple jobs in parallel.</li><li><strong>Common Exam Questions</strong>:<ul><li>How to fix overfitting → Increase data &#x2F; regularization.</li><li>What hyperparameter affects convergence speed → Learning rate.</li><li>Which AWS service automates tuning → SageMaker AMT.</li><li>When NOT to use ML → Deterministic problem with exact answers.</li></ul></li></ul><hr><p>✅ <strong>Summary</strong> - <strong>Hyperparameters</strong> (learning rate, batch size, epochs regularization) must be tuned for best performance.</p><ul><li><strong>Tuning</strong> improves accuracy, reduces overfitting, and enhances generalization.</li><li><strong>Overfitting</strong> occurs when the model memorizes training data → fix by more data, regularization, early stopping.</li><li><strong>ML is not appropriate</strong> for deterministic problems.</li><li>On AWS, <strong>SageMaker AMT</strong> is the go-to tool for automated hyperparameter tuning.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Hyperparameter-Tuning&quot;&gt;&lt;a href=&quot;#Hyperparameter-Tuning&quot; class=&quot;headerlink&quot; title=&quot;Hyperparameter Tuning&quot;&gt;&lt;/a&gt;Hyperparameter Tuning&lt;/</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (30) - 하이퍼파라미터 튜닝</title>
    <link href="https://kish191919.github.io/2025/08/26/KO-AWS-Certified-AI-Practitioner-30/"/>
    <id>https://kish191919.github.io/2025/08/26/KO-AWS-Certified-AI-Practitioner-30/</id>
    <published>2025-08-26T19:20:12.000Z</published>
    <updated>2025-08-27T02:57:51.733Z</updated>
    
    <content type="html"><![CDATA[<h1 id="하이퍼파라미터-튜닝-Hyperparameter-Tuning"><a href="#하이퍼파라미터-튜닝-Hyperparameter-Tuning" class="headerlink" title="하이퍼파라미터 튜닝 (Hyperparameter Tuning)"></a>하이퍼파라미터 튜닝 (Hyperparameter Tuning)</h1><h2 id="1-하이퍼파라미터란"><a href="#1-하이퍼파라미터란" class="headerlink" title="1. 하이퍼파라미터란?"></a>1. 하이퍼파라미터란?</h2><ul><li><strong>정의</strong>: 모델 구조와 학습 방식을 결정하는 설정값</li><li><strong>특징</strong>:<ul><li>학습이 시작되기 전에 정해짐</li><li>데이터 자체가 아니라, <strong>학습 알고리즘의 동작 방식</strong>에 영향을 줌</li></ul></li><li><strong>대표 예시</strong>:<ul><li>학습률(Learning rate)</li><li>배치 크기(Batch size)</li><li>에포크 수(Number of epochs)</li><li>정규화(Regularization)</li></ul></li></ul><p>👉 <strong>시험 포인트</strong>:<br>하이퍼파라미터는 모델 학습 과정에서 자동으로 학습되는 값이 아니라, <strong>사전에 설정하는 값</strong>이다.</p><hr><h2 id="2-하이퍼파라미터-튜닝-Hyperparameter-Tuning"><a href="#2-하이퍼파라미터-튜닝-Hyperparameter-Tuning" class="headerlink" title="2. 하이퍼파라미터 튜닝(Hyperparameter Tuning)"></a>2. 하이퍼파라미터 튜닝(Hyperparameter Tuning)</h2><ul><li><strong>목적</strong>: 최적의 하이퍼파라미터 값을 찾아 모델 성능을 극대화\</li><li><strong>효과</strong>:<ul><li>정확도 향상</li><li>과적합(Overfitting) 감소</li><li>일반화 성능 강화</li></ul></li><li><strong>방법</strong>:<ul><li><strong>Grid Search</strong>: 가능한 모든 조합 탐색</li><li><strong>Random Search</strong>: 임의의 조합을 탐색</li><li><strong>자동화 서비스</strong>:<ul><li><strong>Amazon SageMaker Automatic Model Tuning (AMT)</strong> 활용</li></ul></li></ul></li></ul><hr><h2 id="3-주요-하이퍼파라미터"><a href="#3-주요-하이퍼파라미터" class="headerlink" title="3. 주요 하이퍼파라미터"></a>3. 주요 하이퍼파라미터</h2><h3 id="1-학습률-Learning-Rate"><a href="#1-학습률-Learning-Rate" class="headerlink" title="(1) 학습률 (Learning Rate)"></a>(1) 학습률 (Learning Rate)</h3><ul><li>모델 가중치를 얼마나 크게&#x2F;작게 업데이트할지 결정</li><li><strong>높은 학습률</strong>: 빠른 수렴 가능, 하지만 최적값을 지나칠 위험</li><li><strong>낮은 학습률</strong>: 더 정밀한 수렴 가능, 하지만 속도가 느림</li></ul><hr><h3 id="2-배치-크기-Batch-Size"><a href="#2-배치-크기-Batch-Size" class="headerlink" title="(2) 배치 크기 (Batch Size)"></a>(2) 배치 크기 (Batch Size)</h3><ul><li>한 번의 가중치 업데이트에 사용되는 데이터 샘플 개수</li><li><strong>작은 배치</strong>: 안정적인 학습, 하지만 연산 시간이 오래 걸림</li><li><strong>큰 배치</strong>: 빠른 학습, 하지만 불안정한 업데이트 가능</li></ul><hr><h3 id="3-에포크-수-Number-of-Epochs"><a href="#3-에포크-수-Number-of-Epochs" class="headerlink" title="(3) 에포크 수 (Number of Epochs)"></a>(3) 에포크 수 (Number of Epochs)</h3><ul><li>전체 학습 데이터를 몇 번 반복해서 학습할지 결정</li><li><strong>너무 적으면</strong>: 학습 부족(Underfitting)</li><li><strong>너무 많으면</strong>: 과적합(Overfitting)</li></ul><hr><h3 id="4-정규화-Regularization"><a href="#4-정규화-Regularization" class="headerlink" title="(4) 정규화 (Regularization)"></a>(4) 정규화 (Regularization)</h3><ul><li>모델이 너무 복잡해져 과적합되지 않도록 제어</li><li>정규화를 높이면 단순해지고, 과적합 방지 효과</li></ul><p>👉 <strong>시험 포인트</strong>:<br>“과적합을 줄이고 싶다”라는 질문 → <strong>정규화 강화를 정답으로 선택</strong>하는 경우가 많음.</p><hr><h2 id="4-과적합-Overfitting-과-해결-방법"><a href="#4-과적합-Overfitting-과-해결-방법" class="headerlink" title="4. 과적합(Overfitting)과 해결 방법"></a>4. 과적합(Overfitting)과 해결 방법</h2><ul><li><strong>정의</strong>: 학습 데이터에서는 높은 정확도를 보이지만, 새로운 데이터에서는 성능이 급격히 떨어지는 현상</li></ul><h3 id="원인"><a href="#원인" class="headerlink" title="원인"></a>원인</h3><ul><li>학습 데이터가 너무 적음 → 대표성이 부족</li><li>너무 많은 에포크 학습 → 특정 데이터에만 맞춰짐</li><li>모델이 지나치게 복잡 → 데이터의 <strong>노이즈까지 학습</strong></li></ul><h3 id="방지-방법"><a href="#방지-방법" class="headerlink" title="방지 방법"></a>방지 방법</h3><ul><li><strong>데이터 양 늘리기</strong> (가장 효과적)</li><li><strong>Early Stopping</strong> (학습 조기 종료)</li><li><strong>데이터 증강(Data Augmentation)</strong> (다양성 확보)</li><li><strong>하이퍼파라미터 조정</strong> (학습률, 배치 크기, 정규화 등)</li></ul><p>👉 <strong>시험 포인트</strong>:<br>과적합 방지의 <strong>가장 좋은 답</strong>은 보통 <strong>데이터 양 늘리기</strong></p><hr><h2 id="5-머신러닝이-적합하지-않은-경우"><a href="#5-머신러닝이-적합하지-않은-경우" class="headerlink" title="5. 머신러닝이 적합하지 않은 경우"></a>5. 머신러닝이 적합하지 않은 경우</h2><ul><li><strong>예시 문제</strong>:<br>“카드 10장 중 빨강 5장, 파랑 3장, 노랑 2장 → 파랑 카드를 뽑을 확률은?”<ul><li>답: <strong>3&#x2F;10 &#x3D; 0.3</strong></li><li>단순 수학적 계산으로 정확히 해결 가능</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_143.png" width="80%"></p> <p>👉 <strong>결론</strong>:</p><ul><li><strong>결정론적(Deterministic) 문제</strong>: 코드로 수학적으로 풀 수 있음 → 머신러닝 불필요</li><li>머신러닝은 항상 **근사값(Approximation)**을 내므로, 이런 문제에서는 <strong>적절하지 않음</strong></li></ul><hr><h2 id="6-시험-대비-핵심-요약"><a href="#6-시험-대비-핵심-요약" class="headerlink" title="6. 시험 대비 핵심 요약"></a>6. 시험 대비 핵심 요약</h2><ol><li><strong>하이퍼파라미터</strong> &#x3D; 학습 전 설정 (학습률, 배치 크기, 에포크 수, 정규화)</li><li><strong>튜닝 목적</strong> &#x3D; 성능 향상, 과적합 방지</li><li><strong>과적합 방지 방법</strong> &#x3D; 데이터 늘리기, Early Stopping, 데이터 증강, 정규화</li><li><strong>AWS 서비스</strong> &#x3D; <strong>SageMaker Automatic Model Tuning</strong></li><li><strong>머신러닝이 필요 없는 경우</strong> &#x3D; 답을 명확히 계산할 수 있는 결정론적 문제</li></ol><hr><p>👉 요약하면, <strong>시험에서 하이퍼파라미터와 과적합 방지 방법은 반드시 나오는 단골 주제</strong>입니다.<br>특히 <strong>SageMaker AMT</strong>와 <strong>정규화&#x2F;데이터 증강</strong> 관련 문항이 자주 출제됩니다.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;하이퍼파라미터-튜닝-Hyperparameter-Tuning&quot;&gt;&lt;a href=&quot;#하이퍼파라미터-튜닝-Hyperparameter-Tuning&quot; class=&quot;headerlink&quot; title=&quot;하이퍼파라미터 튜닝 (Hyperparameter T</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (29) - 머신러닝 프로젝트 단계</title>
    <link href="https://kish191919.github.io/2025/08/25/KO-AWS-Certified-AI-Practitioner-29/"/>
    <id>https://kish191919.github.io/2025/08/25/KO-AWS-Certified-AI-Practitioner-29/</id>
    <published>2025-08-25T17:33:46.000Z</published>
    <updated>2025-08-25T17:44:54.806Z</updated>
    
    <content type="html"><![CDATA[<h1 id="머신러닝-프로젝트-단계-Phases-of-Machine-Learning-Project"><a href="#머신러닝-프로젝트-단계-Phases-of-Machine-Learning-Project" class="headerlink" title="머신러닝 프로젝트 단계 (Phases of Machine Learning Project)"></a>머신러닝 프로젝트 단계 (Phases of Machine Learning Project)</h1><h2 id="1-비즈니스-목표-정의"><a href="#1-비즈니스-목표-정의" class="headerlink" title="1. 비즈니스 목표 정의"></a>1. 비즈니스 목표 정의</h2><ul><li><strong>목표</strong>: 어떤 문제를 해결할지 명확히 정의</li><li><strong>이해관계자(Stakeholders)</strong>: 프로젝트의 <strong>가치, 예산, 성공 기준</strong>을 설정</li><li><strong>KPI(핵심 성과 지표)</strong>: 반드시 정의해야 함 → 모델이 실제로 비즈니스 목표에 기여하는지 판단하는 기준</li></ul><p>👉 시험 포인트:<br>머신러닝 프로젝트의 첫 단계는 항상 <strong>비즈니스 문제를 정의</strong>하는 것. <strong>KPI 설정</strong>은 AWS 시험에서 자주 강조됨.</p><hr><h2 id="2-문제-정의와-ML-문제로-전환-ML-Problem-Framing"><a href="#2-문제-정의와-ML-문제로-전환-ML-Problem-Framing" class="headerlink" title="2. 문제 정의와 ML 문제로 전환 (ML Problem Framing)"></a>2. 문제 정의와 ML 문제로 전환 (ML Problem Framing)</h2><ul><li><strong>비즈니스 문제 → ML 문제로 변환</strong></li><li>머신러닝이 정말 필요한지, 다른 해결책(예: 단순 규칙 기반)이 더 나은지 판단</li><li>데이터 과학자, 데이터 엔지니어, ML 아키텍트, 도메인 전문가가 함께 협업</li></ul><hr><h2 id="3-데이터-처리-Data-Processing"><a href="#3-데이터-처리-Data-Processing" class="headerlink" title="3. 데이터 처리 (Data Processing)"></a>3. 데이터 처리 (Data Processing)</h2><ul><li><strong>데이터 수집 및 통합</strong>: 중앙에서 접근 가능하도록 정리</li><li><strong>전처리 및 시각화</strong>: 데이터 품질 확인, 이상치 제거, 결측값 처리</li><li><strong>피처 엔지니어링</strong>: 새로운 변수를 생성, 변환, 추출하여 모델이 학습할 수 있도록 가공</li></ul><p>👉 시험 포인트:<br>AWS 서비스 연결</p><ul><li><strong>AWS Glue</strong>: 데이터 수집&#x2F;정리</li><li><strong>Amazon S3</strong>: 중앙 저장소</li><li><strong>Amazon QuickSight</strong>: 데이터 시각화</li></ul><hr><h2 id="4-탐색적-데이터-분석-EDA-Exploratory-Data-Analysis"><a href="#4-탐색적-데이터-분석-EDA-Exploratory-Data-Analysis" class="headerlink" title="4. 탐색적 데이터 분석 (EDA, Exploratory Data Analysis)"></a>4. 탐색적 데이터 분석 (EDA, Exploratory Data Analysis)</h2><ul><li><strong>그래프 시각화</strong>로 데이터 분포와 특성 이해</li><li><strong>상관행렬(Correlation Matrix)</strong>: 피처들 간의 연관성 파악<ul><li>예: 공부 시간 ↔ 시험 점수 (0.85 상관관계 → 강한 양의 상관관계)</li></ul></li><li>어떤 피처가 모델에 중요한지 판단</li></ul><p align="center">  <img src="/images/aws_basic_142.png" width="80%"></p><hr><h2 id="5-모델-개발-Model-Development"><a href="#5-모델-개발-Model-Development" class="headerlink" title="5. 모델 개발 (Model Development)"></a>5. 모델 개발 (Model Development)</h2><ul><li><strong>모델 학습(Training), 튜닝(Tuning), 평가(Evaluation)</strong></li><li><strong>하이퍼파라미터(Hyperparameters)</strong>: 알고리즘 동작 방식을 조정하는 값 (예: 학습률, 트리 개수 등)</li><li>반복적인 과정 (Iterative Process)<ul><li>추가적인 피처 엔지니어링</li><li>하이퍼파라미터 튜닝</li></ul></li></ul><p>👉 시험 포인트:</p><ul><li><strong>Amazon SageMaker</strong>는 학습, 튜닝, 평가까지 전체 파이프라인을 지원하는 대표 서비스.</li><li>SageMaker <strong>Automatic Model Tuning</strong> 기능도 시험에 자주 나옴.</li></ul><hr><h2 id="6-재학습-Retraining"><a href="#6-재학습-Retraining" class="headerlink" title="6. 재학습 (Retraining)"></a>6. 재학습 (Retraining)</h2><ul><li>새로운 데이터가 들어올 때 모델을 재학습</li><li>피처와 하이퍼파라미터를 조정하여 성능 개선</li></ul><hr><h2 id="7-배포-Deployment"><a href="#7-배포-Deployment" class="headerlink" title="7. 배포 (Deployment)"></a>7. 배포 (Deployment)</h2><ul><li>모델을 실제 환경에 배포하여 <strong>추론(Inferencing)</strong> 시작</li><li><strong>배포 옵션</strong>:<ul><li><strong>실시간 추론 (Real-Time)</strong></li><li><strong>비동기 추론 (Asynchronous)</strong></li><li><strong>배치 추론 (Batch)</strong></li><li><strong>서버리스 (Serverless)</strong></li><li><strong>온프레미스(On-Premises)</strong></li></ul></li></ul><p>👉 시험 포인트:</p><ul><li>SageMaker는 <strong>실시간 엔드포인트</strong>, <strong>배치 변환(Batch Transform)</strong>, <strong>Serverless Inference</strong> 모두 지원</li></ul><hr><h2 id="8-모니터링-Monitoring"><a href="#8-모니터링-Monitoring" class="headerlink" title="8. 모니터링 (Monitoring)"></a>8. 모니터링 (Monitoring)</h2><ul><li>모델이 원하는 성능을 유지하는지 지속적으로 확인</li><li><strong>문제 조기 감지 및 대응(Early Detection &amp; Mitigation)</strong></li><li><strong>모델 드리프트(Model Drift)</strong>: 시간이 지남에 따라 데이터 패턴이 변하면서 모델 성능이 저하되는 현상</li></ul><p>👉 시험 포인트:</p><ul><li><strong>Amazon SageMaker Model Monitor</strong> → 모델 성능 모니터링 자동화</li></ul><hr><h2 id="9-반복-Iteration-과-유지보수"><a href="#9-반복-Iteration-과-유지보수" class="headerlink" title="9. 반복(Iteration)과 유지보수"></a>9. 반복(Iteration)과 유지보수</h2><ul><li><strong>모델 성능 개선 사이클</strong>:<ul><li>새로운 데이터 → 재학습 → 배포 → 모니터링</li></ul></li><li>요구사항과 환경은 시간이 지나면서 변함 → 지속적 개선 필요</li><li>예시: 의류 추천 모델은 <strong>10년 후 패션 트렌드 변화</strong>에 따라 새롭게 학습해야 함</li></ul><hr><h2 id="전체-워크플로우-요약"><a href="#전체-워크플로우-요약" class="headerlink" title="전체 워크플로우 요약"></a>전체 워크플로우 요약</h2><ol><li><strong>비즈니스 목표 정의 &amp; KPI 설정</strong></li><li><strong>ML 문제로 전환</strong></li><li><strong>데이터 수집, 전처리, 피처 엔지니어링</strong></li><li><strong>탐색적 데이터 분석(EDA)</strong></li><li><strong>모델 학습, 튜닝, 평가</strong></li><li><strong>재학습 및 반복 개선</strong></li><li><strong>배포(실시간, 배치, 서버리스 등)</strong></li><li><strong>모니터링 및 디버깅</strong></li><li><strong>지속적 개선 &amp; 요구사항 반영</strong></li></ol><p align="center">  <img src="/images/aws_basic_141.png" width="80%"></p><hr><p>✅ <strong>시험 대비 핵심 포인트</strong>: - KPI 정의가 가장 첫 단계</p><ul><li>EDA(탐색적 데이터 분석)과 상관행렬의 역할</li><li>SageMaker 주요 기능: Training, Tuning, Deployment, Monitoring</li><li>모델 배포 방식: Real-time, Batch, Serverless, On-premises</li><li><strong>모델 드리프트 감지 &amp; 재학습</strong> 중요성</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;머신러닝-프로젝트-단계-Phases-of-Machine-Learning-Project&quot;&gt;&lt;a href=&quot;#머신러닝-프로젝트-단계-Phases-of-Machine-Learning-Project&quot; class=&quot;headerlink&quot; title</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(29) - Phases of a Machine Learning Project</title>
    <link href="https://kish191919.github.io/2025/08/25/AWS-Certified-AI-Practitioner-29/"/>
    <id>https://kish191919.github.io/2025/08/25/AWS-Certified-AI-Practitioner-29/</id>
    <published>2025-08-25T17:33:41.000Z</published>
    <updated>2025-08-25T17:44:54.806Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Phases-of-a-Machine-Learning-Project"><a href="#Phases-of-a-Machine-Learning-Project" class="headerlink" title="Phases of a Machine Learning Project"></a>Phases of a Machine Learning Project</h1><h2 id="1-Define-Business-Goals"><a href="#1-Define-Business-Goals" class="headerlink" title="1. Define Business Goals"></a>1. Define Business Goals</h2><ul><li>Every ML project starts with defining the <strong>business objective</strong>.</li><li><strong>Stakeholders</strong> must agree on:<ul><li>The <strong>value</strong> the project will provide</li><li>The <strong>budget</strong></li><li>The <strong>success criteria</strong></li></ul></li><li><strong>KPI (Key Performance Indicators)</strong> are critical to measure whether<br>the ML model actually achieves business goals.</li></ul><p>👉 <strong>Exam Tip</strong>: AWS often asks about the importance of KPIs in framing an ML project. The first step is always <strong>business problem definition</strong>, not jumping into training a model.</p><hr><h2 id="2-Frame-the-Problem-as-an-ML-Problem"><a href="#2-Frame-the-Problem-as-an-ML-Problem" class="headerlink" title="2. Frame the Problem as an ML Problem"></a>2. Frame the Problem as an ML Problem</h2><ul><li>Convert the <strong>business problem</strong> into a <strong>machine learning problem</strong>.</li><li>Ask: Is machine learning the right tool? Sometimes rules-based systems are more appropriate.</li><li>Collaboration is key: <strong>data scientists, data engineers, ML architects, and subject matter experts (SMEs)</strong> must all contribute.</li></ul><p>👉 <strong>Example</strong>:</p><ul><li>Business problem: “How can we reduce customer churn?”</li><li>ML problem: “Predict whether a customer will leave in the next 30 days.”</li></ul><hr><h2 id="3-Data-Processing"><a href="#3-Data-Processing" class="headerlink" title="3. Data Processing"></a>3. Data Processing</h2><ul><li><strong>Data collection and integration</strong>: Centralize data into a usable location (e.g., Amazon S3).</li><li><strong>Data preprocessing</strong>: Clean, normalize, handle missing values.</li><li><strong>Data visualization</strong>: Understand data patterns and spot anomalies.</li><li><strong>Feature engineering</strong>: Create or transform variables that help the model learn.</li></ul><p>👉 <strong>AWS Services</strong>:</p><ul><li><strong>AWS Glue</strong> for ETL (extract, transform, load)</li><li><strong>Amazon QuickSight</strong> for visualization</li><li><strong>Amazon S3</strong> for data storage</li></ul><hr><h2 id="4-Exploratory-Data-Analysis-EDA"><a href="#4-Exploratory-Data-Analysis-EDA" class="headerlink" title="4. Exploratory Data Analysis (EDA)"></a>4. Exploratory Data Analysis (EDA)</h2><ul><li><strong>Visualize</strong> data distributions and trends using charts.</li><li><strong>Correlation Matrix</strong>: Measures how strongly variables are related.<ul><li>Example: Study hours ↔ Test score correlation of 0.85 shows a strong positive relationship.</li></ul></li><li>Helps you decide which features are most valuable for your model.</li></ul><p align="center">  <img src="/images/aws_basic_142.png" width="80%"></p><p>👉 <strong>Exam Tip</strong>: Feature selection and correlation analysis often appear in ML exam scenarios.</p><hr><h2 id="5-Model-Development"><a href="#5-Model-Development" class="headerlink" title="5. Model Development"></a>5. Model Development</h2><ul><li><strong>Model training</strong>: Fit the model with training data.</li><li><strong>Model tuning</strong>: Adjust <strong>hyperparameters</strong> (e.g., learning rate, number of trees).</li><li><strong>Model evaluation</strong>: Test against validation or test datasets.</li><li>This process is <strong>iterative</strong>:<ul><li>Go back and improve features.</li><li>Try different algorithms.</li><li>Tune hyperparameters repeatedly.</li></ul></li></ul><p>👉 <strong>AWS Services</strong>:</p><ul><li><strong>Amazon SageMaker</strong> provides: - Model training</li><li>Automatic hyperparameter tuning</li><li>Built-in evaluation metrics</li></ul><hr><h2 id="6-Retraining"><a href="#6-Retraining" class="headerlink" title="6. Retraining"></a>6. Retraining</h2><ul><li>As new data arrives, retrain the model to keep it relevant.</li><li>Adjust features and hyperparameters based on performance.</li></ul><hr><h2 id="7-Deployment"><a href="#7-Deployment" class="headerlink" title="7. Deployment"></a>7. Deployment</h2><ul><li>Once the model meets goals, it is deployed for predictions (inference).</li><li><strong>Deployment options</strong>:<ul><li><strong>Real-time</strong> (low-latency APIs)</li><li><strong>Batch</strong> (large-scale predictions at once)</li><li><strong>Serverless</strong> (cost-efficient, scalable)</li><li><strong>On-premises</strong> (for compliance or offline needs)</li></ul></li></ul><p>👉 <strong>AWS Services</strong>:</p><ul><li><strong>SageMaker Endpoints</strong>: real-time inference</li><li><strong>Batch Transform</strong>: batch inference</li><li><strong>Serverless Inference</strong>: scalable, cost-optimized</li></ul><hr><h2 id="8-Monitoring"><a href="#8-Monitoring" class="headerlink" title="8. Monitoring"></a>8. Monitoring</h2><ul><li>Ensure the model maintains expected performance.</li><li><strong>Early detection</strong> of problems such as <strong>model drift</strong> (when new data no longer matches training patterns).</li><li><strong>Debugging</strong> and understanding behavior in production.</li></ul><p>👉 <strong>AWS Service</strong>:</p><ul><li><strong>SageMaker Model Monitor</strong> automatically detects drift, anomalies, and performance degradation.</li></ul><hr><h2 id="9-Iterations-and-Continuous-Improvement"><a href="#9-Iterations-and-Continuous-Improvement" class="headerlink" title="9. Iterations and Continuous Improvement"></a>9. Iterations and Continuous Improvement</h2><ul><li>ML projects are never “one-and-done.”</li><li>As new data becomes available:<ul><li>Retrain</li><li>Deploy again</li><li>Monitor results</li></ul></li><li>Requirements may change over time.</li><li>Example: A clothing recommendation model must be retrained regularly as fashion trends evolve.</li></ul><p>👉 <strong>Exam Tip</strong>: AWS emphasizes <strong>continuous retraining and monitoring</strong> to keep ML models accurate and relevant.</p><hr><h2 id="Workflow-Summary"><a href="#Workflow-Summary" class="headerlink" title="Workflow Summary"></a>Workflow Summary</h2><ol><li>Define <strong>business goals</strong> &amp; KPIs</li><li>Frame as an <strong>ML problem</strong></li><li>Collect &amp; process data</li><li>Perform <strong>EDA</strong> and <strong>feature engineering</strong></li><li>Train, tune, and evaluate the model</li><li>Retrain when needed</li><li>Deploy (real-time, batch, serverless, on-prem)</li><li>Monitor performance &amp; drift</li><li>Iterate for continuous improvement</li></ol><p align="center">  <img src="/images/aws_basic_141.png" width="80%"></p><hr><p>✅ <strong>Key Takeaways for Exams</strong>: - The first step &#x3D; <strong>business goals + KPI definition</strong>.</p><ul><li>EDA and correlation matrices help identify key features.</li><li><strong>SageMaker</strong> supports training, tuning, deployment, and monitoring.</li><li>Know the differences between <strong>real-time vs batch vs serverless</strong> inference.</li><li>Monitoring and retraining are critical due to <strong>model drift</strong>.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Phases-of-a-Machine-Learning-Project&quot;&gt;&lt;a href=&quot;#Phases-of-a-Machine-Learning-Project&quot; class=&quot;headerlink&quot; title=&quot;Phases of a Machine </summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (28) - 머신러닝 추론</title>
    <link href="https://kish191919.github.io/2025/08/25/KO-AWS-Certified-AI-Practitioner-28/"/>
    <id>https://kish191919.github.io/2025/08/25/KO-AWS-Certified-AI-Practitioner-28/</id>
    <published>2025-08-25T17:11:46.000Z</published>
    <updated>2025-08-25T17:29:46.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="머신러닝-–-추론-Inferencing"><a href="#머신러닝-–-추론-Inferencing" class="headerlink" title="머신러닝 – 추론(Inferencing)"></a>머신러닝 – 추론(Inferencing)</h1><h2 id="1-추론이란"><a href="#1-추론이란" class="headerlink" title="1. 추론이란?"></a>1. 추론이란?</h2><ul><li><strong>추론(Inferencing)</strong>: 이미 학습된 모델이 새로운 데이터에 대해<br>예측을 내리는 과정\</li><li>**학습(Training)**은 모델이 패턴을 배우는 과정이고,<br>**추론(Inferencing)**은 학습된 지식을 활용하는 단계</li></ul><hr><h2 id="2-추론의-두-가지-방식"><a href="#2-추론의-두-가지-방식" class="headerlink" title="2. 추론의 두 가지 방식"></a>2. 추론의 두 가지 방식</h2><h3 id="1-실시간-추론-Real-Time-Inference"><a href="#1-실시간-추론-Real-Time-Inference" class="headerlink" title="(1) 실시간 추론 (Real-Time Inference)"></a>(1) 실시간 추론 (Real-Time Inference)</h3><ul><li>데이터가 들어오는 즉시 예측을 내려야 하는 경우</li><li><strong>특징</strong>:<ul><li>빠른 속도가 중요 (정확도보다는 속도 우선)</li><li>결과를 즉각적으로 제공해야 함</li></ul></li><li><strong>예시</strong>: 챗봇, 음성 비서(Alexa, Siri), 온라인 추천 시스템</li></ul><p>👉 AWS 자격증에서 자주 나오는 포인트:<br>실시간 추론은 <strong>지연(latency) 최소화</strong>가 핵심. 모델 정확도가 조금<br>낮더라도 <strong>즉각적인 응답</strong>이 필요한 경우 사용됨.</p><hr><h3 id="2-배치-추론-Batch-Inference"><a href="#2-배치-추론-Batch-Inference" class="headerlink" title="(2) 배치 추론 (Batch Inference)"></a>(2) 배치 추론 (Batch Inference)</h3><ul><li>대량의 데이터를 모아서 한 번에 처리하는 방식</li><li><strong>특징</strong>:<ul><li>속도보다는 정확성이 중요</li><li>분석용으로 주로 사용</li><li>결과를 받기까지 시간이 오래 걸려도 문제 없음 (분 → 시 → 일 단위 가능)</li></ul></li><li><strong>예시</strong>: 대규모 고객 데이터 분석, 리스크 평가 모델</li></ul><p>👉 시험에서 자주 묻는 포인트:</p><ul><li>실시간 vs 배치 추론의 차이점</li><li><strong>실시간 &#x3D; 속도 중시, 배치 &#x3D; 정확성 중시</strong></li></ul><p align="center">  <img src="/images/aws_basic_139.png" width="80%"></p><hr><h2 id="3-엣지-Edge-에서의-추론"><a href="#3-엣지-Edge-에서의-추론" class="headerlink" title="3. 엣지(Edge)에서의 추론"></a>3. 엣지(Edge)에서의 추론</h2><h3 id="1-엣지-디바이스란"><a href="#1-엣지-디바이스란" class="headerlink" title="(1) 엣지 디바이스란?"></a>(1) 엣지 디바이스란?</h3><ul><li>데이터가 생성되는 가까운 위치에 있는 장치들\</li><li>일반적으로 <strong>컴퓨팅 파워가 제한적</strong>이고, <strong>인터넷 연결이 불안정</strong>할<br>수 있음\</li><li>예시: IoT 센서, CCTV, 라즈베리 파이, 스마트폰</li></ul><hr><h3 id="2-소형-언어-모델-SLM-Small-Language-Model"><a href="#2-소형-언어-모델-SLM-Small-Language-Model" class="headerlink" title="(2) 소형 언어 모델 (SLM, Small Language Model)"></a>(2) 소형 언어 모델 (SLM, Small Language Model)</h3><ul><li><strong>엣지 디바이스에서 직접 실행 가능</strong>\</li><li><strong>특징</strong>:<ul><li><strong>지연 시간이 매우 낮음</strong> (인터넷 통신 불필요, 로컬 실행)\</li><li><strong>컴퓨팅 자원 소모 적음</strong>\</li><li><strong>오프라인 상태에서도 추론 가능</strong>\</li></ul></li><li><strong>예시</strong>: 스마트폰 번역 앱, 오프라인 이미지 인식</li></ul><hr><h3 id="3-대형-언어-모델-LLM-Large-Language-Model"><a href="#3-대형-언어-모델-LLM-Large-Language-Model" class="headerlink" title="(3) 대형 언어 모델 (LLM, Large Language Model)"></a>(3) 대형 언어 모델 (LLM, Large Language Model)</h3><ul><li><strong>원격 서버에서 실행</strong>\</li><li><strong>특징</strong>:<ul><li>더 강력한 모델 사용 가능\</li><li>다만, <strong>인터넷 연결 필요</strong>\</li><li><strong>지연 시간(네트워크 왕복)</strong> 발생\</li></ul></li><li><strong>예시</strong>: ChatGPT, Amazon Bedrock 같은 클라우드 기반 AI</li></ul><p>👉 시험 포인트:\</p><ul><li><strong>엣지에서의 추론</strong>은 <strong>SLM → 속도, 오프라인 가능</strong>\</li><li><strong>클라우드 LLM → 성능 우수하지만 지연과 인터넷 의존도 있음</strong>\</li><li>문제에서 “인터넷 연결 불안정, 오프라인 환경”이 나오면 <strong>SLM</strong> 정답!\</li><li>“고성능 모델, 복잡한 연산 필요”가 나오면 <strong>LLM</strong> 선택</li></ul><p align="center">  <img src="/images/aws_basic_140.png" width="80%"></p><hr><h2 id="4-시험-대비-정리-Trade-off-비교"><a href="#4-시험-대비-정리-Trade-off-비교" class="headerlink" title="4. 시험 대비 정리 (Trade-off 비교)"></a>4. 시험 대비 정리 (Trade-off 비교)</h2><hr><p>  구분     실시간 추론       배치 추론      SLM(엣지)       LLM(서버)</p><hr><p>  속도     매우 빠름         느려도 OK      매우 빠름       인터넷 지연<br>                                            (로컬)          발생</p><p>  정확도   다소 낮을 수 있음 최대한 높음    모델 크기       높음<br>                                            제한으로 낮음   </p><p>  환경     챗봇, 음성비서    데이터 분석,   오프라인 IoT,   클라우드 AI<br>                             리스크 모델    스마트폰        서비스</p><h2 id="인터넷-O-O-X-O-필요"><a href="#인터넷-O-O-X-O-필요" class="headerlink" title="  인터넷   O                 O              X               O  필요                                                      "></a>  인터넷   O                 O              X               O<br>  필요                                                      </h2><hr><h2 id="5-추가로-알아두면-좋은-시험-포인트"><a href="#5-추가로-알아두면-좋은-시험-포인트" class="headerlink" title="5. 추가로 알아두면 좋은 시험 포인트"></a>5. 추가로 알아두면 좋은 시험 포인트</h2><ul><li><strong>AWS 관련 서비스와 연결</strong>:<ul><li><strong>Amazon SageMaker</strong>: 실시간&#x2F;배치 추론 모두 지원</li><li><strong>Amazon Bedrock</strong>: 서버 기반 LLM 실행</li><li><strong>AWS IoT Greengrass</strong>: 엣지 디바이스에서 모델 실행 가능</li></ul></li><li><strong>시험 문제 예시</strong>:<ul><li>“한 공장에서 인터넷 연결이 자주 끊기는데, 장치에서 데이터를<br>분석해야 한다. 어떤 추론 방식을 선택할까?” → <strong>엣지 추론, SLM</strong>\</li><li>“수백만 건의 고객 로그를 기반으로 분석을 진행하고, 결과는 하루<br>뒤에 받아도 괜찮다.” → <strong>배치 추론</strong>\</li><li>“고객이 입력한 질문에 즉각 답변해야 한다.” → <strong>실시간 추론</strong>\</li><li>“더 정확한 결과가 필요하고, 인터넷 연결이 안정적이다.” → <strong>LLM<br>원격 서버</strong></li></ul></li></ul><hr><p>👉 요약:\</p><ul><li><strong>실시간 추론 &#x3D; 속도 우선, 챗봇</strong>\</li><li><strong>배치 추론 &#x3D; 정확도 우선, 대규모 분석</strong>\</li><li><strong>SLM(엣지) &#x3D; 빠름 + 오프라인 가능</strong>\</li><li><strong>LLM(서버) &#x3D; 강력하지만 인터넷 필요, 지연 존재</strong></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;머신러닝-–-추론-Inferencing&quot;&gt;&lt;a href=&quot;#머신러닝-–-추론-Inferencing&quot; class=&quot;headerlink&quot; title=&quot;머신러닝 – 추론(Inferencing)&quot;&gt;&lt;/a&gt;머신러닝 – 추론(Inferencing)</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(28) - Machine Learning Inferencing</title>
    <link href="https://kish191919.github.io/2025/08/25/AWS-Certified-AI-Practitioner-28/"/>
    <id>https://kish191919.github.io/2025/08/25/AWS-Certified-AI-Practitioner-28/</id>
    <published>2025-08-25T17:10:35.000Z</published>
    <updated>2025-08-25T17:29:46.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Machine-Learning-–-Inferencing"><a href="#Machine-Learning-–-Inferencing" class="headerlink" title="Machine Learning – Inferencing"></a>Machine Learning – Inferencing</h1><h2 id="1-What-is-Inferencing"><a href="#1-What-is-Inferencing" class="headerlink" title="1. What is Inferencing?"></a>1. What is Inferencing?</h2><ul><li><strong>Inferencing</strong> is when a trained model makes predictions on <strong>new unseen data</strong>.</li><li>Training &#x3D; teaching the model.</li><li>Inferencing &#x3D; applying what the model has learned to make<br>predictions.</li></ul><hr><h2 id="2-Two-Types-of-Inferencing"><a href="#2-Two-Types-of-Inferencing" class="headerlink" title="2. Two Types of Inferencing"></a>2. Two Types of Inferencing</h2><h3 id="1-Real-Time-Inference"><a href="#1-Real-Time-Inference" class="headerlink" title="(1) Real-Time Inference"></a>(1) Real-Time Inference</h3><ul><li>Predictions are made <strong>instantly</strong> as new data arrives.</li><li><strong>Key Points</strong>:<ul><li><strong>Speed is more important than perfect accuracy</strong>.</li><li>Users expect immediate responses.</li></ul></li><li><strong>Examples</strong>:<ul><li>Chatbots (customer service bots, Alexa, Siri)</li><li>Fraud detection while processing a payment</li></ul></li></ul><p>👉 <strong>Exam Tip</strong>: Real-time inference is required when <strong>low latency (fast response)</strong> is critical. Accuracy may be slightly lower, but immediate results are necessary.</p><hr><h3 id="2-Batch-Inference"><a href="#2-Batch-Inference" class="headerlink" title="(2) Batch Inference"></a>(2) Batch Inference</h3><ul><li>Predictions are made on <strong>large datasets all at once</strong>.</li><li><strong>Key Points</strong>:<ul><li>Processing can take <strong>minutes, hours, or days</strong>.</li><li><strong>Accuracy is more important than speed</strong>.</li><li>Often used for large-scale analysis.</li></ul></li><li><strong>Examples</strong>:<ul><li>Analyzing millions of customer transactions overnight</li><li>Generating product recommendations for all users at once</li></ul></li></ul><p>👉 <strong>Exam Tip</strong>: Batch inference is chosen when <strong>speed is not critical</strong>, but <strong>accuracy and completeness</strong> are more important.</p><p align="center">  <img src="/images/aws_basic_139.png" width="80%"></p><hr><h2 id="3-Inferencing-at-the-Edge"><a href="#3-Inferencing-at-the-Edge" class="headerlink" title="3. Inferencing at the Edge"></a>3. Inferencing at the Edge</h2><h3 id="1-What-is-the-Edge"><a href="#1-What-is-the-Edge" class="headerlink" title="(1) What is the Edge?"></a>(1) What is the Edge?</h3><ul><li><strong>Edge devices</strong> are close to where the data is generated.</li><li>Usually have <strong>limited computing power</strong> and may operate with<br><strong>unreliable internet</strong>.</li><li>Examples: IoT sensors, Raspberry Pi, mobile devices, smart cameras.</li></ul><hr><h3 id="2-Small-Language-Models-SLM-on-Edge-Devices"><a href="#2-Small-Language-Models-SLM-on-Edge-Devices" class="headerlink" title="(2) Small Language Models (SLM) on Edge Devices"></a>(2) Small Language Models (SLM) on Edge Devices</h3><ul><li><strong>Run locally on small devices</strong>.</li><li><strong>Key Points</strong>:<ul><li>Very low latency (no internet call required).</li><li>Low compute footprint (uses fewer resources).</li><li>Can work <strong>offline</strong>.</li></ul></li><li><strong>Example</strong>:<ul><li>A smartphone running an offline translation app.</li></ul></li></ul><hr><h3 id="3-Large-Language-Models-LLM-on-Remote-Servers"><a href="#3-Large-Language-Models-LLM-on-Remote-Servers" class="headerlink" title="(3) Large Language Models (LLM) on Remote Servers"></a>(3) Large Language Models (LLM) on Remote Servers</h3><ul><li><strong>Run on powerful cloud servers (not on the device itself)</strong>.</li><li><strong>Key Points</strong>:<ul><li>Can handle <strong>complex tasks</strong> and provide <strong>better accuracy</strong>.</li><li>Requires internet connection.</li><li>Has higher latency (waiting for API response).</li></ul></li><li><strong>Example</strong>:<ul><li>Amazon Bedrock hosting a large model, with the edge device sending API requests.</li></ul></li></ul><p>👉 <strong>Exam Tip</strong>:\</p><ul><li>Use <strong>SLM on edge</strong> if: - Low latency and offline capability are required.</li><li>The device has limited internet connectivity.</li><li>Use <strong>LLM on the cloud</strong> if: - You need higher accuracy and more powerful computation.</li><li>Internet connectivity is reliable.</li></ul><p align="center">  <img src="/images/aws_basic_140.png" width="80%"></p><hr><h2 id="4-Trade-Off-Comparison"><a href="#4-Trade-Off-Comparison" class="headerlink" title="4. Trade-Off Comparison"></a>4. Trade-Off Comparison</h2><hr><p>  Type           Real-Time Inference    Batch Inference   SLM (Edge)   LLM (Cloud)</p><hr><p>  <strong>Speed</strong>      Instant                Slow              Instant      Slower<br>                                        (minutes–days)   (local)      (network<br>                                                                       latency)</p><p>  <strong>Accuracy</strong>   May be lower           High accuracy     Limited by   High<br>                                                          model size   </p><p>  <strong>Use Case</strong>   Chatbots, fraud        Data analytics,   IoT, mobile  Cloud AI<br>                 detection              reporting         apps         services</p><h2 id="Internet-Yes-Yes-No-Yes-Needed"><a href="#Internet-Yes-Yes-No-Yes-Needed" class="headerlink" title="  Internet     Yes                    Yes               No           Yes  Needed                                                             "></a>  <strong>Internet     Yes                    Yes               No           Yes<br>  Needed</strong>                                                             </h2><hr><h2 id="5-AWS-Services-for-Inferencing"><a href="#5-AWS-Services-for-Inferencing" class="headerlink" title="5. AWS Services for Inferencing"></a>5. AWS Services for Inferencing</h2><ul><li><strong>Amazon SageMaker</strong>:<ul><li>Supports <strong>real-time endpoints</strong> and <strong>batch transform jobs</strong>.</li></ul></li><li><strong>Amazon Bedrock</strong>:<ul><li>Provides <strong>LLMs as a managed service</strong> for inference.</li></ul></li><li><strong>AWS IoT Greengrass</strong>:<ul><li>Runs <strong>models locally</strong> on IoT edge devices.</li></ul></li></ul><p>👉 <strong>Common Exam Questions</strong>: 1. <em>A factory with unreliable internet wants to analyze data on-site.</em> → <strong>Edge + SLM</strong><br>2. <em>You need to process millions of records overnight for an analytics report.</em> → <strong>Batch inference</strong><br>3. <em>A chatbot must respond instantly to user queries.</em> → <strong>Real-time inference</strong><br>4. <em>You want maximum accuracy and can rely on cloud connectivity.</em> → <strong>LLM on a remote server</strong></p><hr><p>✅ <strong>Summary</strong>:</p><ul><li><strong>Real-time inference</strong> &#x3D; speed matters (chatbots, fraud detection).</li><li><strong>Batch inference</strong> &#x3D; accuracy matters (large-scale analytics).</li><li><strong>SLM on edge</strong> &#x3D; fast, offline, resource-efficient.</li><li><strong>LLM in cloud</strong> &#x3D; powerful, but requires internet and higher latency.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Machine-Learning-–-Inferencing&quot;&gt;&lt;a href=&quot;#Machine-Learning-–-Inferencing&quot; class=&quot;headerlink&quot; title=&quot;Machine Learning – Inferencing&quot;&gt;</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(27) - Model Evaluation - Classification &amp; Regression</title>
    <link href="https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-27/"/>
    <id>https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-27/</id>
    <published>2025-08-24T00:55:13.000Z</published>
    <updated>2025-08-24T01:05:14.597Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📊-Model-Evaluation-–-Classification-Regression"><a href="#📊-Model-Evaluation-–-Classification-Regression" class="headerlink" title="📊 Model Evaluation – Classification &amp; Regression"></a>📊 Model Evaluation – Classification &amp; Regression</h1><p>When building ML models, it’s not enough to just train them—you also<br>need to evaluate how good they are. Different problems (classification<br>vs regression) use different metrics. Let’s break it down.</p><hr><h2 id="🔹-Binary-Classification-Example-–-Confusion-Matrix"><a href="#🔹-Binary-Classification-Example-–-Confusion-Matrix" class="headerlink" title="🔹 Binary Classification Example – Confusion Matrix"></a>🔹 Binary Classification Example – Confusion Matrix</h2><p>A <strong>confusion matrix</strong> compares actual labels (truth) with the model’s<br>predictions.</p><ul><li><strong>True Positive (TP):</strong> predicted positive, actually positive\</li><li><strong>False Positive (FP):</strong> predicted positive, actually negative\</li><li><strong>True Negative (TN):</strong> predicted negative, actually negative\</li><li><strong>False Negative (FN):</strong> predicted negative, actually positive</li></ul><p>👉 Goal: maximize TP and TN, minimize FP and FN.</p><p align="center">  <img src="/images/aws_basic_135.png" width="80%"></p><h3 id="Key-Metrics"><a href="#Key-Metrics" class="headerlink" title="Key Metrics"></a>Key Metrics</h3><ul><li><p><strong>Precision &#x3D; TP &#x2F; (TP + FP)</strong><br><em>“Of all predicted positives, how many were actually positive?”</em><br>Best when <strong>false positives are costly</strong> (e.g., diagnosing a healthy<br>person as sick).</p></li><li><p><strong>Recall &#x3D; TP &#x2F; (TP + FN)</strong><br><em>“Of all actual positives, how many did we correctly identify?”</em><br>Best when <strong>false negatives are costly</strong> (e.g., missing a cancer<br>diagnosis).</p></li><li><p><strong>F1 Score &#x3D; 2 × (Precision × Recall) &#x2F; (Precision + Recall)</strong><br>Harmonic mean of precision and recall.<br>Best for <strong>imbalanced datasets</strong> where accuracy alone is misleading.</p></li><li><p><strong>Accuracy &#x3D; (TP + TN) &#x2F; (All predictions)</strong><br>Useful only for <strong>balanced datasets</strong>.<br>Example: If 95% of emails are “not spam,” a model that always<br>predicts “not spam” has 95% accuracy but is useless.</p></li></ul><p align="center">  <img src="/images/aws_basic_136.png" width="80%"></p><hr><h2 id="🔹-AUC-ROC-Area-Under-the-Curve-–-Receiver-Operator-Curve"><a href="#🔹-AUC-ROC-Area-Under-the-Curve-–-Receiver-Operator-Curve" class="headerlink" title="🔹 AUC-ROC (Area Under the Curve – Receiver Operator Curve)"></a>🔹 AUC-ROC (Area Under the Curve – Receiver Operator Curve)</h2><ul><li>Plots <strong>True Positive Rate (Sensitivity&#x2F;Recall)</strong> vs <strong>False<br>Positive Rate (1 - Specificity)</strong> at various thresholds.\</li><li><strong>AUC value ranges from 0 to 1.</strong><ul><li><strong>1.0 &#x3D; perfect model</strong>\</li><li><strong>0.5 &#x3D; random guessing</strong></li></ul></li></ul><p>👉 Business use case: choose a threshold that balances precision and<br>recall for your needs (fraud detection, medical tests, etc.).<br>📌 <strong>Exam Tip:</strong> Remember AUC-ROC helps compare multiple models and find<br>the best threshold.</p><p align="center">  <img src="/images/aws_basic_137.png" width="80%"></p><hr><h2 id="🔹-Regression-Model-Metrics"><a href="#🔹-Regression-Model-Metrics" class="headerlink" title="🔹 Regression Model Metrics"></a>🔹 Regression Model Metrics</h2><p>For regression (continuous predictions, e.g., house prices, stock<br>values), we measure <strong>errors</strong>:</p><ul><li><p><strong>MAE (Mean Absolute Error):</strong> average absolute difference between<br>prediction and truth.<br>→ Easy to interpret: “On average, the model is off by X units.”</p></li><li><p><strong>MAPE (Mean Absolute Percentage Error):</strong> average error as a<br>percentage.<br>→ Useful when scale of values matters (e.g., sales forecasts).</p></li><li><p><strong>RMSE (Root Mean Squared Error):</strong> penalizes large errors more<br>heavily than MAE.<br>→ Common when big mistakes are unacceptable.</p></li><li><p><strong>R² (Coefficient of Determination):</strong> measures how much variance in<br>the target is explained by the model.</p><ul><li>R² &#x3D; 0.8 → 80% of variation is explained by features, 20% by<br>noise&#x2F;other factors.\</li><li>R² close to 1 &#x3D; strong model.</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_138.png" width="80%"></p><hr><h2 id="🔹-Example-Regression-Metrics-in-Action"><a href="#🔹-Example-Regression-Metrics-in-Action" class="headerlink" title="🔹 Example (Regression Metrics in Action)"></a>🔹 Example (Regression Metrics in Action)</h2><p>You predict student test scores based on study hours:</p><ul><li><strong>RMSE &#x3D; 5</strong> → model predictions are ~5 points off on average.\</li><li><strong>R² &#x3D; 0.8</strong> → 80% of score differences explained by study hours,<br>20% due to natural ability or luck.</li></ul><hr><h2 id="✅-Key-Takeaways-Exam-Perspective"><a href="#✅-Key-Takeaways-Exam-Perspective" class="headerlink" title="✅ Key Takeaways (Exam Perspective)"></a>✅ Key Takeaways (Exam Perspective)</h2><ul><li><strong>Classification models → Confusion Matrix, Precision, Recall, F1,<br>Accuracy, AUC-ROC</strong>\</li><li><strong>Regression models → MAE, MAPE, RMSE, R²</strong>\</li><li><strong>Choose metrics based on business need:</strong><ul><li>Precision for costly false positives\</li><li>Recall for costly false negatives\</li><li>F1 for imbalanced data\</li><li>Accuracy only for balanced datasets</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📊-Model-Evaluation-–-Classification-Regression&quot;&gt;&lt;a href=&quot;#📊-Model-Evaluation-–-Classification-Regression&quot; class=&quot;headerlink&quot; title</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (27) - 이진 분류와 혼동 행렬 (Confusion Matrix)</title>
    <link href="https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-27/"/>
    <id>https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-27/</id>
    <published>2025-08-24T00:55:08.000Z</published>
    <updated>2025-08-25T17:10:15.641Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📊-Model-Evaluation-in-Machine-Learning"><a href="#📊-Model-Evaluation-in-Machine-Learning" class="headerlink" title="📊 Model Evaluation in Machine Learning"></a>📊 Model Evaluation in Machine Learning</h1><p>머신러닝 모델을 만들었을 때, <strong>성능이 잘 나오는지</strong>를 확인하는 과정이 필요합니다.<br>이때 <strong>분류(Classification)</strong> 모델과 <strong>회귀(Regression)</strong> 모델의 평가 방식이 다르므로 구분해서 알아두어야 합니다.</p><hr><h2 id="🔹-이진-분류-Binary-Classification-와-혼동-행렬-Confusion-Matrix"><a href="#🔹-이진-분류-Binary-Classification-와-혼동-행렬-Confusion-Matrix" class="headerlink" title="🔹 이진 분류 (Binary Classification)와 혼동 행렬 (Confusion Matrix)"></a>🔹 이진 분류 (Binary Classification)와 혼동 행렬 (Confusion Matrix)</h2><h3 id="Confusion-Matrix란"><a href="#Confusion-Matrix란" class="headerlink" title="Confusion Matrix란?"></a>Confusion Matrix란?</h3><ul><li>실제 정답(라벨)과 모델 예측값을 비교해서 성능을 평가하는 도구  </li><li>네 가지 값으로 나뉩니다:</li></ul><table><thead><tr><th>구분</th><th>예측 Positive</th><th>예측 Negative</th></tr></thead><tbody><tr><td>실제 Positive</td><td><strong>True Positive (TP)</strong></td><td><strong>False Negative (FN)</strong></td></tr><tr><td>실제 Negative</td><td><strong>False Positive (FP)</strong></td><td><strong>True Negative (TN)</strong></td></tr></tbody></table><p>👉 목표: <strong>TP와 TN을 최대화</strong>하고, <strong>FP와 FN을 최소화</strong>하는 것.</p><p align="center">  <img src="/images/aws_basic_135.png" width="80%"></p><hr><h3 id="주요-평가-지표-Classification-Metrics"><a href="#주요-평가-지표-Classification-Metrics" class="headerlink" title="주요 평가 지표 (Classification Metrics)"></a>주요 평가 지표 (Classification Metrics)</h3><ul><li><p><strong>Precision (정밀도)</strong>  </p><ul><li>공식: TP &#x2F; (TP + FP)  </li><li>“Positive라고 예측한 것 중에서, 실제로 Positive인 비율”  </li><li>**False Positive(잘못된 양성 예측)**이 치명적인 경우 중요  </li><li>예: 스팸 필터에서 정상 메일을 스팸으로 잘못 분류하면 안 됨</li></ul></li><li><p><strong>Recall (재현율, 민감도)</strong>  </p><ul><li>공식: TP &#x2F; (TP + FN)  </li><li>“실제 Positive 중에서, 제대로 맞춘 비율”  </li><li>**False Negative(놓친 케이스)**가 치명적인 경우 중요  </li><li>예: 암 진단 모델에서 환자를 “정상”으로 잘못 분류하면 안 됨</li></ul></li><li><p><strong>F1 Score</strong>  </p><ul><li>공식: 2 × (Precision × Recall) &#x2F; (Precision + Recall)  </li><li>Precision과 Recall의 <strong>균형을 평가</strong>  </li><li>특히 **데이터가 불균형(imbalanced dataset)**할 때 유용</li></ul></li><li><p><strong>Accuracy (정확도)</strong>  </p><ul><li>공식: (TP + TN) &#x2F; 전체 데이터  </li><li>단순히 “얼마나 맞췄는가”  </li><li>데이터가 <strong>균형 잡힌 경우</strong>에만 의미 있음  </li><li>예: 95%가 Negative인 데이터에서 Accuracy 95% → 쓸모없는 지표</li></ul></li></ul><p>📌 <strong>시험 팁</strong>:  </p><ul><li><strong>Precision → FP가 비쌀 때</strong>  </li><li><strong>Recall → FN이 비쌀 때</strong>  </li><li><strong>F1 → 불균형 데이터셋에서 균형 평가</strong>  </li><li><strong>Accuracy → 데이터가 균형일 때만</strong></li></ul><p align="center">  <img src="/images/aws_basic_136.png" width="80%"></p><hr><h2 id="🔹-AUC-ROC-Area-Under-the-Curve-Receiver-Operating-Characteristic"><a href="#🔹-AUC-ROC-Area-Under-the-Curve-Receiver-Operating-Characteristic" class="headerlink" title="🔹 AUC-ROC (Area Under the Curve - Receiver Operating Characteristic)"></a>🔹 AUC-ROC (Area Under the Curve - Receiver Operating Characteristic)</h2><ul><li><strong>0 ~ 1 사이 값</strong>, 1에 가까울수록 완벽한 모델  </li><li>축:  <ul><li>X축 → False Positive Rate (1 - Specificity)  </li><li>Y축 → True Positive Rate (Sensitivity, Recall)</li></ul></li><li>여러 Threshold(임계값)를 기준으로 Confusion Matrix를 만들고 곡선을 그림  </li><li>AUC &#x3D; ROC Curve 아래 면적</li></ul><p>👉 <strong>시험 포인트</strong>:  </p><ul><li>AUC가 클수록 모델이 좋은 것  </li><li>다양한 임계값을 비교할 때 활용</li></ul><p align="center">  <img src="/images/aws_basic_137.png" width="80%"></p><hr><h2 id="🔹-회귀-모델-평가-지표-Regression-Metrics"><a href="#🔹-회귀-모델-평가-지표-Regression-Metrics" class="headerlink" title="🔹 회귀 모델 평가 지표 (Regression Metrics)"></a>🔹 회귀 모델 평가 지표 (Regression Metrics)</h2><p>회귀 모델은 <strong>연속적인 값</strong>을 예측하기 때문에 평가 방식이 다릅니다.</p><ul><li><p><strong>MAE (Mean Absolute Error)</strong>  </p><ul><li>예측값과 실제값 차이의 절댓값 평균  </li><li>직관적이고 해석하기 쉬움  </li><li>예: MAE &#x3D; 5 → 평균적으로 5점 차이 발생</li></ul></li><li><p><strong>MAPE (Mean Absolute Percentage Error)</strong>  </p><ul><li>퍼센트 기준 오차율  </li><li>값의 크기가 다양할 때 상대적 오류를 보려면 사용</li></ul></li><li><p><strong>RMSE (Root Mean Squared Error)</strong>  </p><ul><li>오차를 제곱 후 평균 내고 제곱근을 취함  </li><li>큰 오차에 더 민감 → 모델 안정성 평가에 유용</li></ul></li><li><p><strong>R² (R-Squared, 결정계수)</strong>  </p><ul><li>모델이 데이터를 얼마나 설명할 수 있는지를 나타냄  </li><li>값이 1에 가까울수록 좋은 모델  </li><li>예: R² &#x3D; 0.8 → 모델이 80%를 설명, 나머지 20%는 다른 요인</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_138.png" width="80%"></p><p>📌 <strong>시험 팁</strong>:  </p><ul><li>분류(Classification) → Precision, Recall, F1, Accuracy, AUC-ROC  </li><li>회귀(Regression) → MAE, MAPE, RMSE, R²</li></ul><hr><h1 id="✅-정리-시험-대비-핵심"><a href="#✅-정리-시험-대비-핵심" class="headerlink" title="✅ 정리 (시험 대비 핵심)"></a>✅ 정리 (시험 대비 핵심)</h1><ul><li><strong>Classification 평가 지표</strong>: Confusion Matrix, Precision, Recall, F1, Accuracy, AUC-ROC  </li><li><strong>Regression 평가 지표</strong>: MAE, MAPE, RMSE, R²  </li><li><strong>Precision ↔ Recall Trade-off</strong> 기억하기 (특히 시험에 자주 출제)</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📊-Model-Evaluation-in-Machine-Learning&quot;&gt;&lt;a href=&quot;#📊-Model-Evaluation-in-Machine-Learning&quot; class=&quot;headerlink&quot; title=&quot;📊 Model Evalu</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>(한국어) AWS Certified AI Practitioner (26) - 모델 적합도와 편향 &amp; 분산</title>
    <link href="https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-26/"/>
    <id>https://kish191919.github.io/2025/08/23/KO-AWS-Certified-AI-Practitioner-26/</id>
    <published>2025-08-24T00:39:04.000Z</published>
    <updated>2025-08-24T01:05:14.598Z</updated>
    
    <content type="html"><![CDATA[<h1 id="🤖-모델-적합도-Model-Fit-와-편향-Bias-·-분산-Variance"><a href="#🤖-모델-적합도-Model-Fit-와-편향-Bias-·-분산-Variance" class="headerlink" title="🤖 모델 적합도(Model Fit)와 편향(Bias) · 분산(Variance)"></a>🤖 모델 적합도(Model Fit)와 편향(Bias) · 분산(Variance)</h1><h2 id="1-모델-적합도-Model-Fit"><a href="#1-모델-적합도-Model-Fit" class="headerlink" title="1. 모델 적합도(Model Fit)"></a>1. 모델 적합도(Model Fit)</h2><p>머신러닝 모델이 제대로 동작하지 않을 때는 <strong>모델의 적합도(Fit)</strong> 를 살펴봐야 합니다.<br>모델이 데이터를 얼마나 잘 설명하는지가 핵심입니다.  </p><ul><li><p><strong>과적합(Overfitting)</strong>  </p><ul><li>훈련 데이터에서는 성능이 매우 좋음  </li><li>새로운 데이터(검증&#x2F;테스트 데이터)에서는 성능이 나쁨  </li><li>원인: 모델이 데이터의 <strong>노이즈까지 학습</strong>해서 일반화가 안 됨  </li><li>📌 예시: 훈련 데이터 점 하나하나에 맞게 선을 구부려 만든 복잡한 곡선</li></ul></li><li><p><strong>과소적합(Underfitting)</strong>  </p><ul><li>훈련 데이터에서도 성능이 나쁨  </li><li>원인: 모델이 너무 단순하거나, 특징(Feature)이 부족함  </li><li>📌 예시: 복잡한 곡선 데이터에 단순 직선을 억지로 적용</li></ul></li><li><p><strong>균형(Balanced)</strong>  </p><ul><li>과적합도, 과소적합도 아닌 상태  </li><li>어느 정도 오차는 있지만, 데이터의 전체적인 패턴을 잘 따름  </li><li>📌 가장 이상적인 상황</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_129.png" width="80%"></p><hr><h2 id="2-편향-Bias-과-분산-Variance"><a href="#2-편향-Bias-과-분산-Variance" class="headerlink" title="2. 편향(Bias)과 분산(Variance)"></a>2. 편향(Bias)과 분산(Variance)</h2><h3 id="📌-Bias-편향"><a href="#📌-Bias-편향" class="headerlink" title="📌 Bias (편향)"></a>📌 Bias (편향)</h3><ul><li><strong>정의</strong>: 실제 값과 예측 값의 차이  </li><li><strong>High Bias (편향 높음)</strong>  <ul><li>모델이 데이터 패턴을 잘 잡지 못함 → 과소적합  </li><li>예시: 곡선 패턴 데이터를 직선으로 예측</li></ul></li><li><strong>줄이는 방법</strong>  <ul><li>더 복잡한 모델 사용 (예: 선형 → 비선형 모델)  </li><li>더 많은 특징(Feature) 추가</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_130.png" width="80%"></p><hr><h3 id="📌-Variance-분산"><a href="#📌-Variance-분산" class="headerlink" title="📌 Variance (분산)"></a>📌 Variance (분산)</h3><ul><li><strong>정의</strong>: 훈련 데이터를 조금만 바꿔도 모델 성능이 크게 달라지는 정도  </li><li><strong>High Variance (분산 높음)</strong>  <ul><li>훈련 데이터에서는 성능이 매우 좋지만, 새로운 데이터에서는 성능이 급격히 떨어짐  </li><li>즉, 과적합 상황</li></ul></li><li><strong>줄이는 방법</strong>  <ul><li>불필요한 특징 제거 (Feature Selection)  </li><li>데이터셋을 여러 번 나눠서 교차검증(Cross Validation) 수행  </li><li>정규화(Regularization, 예: L1&#x2F;L2) 적용</li></ul></li></ul><p align="center">  <img src="/images/aws_basic_131.png" width="80%"></p><hr><h2 id="3-Bias-Variance-Tradeoff-편향-분산-트레이드오프"><a href="#3-Bias-Variance-Tradeoff-편향-분산-트레이드오프" class="headerlink" title="3. Bias-Variance Tradeoff (편향-분산 트레이드오프)"></a>3. Bias-Variance Tradeoff (편향-분산 트레이드오프)</h2><p>머신러닝에서는 <strong>Bias(편향)</strong> 과 <strong>Variance(분산)</strong> 사이에서 균형을 맞추는 것이 중요합니다.</p><ul><li><strong>High Bias + Low Variance → 과소적합</strong></li><li><strong>Low Bias + High Variance → 과적합</strong></li><li><strong>Low Bias + Low Variance → 이상적인 모델</strong></li><li><strong>High Bias + High Variance → 최악의 경우 (피해야 함)</strong></li></ul><p>📌 시험 포인트:  </p><ul><li>과적합 ↔ 분산 높음 (Variance High)  </li><li>과소적합 ↔ 편향 높음 (Bias High)  </li><li>균형 잡힌 모델이 가장 좋은 상태</li></ul><p align="center">  <img src="/images/aws_basic_132.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_133.png" width="80%"></p><hr><h2 id="4-시각적-이해-다트판-예시-🎯"><a href="#4-시각적-이해-다트판-예시-🎯" class="headerlink" title="4. 시각적 이해 (다트판 예시 🎯)"></a>4. 시각적 이해 (다트판 예시 🎯)</h2><ul><li><strong>편향(Bias)</strong>: 다트가 과녁의 중심에서 얼마나 떨어져 있는지  </li><li><strong>분산(Variance)</strong>: 다트가 흩어져 있는 정도</li></ul><table><thead><tr><th>구분</th><th>설명</th><th>결과</th></tr></thead><tbody><tr><td>High Bias + Low Variance</td><td>계속 같은 위치에 맞추지만 중심에서 멂</td><td>Underfitting</td></tr><tr><td>Low Bias + High Variance</td><td>중심 근처에 맞추지만 흩어져 있음</td><td>Overfitting</td></tr><tr><td>Low Bias + Low Variance</td><td>중심에 가깝고 모여 있음</td><td>Best Model</td></tr><tr><td>High Bias + High Variance</td><td>멀리 있고 흩어져 있음</td><td>Worst Model</td></tr></tbody></table><hr><h2 id="✅-시험-대비-Key-Takeaways"><a href="#✅-시험-대비-Key-Takeaways" class="headerlink" title="✅ 시험 대비 Key Takeaways"></a>✅ 시험 대비 Key Takeaways</h2><ol><li><strong>Overfitting</strong> → 훈련 데이터 잘 맞춤, 테스트 데이터 성능 나쁨 → Variance ↑  </li><li><strong>Underfitting</strong> → 훈련 데이터조차 성능 나쁨 → Bias ↑  </li><li><strong>Balanced Fit</strong> → Bias와 Variance 모두 낮아야 함  </li><li><strong>Bias-Variance Tradeoff</strong> 개념 숙지 필수  </li><li>AWS 자격증 시험에서는 <strong>과적합 &#x2F; 과소적합을 어떻게 해결할지</strong>를 물을 수 있음  <ul><li>과적합 해결: Regularization, Feature Selection, Cross Validation  </li><li>과소적합 해결: 더 복잡한 모델, Feature 추가</li></ul></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;🤖-모델-적합도-Model-Fit-와-편향-Bias-·-분산-Variance&quot;&gt;&lt;a href=&quot;#🤖-모델-적합도-Model-Fit-와-편향-Bias-·-분산-Variance&quot; class=&quot;headerlink&quot; title=&quot;🤖 모델 </summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER_KR" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER-KR/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
    <category term="KOREAN" scheme="https://kish191919.github.io/tags/KOREAN/"/>
    
  </entry>
  
  <entry>
    <title>AWS Certified AI Practitioner(26) - Model Fit, Bias, and Variance</title>
    <link href="https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-26/"/>
    <id>https://kish191919.github.io/2025/08/23/AWS-Certified-AI-Practitioner-26/</id>
    <published>2025-08-24T00:39:00.000Z</published>
    <updated>2025-08-24T01:02:42.203Z</updated>
    
    <content type="html"><![CDATA[<h1 id="📊-Model-Fit-Bias-and-Variance"><a href="#📊-Model-Fit-Bias-and-Variance" class="headerlink" title="📊 Model Fit, Bias, and Variance"></a>📊 Model Fit, Bias, and Variance</h1><p>When a machine learning model performs poorly, one of the first things<br>to check is whether it’s a <strong>good fit</strong> for the data. This is often<br>discussed in terms of <strong>overfitting</strong>, <strong>underfitting</strong>, and<br><strong>balance</strong>.</p><hr><h2 id="✅-Model-Fit"><a href="#✅-Model-Fit" class="headerlink" title="✅ Model Fit"></a>✅ Model Fit</h2><h3 id="🔹-Overfitting"><a href="#🔹-Overfitting" class="headerlink" title="🔹 Overfitting"></a>🔹 Overfitting</h3><ul><li>The model performs <strong>very well</strong> on training data.\</li><li>But performs <strong>poorly</strong> on evaluation or unseen test data.\</li><li>Example: A line that connects every single training point perfectly<br>— great for training, useless for new data.\</li><li>Common when the model is <strong>too complex</strong> and “memorizes” instead of<br>generalizing.</li></ul><h3 id="🔹-Underfitting"><a href="#🔹-Underfitting" class="headerlink" title="🔹 Underfitting"></a>🔹 Underfitting</h3><ul><li>The model performs poorly even on training data.\</li><li>Often happens when the model is <strong>too simple</strong> (e.g., a straight<br>line for data that is clearly non-linear).\</li><li>Can also be caused by <strong>poor features</strong>.</li></ul><h3 id="🔹-Balanced-Fit"><a href="#🔹-Balanced-Fit" class="headerlink" title="🔹 Balanced Fit"></a>🔹 Balanced Fit</h3><ul><li>Neither overfitting nor underfitting.\</li><li>The model generalizes well: some error is expected, but predictions<br>follow the data trend.\</li><li><strong>Goal: Low training error + low test error.</strong></li></ul><p>👉 <strong>AWS Exam Tip</strong>: You might get questions asking which situation<br>describes <em>overfitting vs. underfitting</em>. Remember:\</p><ul><li><strong>Overfitting → High variance problem.</strong>\</li><li><strong>Underfitting → High bias problem.</strong></li></ul><p align="center">  <img src="/images/aws_basic_129.png" width="80%"></p><hr><h2 id="⚖️-Bias-and-Variance"><a href="#⚖️-Bias-and-Variance" class="headerlink" title="⚖️ Bias and Variance"></a>⚖️ Bias and Variance</h2><p>Bias and variance help explain why models underfit or overfit.</p><h3 id="🔹-Bias"><a href="#🔹-Bias" class="headerlink" title="🔹 Bias"></a>🔹 Bias</h3><ul><li>Difference between <strong>predicted values</strong> and <strong>actual values</strong>.\</li><li>High Bias &#x3D; model is too simple → can’t capture the pattern.\</li><li>Example: Using linear regression on a clearly curved dataset.\</li><li>Considered <strong>underfitting</strong>.</li></ul><p><strong>How to reduce bias:</strong> - Use a <strong>more complex model</strong> (e.g., move from<br>linear regression to decision trees or neural networks).\</p><ul><li>Add more <strong>features</strong> (better input data).</li></ul><p align="center">  <img src="/images/aws_basic_130.png" width="80%"></p><hr><h3 id="🔹-Variance"><a href="#🔹-Variance" class="headerlink" title="🔹 Variance"></a>🔹 Variance</h3><ul><li>Describes how much the model’s predictions change if trained on<br>different (but similar) datasets.\</li><li>High Variance &#x3D; model is <strong>too sensitive</strong> to training data<br>changes.\</li><li>Typical in <strong>overfitting</strong> cases.</li></ul><p><strong>How to reduce variance:</strong> - Feature selection (keep fewer, more<br>important features).\</p><ul><li>Use <strong>cross-validation</strong> (split data into train&#x2F;test multiple times).\</li><li>Regularization techniques (e.g., L1&#x2F;L2 penalties).</li></ul><p align="center">  <img src="/images/aws_basic_131.png" width="80%"></p><hr><h2 id="🎯-Putting-It-All-Together"><a href="#🎯-Putting-It-All-Together" class="headerlink" title="🎯 Putting It All Together"></a>🎯 Putting It All Together</h2><ul><li><strong>High Bias, Low Variance</strong> → Underfitting (too simple).\</li><li><strong>Low Bias, High Variance</strong> → Overfitting (too complex).\</li><li><strong>High Bias, High Variance</strong> → Bad model (don’t use it).\</li><li><strong>Low Bias, Low Variance</strong> → Balanced (ideal).</li></ul><h3 id="🎯-Visual-Analogy-–-Dartboard-🎯"><a href="#🎯-Visual-Analogy-–-Dartboard-🎯" class="headerlink" title="🎯 Visual Analogy – Dartboard 🎯"></a>🎯 Visual Analogy – Dartboard 🎯</h3><ul><li><strong>High Bias</strong>: All darts clustered far from the bullseye<br>(consistently wrong).\</li><li><strong>High Variance</strong>: Darts scattered everywhere (inconsistent).\</li><li><strong>Balanced</strong>: Darts tightly grouped near the bullseye.</li></ul><p align="center">  <img src="/images/aws_basic_132.png" width="80%"></p><p align="center">  <img src="/images/aws_basic_133.png" width="80%"></p><hr><h2 id="🔑-Key-Takeaways-Exam-Focused"><a href="#🔑-Key-Takeaways-Exam-Focused" class="headerlink" title="🔑 Key Takeaways (Exam-Focused)"></a>🔑 Key Takeaways (Exam-Focused)</h2><ul><li><strong>Overfitting</strong> &#x3D; High variance problem → fix with simpler models or<br>regularization.\</li><li><strong>Underfitting</strong> &#x3D; High bias problem → fix with more complex models<br>or better features.\</li><li><strong>Balanced models</strong> generalize well.\</li><li>AWS exams often test your understanding of these tradeoffs when<br>evaluating ML models.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;📊-Model-Fit-Bias-and-Variance&quot;&gt;&lt;a href=&quot;#📊-Model-Fit-Bias-and-Variance&quot; class=&quot;headerlink&quot; title=&quot;📊 Model Fit, Bias, and Variance</summary>
      
    
    
    
    <category term="CERTIFICATION" scheme="https://kish191919.github.io/categories/CERTIFICATION/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/categories/CERTIFICATION/AWS-AI-PRACTITIONER/"/>
    
    
    <category term="AWS" scheme="https://kish191919.github.io/tags/AWS/"/>
    
    <category term="AWS_AI_PRACTITIONER" scheme="https://kish191919.github.io/tags/AWS-AI-PRACTITIONER/"/>
    
  </entry>
  
</feed>
